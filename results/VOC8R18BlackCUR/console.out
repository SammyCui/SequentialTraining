Loading openmpi/cuda/64/3.1.4
  Loading requirement: hpcx/2.4.0
Loading pytorch-py36-cuda10.1-gcc/1.5.0
  Loading requirement: python36 ml-pythondeps-py36-cuda10.1-gcc/3.3.0
    openblas/dynamic/0.2.20 cudnn7.6-cuda10.1/7.6.5.32 hdf5_18/1.8.20
    nccl2-cuda10.1-gcc/2.7.8
Run:  0
 # ------------------ Running pipeline on bts_startsame color run_0 -------------------- #
cuda:0
 ------ Pipeline with following parameters ------
training_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/train
val_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/val
test_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/test
dataset_name :  VOC
target_distances :  [0.2, 0.8, 0.4, 0.6, 1]
training_mode :  bts_startsame
n_distances :  None
training_size :  None
background :  color
size :  (150, 150)
cls_to_use :  ['aeroplane', 'bicycle', 'bird', 'boat', 'car', 'cat', 'train', 'tvmonitor']
batch_size :  128
val_size :  1
epochs :  400
resize_method :  long
n_folds :  5
num_workers :  16
model_name :  resnet18
device :  cuda:0
random_seed :  40
result_dirpath :  /u/erdos/students/xcui32/cnslab/results/VOC8R18BlackCUR
save_checkpoints :  False
save_progress_checkpoints :  False
verbose :  0
 ---  Loading datasets ---
 ---  Running  ---
Parameters: --------------------
{'scheduler_kwargs': {'mode': 'min', 'factor': 0.1, 'patience': 5}, 'optim_kwargs': {'lr': 0.001, 'momentum': 0.9}, 'max_norm': None, 'val_target': 'current', 'patience': 30, 'early_stopping': True, 'scheduler_object': None, 'optimizer_object': <class 'torch.optim.sgd.SGD'>, 'criterion_object': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'self': <pipelineCV2.RunModel object at 0x2aac7872cdd8>}
--------------------
Fold: 0
----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.9585, Validation Loss Current: 9.9060, Validation Loss AVG: 9.9784, lr: 0.001
Epoch [2/400], Training Loss: 38.7245, Validation Loss Current: 9.5136, Validation Loss AVG: 9.8466, lr: 0.001
Epoch [3/400], Training Loss: 37.4710, Validation Loss Current: 9.1771, Validation Loss AVG: 9.6571, lr: 0.001
Epoch [4/400], Training Loss: 34.8756, Validation Loss Current: 8.8489, Validation Loss AVG: 9.4665, lr: 0.001
Epoch [5/400], Training Loss: 34.5208, Validation Loss Current: 8.5330, Validation Loss AVG: 9.4626, lr: 0.001
Epoch [6/400], Training Loss: 33.3727, Validation Loss Current: 8.3746, Validation Loss AVG: 9.1586, lr: 0.001
Epoch [7/400], Training Loss: 31.4942, Validation Loss Current: 8.0381, Validation Loss AVG: 9.1183, lr: 0.001
Epoch [8/400], Training Loss: 30.3935, Validation Loss Current: 7.4663, Validation Loss AVG: 9.0691, lr: 0.001
Epoch [9/400], Training Loss: 28.6377, Validation Loss Current: 7.5755, Validation Loss AVG: 9.0019, lr: 0.001
Epoch [10/400], Training Loss: 28.6297, Validation Loss Current: 7.2557, Validation Loss AVG: 8.8498, lr: 0.001
Epoch [11/400], Training Loss: 28.3524, Validation Loss Current: 7.8109, Validation Loss AVG: 10.8914, lr: 0.001
Epoch [12/400], Training Loss: 26.9065, Validation Loss Current: 7.2307, Validation Loss AVG: 8.7713, lr: 0.001
Epoch [13/400], Training Loss: 27.1177, Validation Loss Current: 7.4818, Validation Loss AVG: 10.7972, lr: 0.001
Epoch [14/400], Training Loss: 26.3159, Validation Loss Current: 7.4874, Validation Loss AVG: 10.5577, lr: 0.001
Epoch [15/400], Training Loss: 26.0495, Validation Loss Current: 6.5889, Validation Loss AVG: 8.5311, lr: 0.001
Epoch [16/400], Training Loss: 25.3265, Validation Loss Current: 6.8223, Validation Loss AVG: 8.6844, lr: 0.001
Epoch [17/400], Training Loss: 23.8201, Validation Loss Current: 6.2949, Validation Loss AVG: 8.6577, lr: 0.001
Epoch [18/400], Training Loss: 22.2303, Validation Loss Current: 6.3224, Validation Loss AVG: 9.6178, lr: 0.001
Epoch [19/400], Training Loss: 22.5855, Validation Loss Current: 7.3209, Validation Loss AVG: 11.8287, lr: 0.001
Epoch [20/400], Training Loss: 22.1469, Validation Loss Current: 6.2724, Validation Loss AVG: 8.2421, lr: 0.001
Epoch [21/400], Training Loss: 20.2939, Validation Loss Current: 5.9220, Validation Loss AVG: 9.5242, lr: 0.001
Epoch [22/400], Training Loss: 19.9123, Validation Loss Current: 5.8787, Validation Loss AVG: 9.7254, lr: 0.001
Epoch [23/400], Training Loss: 18.8508, Validation Loss Current: 5.9609, Validation Loss AVG: 9.0791, lr: 0.001
Epoch [24/400], Training Loss: 18.0802, Validation Loss Current: 5.9974, Validation Loss AVG: 9.8932, lr: 0.001
Epoch [25/400], Training Loss: 17.4954, Validation Loss Current: 5.6320, Validation Loss AVG: 8.2446, lr: 0.001
Epoch [26/400], Training Loss: 17.3439, Validation Loss Current: 6.0910, Validation Loss AVG: 9.4212, lr: 0.001
Epoch [27/400], Training Loss: 17.5366, Validation Loss Current: 6.3736, Validation Loss AVG: 10.5841, lr: 0.001
Epoch [28/400], Training Loss: 16.7596, Validation Loss Current: 6.6151, Validation Loss AVG: 14.4770, lr: 0.001
Epoch [29/400], Training Loss: 15.8377, Validation Loss Current: 7.0868, Validation Loss AVG: 10.2211, lr: 0.001
Epoch [30/400], Training Loss: 15.5212, Validation Loss Current: 6.6777, Validation Loss AVG: 12.2014, lr: 0.001
Epoch [31/400], Training Loss: 14.3903, Validation Loss Current: 6.0595, Validation Loss AVG: 8.1710, lr: 0.001
Epoch [32/400], Training Loss: 13.2874, Validation Loss Current: 6.0499, Validation Loss AVG: 10.2208, lr: 0.001
Epoch [33/400], Training Loss: 12.6873, Validation Loss Current: 5.9450, Validation Loss AVG: 8.8855, lr: 0.001
Epoch [34/400], Training Loss: 11.9489, Validation Loss Current: 6.7141, Validation Loss AVG: 12.8095, lr: 0.001
Epoch [35/400], Training Loss: 13.9676, Validation Loss Current: 5.9886, Validation Loss AVG: 10.9992, lr: 0.001
Epoch [36/400], Training Loss: 11.6387, Validation Loss Current: 6.6341, Validation Loss AVG: 9.1430, lr: 0.001
Epoch [37/400], Training Loss: 12.0852, Validation Loss Current: 6.7838, Validation Loss AVG: 11.5719, lr: 0.001
Epoch [38/400], Training Loss: 11.6133, Validation Loss Current: 6.1236, Validation Loss AVG: 8.6443, lr: 0.001
Epoch [39/400], Training Loss: 10.9552, Validation Loss Current: 5.8195, Validation Loss AVG: 10.6961, lr: 0.001
Epoch [40/400], Training Loss: 9.6471, Validation Loss Current: 5.6505, Validation Loss AVG: 8.9866, lr: 0.001
Epoch [41/400], Training Loss: 8.2318, Validation Loss Current: 5.7611, Validation Loss AVG: 8.6463, lr: 0.001
Epoch [42/400], Training Loss: 8.9240, Validation Loss Current: 5.6060, Validation Loss AVG: 11.6199, lr: 0.001
Epoch [43/400], Training Loss: 9.7007, Validation Loss Current: 6.5729, Validation Loss AVG: 12.1214, lr: 0.001
Epoch [44/400], Training Loss: 10.2949, Validation Loss Current: 6.0035, Validation Loss AVG: 12.3924, lr: 0.001
Epoch [45/400], Training Loss: 8.1153, Validation Loss Current: 6.0520, Validation Loss AVG: 14.0751, lr: 0.001
Epoch [46/400], Training Loss: 9.1975, Validation Loss Current: 5.6931, Validation Loss AVG: 8.8696, lr: 0.001
Epoch [47/400], Training Loss: 6.6178, Validation Loss Current: 5.4560, Validation Loss AVG: 10.2298, lr: 0.001
Epoch [48/400], Training Loss: 6.7478, Validation Loss Current: 6.4992, Validation Loss AVG: 10.1355, lr: 0.001
Epoch [49/400], Training Loss: 9.0595, Validation Loss Current: 9.4473, Validation Loss AVG: 17.5293, lr: 0.001
Epoch [50/400], Training Loss: 10.7876, Validation Loss Current: 7.1496, Validation Loss AVG: 11.4590, lr: 0.001
Epoch [51/400], Training Loss: 9.2745, Validation Loss Current: 6.8480, Validation Loss AVG: 11.7291, lr: 0.001
Epoch [52/400], Training Loss: 8.9766, Validation Loss Current: 6.8116, Validation Loss AVG: 13.3639, lr: 0.001
Epoch [53/400], Training Loss: 5.2200, Validation Loss Current: 7.1560, Validation Loss AVG: 10.3641, lr: 0.001
Epoch [54/400], Training Loss: 5.1255, Validation Loss Current: 6.9401, Validation Loss AVG: 11.8940, lr: 0.001
Epoch [55/400], Training Loss: 3.2461, Validation Loss Current: 5.9392, Validation Loss AVG: 12.5279, lr: 0.001
Epoch [56/400], Training Loss: 3.8128, Validation Loss Current: 6.9577, Validation Loss AVG: 11.8604, lr: 0.001
Epoch [57/400], Training Loss: 5.4880, Validation Loss Current: 7.1097, Validation Loss AVG: 11.8681, lr: 0.001
Epoch [58/400], Training Loss: 3.8007, Validation Loss Current: 6.6907, Validation Loss AVG: 10.7344, lr: 0.001
Epoch [59/400], Training Loss: 3.5742, Validation Loss Current: 6.2001, Validation Loss AVG: 11.5144, lr: 0.001
Epoch [60/400], Training Loss: 3.5756, Validation Loss Current: 7.2047, Validation Loss AVG: 11.3807, lr: 0.001
Epoch [61/400], Training Loss: 2.4415, Validation Loss Current: 6.4076, Validation Loss AVG: 10.8237, lr: 0.001
Epoch [62/400], Training Loss: 2.1937, Validation Loss Current: 7.1468, Validation Loss AVG: 11.9657, lr: 0.001
Epoch [63/400], Training Loss: 3.3026, Validation Loss Current: 8.8947, Validation Loss AVG: 12.3297, lr: 0.001
Epoch [64/400], Training Loss: 6.7057, Validation Loss Current: 8.4281, Validation Loss AVG: 16.5822, lr: 0.001
Epoch [65/400], Training Loss: 3.8004, Validation Loss Current: 6.8785, Validation Loss AVG: 14.4502, lr: 0.001
Epoch [66/400], Training Loss: 6.1556, Validation Loss Current: 6.5347, Validation Loss AVG: 10.9164, lr: 0.001
Epoch [67/400], Training Loss: 3.9079, Validation Loss Current: 7.0878, Validation Loss AVG: 11.9304, lr: 0.001
Epoch [68/400], Training Loss: 4.1210, Validation Loss Current: 7.3312, Validation Loss AVG: 12.8967, lr: 0.001
Epoch [69/400], Training Loss: 5.0083, Validation Loss Current: 7.1299, Validation Loss AVG: 12.8744, lr: 0.001
Epoch [70/400], Training Loss: 3.9243, Validation Loss Current: 7.1684, Validation Loss AVG: 12.3138, lr: 0.001
Epoch [71/400], Training Loss: 6.6479, Validation Loss Current: 6.9832, Validation Loss AVG: 13.3478, lr: 0.001
Epoch [72/400], Training Loss: 4.9019, Validation Loss Current: 7.8185, Validation Loss AVG: 12.0670, lr: 0.001
Epoch [73/400], Training Loss: 6.9354, Validation Loss Current: 8.1436, Validation Loss AVG: 18.3393, lr: 0.001
Epoch [74/400], Training Loss: 10.3306, Validation Loss Current: 10.0279, Validation Loss AVG: 17.3737, lr: 0.001
Epoch [75/400], Training Loss: 5.6074, Validation Loss Current: 8.7715, Validation Loss AVG: 14.1167, lr: 0.001
Epoch [76/400], Training Loss: 6.1128, Validation Loss Current: 9.2671, Validation Loss AVG: 14.6510, lr: 0.001
Epoch [77/400], Training Loss: 4.2005, Validation Loss Current: 6.8823, Validation Loss AVG: 11.6662, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 47 Best val accuracy: [0.23190789473684212, 0.2993421052631579, 0.3371710526315789, 0.36348684210526316, 0.40131578947368424, 0.38651315789473684, 0.40789473684210525, 0.4819078947368421, 0.43256578947368424, 0.49835526315789475, 0.42105263157894735, 0.4654605263157895, 0.47039473684210525, 0.48848684210526316, 0.5592105263157895, 0.5197368421052632, 0.5592105263157895, 0.5707236842105263, 0.5279605263157895, 0.5296052631578947, 0.6019736842105263, 0.5855263157894737, 0.5707236842105263, 0.5970394736842105, 0.5953947368421053, 0.5986842105263158, 0.5641447368421053, 0.537828947368421, 0.5608552631578947, 0.537828947368421, 0.5838815789473685, 0.5641447368421053, 0.5921052631578947, 0.5608552631578947, 0.5986842105263158, 0.5756578947368421, 0.5493421052631579, 0.6052631578947368, 0.5953947368421053, 0.6365131578947368, 0.6069078947368421, 0.6266447368421053, 0.5805921052631579, 0.6101973684210527, 0.6134868421052632, 0.6447368421052632, 0.6414473684210527, 0.5707236842105263, 0.4901315789473684, 0.5592105263157895, 0.5986842105263158, 0.5592105263157895, 0.600328947368421, 0.5608552631578947, 0.6266447368421053, 0.5921052631578947, 0.5855263157894737, 0.6167763157894737, 0.6217105263157895, 0.5740131578947368, 0.6134868421052632, 0.6085526315789473, 0.5411184210526315, 0.53125, 0.6069078947368421, 0.6398026315789473, 0.5921052631578947, 0.569078947368421, 0.5822368421052632, 0.6069078947368421, 0.6069078947368421, 0.5805921052631579, 0.5509868421052632, 0.5361842105263158, 0.5592105263157895, 0.5296052631578947, 0.6151315789473685] Best val loss: 5.4559714794158936


----- Training resnet18 with sequence: [1, 0.8] -----
Current group: 1
Epoch [1/200], Training Loss: 41.0399, Validation Loss Current: 9.9938, Validation Loss AVG: 10.0857, lr: 0.001
Epoch [2/200], Training Loss: 38.8261, Validation Loss Current: 9.5281, Validation Loss AVG: 9.9085, lr: 0.001
Epoch [3/200], Training Loss: 36.4537, Validation Loss Current: 9.0133, Validation Loss AVG: 9.5247, lr: 0.001
Epoch [4/200], Training Loss: 35.2965, Validation Loss Current: 8.8370, Validation Loss AVG: 9.4684, lr: 0.001
Epoch [5/200], Training Loss: 33.9480, Validation Loss Current: 8.3272, Validation Loss AVG: 9.2130, lr: 0.001
Epoch [6/200], Training Loss: 31.8520, Validation Loss Current: 8.0757, Validation Loss AVG: 8.9827, lr: 0.001
Epoch [7/200], Training Loss: 31.0060, Validation Loss Current: 7.7851, Validation Loss AVG: 8.9972, lr: 0.001
Epoch [8/200], Training Loss: 29.7109, Validation Loss Current: 7.4078, Validation Loss AVG: 8.6735, lr: 0.001
Epoch [9/200], Training Loss: 28.6354, Validation Loss Current: 7.3024, Validation Loss AVG: 8.7914, lr: 0.001
Epoch [10/200], Training Loss: 27.6905, Validation Loss Current: 6.9798, Validation Loss AVG: 8.7302, lr: 0.001
Epoch [11/200], Training Loss: 27.3910, Validation Loss Current: 6.8560, Validation Loss AVG: 8.9987, lr: 0.001
Epoch [12/200], Training Loss: 26.1544, Validation Loss Current: 7.0222, Validation Loss AVG: 9.0926, lr: 0.001
Epoch [13/200], Training Loss: 25.4505, Validation Loss Current: 6.9677, Validation Loss AVG: 9.6035, lr: 0.001
Epoch [14/200], Training Loss: 25.4291, Validation Loss Current: 7.0694, Validation Loss AVG: 14.3502, lr: 0.001
Epoch [15/200], Training Loss: 23.9099, Validation Loss Current: 6.6352, Validation Loss AVG: 8.7658, lr: 0.001
Epoch [16/200], Training Loss: 22.6051, Validation Loss Current: 6.5815, Validation Loss AVG: 9.1088, lr: 0.001
Epoch [17/200], Training Loss: 23.7727, Validation Loss Current: 6.8210, Validation Loss AVG: 8.3856, lr: 0.001
Epoch [18/200], Training Loss: 23.7090, Validation Loss Current: 6.5238, Validation Loss AVG: 9.1172, lr: 0.001
Epoch [19/200], Training Loss: 23.2512, Validation Loss Current: 6.4368, Validation Loss AVG: 8.9436, lr: 0.001
Epoch [20/200], Training Loss: 22.6604, Validation Loss Current: 6.5805, Validation Loss AVG: 9.9505, lr: 0.001
Epoch [21/200], Training Loss: 21.7377, Validation Loss Current: 6.9667, Validation Loss AVG: 10.6096, lr: 0.001
Epoch [22/200], Training Loss: 20.8338, Validation Loss Current: 6.5917, Validation Loss AVG: 10.6943, lr: 0.001
Epoch [23/200], Training Loss: 21.1212, Validation Loss Current: 6.6330, Validation Loss AVG: 9.0598, lr: 0.001
Epoch [24/200], Training Loss: 19.0461, Validation Loss Current: 6.4437, Validation Loss AVG: 8.1424, lr: 0.001
Epoch [25/200], Training Loss: 18.9925, Validation Loss Current: 5.7742, Validation Loss AVG: 9.7027, lr: 0.001
Epoch [26/200], Training Loss: 17.4307, Validation Loss Current: 5.8347, Validation Loss AVG: 8.5395, lr: 0.001
Epoch [27/200], Training Loss: 16.9146, Validation Loss Current: 6.1194, Validation Loss AVG: 10.9152, lr: 0.001
Epoch [28/200], Training Loss: 15.9535, Validation Loss Current: 6.0400, Validation Loss AVG: 9.5351, lr: 0.001
Epoch [29/200], Training Loss: 17.4837, Validation Loss Current: 6.0752, Validation Loss AVG: 8.0304, lr: 0.001
Epoch [30/200], Training Loss: 16.2183, Validation Loss Current: 6.2232, Validation Loss AVG: 9.2816, lr: 0.001
Epoch [31/200], Training Loss: 14.2222, Validation Loss Current: 6.0303, Validation Loss AVG: 8.1857, lr: 0.001
Epoch [32/200], Training Loss: 14.2736, Validation Loss Current: 6.1876, Validation Loss AVG: 10.1857, lr: 0.001
Epoch [33/200], Training Loss: 12.8553, Validation Loss Current: 6.3637, Validation Loss AVG: 9.3945, lr: 0.001
Epoch [34/200], Training Loss: 12.6818, Validation Loss Current: 6.1501, Validation Loss AVG: 10.2296, lr: 0.001
Epoch [35/200], Training Loss: 12.9969, Validation Loss Current: 6.4899, Validation Loss AVG: 9.4168, lr: 0.001
Epoch [36/200], Training Loss: 11.4276, Validation Loss Current: 6.4947, Validation Loss AVG: 12.7377, lr: 0.001
Epoch [37/200], Training Loss: 9.2110, Validation Loss Current: 5.7680, Validation Loss AVG: 10.2764, lr: 0.001
Epoch [38/200], Training Loss: 10.5514, Validation Loss Current: 6.4517, Validation Loss AVG: 9.4606, lr: 0.001
Epoch [39/200], Training Loss: 10.1129, Validation Loss Current: 7.4298, Validation Loss AVG: 11.8447, lr: 0.001
Epoch [40/200], Training Loss: 10.6276, Validation Loss Current: 6.2395, Validation Loss AVG: 8.5316, lr: 0.001
Epoch [41/200], Training Loss: 7.9669, Validation Loss Current: 5.9351, Validation Loss AVG: 10.5567, lr: 0.001
Epoch [42/200], Training Loss: 7.0835, Validation Loss Current: 6.7359, Validation Loss AVG: 8.7950, lr: 0.001
Epoch [43/200], Training Loss: 6.9602, Validation Loss Current: 6.2432, Validation Loss AVG: 10.5576, lr: 0.001
Epoch [44/200], Training Loss: 6.6973, Validation Loss Current: 6.0480, Validation Loss AVG: 9.4406, lr: 0.001
Epoch [45/200], Training Loss: 6.4027, Validation Loss Current: 6.4618, Validation Loss AVG: 12.0815, lr: 0.001
Epoch [46/200], Training Loss: 5.1758, Validation Loss Current: 6.4328, Validation Loss AVG: 10.8882, lr: 0.001
Epoch [47/200], Training Loss: 7.5165, Validation Loss Current: 6.5043, Validation Loss AVG: 8.9607, lr: 0.001
Epoch [48/200], Training Loss: 6.0472, Validation Loss Current: 6.8608, Validation Loss AVG: 9.7490, lr: 0.001
Epoch [49/200], Training Loss: 6.6519, Validation Loss Current: 6.7966, Validation Loss AVG: 10.1674, lr: 0.001
Epoch [50/200], Training Loss: 6.3070, Validation Loss Current: 6.7466, Validation Loss AVG: 10.9944, lr: 0.001
Epoch [51/200], Training Loss: 6.2714, Validation Loss Current: 6.6018, Validation Loss AVG: 10.0190, lr: 0.001
Epoch [52/200], Training Loss: 4.4570, Validation Loss Current: 6.4190, Validation Loss AVG: 11.2671, lr: 0.001
Epoch [53/200], Training Loss: 7.6741, Validation Loss Current: 11.2863, Validation Loss AVG: 18.9973, lr: 0.001
Epoch [54/200], Training Loss: 7.8397, Validation Loss Current: 7.4203, Validation Loss AVG: 14.4794, lr: 0.001
Epoch [55/200], Training Loss: 6.1142, Validation Loss Current: 6.6567, Validation Loss AVG: 14.0028, lr: 0.001
Epoch [56/200], Training Loss: 4.6147, Validation Loss Current: 6.6122, Validation Loss AVG: 10.1759, lr: 0.001
Epoch [57/200], Training Loss: 4.8643, Validation Loss Current: 7.7109, Validation Loss AVG: 11.2920, lr: 0.001
Epoch [58/200], Training Loss: 4.6018, Validation Loss Current: 6.8853, Validation Loss AVG: 10.0745, lr: 0.001
Epoch [59/200], Training Loss: 3.9797, Validation Loss Current: 7.1619, Validation Loss AVG: 11.4059, lr: 0.001
Epoch [60/200], Training Loss: 3.0953, Validation Loss Current: 7.0033, Validation Loss AVG: 13.3610, lr: 0.001
Epoch [61/200], Training Loss: 3.3183, Validation Loss Current: 8.6956, Validation Loss AVG: 11.1611, lr: 0.001
Epoch [62/200], Training Loss: 3.5602, Validation Loss Current: 7.2428, Validation Loss AVG: 10.8497, lr: 0.001
Epoch [63/200], Training Loss: 4.1698, Validation Loss Current: 7.5897, Validation Loss AVG: 11.6848, lr: 0.001
Epoch [64/200], Training Loss: 3.7291, Validation Loss Current: 6.9883, Validation Loss AVG: 10.7971, lr: 0.001
Epoch [65/200], Training Loss: 2.9356, Validation Loss Current: 7.3113, Validation Loss AVG: 11.3394, lr: 0.001
Epoch [66/200], Training Loss: 2.8326, Validation Loss Current: 7.6981, Validation Loss AVG: 12.7625, lr: 0.001
Epoch [67/200], Training Loss: 2.5085, Validation Loss Current: 7.6378, Validation Loss AVG: 11.4914, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 37 Best val accuracy: [0.23355263157894737, 0.3223684210526316, 0.36019736842105265, 0.3470394736842105, 0.3996710526315789, 0.40625, 0.4440789473684211, 0.48355263157894735, 0.5230263157894737, 0.5263157894736842, 0.5197368421052632, 0.5, 0.5197368421052632, 0.506578947368421, 0.524671052631579, 0.5526315789473685, 0.49835526315789475, 0.5296052631578947, 0.5509868421052632, 0.5444078947368421, 0.5032894736842105, 0.5476973684210527, 0.5197368421052632, 0.53125, 0.600328947368421, 0.6019736842105263, 0.587171052631579, 0.5888157894736842, 0.5657894736842105, 0.5674342105263158, 0.59375, 0.5838815789473685, 0.5625, 0.5756578947368421, 0.5476973684210527, 0.5740131578947368, 0.5970394736842105, 0.5460526315789473, 0.5493421052631579, 0.587171052631579, 0.6052631578947368, 0.5707236842105263, 0.6019736842105263, 0.6019736842105263, 0.5608552631578947, 0.600328947368421, 0.600328947368421, 0.569078947368421, 0.5641447368421053, 0.59375, 0.5970394736842105, 0.5921052631578947, 0.4901315789473684, 0.5361842105263158, 0.5723684210526315, 0.6134868421052632, 0.5427631578947368, 0.5723684210526315, 0.5970394736842105, 0.5904605263157895, 0.5296052631578947, 0.587171052631579, 0.5888157894736842, 0.625, 0.5921052631578947, 0.587171052631579, 0.6085526315789473] Best val loss: 5.768019676208496


Current group: 0.8
Epoch [1/200], Training Loss: 23.8920, Validation Loss Current: 12.3832, Validation Loss AVG: 12.3832, lr: 0.001
Epoch [2/200], Training Loss: 15.8708, Validation Loss Current: 10.0529, Validation Loss AVG: 10.0529, lr: 0.001
Epoch [3/200], Training Loss: 12.1644, Validation Loss Current: 9.5881, Validation Loss AVG: 9.5881, lr: 0.001
Epoch [4/200], Training Loss: 11.9212, Validation Loss Current: 10.3999, Validation Loss AVG: 10.3999, lr: 0.001
Epoch [5/200], Training Loss: 9.7680, Validation Loss Current: 9.9729, Validation Loss AVG: 9.9729, lr: 0.001
Epoch [6/200], Training Loss: 9.4692, Validation Loss Current: 10.2127, Validation Loss AVG: 10.2127, lr: 0.001
Epoch [7/200], Training Loss: 8.9528, Validation Loss Current: 9.7440, Validation Loss AVG: 9.7440, lr: 0.001
Epoch [8/200], Training Loss: 10.4019, Validation Loss Current: 10.0098, Validation Loss AVG: 10.0098, lr: 0.001
Epoch [9/200], Training Loss: 8.1118, Validation Loss Current: 9.3522, Validation Loss AVG: 9.3522, lr: 0.001
Epoch [10/200], Training Loss: 5.8738, Validation Loss Current: 11.2991, Validation Loss AVG: 11.2991, lr: 0.001
Epoch [11/200], Training Loss: 5.7237, Validation Loss Current: 8.8803, Validation Loss AVG: 8.8803, lr: 0.001
Epoch [12/200], Training Loss: 5.9919, Validation Loss Current: 9.0665, Validation Loss AVG: 9.0665, lr: 0.001
Epoch [13/200], Training Loss: 4.4610, Validation Loss Current: 9.7054, Validation Loss AVG: 9.7054, lr: 0.001
Epoch [14/200], Training Loss: 5.5290, Validation Loss Current: 11.9000, Validation Loss AVG: 11.9000, lr: 0.001
Epoch [15/200], Training Loss: 9.1684, Validation Loss Current: 12.6124, Validation Loss AVG: 12.6124, lr: 0.001
Epoch [16/200], Training Loss: 11.7794, Validation Loss Current: 10.7890, Validation Loss AVG: 10.7890, lr: 0.001
Epoch [17/200], Training Loss: 6.9037, Validation Loss Current: 10.9239, Validation Loss AVG: 10.9239, lr: 0.001
Epoch [18/200], Training Loss: 6.0040, Validation Loss Current: 10.3376, Validation Loss AVG: 10.3376, lr: 0.001
Epoch [19/200], Training Loss: 3.9406, Validation Loss Current: 10.3284, Validation Loss AVG: 10.3284, lr: 0.001
Epoch [20/200], Training Loss: 5.6361, Validation Loss Current: 9.9417, Validation Loss AVG: 9.9417, lr: 0.001
Epoch [21/200], Training Loss: 3.0966, Validation Loss Current: 13.1640, Validation Loss AVG: 13.1640, lr: 0.001
Epoch [22/200], Training Loss: 5.0259, Validation Loss Current: 10.3487, Validation Loss AVG: 10.3487, lr: 0.001
Epoch [23/200], Training Loss: 7.0317, Validation Loss Current: 11.0979, Validation Loss AVG: 11.0979, lr: 0.001
Epoch [24/200], Training Loss: 7.5600, Validation Loss Current: 12.0345, Validation Loss AVG: 12.0345, lr: 0.001
Epoch [25/200], Training Loss: 4.8741, Validation Loss Current: 11.0062, Validation Loss AVG: 11.0062, lr: 0.001
Epoch [26/200], Training Loss: 4.3203, Validation Loss Current: 11.6242, Validation Loss AVG: 11.6242, lr: 0.001
Epoch [27/200], Training Loss: 2.4694, Validation Loss Current: 11.0981, Validation Loss AVG: 11.0981, lr: 0.001
Epoch [28/200], Training Loss: 4.3908, Validation Loss Current: 11.9839, Validation Loss AVG: 11.9839, lr: 0.001
Epoch [29/200], Training Loss: 8.3245, Validation Loss Current: 11.8528, Validation Loss AVG: 11.8528, lr: 0.001
Epoch [30/200], Training Loss: 4.5166, Validation Loss Current: 10.1180, Validation Loss AVG: 10.1180, lr: 0.001
Epoch [31/200], Training Loss: 3.0118, Validation Loss Current: 11.2902, Validation Loss AVG: 11.2902, lr: 0.001
Epoch [32/200], Training Loss: 4.4162, Validation Loss Current: 10.4256, Validation Loss AVG: 10.4256, lr: 0.001
Epoch [33/200], Training Loss: 2.6322, Validation Loss Current: 10.5520, Validation Loss AVG: 10.5520, lr: 0.001
Epoch [34/200], Training Loss: 3.0624, Validation Loss Current: 11.4141, Validation Loss AVG: 11.4141, lr: 0.001
Epoch [35/200], Training Loss: 2.5272, Validation Loss Current: 12.2150, Validation Loss AVG: 12.2150, lr: 0.001
Epoch [36/200], Training Loss: 2.6291, Validation Loss Current: 13.1489, Validation Loss AVG: 13.1489, lr: 0.001
Epoch [37/200], Training Loss: 4.4750, Validation Loss Current: 10.8493, Validation Loss AVG: 10.8493, lr: 0.001
Epoch [38/200], Training Loss: 3.4369, Validation Loss Current: 13.5530, Validation Loss AVG: 13.5530, lr: 0.001
Epoch [39/200], Training Loss: 3.5021, Validation Loss Current: 11.5308, Validation Loss AVG: 11.5308, lr: 0.001
Epoch [40/200], Training Loss: 5.8841, Validation Loss Current: 11.8730, Validation Loss AVG: 11.8730, lr: 0.001
Epoch [41/200], Training Loss: 5.8181, Validation Loss Current: 13.6029, Validation Loss AVG: 13.6029, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 11 Best val accuracy: [0.42269736842105265, 0.43289473684210533, 0.4496710526315789, 0.4430921052631579, 0.44868421052631574, 0.4621710526315789, 0.47203947368421045, 0.44703947368421054, 0.4585526315789473, 0.4463815789473684, 0.46677631578947365, 0.4796052631578947, 0.4717105263157896, 0.39868421052631575, 0.4230263157894737, 0.42598684210526316, 0.4131578947368421, 0.47269736842105264, 0.47006578947368427, 0.47730263157894737, 0.39671052631578946, 0.4703947368421053, 0.46118421052631575, 0.4180921052631579, 0.45723684210526316, 0.43717105263157896, 0.4759868421052632, 0.4276315789473684, 0.4463815789473684, 0.4473684210526316, 0.4430921052631579, 0.48684210526315785, 0.47006578947368427, 0.4180921052631579, 0.4631578947368421, 0.4180921052631579, 0.4638157894736842, 0.40921052631578947, 0.44144736842105264, 0.48421052631578954, 0.4] Best val loss: 8.880324816703796


----- Training resnet18 with sequence: [1, 0.8, 0.6] -----
Current group: 1
Epoch [1/134], Training Loss: 40.5788, Validation Loss Current: 9.8521, Validation Loss AVG: 9.9939, lr: 0.001
Epoch [2/134], Training Loss: 38.2821, Validation Loss Current: 9.5101, Validation Loss AVG: 9.9187, lr: 0.001
Epoch [3/134], Training Loss: 37.1350, Validation Loss Current: 9.2124, Validation Loss AVG: 9.6859, lr: 0.001
Epoch [4/134], Training Loss: 35.3654, Validation Loss Current: 8.9193, Validation Loss AVG: 9.6690, lr: 0.001
Epoch [5/134], Training Loss: 34.6773, Validation Loss Current: 8.4859, Validation Loss AVG: 9.2175, lr: 0.001
Epoch [6/134], Training Loss: 33.3483, Validation Loss Current: 8.2682, Validation Loss AVG: 9.2504, lr: 0.001
Epoch [7/134], Training Loss: 30.9839, Validation Loss Current: 8.3444, Validation Loss AVG: 11.3380, lr: 0.001
Epoch [8/134], Training Loss: 30.8770, Validation Loss Current: 7.6070, Validation Loss AVG: 8.8134, lr: 0.001
Epoch [9/134], Training Loss: 29.5539, Validation Loss Current: 8.3075, Validation Loss AVG: 9.5003, lr: 0.001
Epoch [10/134], Training Loss: 29.7382, Validation Loss Current: 7.3189, Validation Loss AVG: 9.5867, lr: 0.001
Epoch [11/134], Training Loss: 27.6151, Validation Loss Current: 7.1068, Validation Loss AVG: 10.8558, lr: 0.001
Epoch [12/134], Training Loss: 26.8714, Validation Loss Current: 6.9446, Validation Loss AVG: 8.6870, lr: 0.001
Epoch [13/134], Training Loss: 25.0535, Validation Loss Current: 6.7159, Validation Loss AVG: 8.9789, lr: 0.001
Epoch [14/134], Training Loss: 23.7406, Validation Loss Current: 6.9929, Validation Loss AVG: 9.1725, lr: 0.001
Epoch [15/134], Training Loss: 23.1465, Validation Loss Current: 7.0041, Validation Loss AVG: 10.4983, lr: 0.001
Epoch [16/134], Training Loss: 23.5808, Validation Loss Current: 6.1869, Validation Loss AVG: 8.3098, lr: 0.001
Epoch [17/134], Training Loss: 22.1660, Validation Loss Current: 7.9197, Validation Loss AVG: 11.3002, lr: 0.001
Epoch [18/134], Training Loss: 22.3301, Validation Loss Current: 7.0199, Validation Loss AVG: 9.4120, lr: 0.001
Epoch [19/134], Training Loss: 22.4674, Validation Loss Current: 6.5858, Validation Loss AVG: 9.1251, lr: 0.001
Epoch [20/134], Training Loss: 21.7246, Validation Loss Current: 14.7810, Validation Loss AVG: 20.3406, lr: 0.001
Epoch [21/134], Training Loss: 24.8197, Validation Loss Current: 7.1655, Validation Loss AVG: 8.7975, lr: 0.001
Epoch [22/134], Training Loss: 22.3610, Validation Loss Current: 6.7122, Validation Loss AVG: 9.8811, lr: 0.001
Epoch [23/134], Training Loss: 20.4342, Validation Loss Current: 6.0255, Validation Loss AVG: 9.5513, lr: 0.001
Epoch [24/134], Training Loss: 18.4535, Validation Loss Current: 5.8429, Validation Loss AVG: 7.8949, lr: 0.001
Epoch [25/134], Training Loss: 18.0712, Validation Loss Current: 5.7557, Validation Loss AVG: 8.0329, lr: 0.001
Epoch [26/134], Training Loss: 18.2725, Validation Loss Current: 5.9655, Validation Loss AVG: 8.0983, lr: 0.001
Epoch [27/134], Training Loss: 18.5316, Validation Loss Current: 5.9424, Validation Loss AVG: 9.3760, lr: 0.001
Epoch [28/134], Training Loss: 16.5088, Validation Loss Current: 5.7240, Validation Loss AVG: 8.1647, lr: 0.001
Epoch [29/134], Training Loss: 15.0107, Validation Loss Current: 5.8750, Validation Loss AVG: 9.7074, lr: 0.001
Epoch [30/134], Training Loss: 14.7530, Validation Loss Current: 6.3689, Validation Loss AVG: 8.9443, lr: 0.001
Epoch [31/134], Training Loss: 14.5174, Validation Loss Current: 5.8077, Validation Loss AVG: 10.1151, lr: 0.001
Epoch [32/134], Training Loss: 14.9461, Validation Loss Current: 5.9054, Validation Loss AVG: 8.7208, lr: 0.001
Epoch [33/134], Training Loss: 13.3682, Validation Loss Current: 5.8119, Validation Loss AVG: 9.1980, lr: 0.001
Epoch [34/134], Training Loss: 13.7366, Validation Loss Current: 5.8785, Validation Loss AVG: 10.1035, lr: 0.001
Epoch [35/134], Training Loss: 14.3786, Validation Loss Current: 6.4571, Validation Loss AVG: 10.4934, lr: 0.001
Epoch [36/134], Training Loss: 11.7669, Validation Loss Current: 6.0216, Validation Loss AVG: 11.0504, lr: 0.001
Epoch [37/134], Training Loss: 10.0068, Validation Loss Current: 5.3464, Validation Loss AVG: 9.3491, lr: 0.001
Epoch [38/134], Training Loss: 8.6997, Validation Loss Current: 4.9942, Validation Loss AVG: 9.3224, lr: 0.001
Epoch [39/134], Training Loss: 7.9600, Validation Loss Current: 6.8166, Validation Loss AVG: 9.2344, lr: 0.001
Epoch [40/134], Training Loss: 9.8872, Validation Loss Current: 5.8650, Validation Loss AVG: 9.4465, lr: 0.001
Epoch [41/134], Training Loss: 9.4103, Validation Loss Current: 6.3894, Validation Loss AVG: 9.8335, lr: 0.001
Epoch [42/134], Training Loss: 7.3123, Validation Loss Current: 5.4653, Validation Loss AVG: 8.2359, lr: 0.001
Epoch [43/134], Training Loss: 6.6124, Validation Loss Current: 5.3918, Validation Loss AVG: 8.3679, lr: 0.001
Epoch [44/134], Training Loss: 7.1020, Validation Loss Current: 5.2473, Validation Loss AVG: 10.4369, lr: 0.001
Epoch [45/134], Training Loss: 7.5088, Validation Loss Current: 7.2241, Validation Loss AVG: 8.7972, lr: 0.001
Epoch [46/134], Training Loss: 10.5108, Validation Loss Current: 10.4823, Validation Loss AVG: 13.4850, lr: 0.001
Epoch [47/134], Training Loss: 8.7067, Validation Loss Current: 6.0061, Validation Loss AVG: 12.0578, lr: 0.001
Epoch [48/134], Training Loss: 6.8042, Validation Loss Current: 6.5810, Validation Loss AVG: 11.0271, lr: 0.001
Epoch [49/134], Training Loss: 7.9512, Validation Loss Current: 6.0575, Validation Loss AVG: 12.6583, lr: 0.001
Epoch [50/134], Training Loss: 6.9689, Validation Loss Current: 6.2594, Validation Loss AVG: 10.6210, lr: 0.001
Epoch [51/134], Training Loss: 6.1802, Validation Loss Current: 6.0099, Validation Loss AVG: 12.6887, lr: 0.001
Epoch [52/134], Training Loss: 6.4236, Validation Loss Current: 6.1793, Validation Loss AVG: 8.9314, lr: 0.001
Epoch [53/134], Training Loss: 5.7703, Validation Loss Current: 6.1896, Validation Loss AVG: 12.6343, lr: 0.001
Epoch [54/134], Training Loss: 4.9434, Validation Loss Current: 5.6714, Validation Loss AVG: 10.4302, lr: 0.001
Epoch [55/134], Training Loss: 5.9983, Validation Loss Current: 6.3864, Validation Loss AVG: 13.6818, lr: 0.001
Epoch [56/134], Training Loss: 4.4954, Validation Loss Current: 6.0861, Validation Loss AVG: 11.7413, lr: 0.001
Epoch [57/134], Training Loss: 3.5962, Validation Loss Current: 6.2400, Validation Loss AVG: 12.6234, lr: 0.001
Epoch [58/134], Training Loss: 6.5258, Validation Loss Current: 6.9145, Validation Loss AVG: 10.6805, lr: 0.001
Epoch [59/134], Training Loss: 6.7558, Validation Loss Current: 6.8478, Validation Loss AVG: 12.2095, lr: 0.001
Epoch [60/134], Training Loss: 4.7047, Validation Loss Current: 6.6177, Validation Loss AVG: 9.4137, lr: 0.001
Epoch [61/134], Training Loss: 2.3361, Validation Loss Current: 5.9147, Validation Loss AVG: 11.6847, lr: 0.001
Epoch [62/134], Training Loss: 3.2361, Validation Loss Current: 5.8124, Validation Loss AVG: 9.9030, lr: 0.001
Epoch [63/134], Training Loss: 5.1579, Validation Loss Current: 6.7946, Validation Loss AVG: 12.2080, lr: 0.001
Epoch [64/134], Training Loss: 2.6634, Validation Loss Current: 5.9807, Validation Loss AVG: 11.0522, lr: 0.001
Epoch [65/134], Training Loss: 3.0374, Validation Loss Current: 6.3049, Validation Loss AVG: 11.0819, lr: 0.001
Epoch [66/134], Training Loss: 5.0982, Validation Loss Current: 6.6856, Validation Loss AVG: 11.1557, lr: 0.001
Epoch [67/134], Training Loss: 3.0538, Validation Loss Current: 7.1607, Validation Loss AVG: 12.8850, lr: 0.001
Epoch [68/134], Training Loss: 3.6645, Validation Loss Current: 7.5976, Validation Loss AVG: 11.1956, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 38 Best val accuracy: [0.26151315789473684, 0.26480263157894735, 0.3338815789473684, 0.34375, 0.4128289473684211, 0.3930921052631579, 0.38980263157894735, 0.48355263157894735, 0.41118421052631576, 0.506578947368421, 0.506578947368421, 0.49506578947368424, 0.5328947368421053, 0.49506578947368424, 0.5394736842105263, 0.5411184210526315, 0.4654605263157895, 0.524671052631579, 0.5197368421052632, 0.3256578947368421, 0.5345394736842105, 0.506578947368421, 0.6019736842105263, 0.5921052631578947, 0.600328947368421, 0.5953947368421053, 0.5888157894736842, 0.600328947368421, 0.5756578947368421, 0.5789473684210527, 0.5953947368421053, 0.5953947368421053, 0.5888157894736842, 0.5805921052631579, 0.5657894736842105, 0.59375, 0.631578947368421, 0.6463815789473685, 0.59375, 0.5904605263157895, 0.5789473684210527, 0.6381578947368421, 0.625, 0.6447368421052632, 0.5608552631578947, 0.45394736842105265, 0.6085526315789473, 0.625, 0.6217105263157895, 0.5970394736842105, 0.6282894736842105, 0.6036184210526315, 0.649671052631579, 0.6332236842105263, 0.5970394736842105, 0.6217105263157895, 0.6167763157894737, 0.5822368421052632, 0.6200657894736842, 0.5888157894736842, 0.6332236842105263, 0.6414473684210527, 0.587171052631579, 0.618421052631579, 0.600328947368421, 0.5953947368421053, 0.6134868421052632, 0.5921052631578947] Best val loss: 4.994242906570435


Current group: 0.8
Epoch [1/134], Training Loss: 21.6926, Validation Loss Current: 14.9985, Validation Loss AVG: 14.9985, lr: 0.001
Epoch [2/134], Training Loss: 20.1142, Validation Loss Current: 9.2760, Validation Loss AVG: 9.2760, lr: 0.001
Epoch [3/134], Training Loss: 14.6755, Validation Loss Current: 10.7037, Validation Loss AVG: 10.7037, lr: 0.001
Epoch [4/134], Training Loss: 9.2884, Validation Loss Current: 10.8230, Validation Loss AVG: 10.8230, lr: 0.001
Epoch [5/134], Training Loss: 7.5456, Validation Loss Current: 11.7778, Validation Loss AVG: 11.7778, lr: 0.001
Epoch [6/134], Training Loss: 8.0198, Validation Loss Current: 13.5835, Validation Loss AVG: 13.5835, lr: 0.001
Epoch [7/134], Training Loss: 8.1478, Validation Loss Current: 9.3247, Validation Loss AVG: 9.3247, lr: 0.001
Epoch [8/134], Training Loss: 6.1528, Validation Loss Current: 9.3580, Validation Loss AVG: 9.3580, lr: 0.001
Epoch [9/134], Training Loss: 5.5551, Validation Loss Current: 9.3513, Validation Loss AVG: 9.3513, lr: 0.001
Epoch [10/134], Training Loss: 6.0594, Validation Loss Current: 10.4274, Validation Loss AVG: 10.4274, lr: 0.001
Epoch [11/134], Training Loss: 5.9460, Validation Loss Current: 8.8302, Validation Loss AVG: 8.8302, lr: 0.001
Epoch [12/134], Training Loss: 5.3721, Validation Loss Current: 10.0011, Validation Loss AVG: 10.0011, lr: 0.001
Epoch [13/134], Training Loss: 5.9056, Validation Loss Current: 10.2875, Validation Loss AVG: 10.2875, lr: 0.001
Epoch [14/134], Training Loss: 3.7281, Validation Loss Current: 9.0284, Validation Loss AVG: 9.0284, lr: 0.001
Epoch [15/134], Training Loss: 3.4792, Validation Loss Current: 9.4759, Validation Loss AVG: 9.4759, lr: 0.001
Epoch [16/134], Training Loss: 4.5696, Validation Loss Current: 12.5240, Validation Loss AVG: 12.5240, lr: 0.001
Epoch [17/134], Training Loss: 5.3801, Validation Loss Current: 11.3623, Validation Loss AVG: 11.3623, lr: 0.001
Epoch [18/134], Training Loss: 8.1038, Validation Loss Current: 11.7533, Validation Loss AVG: 11.7533, lr: 0.001
Epoch [19/134], Training Loss: 5.7659, Validation Loss Current: 13.4416, Validation Loss AVG: 13.4416, lr: 0.001
Epoch [20/134], Training Loss: 4.9816, Validation Loss Current: 11.4238, Validation Loss AVG: 11.4238, lr: 0.001
Epoch [21/134], Training Loss: 6.1631, Validation Loss Current: 11.3144, Validation Loss AVG: 11.3144, lr: 0.001
Epoch [22/134], Training Loss: 4.8042, Validation Loss Current: 14.2977, Validation Loss AVG: 14.2977, lr: 0.001
Epoch [23/134], Training Loss: 4.4845, Validation Loss Current: 10.5445, Validation Loss AVG: 10.5445, lr: 0.001
Epoch [24/134], Training Loss: 6.1742, Validation Loss Current: 11.8538, Validation Loss AVG: 11.8538, lr: 0.001
Epoch [25/134], Training Loss: 6.1988, Validation Loss Current: 13.0736, Validation Loss AVG: 13.0736, lr: 0.001
Epoch [26/134], Training Loss: 4.4590, Validation Loss Current: 12.2914, Validation Loss AVG: 12.2914, lr: 0.001
Epoch [27/134], Training Loss: 6.0965, Validation Loss Current: 14.9441, Validation Loss AVG: 14.9441, lr: 0.001
Epoch [28/134], Training Loss: 4.7483, Validation Loss Current: 12.3690, Validation Loss AVG: 12.3690, lr: 0.001
Epoch [29/134], Training Loss: 3.3772, Validation Loss Current: 11.5819, Validation Loss AVG: 11.5819, lr: 0.001
Epoch [30/134], Training Loss: 2.9091, Validation Loss Current: 10.6088, Validation Loss AVG: 10.6088, lr: 0.001
Epoch [31/134], Training Loss: 3.0291, Validation Loss Current: 13.5988, Validation Loss AVG: 13.5988, lr: 0.001
Epoch [32/134], Training Loss: 1.6909, Validation Loss Current: 10.2718, Validation Loss AVG: 10.2718, lr: 0.001
Epoch [33/134], Training Loss: 1.9699, Validation Loss Current: 13.5605, Validation Loss AVG: 13.5605, lr: 0.001
Epoch [34/134], Training Loss: 2.6400, Validation Loss Current: 12.1492, Validation Loss AVG: 12.1492, lr: 0.001
Epoch [35/134], Training Loss: 3.2843, Validation Loss Current: 12.7230, Validation Loss AVG: 12.7230, lr: 0.001
Epoch [36/134], Training Loss: 1.3825, Validation Loss Current: 14.1427, Validation Loss AVG: 14.1427, lr: 0.001
Epoch [37/134], Training Loss: 1.0257, Validation Loss Current: 10.6992, Validation Loss AVG: 10.6992, lr: 0.001
Epoch [38/134], Training Loss: 1.0597, Validation Loss Current: 14.1227, Validation Loss AVG: 14.1227, lr: 0.001
Epoch [39/134], Training Loss: 3.8457, Validation Loss Current: 11.2744, Validation Loss AVG: 11.2744, lr: 0.001
Epoch [40/134], Training Loss: 4.3871, Validation Loss Current: 12.0715, Validation Loss AVG: 12.0715, lr: 0.001
Epoch [41/134], Training Loss: 10.2646, Validation Loss Current: 14.0701, Validation Loss AVG: 14.0701, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 11 Best val accuracy: [0.38355263157894737, 0.4549342105263158, 0.4473684210526316, 0.4322368421052632, 0.42072368421052636, 0.42631578947368426, 0.45723684210526316, 0.47368421052631576, 0.46578947368421053, 0.4805921052631579, 0.46875, 0.4411184210526316, 0.4519736842105263, 0.48914473684210524, 0.47796052631578956, 0.44769736842105257, 0.4463815789473685, 0.43519736842105267, 0.42828947368421055, 0.4713815789473685, 0.4375, 0.425, 0.46842105263157896, 0.4536184210526316, 0.4273026315789473, 0.3891447368421052, 0.4223684210526316, 0.44572368421052627, 0.4661184210526315, 0.4743421052631579, 0.4516447368421052, 0.44572368421052627, 0.4236842105263158, 0.45394736842105265, 0.47631578947368425, 0.45296052631578937, 0.44868421052631574, 0.45921052631578957, 0.4513157894736842, 0.43947368421052635, 0.42105263157894735] Best val loss: 8.830157899856568


Current group: 0.6
Epoch [1/134], Training Loss: 26.7504, Validation Loss Current: 10.8637, Validation Loss AVG: 10.8637, lr: 0.001
Epoch [2/134], Training Loss: 16.7939, Validation Loss Current: 9.9851, Validation Loss AVG: 9.9851, lr: 0.001
Epoch [3/134], Training Loss: 10.5684, Validation Loss Current: 10.3455, Validation Loss AVG: 10.3455, lr: 0.001
Epoch [4/134], Training Loss: 7.1303, Validation Loss Current: 9.7546, Validation Loss AVG: 9.7546, lr: 0.001
Epoch [5/134], Training Loss: 8.2377, Validation Loss Current: 10.6605, Validation Loss AVG: 10.6605, lr: 0.001
Epoch [6/134], Training Loss: 7.6581, Validation Loss Current: 9.3603, Validation Loss AVG: 9.3603, lr: 0.001
Epoch [7/134], Training Loss: 5.9763, Validation Loss Current: 11.2827, Validation Loss AVG: 11.2827, lr: 0.001
Epoch [8/134], Training Loss: 5.0494, Validation Loss Current: 9.9324, Validation Loss AVG: 9.9324, lr: 0.001
Epoch [9/134], Training Loss: 5.5605, Validation Loss Current: 11.0374, Validation Loss AVG: 11.0374, lr: 0.001
Epoch [10/134], Training Loss: 6.4744, Validation Loss Current: 11.0759, Validation Loss AVG: 11.0759, lr: 0.001
Epoch [11/134], Training Loss: 6.9206, Validation Loss Current: 10.4067, Validation Loss AVG: 10.4067, lr: 0.001
Epoch [12/134], Training Loss: 5.8747, Validation Loss Current: 13.0081, Validation Loss AVG: 13.0081, lr: 0.001
Epoch [13/134], Training Loss: 4.4265, Validation Loss Current: 11.4629, Validation Loss AVG: 11.4629, lr: 0.001
Epoch [14/134], Training Loss: 5.3979, Validation Loss Current: 11.8303, Validation Loss AVG: 11.8303, lr: 0.001
Epoch [15/134], Training Loss: 4.1001, Validation Loss Current: 12.2608, Validation Loss AVG: 12.2608, lr: 0.001
Epoch [16/134], Training Loss: 7.5493, Validation Loss Current: 11.9844, Validation Loss AVG: 11.9844, lr: 0.001
Epoch [17/134], Training Loss: 5.0789, Validation Loss Current: 14.1788, Validation Loss AVG: 14.1788, lr: 0.001
Epoch [18/134], Training Loss: 11.0514, Validation Loss Current: 14.6773, Validation Loss AVG: 14.6773, lr: 0.001
Epoch [19/134], Training Loss: 10.8236, Validation Loss Current: 12.8213, Validation Loss AVG: 12.8213, lr: 0.001
Epoch [20/134], Training Loss: 5.3867, Validation Loss Current: 14.3493, Validation Loss AVG: 14.3493, lr: 0.001
Epoch [21/134], Training Loss: 3.0502, Validation Loss Current: 11.4879, Validation Loss AVG: 11.4879, lr: 0.001
Epoch [22/134], Training Loss: 3.5171, Validation Loss Current: 12.7069, Validation Loss AVG: 12.7069, lr: 0.001
Epoch [23/134], Training Loss: 4.7479, Validation Loss Current: 13.7305, Validation Loss AVG: 13.7305, lr: 0.001
Epoch [24/134], Training Loss: 5.7236, Validation Loss Current: 12.9363, Validation Loss AVG: 12.9363, lr: 0.001
Epoch [25/134], Training Loss: 3.5340, Validation Loss Current: 13.7852, Validation Loss AVG: 13.7852, lr: 0.001
Epoch [26/134], Training Loss: 1.4322, Validation Loss Current: 10.9936, Validation Loss AVG: 10.9936, lr: 0.001
Epoch [27/134], Training Loss: 0.8812, Validation Loss Current: 10.4049, Validation Loss AVG: 10.4049, lr: 0.001
Epoch [28/134], Training Loss: 2.0772, Validation Loss Current: 11.6099, Validation Loss AVG: 11.6099, lr: 0.001
Epoch [29/134], Training Loss: 2.4912, Validation Loss Current: 12.0923, Validation Loss AVG: 12.0923, lr: 0.001
Epoch [30/134], Training Loss: 1.8793, Validation Loss Current: 11.3149, Validation Loss AVG: 11.3149, lr: 0.001
Epoch [31/134], Training Loss: 3.0237, Validation Loss Current: 11.0161, Validation Loss AVG: 11.0161, lr: 0.001
Epoch [32/134], Training Loss: 4.4872, Validation Loss Current: 12.1064, Validation Loss AVG: 12.1064, lr: 0.001
Epoch [33/134], Training Loss: 3.6939, Validation Loss Current: 13.0904, Validation Loss AVG: 13.0904, lr: 0.001
Epoch [34/134], Training Loss: 3.6197, Validation Loss Current: 13.6032, Validation Loss AVG: 13.6032, lr: 0.001
Epoch [35/134], Training Loss: 4.4681, Validation Loss Current: 12.1752, Validation Loss AVG: 12.1752, lr: 0.001
Epoch [36/134], Training Loss: 2.9927, Validation Loss Current: 15.2155, Validation Loss AVG: 15.2155, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 6 Best val accuracy: [0.46447368421052637, 0.4930921052631579, 0.48519736842105265, 0.4792763157894736, 0.4526315789473684, 0.5013157894736843, 0.46019736842105263, 0.49572368421052626, 0.4697368421052631, 0.47467105263157894, 0.4776315789473684, 0.4625, 0.44671052631578945, 0.4796052631578947, 0.47302631578947374, 0.48519736842105265, 0.4223684210526316, 0.43289473684210533, 0.4220394736842105, 0.46809210526315786, 0.4809210526315789, 0.43157894736842106, 0.45230263157894735, 0.4509868421052632, 0.4651315789473684, 0.4776315789473685, 0.5157894736842105, 0.4881578947368421, 0.4546052631578948, 0.49342105263157904, 0.48190789473684215, 0.4740131578947368, 0.44407894736842096, 0.44046052631578947, 0.4598684210526316, 0.45559210526315785] Best val loss: 9.360275554656983


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4] -----
Current group: 1
Epoch [1/100], Training Loss: 41.3307, Validation Loss Current: 9.9693, Validation Loss AVG: 10.0154, lr: 0.001
Epoch [2/100], Training Loss: 38.1915, Validation Loss Current: 9.5664, Validation Loss AVG: 10.0393, lr: 0.001
Epoch [3/100], Training Loss: 36.7283, Validation Loss Current: 9.2844, Validation Loss AVG: 9.8882, lr: 0.001
Epoch [4/100], Training Loss: 36.0947, Validation Loss Current: 8.7826, Validation Loss AVG: 9.6214, lr: 0.001
Epoch [5/100], Training Loss: 34.8469, Validation Loss Current: 8.4090, Validation Loss AVG: 9.4266, lr: 0.001
Epoch [6/100], Training Loss: 33.3750, Validation Loss Current: 8.1316, Validation Loss AVG: 9.0924, lr: 0.001
Epoch [7/100], Training Loss: 31.7120, Validation Loss Current: 7.7952, Validation Loss AVG: 8.9516, lr: 0.001
Epoch [8/100], Training Loss: 30.2622, Validation Loss Current: 7.6120, Validation Loss AVG: 8.9773, lr: 0.001
Epoch [9/100], Training Loss: 29.5728, Validation Loss Current: 7.3150, Validation Loss AVG: 9.1987, lr: 0.001
Epoch [10/100], Training Loss: 28.8151, Validation Loss Current: 7.0213, Validation Loss AVG: 8.7500, lr: 0.001
Epoch [11/100], Training Loss: 27.6823, Validation Loss Current: 7.1180, Validation Loss AVG: 9.0830, lr: 0.001
Epoch [12/100], Training Loss: 27.5179, Validation Loss Current: 6.7816, Validation Loss AVG: 9.1504, lr: 0.001
Epoch [13/100], Training Loss: 25.8737, Validation Loss Current: 7.0338, Validation Loss AVG: 8.6457, lr: 0.001
Epoch [14/100], Training Loss: 26.6461, Validation Loss Current: 6.7657, Validation Loss AVG: 8.5786, lr: 0.001
Epoch [15/100], Training Loss: 25.9010, Validation Loss Current: 6.6750, Validation Loss AVG: 9.4854, lr: 0.001
Epoch [16/100], Training Loss: 24.0926, Validation Loss Current: 6.4140, Validation Loss AVG: 9.0325, lr: 0.001
Epoch [17/100], Training Loss: 22.9204, Validation Loss Current: 6.2736, Validation Loss AVG: 8.6980, lr: 0.001
Epoch [18/100], Training Loss: 22.2935, Validation Loss Current: 6.6432, Validation Loss AVG: 9.8458, lr: 0.001
Epoch [19/100], Training Loss: 22.0303, Validation Loss Current: 6.6463, Validation Loss AVG: 10.3642, lr: 0.001
Epoch [20/100], Training Loss: 20.9251, Validation Loss Current: 6.5839, Validation Loss AVG: 10.9134, lr: 0.001
Epoch [21/100], Training Loss: 19.7676, Validation Loss Current: 5.9315, Validation Loss AVG: 8.7031, lr: 0.001
Epoch [22/100], Training Loss: 21.3463, Validation Loss Current: 6.9001, Validation Loss AVG: 9.1332, lr: 0.001
Epoch [23/100], Training Loss: 21.6564, Validation Loss Current: 7.3236, Validation Loss AVG: 11.6895, lr: 0.001
Epoch [24/100], Training Loss: 20.4641, Validation Loss Current: 6.0510, Validation Loss AVG: 9.9841, lr: 0.001
Epoch [25/100], Training Loss: 19.4372, Validation Loss Current: 5.8588, Validation Loss AVG: 9.0153, lr: 0.001
Epoch [26/100], Training Loss: 17.6575, Validation Loss Current: 6.7638, Validation Loss AVG: 9.8060, lr: 0.001
Epoch [27/100], Training Loss: 19.3563, Validation Loss Current: 6.4438, Validation Loss AVG: 9.8369, lr: 0.001
Epoch [28/100], Training Loss: 17.6980, Validation Loss Current: 6.1805, Validation Loss AVG: 10.0269, lr: 0.001
Epoch [29/100], Training Loss: 16.7366, Validation Loss Current: 6.1776, Validation Loss AVG: 8.6484, lr: 0.001
Epoch [30/100], Training Loss: 17.0034, Validation Loss Current: 5.7665, Validation Loss AVG: 7.6919, lr: 0.001
Epoch [31/100], Training Loss: 16.1870, Validation Loss Current: 5.7155, Validation Loss AVG: 10.3209, lr: 0.001
Epoch [32/100], Training Loss: 16.1004, Validation Loss Current: 6.7079, Validation Loss AVG: 9.4871, lr: 0.001
Epoch [33/100], Training Loss: 15.0831, Validation Loss Current: 5.8701, Validation Loss AVG: 10.2036, lr: 0.001
Epoch [34/100], Training Loss: 14.7078, Validation Loss Current: 8.2292, Validation Loss AVG: 15.9239, lr: 0.001
Epoch [35/100], Training Loss: 18.8672, Validation Loss Current: 7.0452, Validation Loss AVG: 8.8819, lr: 0.001
Epoch [36/100], Training Loss: 15.2498, Validation Loss Current: 6.0195, Validation Loss AVG: 11.9772, lr: 0.001
Epoch [37/100], Training Loss: 14.6887, Validation Loss Current: 6.0705, Validation Loss AVG: 9.6886, lr: 0.001
Epoch [38/100], Training Loss: 14.6474, Validation Loss Current: 8.0574, Validation Loss AVG: 10.8742, lr: 0.001
Epoch [39/100], Training Loss: 11.4983, Validation Loss Current: 5.8033, Validation Loss AVG: 9.0164, lr: 0.001
Epoch [40/100], Training Loss: 9.6435, Validation Loss Current: 5.8300, Validation Loss AVG: 9.2687, lr: 0.001
Epoch [41/100], Training Loss: 9.0427, Validation Loss Current: 5.9117, Validation Loss AVG: 10.2894, lr: 0.001
Epoch [42/100], Training Loss: 9.6156, Validation Loss Current: 5.7402, Validation Loss AVG: 10.5346, lr: 0.001
Epoch [43/100], Training Loss: 10.0284, Validation Loss Current: 6.5636, Validation Loss AVG: 11.9936, lr: 0.001
Epoch [44/100], Training Loss: 10.0046, Validation Loss Current: 5.6587, Validation Loss AVG: 9.5456, lr: 0.001
Epoch [45/100], Training Loss: 9.2003, Validation Loss Current: 5.8352, Validation Loss AVG: 9.8129, lr: 0.001
Epoch [46/100], Training Loss: 7.2757, Validation Loss Current: 6.7307, Validation Loss AVG: 13.2524, lr: 0.001
Epoch [47/100], Training Loss: 5.7317, Validation Loss Current: 6.1479, Validation Loss AVG: 11.1716, lr: 0.001
Epoch [48/100], Training Loss: 4.8527, Validation Loss Current: 6.1993, Validation Loss AVG: 9.0473, lr: 0.001
Epoch [49/100], Training Loss: 5.0660, Validation Loss Current: 6.9073, Validation Loss AVG: 14.3129, lr: 0.001
Epoch [50/100], Training Loss: 5.9253, Validation Loss Current: 6.5678, Validation Loss AVG: 10.3214, lr: 0.001
Epoch [51/100], Training Loss: 5.3642, Validation Loss Current: 6.7007, Validation Loss AVG: 9.9577, lr: 0.001
Epoch [52/100], Training Loss: 5.0873, Validation Loss Current: 6.4066, Validation Loss AVG: 11.1702, lr: 0.001
Epoch [53/100], Training Loss: 4.0185, Validation Loss Current: 6.5707, Validation Loss AVG: 10.4208, lr: 0.001
Epoch [54/100], Training Loss: 4.2278, Validation Loss Current: 6.6626, Validation Loss AVG: 9.9537, lr: 0.001
Epoch [55/100], Training Loss: 4.0896, Validation Loss Current: 7.0322, Validation Loss AVG: 9.9259, lr: 0.001
Epoch [56/100], Training Loss: 4.1009, Validation Loss Current: 7.5714, Validation Loss AVG: 13.3329, lr: 0.001
Epoch [57/100], Training Loss: 5.7242, Validation Loss Current: 6.8049, Validation Loss AVG: 13.6740, lr: 0.001
Epoch [58/100], Training Loss: 3.6243, Validation Loss Current: 6.6443, Validation Loss AVG: 12.4418, lr: 0.001
Epoch [59/100], Training Loss: 6.4425, Validation Loss Current: 9.3314, Validation Loss AVG: 13.8379, lr: 0.001
Epoch [60/100], Training Loss: 8.7037, Validation Loss Current: 6.9116, Validation Loss AVG: 9.7526, lr: 0.001
Epoch [61/100], Training Loss: 5.5996, Validation Loss Current: 6.9043, Validation Loss AVG: 13.2376, lr: 0.001
Epoch [62/100], Training Loss: 3.2857, Validation Loss Current: 6.1815, Validation Loss AVG: 13.6459, lr: 0.001
Epoch [63/100], Training Loss: 3.6131, Validation Loss Current: 6.5954, Validation Loss AVG: 13.2620, lr: 0.001
Epoch [64/100], Training Loss: 2.2980, Validation Loss Current: 6.4837, Validation Loss AVG: 11.7495, lr: 0.001
Epoch [65/100], Training Loss: 3.5435, Validation Loss Current: 7.1833, Validation Loss AVG: 11.9122, lr: 0.001
Epoch [66/100], Training Loss: 4.1077, Validation Loss Current: 8.0237, Validation Loss AVG: 12.2336, lr: 0.001
Epoch [67/100], Training Loss: 4.9484, Validation Loss Current: 7.7005, Validation Loss AVG: 11.7587, lr: 0.001
Epoch [68/100], Training Loss: 3.8123, Validation Loss Current: 7.3077, Validation Loss AVG: 13.6843, lr: 0.001
Epoch [69/100], Training Loss: 4.1928, Validation Loss Current: 7.0455, Validation Loss AVG: 14.8630, lr: 0.001
Epoch [70/100], Training Loss: 3.5476, Validation Loss Current: 7.0908, Validation Loss AVG: 15.5524, lr: 0.001
Epoch [71/100], Training Loss: 2.8051, Validation Loss Current: 7.7845, Validation Loss AVG: 11.9274, lr: 0.001
Epoch [72/100], Training Loss: 5.1257, Validation Loss Current: 7.7635, Validation Loss AVG: 14.5226, lr: 0.001
Epoch [73/100], Training Loss: 2.5033, Validation Loss Current: 7.6495, Validation Loss AVG: 11.0342, lr: 0.001
Epoch [74/100], Training Loss: 3.7282, Validation Loss Current: 7.2439, Validation Loss AVG: 12.4301, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 44 Best val accuracy: [0.22861842105263158, 0.3338815789473684, 0.3207236842105263, 0.35526315789473684, 0.39144736842105265, 0.39144736842105265, 0.4292763157894737, 0.4506578947368421, 0.4720394736842105, 0.49835526315789475, 0.4934210526315789, 0.5394736842105263, 0.4934210526315789, 0.5098684210526315, 0.5263157894736842, 0.5476973684210527, 0.5641447368421053, 0.5427631578947368, 0.5296052631578947, 0.524671052631579, 0.5526315789473685, 0.5427631578947368, 0.5032894736842105, 0.5641447368421053, 0.5855263157894737, 0.5427631578947368, 0.5674342105263158, 0.569078947368421, 0.5888157894736842, 0.5822368421052632, 0.618421052631579, 0.5411184210526315, 0.6085526315789473, 0.506578947368421, 0.5032894736842105, 0.5707236842105263, 0.5888157894736842, 0.4868421052631579, 0.6118421052631579, 0.6233552631578947, 0.5822368421052632, 0.6200657894736842, 0.5575657894736842, 0.6365131578947368, 0.6167763157894737, 0.555921052631579, 0.6085526315789473, 0.5970394736842105, 0.5756578947368421, 0.6036184210526315, 0.5707236842105263, 0.6019736842105263, 0.6134868421052632, 0.5986842105263158, 0.5756578947368421, 0.5740131578947368, 0.5921052631578947, 0.6151315789473685, 0.5049342105263158, 0.600328947368421, 0.6134868421052632, 0.6200657894736842, 0.59375, 0.625, 0.6085526315789473, 0.5970394736842105, 0.5460526315789473, 0.6069078947368421, 0.6200657894736842, 0.5986842105263158, 0.5723684210526315, 0.6200657894736842, 0.5855263157894737, 0.6019736842105263] Best val loss: 5.658722519874573


Current group: 0.8
Epoch [1/100], Training Loss: 21.3666, Validation Loss Current: 11.9184, Validation Loss AVG: 11.9184, lr: 0.001
Epoch [2/100], Training Loss: 18.0155, Validation Loss Current: 10.3540, Validation Loss AVG: 10.3540, lr: 0.001
Epoch [3/100], Training Loss: 12.3724, Validation Loss Current: 9.6769, Validation Loss AVG: 9.6769, lr: 0.001
Epoch [4/100], Training Loss: 13.6757, Validation Loss Current: 9.8989, Validation Loss AVG: 9.8989, lr: 0.001
Epoch [5/100], Training Loss: 11.6370, Validation Loss Current: 11.2778, Validation Loss AVG: 11.2778, lr: 0.001
Epoch [6/100], Training Loss: 8.1607, Validation Loss Current: 9.3381, Validation Loss AVG: 9.3381, lr: 0.001
Epoch [7/100], Training Loss: 7.3451, Validation Loss Current: 13.9330, Validation Loss AVG: 13.9330, lr: 0.001
Epoch [8/100], Training Loss: 6.8324, Validation Loss Current: 8.9784, Validation Loss AVG: 8.9784, lr: 0.001
Epoch [9/100], Training Loss: 7.8994, Validation Loss Current: 10.2247, Validation Loss AVG: 10.2247, lr: 0.001
Epoch [10/100], Training Loss: 4.7602, Validation Loss Current: 10.7771, Validation Loss AVG: 10.7771, lr: 0.001
Epoch [11/100], Training Loss: 3.8950, Validation Loss Current: 9.9568, Validation Loss AVG: 9.9568, lr: 0.001
Epoch [12/100], Training Loss: 4.7058, Validation Loss Current: 9.9287, Validation Loss AVG: 9.9287, lr: 0.001
Epoch [13/100], Training Loss: 3.8126, Validation Loss Current: 12.1176, Validation Loss AVG: 12.1176, lr: 0.001
Epoch [14/100], Training Loss: 2.2614, Validation Loss Current: 9.7179, Validation Loss AVG: 9.7179, lr: 0.001
Epoch [15/100], Training Loss: 1.5429, Validation Loss Current: 10.0669, Validation Loss AVG: 10.0669, lr: 0.001
Epoch [16/100], Training Loss: 2.8181, Validation Loss Current: 11.5427, Validation Loss AVG: 11.5427, lr: 0.001
Epoch [17/100], Training Loss: 6.0237, Validation Loss Current: 10.8295, Validation Loss AVG: 10.8295, lr: 0.001
Epoch [18/100], Training Loss: 4.5559, Validation Loss Current: 12.8523, Validation Loss AVG: 12.8523, lr: 0.001
Epoch [19/100], Training Loss: 8.1805, Validation Loss Current: 15.0825, Validation Loss AVG: 15.0825, lr: 0.001
Epoch [20/100], Training Loss: 11.1226, Validation Loss Current: 10.1738, Validation Loss AVG: 10.1738, lr: 0.001
Epoch [21/100], Training Loss: 8.3858, Validation Loss Current: 11.1648, Validation Loss AVG: 11.1648, lr: 0.001
Epoch [22/100], Training Loss: 4.9337, Validation Loss Current: 12.4763, Validation Loss AVG: 12.4763, lr: 0.001
Epoch [23/100], Training Loss: 3.6884, Validation Loss Current: 10.9855, Validation Loss AVG: 10.9855, lr: 0.001
Epoch [24/100], Training Loss: 3.1472, Validation Loss Current: 10.0179, Validation Loss AVG: 10.0179, lr: 0.001
Epoch [25/100], Training Loss: 2.5996, Validation Loss Current: 11.2882, Validation Loss AVG: 11.2882, lr: 0.001
Epoch [26/100], Training Loss: 1.8730, Validation Loss Current: 9.9309, Validation Loss AVG: 9.9309, lr: 0.001
Epoch [27/100], Training Loss: 3.7589, Validation Loss Current: 11.7536, Validation Loss AVG: 11.7536, lr: 0.001
Epoch [28/100], Training Loss: 8.6048, Validation Loss Current: 20.8633, Validation Loss AVG: 20.8633, lr: 0.001
Epoch [29/100], Training Loss: 10.7864, Validation Loss Current: 10.3000, Validation Loss AVG: 10.3000, lr: 0.001
Epoch [30/100], Training Loss: 7.3569, Validation Loss Current: 10.3615, Validation Loss AVG: 10.3615, lr: 0.001
Epoch [31/100], Training Loss: 3.8366, Validation Loss Current: 10.6107, Validation Loss AVG: 10.6107, lr: 0.001
Epoch [32/100], Training Loss: 2.8081, Validation Loss Current: 12.7261, Validation Loss AVG: 12.7261, lr: 0.001
Epoch [33/100], Training Loss: 2.7869, Validation Loss Current: 10.5826, Validation Loss AVG: 10.5826, lr: 0.001
Epoch [34/100], Training Loss: 2.0226, Validation Loss Current: 12.0894, Validation Loss AVG: 12.0894, lr: 0.001
Epoch [35/100], Training Loss: 2.4473, Validation Loss Current: 12.9750, Validation Loss AVG: 12.9750, lr: 0.001
Epoch [36/100], Training Loss: 3.4969, Validation Loss Current: 12.0874, Validation Loss AVG: 12.0874, lr: 0.001
Epoch [37/100], Training Loss: 3.0148, Validation Loss Current: 14.6871, Validation Loss AVG: 14.6871, lr: 0.001
Epoch [38/100], Training Loss: 3.7870, Validation Loss Current: 11.1371, Validation Loss AVG: 11.1371, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 8 Best val accuracy: [0.42467105263157895, 0.43125, 0.4641447368421052, 0.43881578947368416, 0.4598684210526316, 0.4516447368421053, 0.39671052631578946, 0.47203947368421045, 0.4618421052631579, 0.44046052631578947, 0.4605263157894736, 0.46578947368421053, 0.43815789473684214, 0.46940789473684214, 0.4736842105263158, 0.4358552631578948, 0.45723684210526316, 0.4536184210526316, 0.3851973684210526, 0.43256578947368424, 0.4740131578947368, 0.43881578947368427, 0.43157894736842106, 0.4513157894736842, 0.4703947368421052, 0.48190789473684215, 0.43256578947368424, 0.36776315789473685, 0.4384868421052632, 0.4828947368421053, 0.4358552631578948, 0.45032894736842105, 0.47697368421052627, 0.4598684210526316, 0.43717105263157896, 0.47368421052631576, 0.41546052631578945, 0.47006578947368427] Best val loss: 8.978427350521088


Current group: 0.6
Epoch [1/100], Training Loss: 27.6061, Validation Loss Current: 21.0996, Validation Loss AVG: 21.0996, lr: 0.001
Epoch [2/100], Training Loss: 19.5262, Validation Loss Current: 12.5981, Validation Loss AVG: 12.5981, lr: 0.001
Epoch [3/100], Training Loss: 16.4528, Validation Loss Current: 14.5424, Validation Loss AVG: 14.5424, lr: 0.001
Epoch [4/100], Training Loss: 13.1054, Validation Loss Current: 12.6428, Validation Loss AVG: 12.6428, lr: 0.001
Epoch [5/100], Training Loss: 11.4443, Validation Loss Current: 10.7212, Validation Loss AVG: 10.7212, lr: 0.001
Epoch [6/100], Training Loss: 7.3164, Validation Loss Current: 9.5290, Validation Loss AVG: 9.5290, lr: 0.001
Epoch [7/100], Training Loss: 8.9101, Validation Loss Current: 12.9338, Validation Loss AVG: 12.9338, lr: 0.001
Epoch [8/100], Training Loss: 6.9697, Validation Loss Current: 10.1790, Validation Loss AVG: 10.1790, lr: 0.001
Epoch [9/100], Training Loss: 5.0745, Validation Loss Current: 10.1061, Validation Loss AVG: 10.1061, lr: 0.001
Epoch [10/100], Training Loss: 5.3918, Validation Loss Current: 11.5055, Validation Loss AVG: 11.5055, lr: 0.001
Epoch [11/100], Training Loss: 8.4473, Validation Loss Current: 12.7468, Validation Loss AVG: 12.7468, lr: 0.001
Epoch [12/100], Training Loss: 8.3634, Validation Loss Current: 11.3819, Validation Loss AVG: 11.3819, lr: 0.001
Epoch [13/100], Training Loss: 5.7612, Validation Loss Current: 10.7938, Validation Loss AVG: 10.7938, lr: 0.001
Epoch [14/100], Training Loss: 6.9116, Validation Loss Current: 11.4522, Validation Loss AVG: 11.4522, lr: 0.001
Epoch [15/100], Training Loss: 9.7883, Validation Loss Current: 13.4349, Validation Loss AVG: 13.4349, lr: 0.001
Epoch [16/100], Training Loss: 6.5486, Validation Loss Current: 11.6444, Validation Loss AVG: 11.6444, lr: 0.001
Epoch [17/100], Training Loss: 4.8376, Validation Loss Current: 11.9491, Validation Loss AVG: 11.9491, lr: 0.001
Epoch [18/100], Training Loss: 5.1169, Validation Loss Current: 11.2430, Validation Loss AVG: 11.2430, lr: 0.001
Epoch [19/100], Training Loss: 3.3295, Validation Loss Current: 10.3584, Validation Loss AVG: 10.3584, lr: 0.001
Epoch [20/100], Training Loss: 6.5506, Validation Loss Current: 13.5825, Validation Loss AVG: 13.5825, lr: 0.001
Epoch [21/100], Training Loss: 2.7610, Validation Loss Current: 10.6299, Validation Loss AVG: 10.6299, lr: 0.001
Epoch [22/100], Training Loss: 3.1971, Validation Loss Current: 12.0004, Validation Loss AVG: 12.0004, lr: 0.001
Epoch [23/100], Training Loss: 3.2710, Validation Loss Current: 10.5149, Validation Loss AVG: 10.5149, lr: 0.001
Epoch [24/100], Training Loss: 2.5277, Validation Loss Current: 13.0106, Validation Loss AVG: 13.0106, lr: 0.001
Epoch [25/100], Training Loss: 3.3065, Validation Loss Current: 12.5174, Validation Loss AVG: 12.5174, lr: 0.001
Epoch [26/100], Training Loss: 3.2406, Validation Loss Current: 12.0245, Validation Loss AVG: 12.0245, lr: 0.001
Epoch [27/100], Training Loss: 2.7265, Validation Loss Current: 13.8989, Validation Loss AVG: 13.8989, lr: 0.001
Epoch [28/100], Training Loss: 2.5998, Validation Loss Current: 11.5080, Validation Loss AVG: 11.5080, lr: 0.001
Epoch [29/100], Training Loss: 2.0530, Validation Loss Current: 12.4021, Validation Loss AVG: 12.4021, lr: 0.001
Epoch [30/100], Training Loss: 4.0648, Validation Loss Current: 12.4998, Validation Loss AVG: 12.4998, lr: 0.001
Epoch [31/100], Training Loss: 2.9768, Validation Loss Current: 12.3821, Validation Loss AVG: 12.3821, lr: 0.001
Epoch [32/100], Training Loss: 2.9955, Validation Loss Current: 14.3274, Validation Loss AVG: 14.3274, lr: 0.001
Epoch [33/100], Training Loss: 1.6951, Validation Loss Current: 11.2144, Validation Loss AVG: 11.2144, lr: 0.001
Epoch [34/100], Training Loss: 1.4243, Validation Loss Current: 11.3193, Validation Loss AVG: 11.3193, lr: 0.001
Epoch [35/100], Training Loss: 1.6564, Validation Loss Current: 12.3269, Validation Loss AVG: 12.3269, lr: 0.001
Epoch [36/100], Training Loss: 3.2609, Validation Loss Current: 15.1428, Validation Loss AVG: 15.1428, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 6 Best val accuracy: [0.2825657894736842, 0.4240131578947368, 0.3299342105263158, 0.4391447368421053, 0.43125, 0.46809210526315786, 0.4582236842105264, 0.45131578947368417, 0.48848684210526316, 0.4546052631578948, 0.4236842105263158, 0.41447368421052627, 0.4848684210526316, 0.4805921052631579, 0.43552631578947365, 0.469078947368421, 0.43684210526315786, 0.4766447368421053, 0.45723684210526316, 0.4631578947368421, 0.4911184210526315, 0.4697368421052632, 0.4914473684210526, 0.48355263157894735, 0.47796052631578945, 0.4493421052631579, 0.4743421052631579, 0.4792763157894736, 0.47697368421052627, 0.46217105263157904, 0.4740131578947368, 0.44375, 0.4930921052631579, 0.48881578947368426, 0.48355263157894735, 0.46118421052631575] Best val loss: 9.529040455818176


Current group: 0.4
Epoch [1/100], Training Loss: 34.6736, Validation Loss Current: 16.3388, Validation Loss AVG: 16.3388, lr: 0.001
Epoch [2/100], Training Loss: 21.3345, Validation Loss Current: 11.6763, Validation Loss AVG: 11.6763, lr: 0.001
Epoch [3/100], Training Loss: 14.2757, Validation Loss Current: 12.3190, Validation Loss AVG: 12.3190, lr: 0.001
Epoch [4/100], Training Loss: 11.3966, Validation Loss Current: 10.7858, Validation Loss AVG: 10.7858, lr: 0.001
Epoch [5/100], Training Loss: 9.2077, Validation Loss Current: 10.2832, Validation Loss AVG: 10.2832, lr: 0.001
Epoch [6/100], Training Loss: 7.8830, Validation Loss Current: 10.2518, Validation Loss AVG: 10.2518, lr: 0.001
Epoch [7/100], Training Loss: 6.7686, Validation Loss Current: 13.1575, Validation Loss AVG: 13.1575, lr: 0.001
Epoch [8/100], Training Loss: 4.6640, Validation Loss Current: 10.4414, Validation Loss AVG: 10.4414, lr: 0.001
Epoch [9/100], Training Loss: 3.6943, Validation Loss Current: 10.5907, Validation Loss AVG: 10.5907, lr: 0.001
Epoch [10/100], Training Loss: 4.3960, Validation Loss Current: 11.5121, Validation Loss AVG: 11.5121, lr: 0.001
Epoch [11/100], Training Loss: 3.5165, Validation Loss Current: 11.5931, Validation Loss AVG: 11.5931, lr: 0.001
Epoch [12/100], Training Loss: 6.6499, Validation Loss Current: 17.2263, Validation Loss AVG: 17.2263, lr: 0.001
Epoch [13/100], Training Loss: 6.3718, Validation Loss Current: 16.6578, Validation Loss AVG: 16.6578, lr: 0.001
Epoch [14/100], Training Loss: 9.2465, Validation Loss Current: 16.1018, Validation Loss AVG: 16.1018, lr: 0.001
Epoch [15/100], Training Loss: 4.3316, Validation Loss Current: 11.3443, Validation Loss AVG: 11.3443, lr: 0.001
Epoch [16/100], Training Loss: 2.6150, Validation Loss Current: 13.4436, Validation Loss AVG: 13.4436, lr: 0.001
Epoch [17/100], Training Loss: 1.9407, Validation Loss Current: 12.6721, Validation Loss AVG: 12.6721, lr: 0.001
Epoch [18/100], Training Loss: 2.5004, Validation Loss Current: 13.1824, Validation Loss AVG: 13.1824, lr: 0.001
Epoch [19/100], Training Loss: 5.9159, Validation Loss Current: 14.3886, Validation Loss AVG: 14.3886, lr: 0.001
Epoch [20/100], Training Loss: 8.0383, Validation Loss Current: 15.1667, Validation Loss AVG: 15.1667, lr: 0.001
Epoch [21/100], Training Loss: 8.6151, Validation Loss Current: 17.9836, Validation Loss AVG: 17.9836, lr: 0.001
Epoch [22/100], Training Loss: 7.5148, Validation Loss Current: 14.1340, Validation Loss AVG: 14.1340, lr: 0.001
Epoch [23/100], Training Loss: 5.1041, Validation Loss Current: 15.7342, Validation Loss AVG: 15.7342, lr: 0.001
Epoch [24/100], Training Loss: 9.0560, Validation Loss Current: 14.3837, Validation Loss AVG: 14.3837, lr: 0.001
Epoch [25/100], Training Loss: 3.5772, Validation Loss Current: 12.5997, Validation Loss AVG: 12.5997, lr: 0.001
Epoch [26/100], Training Loss: 2.5073, Validation Loss Current: 13.1252, Validation Loss AVG: 13.1252, lr: 0.001
Epoch [27/100], Training Loss: 5.1845, Validation Loss Current: 11.8616, Validation Loss AVG: 11.8616, lr: 0.001
Epoch [28/100], Training Loss: 2.4045, Validation Loss Current: 12.9990, Validation Loss AVG: 12.9990, lr: 0.001
Epoch [29/100], Training Loss: 5.0397, Validation Loss Current: 13.9699, Validation Loss AVG: 13.9699, lr: 0.001
Epoch [30/100], Training Loss: 5.0870, Validation Loss Current: 14.6236, Validation Loss AVG: 14.6236, lr: 0.001
Epoch [31/100], Training Loss: 9.0172, Validation Loss Current: 13.6852, Validation Loss AVG: 13.6852, lr: 0.001
Epoch [32/100], Training Loss: 2.5466, Validation Loss Current: 13.8634, Validation Loss AVG: 13.8634, lr: 0.001
Epoch [33/100], Training Loss: 4.0994, Validation Loss Current: 14.7288, Validation Loss AVG: 14.7288, lr: 0.001
Epoch [34/100], Training Loss: 7.3800, Validation Loss Current: 14.6156, Validation Loss AVG: 14.6156, lr: 0.001
Epoch [35/100], Training Loss: 2.7506, Validation Loss Current: 12.4453, Validation Loss AVG: 12.4453, lr: 0.001
Epoch [36/100], Training Loss: 0.9891, Validation Loss Current: 11.5585, Validation Loss AVG: 11.5585, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 6 Best val accuracy: [0.3907894736842105, 0.45000000000000007, 0.43486842105263157, 0.46052631578947373, 0.4911184210526315, 0.48125, 0.4480263157894737, 0.4723684210526316, 0.4875, 0.45921052631578946, 0.44243421052631576, 0.40625, 0.3921052631578948, 0.40921052631578947, 0.4759868421052632, 0.4427631578947369, 0.45756578947368426, 0.47730263157894737, 0.39473684210526316, 0.43618421052631573, 0.31480263157894733, 0.4519736842105263, 0.39342105263157895, 0.4236842105263158, 0.4671052631578948, 0.4473684210526316, 0.4875, 0.4509868421052632, 0.4552631578947368, 0.4565789473684211, 0.45625, 0.41480263157894737, 0.4391447368421052, 0.39802631578947373, 0.46282894736842106, 0.4848684210526316] Best val loss: 10.251799845695496


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4, 0.2] -----
Current group: 1
Epoch [1/80], Training Loss: 40.3285, Validation Loss Current: 9.8550, Validation Loss AVG: 9.9604, lr: 0.001
Epoch [2/80], Training Loss: 38.5671, Validation Loss Current: 9.3077, Validation Loss AVG: 10.2210, lr: 0.001
Epoch [3/80], Training Loss: 36.7759, Validation Loss Current: 8.8372, Validation Loss AVG: 10.0204, lr: 0.001
Epoch [4/80], Training Loss: 34.6836, Validation Loss Current: 8.4689, Validation Loss AVG: 9.5373, lr: 0.001
Epoch [5/80], Training Loss: 33.3130, Validation Loss Current: 8.2353, Validation Loss AVG: 9.5387, lr: 0.001
Epoch [6/80], Training Loss: 32.4261, Validation Loss Current: 8.3076, Validation Loss AVG: 9.7798, lr: 0.001
Epoch [7/80], Training Loss: 31.0197, Validation Loss Current: 7.3370, Validation Loss AVG: 9.3912, lr: 0.001
Epoch [8/80], Training Loss: 29.2589, Validation Loss Current: 7.3029, Validation Loss AVG: 9.9240, lr: 0.001
Epoch [9/80], Training Loss: 28.5016, Validation Loss Current: 7.6244, Validation Loss AVG: 9.1691, lr: 0.001
Epoch [10/80], Training Loss: 27.3660, Validation Loss Current: 7.0117, Validation Loss AVG: 9.6180, lr: 0.001
Epoch [11/80], Training Loss: 25.6335, Validation Loss Current: 6.5844, Validation Loss AVG: 8.7770, lr: 0.001
Epoch [12/80], Training Loss: 24.8180, Validation Loss Current: 6.8068, Validation Loss AVG: 8.7024, lr: 0.001
Epoch [13/80], Training Loss: 24.2520, Validation Loss Current: 6.8420, Validation Loss AVG: 11.7397, lr: 0.001
Epoch [14/80], Training Loss: 23.8686, Validation Loss Current: 6.7631, Validation Loss AVG: 8.3539, lr: 0.001
Epoch [15/80], Training Loss: 24.5519, Validation Loss Current: 6.1780, Validation Loss AVG: 9.0691, lr: 0.001
Epoch [16/80], Training Loss: 23.1548, Validation Loss Current: 6.7146, Validation Loss AVG: 11.6544, lr: 0.001
Epoch [17/80], Training Loss: 20.9030, Validation Loss Current: 6.1499, Validation Loss AVG: 9.3748, lr: 0.001
Epoch [18/80], Training Loss: 22.1491, Validation Loss Current: 6.7590, Validation Loss AVG: 13.1365, lr: 0.001
Epoch [19/80], Training Loss: 21.6872, Validation Loss Current: 6.7370, Validation Loss AVG: 11.1088, lr: 0.001
Epoch [20/80], Training Loss: 20.2701, Validation Loss Current: 6.3488, Validation Loss AVG: 8.5328, lr: 0.001
Epoch [21/80], Training Loss: 19.3609, Validation Loss Current: 5.9322, Validation Loss AVG: 9.0364, lr: 0.001
Epoch [22/80], Training Loss: 18.0546, Validation Loss Current: 5.9973, Validation Loss AVG: 8.7985, lr: 0.001
Epoch [23/80], Training Loss: 16.7073, Validation Loss Current: 6.0102, Validation Loss AVG: 10.6065, lr: 0.001
Epoch [24/80], Training Loss: 17.2958, Validation Loss Current: 5.7310, Validation Loss AVG: 8.3146, lr: 0.001
Epoch [25/80], Training Loss: 17.2986, Validation Loss Current: 6.4955, Validation Loss AVG: 13.0655, lr: 0.001
Epoch [26/80], Training Loss: 17.8578, Validation Loss Current: 6.0654, Validation Loss AVG: 9.2690, lr: 0.001
Epoch [27/80], Training Loss: 18.2244, Validation Loss Current: 5.6405, Validation Loss AVG: 8.5165, lr: 0.001
Epoch [28/80], Training Loss: 15.9218, Validation Loss Current: 5.5597, Validation Loss AVG: 9.7372, lr: 0.001
Epoch [29/80], Training Loss: 15.1328, Validation Loss Current: 5.4551, Validation Loss AVG: 10.1925, lr: 0.001
Epoch [30/80], Training Loss: 13.4237, Validation Loss Current: 5.2671, Validation Loss AVG: 11.0037, lr: 0.001
Epoch [31/80], Training Loss: 13.0275, Validation Loss Current: 5.4138, Validation Loss AVG: 9.4021, lr: 0.001
Epoch [32/80], Training Loss: 13.5323, Validation Loss Current: 7.1956, Validation Loss AVG: 9.9974, lr: 0.001
Epoch [33/80], Training Loss: 12.8535, Validation Loss Current: 5.3148, Validation Loss AVG: 9.7935, lr: 0.001
Epoch [34/80], Training Loss: 10.9725, Validation Loss Current: 5.5815, Validation Loss AVG: 9.6253, lr: 0.001
Epoch [35/80], Training Loss: 9.8082, Validation Loss Current: 5.7044, Validation Loss AVG: 15.2971, lr: 0.001
Epoch [36/80], Training Loss: 8.4358, Validation Loss Current: 5.3531, Validation Loss AVG: 8.9389, lr: 0.001
Epoch [37/80], Training Loss: 8.3464, Validation Loss Current: 5.4845, Validation Loss AVG: 10.4419, lr: 0.001
Epoch [38/80], Training Loss: 8.6972, Validation Loss Current: 5.6434, Validation Loss AVG: 11.5075, lr: 0.001
Epoch [39/80], Training Loss: 8.9297, Validation Loss Current: 5.5828, Validation Loss AVG: 9.8242, lr: 0.001
Epoch [40/80], Training Loss: 7.4257, Validation Loss Current: 5.6650, Validation Loss AVG: 11.9200, lr: 0.001
Epoch [41/80], Training Loss: 6.2477, Validation Loss Current: 6.2305, Validation Loss AVG: 8.9816, lr: 0.001
Epoch [42/80], Training Loss: 7.5561, Validation Loss Current: 5.5394, Validation Loss AVG: 8.8317, lr: 0.001
Epoch [43/80], Training Loss: 9.3815, Validation Loss Current: 6.6163, Validation Loss AVG: 8.5754, lr: 0.001
Epoch [44/80], Training Loss: 5.6704, Validation Loss Current: 5.7473, Validation Loss AVG: 10.5886, lr: 0.001
Epoch [45/80], Training Loss: 5.0229, Validation Loss Current: 6.3924, Validation Loss AVG: 15.2990, lr: 0.001
Epoch [46/80], Training Loss: 5.4465, Validation Loss Current: 6.6631, Validation Loss AVG: 12.6416, lr: 0.001
Epoch [47/80], Training Loss: 4.3800, Validation Loss Current: 5.7764, Validation Loss AVG: 11.8077, lr: 0.001
Epoch [48/80], Training Loss: 3.5620, Validation Loss Current: 5.3050, Validation Loss AVG: 8.9337, lr: 0.001
Epoch [49/80], Training Loss: 2.7869, Validation Loss Current: 5.7453, Validation Loss AVG: 10.2778, lr: 0.001
Epoch [50/80], Training Loss: 3.1057, Validation Loss Current: 5.8569, Validation Loss AVG: 9.2852, lr: 0.001
Epoch [51/80], Training Loss: 3.9725, Validation Loss Current: 6.4716, Validation Loss AVG: 8.6841, lr: 0.001
Epoch [52/80], Training Loss: 3.8255, Validation Loss Current: 6.6374, Validation Loss AVG: 10.6482, lr: 0.001
Epoch [53/80], Training Loss: 2.9236, Validation Loss Current: 6.1360, Validation Loss AVG: 11.4023, lr: 0.001
Epoch [54/80], Training Loss: 1.9115, Validation Loss Current: 5.9967, Validation Loss AVG: 9.8945, lr: 0.001
Epoch [55/80], Training Loss: 4.0089, Validation Loss Current: 5.6077, Validation Loss AVG: 11.9367, lr: 0.001
Epoch [56/80], Training Loss: 6.2722, Validation Loss Current: 7.7846, Validation Loss AVG: 15.6027, lr: 0.001
Epoch [57/80], Training Loss: 19.0906, Validation Loss Current: 8.6426, Validation Loss AVG: 12.1931, lr: 0.001
Epoch [58/80], Training Loss: 10.5556, Validation Loss Current: 10.8742, Validation Loss AVG: 12.3445, lr: 0.001
Epoch [59/80], Training Loss: 11.1126, Validation Loss Current: 6.9630, Validation Loss AVG: 10.3638, lr: 0.001
Epoch [60/80], Training Loss: 7.4236, Validation Loss Current: 6.6230, Validation Loss AVG: 14.0801, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 30 Best val accuracy: [0.25, 0.34539473684210525, 0.3470394736842105, 0.3815789473684211, 0.4194078947368421, 0.40625, 0.46710526315789475, 0.4819078947368421, 0.43585526315789475, 0.5, 0.5345394736842105, 0.5197368421052632, 0.5197368421052632, 0.4967105263157895, 0.5674342105263158, 0.5296052631578947, 0.569078947368421, 0.5641447368421053, 0.5345394736842105, 0.5625, 0.5740131578947368, 0.5723684210526315, 0.5822368421052632, 0.6101973684210527, 0.5805921052631579, 0.5953947368421053, 0.600328947368421, 0.625, 0.6217105263157895, 0.6332236842105263, 0.6266447368421053, 0.5493421052631579, 0.6414473684210527, 0.6151315789473685, 0.618421052631579, 0.6332236842105263, 0.6217105263157895, 0.6233552631578947, 0.6299342105263158, 0.625, 0.6233552631578947, 0.6167763157894737, 0.5444078947368421, 0.6513157894736842, 0.6019736842105263, 0.5855263157894737, 0.6167763157894737, 0.6546052631578947, 0.631578947368421, 0.6299342105263158, 0.5904605263157895, 0.6167763157894737, 0.6348684210526315, 0.6463815789473685, 0.6282894736842105, 0.5493421052631579, 0.5361842105263158, 0.3963815789473684, 0.5427631578947368, 0.6101973684210527] Best val loss: 5.267132818698883


Current group: 0.8
Epoch [1/80], Training Loss: 23.1675, Validation Loss Current: 8.8984, Validation Loss AVG: 8.8984, lr: 0.001
Epoch [2/80], Training Loss: 18.6085, Validation Loss Current: 11.1351, Validation Loss AVG: 11.1351, lr: 0.001
Epoch [3/80], Training Loss: 14.1043, Validation Loss Current: 10.6646, Validation Loss AVG: 10.6646, lr: 0.001
Epoch [4/80], Training Loss: 12.1999, Validation Loss Current: 8.0096, Validation Loss AVG: 8.0096, lr: 0.001
Epoch [5/80], Training Loss: 9.6674, Validation Loss Current: 10.9245, Validation Loss AVG: 10.9245, lr: 0.001
Epoch [6/80], Training Loss: 9.8162, Validation Loss Current: 9.7272, Validation Loss AVG: 9.7272, lr: 0.001
Epoch [7/80], Training Loss: 11.7161, Validation Loss Current: 10.0394, Validation Loss AVG: 10.0394, lr: 0.001
Epoch [8/80], Training Loss: 8.6076, Validation Loss Current: 11.3139, Validation Loss AVG: 11.3139, lr: 0.001
Epoch [9/80], Training Loss: 8.1462, Validation Loss Current: 11.1975, Validation Loss AVG: 11.1975, lr: 0.001
Epoch [10/80], Training Loss: 6.2309, Validation Loss Current: 9.5686, Validation Loss AVG: 9.5686, lr: 0.001
Epoch [11/80], Training Loss: 9.6072, Validation Loss Current: 14.3160, Validation Loss AVG: 14.3160, lr: 0.001
Epoch [12/80], Training Loss: 10.0102, Validation Loss Current: 9.5204, Validation Loss AVG: 9.5204, lr: 0.001
Epoch [13/80], Training Loss: 5.6781, Validation Loss Current: 11.4473, Validation Loss AVG: 11.4473, lr: 0.001
Epoch [14/80], Training Loss: 4.2829, Validation Loss Current: 9.0870, Validation Loss AVG: 9.0870, lr: 0.001
Epoch [15/80], Training Loss: 6.3582, Validation Loss Current: 12.6623, Validation Loss AVG: 12.6623, lr: 0.001
Epoch [16/80], Training Loss: 4.6393, Validation Loss Current: 9.2557, Validation Loss AVG: 9.2557, lr: 0.001
Epoch [17/80], Training Loss: 4.4874, Validation Loss Current: 10.8275, Validation Loss AVG: 10.8275, lr: 0.001
Epoch [18/80], Training Loss: 4.1363, Validation Loss Current: 10.1400, Validation Loss AVG: 10.1400, lr: 0.001
Epoch [19/80], Training Loss: 5.2841, Validation Loss Current: 14.2849, Validation Loss AVG: 14.2849, lr: 0.001
Epoch [20/80], Training Loss: 7.2288, Validation Loss Current: 10.1710, Validation Loss AVG: 10.1710, lr: 0.001
Epoch [21/80], Training Loss: 5.0731, Validation Loss Current: 10.0182, Validation Loss AVG: 10.0182, lr: 0.001
Epoch [22/80], Training Loss: 5.0120, Validation Loss Current: 10.4635, Validation Loss AVG: 10.4635, lr: 0.001
Epoch [23/80], Training Loss: 5.1237, Validation Loss Current: 12.6842, Validation Loss AVG: 12.6842, lr: 0.001
Epoch [24/80], Training Loss: 5.1736, Validation Loss Current: 11.5892, Validation Loss AVG: 11.5892, lr: 0.001
Epoch [25/80], Training Loss: 3.9492, Validation Loss Current: 11.1521, Validation Loss AVG: 11.1521, lr: 0.001
Epoch [26/80], Training Loss: 4.4643, Validation Loss Current: 10.5639, Validation Loss AVG: 10.5639, lr: 0.001
Epoch [27/80], Training Loss: 5.1304, Validation Loss Current: 12.0984, Validation Loss AVG: 12.0984, lr: 0.001
Epoch [28/80], Training Loss: 6.6137, Validation Loss Current: 14.2202, Validation Loss AVG: 14.2202, lr: 0.001
Epoch [29/80], Training Loss: 3.4712, Validation Loss Current: 10.4571, Validation Loss AVG: 10.4571, lr: 0.001
Epoch [30/80], Training Loss: 4.0611, Validation Loss Current: 12.2723, Validation Loss AVG: 12.2723, lr: 0.001
Epoch [31/80], Training Loss: 4.6593, Validation Loss Current: 10.7723, Validation Loss AVG: 10.7723, lr: 0.001
Epoch [32/80], Training Loss: 3.1628, Validation Loss Current: 12.0447, Validation Loss AVG: 12.0447, lr: 0.001
Epoch [33/80], Training Loss: 3.1690, Validation Loss Current: 12.1213, Validation Loss AVG: 12.1213, lr: 0.001
Epoch [34/80], Training Loss: 2.7847, Validation Loss Current: 11.5543, Validation Loss AVG: 11.5543, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.43684210526315786, 0.3921052631578947, 0.38782894736842105, 0.4726973684210526, 0.43552631578947365, 0.4394736842105263, 0.40394736842105267, 0.4302631578947368, 0.4161184210526316, 0.43684210526315786, 0.3766447368421053, 0.43980263157894733, 0.4536184210526316, 0.44342105263157894, 0.4309210526315789, 0.48190789473684215, 0.4723684210526316, 0.44703947368421054, 0.38881578947368417, 0.45756578947368426, 0.4776315789473684, 0.43157894736842106, 0.4411184210526316, 0.42269736842105265, 0.4618421052631579, 0.4384868421052632, 0.4384868421052632, 0.43519736842105256, 0.46677631578947365, 0.44243421052631576, 0.4292763157894736, 0.4496710526315789, 0.44868421052631585, 0.4207236842105263] Best val loss: 8.009649538993836


Current group: 0.6
Epoch [1/80], Training Loss: 26.6442, Validation Loss Current: 14.2761, Validation Loss AVG: 14.2761, lr: 0.001
Epoch [2/80], Training Loss: 16.3081, Validation Loss Current: 11.2006, Validation Loss AVG: 11.2006, lr: 0.001
Epoch [3/80], Training Loss: 13.6169, Validation Loss Current: 10.8880, Validation Loss AVG: 10.8880, lr: 0.001
Epoch [4/80], Training Loss: 11.0218, Validation Loss Current: 14.4077, Validation Loss AVG: 14.4077, lr: 0.001
Epoch [5/80], Training Loss: 11.1970, Validation Loss Current: 11.3226, Validation Loss AVG: 11.3226, lr: 0.001
Epoch [6/80], Training Loss: 8.2066, Validation Loss Current: 9.4745, Validation Loss AVG: 9.4745, lr: 0.001
Epoch [7/80], Training Loss: 8.5926, Validation Loss Current: 10.7167, Validation Loss AVG: 10.7167, lr: 0.001
Epoch [8/80], Training Loss: 6.4213, Validation Loss Current: 10.8313, Validation Loss AVG: 10.8313, lr: 0.001
Epoch [9/80], Training Loss: 9.4569, Validation Loss Current: 12.6666, Validation Loss AVG: 12.6666, lr: 0.001
Epoch [10/80], Training Loss: 7.4152, Validation Loss Current: 9.8631, Validation Loss AVG: 9.8631, lr: 0.001
Epoch [11/80], Training Loss: 7.3260, Validation Loss Current: 10.3053, Validation Loss AVG: 10.3053, lr: 0.001
Epoch [12/80], Training Loss: 7.0224, Validation Loss Current: 11.3915, Validation Loss AVG: 11.3915, lr: 0.001
Epoch [13/80], Training Loss: 4.5688, Validation Loss Current: 9.8757, Validation Loss AVG: 9.8757, lr: 0.001
Epoch [14/80], Training Loss: 5.8922, Validation Loss Current: 11.4234, Validation Loss AVG: 11.4234, lr: 0.001
Epoch [15/80], Training Loss: 3.1984, Validation Loss Current: 11.7426, Validation Loss AVG: 11.7426, lr: 0.001
Epoch [16/80], Training Loss: 4.6322, Validation Loss Current: 12.1047, Validation Loss AVG: 12.1047, lr: 0.001
Epoch [17/80], Training Loss: 5.3352, Validation Loss Current: 11.0594, Validation Loss AVG: 11.0594, lr: 0.001
Epoch [18/80], Training Loss: 7.5031, Validation Loss Current: 13.0842, Validation Loss AVG: 13.0842, lr: 0.001
Epoch [19/80], Training Loss: 6.6522, Validation Loss Current: 13.2115, Validation Loss AVG: 13.2115, lr: 0.001
Epoch [20/80], Training Loss: 5.5244, Validation Loss Current: 11.4984, Validation Loss AVG: 11.4984, lr: 0.001
Epoch [21/80], Training Loss: 4.7336, Validation Loss Current: 14.0217, Validation Loss AVG: 14.0217, lr: 0.001
Epoch [22/80], Training Loss: 4.6461, Validation Loss Current: 10.3421, Validation Loss AVG: 10.3421, lr: 0.001
Epoch [23/80], Training Loss: 3.5084, Validation Loss Current: 11.0527, Validation Loss AVG: 11.0527, lr: 0.001
Epoch [24/80], Training Loss: 2.8267, Validation Loss Current: 12.2179, Validation Loss AVG: 12.2179, lr: 0.001
Epoch [25/80], Training Loss: 3.5769, Validation Loss Current: 14.4923, Validation Loss AVG: 14.4923, lr: 0.001
Epoch [26/80], Training Loss: 2.8355, Validation Loss Current: 10.9234, Validation Loss AVG: 10.9234, lr: 0.001
Epoch [27/80], Training Loss: 2.3115, Validation Loss Current: 14.7209, Validation Loss AVG: 14.7209, lr: 0.001
Epoch [28/80], Training Loss: 2.3792, Validation Loss Current: 12.7847, Validation Loss AVG: 12.7847, lr: 0.001
Epoch [29/80], Training Loss: 3.1855, Validation Loss Current: 11.7197, Validation Loss AVG: 11.7197, lr: 0.001
Epoch [30/80], Training Loss: 5.0567, Validation Loss Current: 12.1869, Validation Loss AVG: 12.1869, lr: 0.001
Epoch [31/80], Training Loss: 5.8278, Validation Loss Current: 11.7175, Validation Loss AVG: 11.7175, lr: 0.001
Epoch [32/80], Training Loss: 6.4259, Validation Loss Current: 10.8939, Validation Loss AVG: 10.8939, lr: 0.001
Epoch [33/80], Training Loss: 6.8370, Validation Loss Current: 14.1544, Validation Loss AVG: 14.1544, lr: 0.001
Epoch [34/80], Training Loss: 5.2017, Validation Loss Current: 12.5468, Validation Loss AVG: 12.5468, lr: 0.001
Epoch [35/80], Training Loss: 6.5973, Validation Loss Current: 13.6948, Validation Loss AVG: 13.6948, lr: 0.001
Epoch [36/80], Training Loss: 4.1138, Validation Loss Current: 11.9994, Validation Loss AVG: 11.9994, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 6 Best val accuracy: [0.4131578947368421, 0.41414473684210523, 0.4848684210526316, 0.40394736842105267, 0.4621710526315789, 0.47894736842105257, 0.4733552631578948, 0.4743421052631579, 0.44703947368421054, 0.5052631578947369, 0.4759868421052632, 0.46644736842105256, 0.4917763157894736, 0.46085526315789477, 0.48552631578947364, 0.4697368421052632, 0.4516447368421053, 0.46578947368421053, 0.4338815789473684, 0.47105263157894733, 0.4529605263157895, 0.4828947368421053, 0.48190789473684215, 0.47138157894736843, 0.45789473684210524, 0.5036184210526315, 0.4720394736842105, 0.46809210526315786, 0.4980263157894737, 0.4549342105263158, 0.48848684210526316, 0.5075657894736841, 0.4496710526315789, 0.4516447368421053, 0.47105263157894744, 0.45723684210526316] Best val loss: 9.474502444267273


Current group: 0.4
Epoch [1/80], Training Loss: 35.9593, Validation Loss Current: 14.2244, Validation Loss AVG: 14.2244, lr: 0.001
Epoch [2/80], Training Loss: 22.3464, Validation Loss Current: 11.8415, Validation Loss AVG: 11.8415, lr: 0.001
Epoch [3/80], Training Loss: 17.6760, Validation Loss Current: 15.2856, Validation Loss AVG: 15.2856, lr: 0.001
Epoch [4/80], Training Loss: 15.5539, Validation Loss Current: 21.2019, Validation Loss AVG: 21.2019, lr: 0.001
Epoch [5/80], Training Loss: 10.0662, Validation Loss Current: 10.7337, Validation Loss AVG: 10.7337, lr: 0.001
Epoch [6/80], Training Loss: 8.4040, Validation Loss Current: 9.6918, Validation Loss AVG: 9.6918, lr: 0.001
Epoch [7/80], Training Loss: 7.3688, Validation Loss Current: 12.2698, Validation Loss AVG: 12.2698, lr: 0.001
Epoch [8/80], Training Loss: 5.1192, Validation Loss Current: 10.5515, Validation Loss AVG: 10.5515, lr: 0.001
Epoch [9/80], Training Loss: 5.5573, Validation Loss Current: 12.5204, Validation Loss AVG: 12.5204, lr: 0.001
Epoch [10/80], Training Loss: 7.3350, Validation Loss Current: 12.2230, Validation Loss AVG: 12.2230, lr: 0.001
Epoch [11/80], Training Loss: 6.2486, Validation Loss Current: 13.8403, Validation Loss AVG: 13.8403, lr: 0.001
Epoch [12/80], Training Loss: 7.1684, Validation Loss Current: 11.7353, Validation Loss AVG: 11.7353, lr: 0.001
Epoch [13/80], Training Loss: 5.5109, Validation Loss Current: 16.3125, Validation Loss AVG: 16.3125, lr: 0.001
Epoch [14/80], Training Loss: 6.2823, Validation Loss Current: 10.8854, Validation Loss AVG: 10.8854, lr: 0.001
Epoch [15/80], Training Loss: 4.8566, Validation Loss Current: 11.1385, Validation Loss AVG: 11.1385, lr: 0.001
Epoch [16/80], Training Loss: 7.0763, Validation Loss Current: 14.2571, Validation Loss AVG: 14.2571, lr: 0.001
Epoch [17/80], Training Loss: 5.1794, Validation Loss Current: 11.2842, Validation Loss AVG: 11.2842, lr: 0.001
Epoch [18/80], Training Loss: 9.7753, Validation Loss Current: 12.4986, Validation Loss AVG: 12.4986, lr: 0.001
Epoch [19/80], Training Loss: 6.3165, Validation Loss Current: 13.9845, Validation Loss AVG: 13.9845, lr: 0.001
Epoch [20/80], Training Loss: 6.0241, Validation Loss Current: 14.7025, Validation Loss AVG: 14.7025, lr: 0.001
Epoch [21/80], Training Loss: 4.3403, Validation Loss Current: 12.0911, Validation Loss AVG: 12.0911, lr: 0.001
Epoch [22/80], Training Loss: 3.3948, Validation Loss Current: 15.9763, Validation Loss AVG: 15.9763, lr: 0.001
Epoch [23/80], Training Loss: 5.6740, Validation Loss Current: 12.5562, Validation Loss AVG: 12.5562, lr: 0.001
Epoch [24/80], Training Loss: 4.3462, Validation Loss Current: 13.2390, Validation Loss AVG: 13.2390, lr: 0.001
Epoch [25/80], Training Loss: 5.1761, Validation Loss Current: 15.8808, Validation Loss AVG: 15.8808, lr: 0.001
Epoch [26/80], Training Loss: 2.8273, Validation Loss Current: 11.8623, Validation Loss AVG: 11.8623, lr: 0.001
Epoch [27/80], Training Loss: 4.2591, Validation Loss Current: 16.2054, Validation Loss AVG: 16.2054, lr: 0.001
Epoch [28/80], Training Loss: 4.9793, Validation Loss Current: 13.4397, Validation Loss AVG: 13.4397, lr: 0.001
Epoch [29/80], Training Loss: 4.9134, Validation Loss Current: 12.1159, Validation Loss AVG: 12.1159, lr: 0.001
Epoch [30/80], Training Loss: 3.7681, Validation Loss Current: 12.0642, Validation Loss AVG: 12.0642, lr: 0.001
Epoch [31/80], Training Loss: 6.0565, Validation Loss Current: 15.3395, Validation Loss AVG: 15.3395, lr: 0.001
Epoch [32/80], Training Loss: 11.2710, Validation Loss Current: 19.4770, Validation Loss AVG: 19.4770, lr: 0.001
Epoch [33/80], Training Loss: 4.3038, Validation Loss Current: 13.5391, Validation Loss AVG: 13.5391, lr: 0.001
Epoch [34/80], Training Loss: 2.5351, Validation Loss Current: 12.3559, Validation Loss AVG: 12.3559, lr: 0.001
Epoch [35/80], Training Loss: 2.1457, Validation Loss Current: 12.1732, Validation Loss AVG: 12.1732, lr: 0.001
Epoch [36/80], Training Loss: 1.4511, Validation Loss Current: 12.8849, Validation Loss AVG: 12.8849, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 6 Best val accuracy: [0.4509868421052632, 0.43684210526315786, 0.41907894736842105, 0.35197368421052627, 0.45032894736842105, 0.49769736842105267, 0.45559210526315785, 0.47302631578947374, 0.4631578947368421, 0.4582236842105264, 0.4269736842105264, 0.4822368421052632, 0.36085526315789473, 0.4858552631578947, 0.47697368421052627, 0.4654605263157895, 0.4707236842105263, 0.4427631578947368, 0.4098684210526316, 0.3950657894736842, 0.4865131578947368, 0.4009868421052632, 0.4786184210526316, 0.4608552631578947, 0.4516447368421053, 0.4756578947368421, 0.41546052631578945, 0.44210526315789467, 0.47828947368421054, 0.4776315789473684, 0.4394736842105263, 0.3996710526315789, 0.4546052631578947, 0.4569078947368421, 0.49802631578947365, 0.4759868421052632] Best val loss: 9.6918466091156


Current group: 0.2
Epoch [1/80], Training Loss: 39.5910, Validation Loss Current: 37.9038, Validation Loss AVG: 37.9038, lr: 0.001
Epoch [2/80], Training Loss: 26.3514, Validation Loss Current: 23.3490, Validation Loss AVG: 23.3490, lr: 0.001
Epoch [3/80], Training Loss: 19.7670, Validation Loss Current: 16.6496, Validation Loss AVG: 16.6496, lr: 0.001
Epoch [4/80], Training Loss: 15.9623, Validation Loss Current: 19.2317, Validation Loss AVG: 19.2317, lr: 0.001
Epoch [5/80], Training Loss: 13.7641, Validation Loss Current: 17.0684, Validation Loss AVG: 17.0684, lr: 0.001
Epoch [6/80], Training Loss: 11.6225, Validation Loss Current: 15.5007, Validation Loss AVG: 15.5007, lr: 0.001
Epoch [7/80], Training Loss: 9.1793, Validation Loss Current: 17.0182, Validation Loss AVG: 17.0182, lr: 0.001
Epoch [8/80], Training Loss: 8.4858, Validation Loss Current: 14.8670, Validation Loss AVG: 14.8670, lr: 0.001
Epoch [9/80], Training Loss: 6.9899, Validation Loss Current: 18.2964, Validation Loss AVG: 18.2964, lr: 0.001
Epoch [10/80], Training Loss: 6.2614, Validation Loss Current: 24.8068, Validation Loss AVG: 24.8068, lr: 0.001
Epoch [11/80], Training Loss: 5.5194, Validation Loss Current: 15.2980, Validation Loss AVG: 15.2980, lr: 0.001
Epoch [12/80], Training Loss: 7.9076, Validation Loss Current: 28.9487, Validation Loss AVG: 28.9487, lr: 0.001
Epoch [13/80], Training Loss: 8.5378, Validation Loss Current: 21.1552, Validation Loss AVG: 21.1552, lr: 0.001
Epoch [14/80], Training Loss: 6.4646, Validation Loss Current: 20.8693, Validation Loss AVG: 20.8693, lr: 0.001
Epoch [15/80], Training Loss: 5.0138, Validation Loss Current: 19.6466, Validation Loss AVG: 19.6466, lr: 0.001
Epoch [16/80], Training Loss: 6.8610, Validation Loss Current: 21.5734, Validation Loss AVG: 21.5734, lr: 0.001
Epoch [17/80], Training Loss: 4.8608, Validation Loss Current: 33.7787, Validation Loss AVG: 33.7787, lr: 0.001
Epoch [18/80], Training Loss: 2.9189, Validation Loss Current: 22.7308, Validation Loss AVG: 22.7308, lr: 0.001
Epoch [19/80], Training Loss: 2.3112, Validation Loss Current: 20.7582, Validation Loss AVG: 20.7582, lr: 0.001
Epoch [20/80], Training Loss: 6.5106, Validation Loss Current: 25.1144, Validation Loss AVG: 25.1144, lr: 0.001
Epoch [21/80], Training Loss: 5.5345, Validation Loss Current: 27.9184, Validation Loss AVG: 27.9184, lr: 0.001
Epoch [22/80], Training Loss: 8.0266, Validation Loss Current: 27.7518, Validation Loss AVG: 27.7518, lr: 0.001
Epoch [23/80], Training Loss: 3.1504, Validation Loss Current: 23.1246, Validation Loss AVG: 23.1246, lr: 0.001
Epoch [24/80], Training Loss: 4.1073, Validation Loss Current: 20.4035, Validation Loss AVG: 20.4035, lr: 0.001
Epoch [25/80], Training Loss: 2.9219, Validation Loss Current: 22.4786, Validation Loss AVG: 22.4786, lr: 0.001
Epoch [26/80], Training Loss: 3.3902, Validation Loss Current: 19.5322, Validation Loss AVG: 19.5322, lr: 0.001
Epoch [27/80], Training Loss: 4.7389, Validation Loss Current: 20.3772, Validation Loss AVG: 20.3772, lr: 0.001
Epoch [28/80], Training Loss: 3.1017, Validation Loss Current: 22.2138, Validation Loss AVG: 22.2138, lr: 0.001
Epoch [29/80], Training Loss: 2.4100, Validation Loss Current: 21.5947, Validation Loss AVG: 21.5947, lr: 0.001
Epoch [30/80], Training Loss: 1.9989, Validation Loss Current: 21.4942, Validation Loss AVG: 21.4942, lr: 0.001
Epoch [31/80], Training Loss: 2.0547, Validation Loss Current: 21.5505, Validation Loss AVG: 21.5505, lr: 0.001
Epoch [32/80], Training Loss: 7.1736, Validation Loss Current: 29.1606, Validation Loss AVG: 29.1606, lr: 0.001
Epoch [33/80], Training Loss: 5.8233, Validation Loss Current: 22.2468, Validation Loss AVG: 22.2468, lr: 0.001
Epoch [34/80], Training Loss: 5.4782, Validation Loss Current: 31.0849, Validation Loss AVG: 31.0849, lr: 0.001
Epoch [35/80], Training Loss: 4.8385, Validation Loss Current: 32.7001, Validation Loss AVG: 32.7001, lr: 0.001
Epoch [36/80], Training Loss: 5.4859, Validation Loss Current: 17.8924, Validation Loss AVG: 17.8924, lr: 0.001
Epoch [37/80], Training Loss: 10.8021, Validation Loss Current: 24.5605, Validation Loss AVG: 24.5605, lr: 0.001
Epoch [38/80], Training Loss: 10.8095, Validation Loss Current: 34.9125, Validation Loss AVG: 34.9125, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 8 Best val accuracy: [0.2299342105263158, 0.29210526315789476, 0.3516447368421053, 0.3388157894736842, 0.35855263157894735, 0.3898026315789474, 0.36184210526315785, 0.41743421052631585, 0.3578947368421052, 0.32598684210526313, 0.4253289473684211, 0.3358552631578947, 0.3907894736842105, 0.3368421052631579, 0.35065789473684206, 0.3786184210526316, 0.2677631578947368, 0.3506578947368421, 0.3838815789473684, 0.28092105263157896, 0.30164473684210524, 0.3088815789473684, 0.3338815789473684, 0.40855263157894733, 0.36776315789473685, 0.38223684210526315, 0.34638157894736843, 0.3476973684210526, 0.3838815789473684, 0.37796052631578947, 0.3444078947368421, 0.3134868421052631, 0.3424342105263158, 0.27006578947368426, 0.2661184210526316, 0.40427631578947365, 0.35526315789473684, 0.28980263157894737] Best val loss: 14.866951179504394


Fold: 1
----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.4657, Validation Loss Current: 9.9524, Validation Loss AVG: 10.0268, lr: 0.001
Epoch [2/400], Training Loss: 38.3267, Validation Loss Current: 9.4993, Validation Loss AVG: 9.8263, lr: 0.001
Epoch [3/400], Training Loss: 37.8434, Validation Loss Current: 9.1349, Validation Loss AVG: 9.7076, lr: 0.001
Epoch [4/400], Training Loss: 36.6932, Validation Loss Current: 8.8660, Validation Loss AVG: 9.4462, lr: 0.001
Epoch [5/400], Training Loss: 34.0664, Validation Loss Current: 8.4470, Validation Loss AVG: 9.5127, lr: 0.001
Epoch [6/400], Training Loss: 32.9383, Validation Loss Current: 8.1754, Validation Loss AVG: 9.2146, lr: 0.001
Epoch [7/400], Training Loss: 31.4188, Validation Loss Current: 8.2578, Validation Loss AVG: 10.9014, lr: 0.001
Epoch [8/400], Training Loss: 29.3919, Validation Loss Current: 7.5288, Validation Loss AVG: 10.0061, lr: 0.001
Epoch [9/400], Training Loss: 28.1841, Validation Loss Current: 7.2024, Validation Loss AVG: 8.7754, lr: 0.001
Epoch [10/400], Training Loss: 28.1608, Validation Loss Current: 7.1061, Validation Loss AVG: 8.7164, lr: 0.001
Epoch [11/400], Training Loss: 26.4253, Validation Loss Current: 7.4526, Validation Loss AVG: 9.3942, lr: 0.001
Epoch [12/400], Training Loss: 25.9536, Validation Loss Current: 6.6352, Validation Loss AVG: 8.9538, lr: 0.001
Epoch [13/400], Training Loss: 28.9609, Validation Loss Current: 11.4965, Validation Loss AVG: 12.4658, lr: 0.001
Epoch [14/400], Training Loss: 34.2137, Validation Loss Current: 7.8261, Validation Loss AVG: 9.1795, lr: 0.001
Epoch [15/400], Training Loss: 28.3748, Validation Loss Current: 7.0968, Validation Loss AVG: 9.3599, lr: 0.001
Epoch [16/400], Training Loss: 26.5935, Validation Loss Current: 6.8314, Validation Loss AVG: 9.3331, lr: 0.001
Epoch [17/400], Training Loss: 25.1257, Validation Loss Current: 6.7522, Validation Loss AVG: 10.4232, lr: 0.001
Epoch [18/400], Training Loss: 24.7995, Validation Loss Current: 7.5075, Validation Loss AVG: 12.1087, lr: 0.001
Epoch [19/400], Training Loss: 24.3774, Validation Loss Current: 6.4687, Validation Loss AVG: 9.1397, lr: 0.001
Epoch [20/400], Training Loss: 22.7978, Validation Loss Current: 6.6623, Validation Loss AVG: 8.7172, lr: 0.001
Epoch [21/400], Training Loss: 22.1011, Validation Loss Current: 6.7162, Validation Loss AVG: 9.5243, lr: 0.001
Epoch [22/400], Training Loss: 22.5141, Validation Loss Current: 6.3843, Validation Loss AVG: 8.9677, lr: 0.001
Epoch [23/400], Training Loss: 20.7315, Validation Loss Current: 6.4087, Validation Loss AVG: 8.6611, lr: 0.001
Epoch [24/400], Training Loss: 19.2055, Validation Loss Current: 6.2098, Validation Loss AVG: 8.6966, lr: 0.001
Epoch [25/400], Training Loss: 18.8137, Validation Loss Current: 6.4393, Validation Loss AVG: 8.5553, lr: 0.001
Epoch [26/400], Training Loss: 17.7167, Validation Loss Current: 6.3385, Validation Loss AVG: 8.7372, lr: 0.001
Epoch [27/400], Training Loss: 16.8449, Validation Loss Current: 6.3636, Validation Loss AVG: 9.3192, lr: 0.001
Epoch [28/400], Training Loss: 16.9049, Validation Loss Current: 7.2078, Validation Loss AVG: 12.1327, lr: 0.001
Epoch [29/400], Training Loss: 16.8297, Validation Loss Current: 6.1703, Validation Loss AVG: 9.5658, lr: 0.001
Epoch [30/400], Training Loss: 16.0839, Validation Loss Current: 6.2308, Validation Loss AVG: 9.4912, lr: 0.001
Epoch [31/400], Training Loss: 14.2287, Validation Loss Current: 6.1804, Validation Loss AVG: 9.4029, lr: 0.001
Epoch [32/400], Training Loss: 14.4218, Validation Loss Current: 7.2713, Validation Loss AVG: 11.6549, lr: 0.001
Epoch [33/400], Training Loss: 15.8874, Validation Loss Current: 6.1048, Validation Loss AVG: 9.4651, lr: 0.001
Epoch [34/400], Training Loss: 14.1666, Validation Loss Current: 6.5183, Validation Loss AVG: 10.2692, lr: 0.001
Epoch [35/400], Training Loss: 13.4327, Validation Loss Current: 6.3712, Validation Loss AVG: 11.8384, lr: 0.001
Epoch [36/400], Training Loss: 11.2894, Validation Loss Current: 5.9396, Validation Loss AVG: 9.4019, lr: 0.001
Epoch [37/400], Training Loss: 11.6722, Validation Loss Current: 6.0481, Validation Loss AVG: 10.2655, lr: 0.001
Epoch [38/400], Training Loss: 9.4916, Validation Loss Current: 5.8799, Validation Loss AVG: 9.3205, lr: 0.001
Epoch [39/400], Training Loss: 10.1946, Validation Loss Current: 6.1774, Validation Loss AVG: 9.7056, lr: 0.001
Epoch [40/400], Training Loss: 10.9757, Validation Loss Current: 6.3875, Validation Loss AVG: 8.6396, lr: 0.001
Epoch [41/400], Training Loss: 10.1512, Validation Loss Current: 6.1743, Validation Loss AVG: 8.9196, lr: 0.001
Epoch [42/400], Training Loss: 8.1154, Validation Loss Current: 6.1782, Validation Loss AVG: 11.5152, lr: 0.001
Epoch [43/400], Training Loss: 8.1766, Validation Loss Current: 8.9878, Validation Loss AVG: 17.7292, lr: 0.001
Epoch [44/400], Training Loss: 9.8284, Validation Loss Current: 6.3438, Validation Loss AVG: 13.5990, lr: 0.001
Epoch [45/400], Training Loss: 9.5734, Validation Loss Current: 6.3847, Validation Loss AVG: 10.1040, lr: 0.001
Epoch [46/400], Training Loss: 7.0963, Validation Loss Current: 6.5491, Validation Loss AVG: 10.9551, lr: 0.001
Epoch [47/400], Training Loss: 6.7438, Validation Loss Current: 8.8100, Validation Loss AVG: 12.2705, lr: 0.001
Epoch [48/400], Training Loss: 6.4414, Validation Loss Current: 6.2760, Validation Loss AVG: 9.9197, lr: 0.001
Epoch [49/400], Training Loss: 6.0025, Validation Loss Current: 6.6264, Validation Loss AVG: 9.6420, lr: 0.001
Epoch [50/400], Training Loss: 5.8801, Validation Loss Current: 5.8344, Validation Loss AVG: 10.7257, lr: 0.001
Epoch [51/400], Training Loss: 8.1481, Validation Loss Current: 6.9521, Validation Loss AVG: 9.4764, lr: 0.001
Epoch [52/400], Training Loss: 9.7089, Validation Loss Current: 7.1989, Validation Loss AVG: 10.9467, lr: 0.001
Epoch [53/400], Training Loss: 7.0716, Validation Loss Current: 7.1829, Validation Loss AVG: 11.2028, lr: 0.001
Epoch [54/400], Training Loss: 6.7749, Validation Loss Current: 7.3737, Validation Loss AVG: 12.6527, lr: 0.001
Epoch [55/400], Training Loss: 7.3002, Validation Loss Current: 6.6867, Validation Loss AVG: 14.7731, lr: 0.001
Epoch [56/400], Training Loss: 6.3861, Validation Loss Current: 7.0209, Validation Loss AVG: 13.3036, lr: 0.001
Epoch [57/400], Training Loss: 3.2560, Validation Loss Current: 7.1018, Validation Loss AVG: 10.4312, lr: 0.001
Epoch [58/400], Training Loss: 2.5991, Validation Loss Current: 6.5347, Validation Loss AVG: 10.4331, lr: 0.001
Epoch [59/400], Training Loss: 3.0964, Validation Loss Current: 6.7025, Validation Loss AVG: 12.0981, lr: 0.001
Epoch [60/400], Training Loss: 3.5040, Validation Loss Current: 7.3649, Validation Loss AVG: 12.7455, lr: 0.001
Epoch [61/400], Training Loss: 2.3668, Validation Loss Current: 6.6679, Validation Loss AVG: 10.6796, lr: 0.001
Epoch [62/400], Training Loss: 5.3633, Validation Loss Current: 6.6815, Validation Loss AVG: 13.3949, lr: 0.001
Epoch [63/400], Training Loss: 3.3877, Validation Loss Current: 7.4655, Validation Loss AVG: 14.4478, lr: 0.001
Epoch [64/400], Training Loss: 3.4789, Validation Loss Current: 7.1261, Validation Loss AVG: 11.8464, lr: 0.001
Epoch [65/400], Training Loss: 6.0805, Validation Loss Current: 7.4723, Validation Loss AVG: 13.2279, lr: 0.001
Epoch [66/400], Training Loss: 6.3897, Validation Loss Current: 7.2202, Validation Loss AVG: 11.8723, lr: 0.001
Epoch [67/400], Training Loss: 6.1728, Validation Loss Current: 8.1725, Validation Loss AVG: 14.7704, lr: 0.001
Epoch [68/400], Training Loss: 3.2906, Validation Loss Current: 8.6482, Validation Loss AVG: 14.9880, lr: 0.001
Epoch [69/400], Training Loss: 2.3922, Validation Loss Current: 7.2330, Validation Loss AVG: 13.4975, lr: 0.001
Epoch [70/400], Training Loss: 1.6800, Validation Loss Current: 6.9683, Validation Loss AVG: 12.7053, lr: 0.001
Epoch [71/400], Training Loss: 1.5072, Validation Loss Current: 7.1310, Validation Loss AVG: 12.0624, lr: 0.001
Epoch [72/400], Training Loss: 2.1173, Validation Loss Current: 7.5130, Validation Loss AVG: 13.2694, lr: 0.001
Epoch [73/400], Training Loss: 2.8415, Validation Loss Current: 7.5774, Validation Loss AVG: 13.7837, lr: 0.001
Epoch [74/400], Training Loss: 4.2027, Validation Loss Current: 8.2355, Validation Loss AVG: 12.8180, lr: 0.001
Epoch [75/400], Training Loss: 4.3905, Validation Loss Current: 8.6163, Validation Loss AVG: 15.4396, lr: 0.001
Epoch [76/400], Training Loss: 2.5515, Validation Loss Current: 7.4988, Validation Loss AVG: 13.6025, lr: 0.001
Epoch [77/400], Training Loss: 5.1559, Validation Loss Current: 8.3375, Validation Loss AVG: 15.0815, lr: 0.001
Epoch [78/400], Training Loss: 7.7163, Validation Loss Current: 8.7427, Validation Loss AVG: 18.2308, lr: 0.001
Epoch [79/400], Training Loss: 6.3320, Validation Loss Current: 9.1622, Validation Loss AVG: 13.9114, lr: 0.001
Epoch [80/400], Training Loss: 7.1497, Validation Loss Current: 8.7684, Validation Loss AVG: 17.2759, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 50 Best val accuracy: [0.26151315789473684, 0.3190789473684211, 0.3536184210526316, 0.3667763157894737, 0.4161184210526316, 0.42105263157894735, 0.42105263157894735, 0.48355263157894735, 0.524671052631579, 0.5016447368421053, 0.48519736842105265, 0.5427631578947368, 0.35526315789473684, 0.43585526315789475, 0.5032894736842105, 0.5213815789473685, 0.5411184210526315, 0.4901315789473684, 0.5476973684210527, 0.5526315789473685, 0.537828947368421, 0.5526315789473685, 0.5476973684210527, 0.5756578947368421, 0.5460526315789473, 0.5822368421052632, 0.5575657894736842, 0.5164473684210527, 0.5756578947368421, 0.5953947368421053, 0.587171052631579, 0.5345394736842105, 0.5888157894736842, 0.5740131578947368, 0.5789473684210527, 0.6151315789473685, 0.6151315789473685, 0.6118421052631579, 0.5986842105263158, 0.5953947368421053, 0.6052631578947368, 0.6134868421052632, 0.5016447368421053, 0.5921052631578947, 0.587171052631579, 0.587171052631579, 0.5148026315789473, 0.5888157894736842, 0.6069078947368421, 0.600328947368421, 0.53125, 0.5641447368421053, 0.5822368421052632, 0.5509868421052632, 0.5888157894736842, 0.587171052631579, 0.5641447368421053, 0.6085526315789473, 0.59375, 0.5707236842105263, 0.6085526315789473, 0.6085526315789473, 0.5855263157894737, 0.5822368421052632, 0.5608552631578947, 0.5904605263157895, 0.537828947368421, 0.5756578947368421, 0.5773026315789473, 0.5970394736842105, 0.6085526315789473, 0.5855263157894737, 0.5707236842105263, 0.5723684210526315, 0.5493421052631579, 0.5953947368421053, 0.5509868421052632, 0.5575657894736842, 0.4967105263157895, 0.5756578947368421] Best val loss: 5.834394156932831


----- Training resnet18 with sequence: [1, 0.8] -----
Current group: 1
Epoch [1/200], Training Loss: 40.4479, Validation Loss Current: 9.9359, Validation Loss AVG: 10.0272, lr: 0.001
Epoch [2/200], Training Loss: 38.6936, Validation Loss Current: 9.5335, Validation Loss AVG: 9.8266, lr: 0.001
Epoch [3/200], Training Loss: 37.8465, Validation Loss Current: 9.1730, Validation Loss AVG: 9.7218, lr: 0.001
Epoch [4/200], Training Loss: 36.1729, Validation Loss Current: 8.8617, Validation Loss AVG: 9.6158, lr: 0.001
Epoch [5/200], Training Loss: 34.3975, Validation Loss Current: 8.2427, Validation Loss AVG: 9.3350, lr: 0.001
Epoch [6/200], Training Loss: 33.6273, Validation Loss Current: 8.2939, Validation Loss AVG: 9.3070, lr: 0.001
Epoch [7/200], Training Loss: 32.1220, Validation Loss Current: 8.2663, Validation Loss AVG: 11.7698, lr: 0.001
Epoch [8/200], Training Loss: 30.2834, Validation Loss Current: 7.6779, Validation Loss AVG: 9.0823, lr: 0.001
Epoch [9/200], Training Loss: 28.4663, Validation Loss Current: 7.4749, Validation Loss AVG: 8.8085, lr: 0.001
Epoch [10/200], Training Loss: 29.0066, Validation Loss Current: 7.5163, Validation Loss AVG: 8.8198, lr: 0.001
Epoch [11/200], Training Loss: 27.2828, Validation Loss Current: 7.0792, Validation Loss AVG: 9.2226, lr: 0.001
Epoch [12/200], Training Loss: 26.2312, Validation Loss Current: 7.1857, Validation Loss AVG: 9.2257, lr: 0.001
Epoch [13/200], Training Loss: 25.3861, Validation Loss Current: 6.8453, Validation Loss AVG: 8.9714, lr: 0.001
Epoch [14/200], Training Loss: 26.0568, Validation Loss Current: 6.6705, Validation Loss AVG: 8.7079, lr: 0.001
Epoch [15/200], Training Loss: 24.9016, Validation Loss Current: 8.4113, Validation Loss AVG: 11.4806, lr: 0.001
Epoch [16/200], Training Loss: 25.5536, Validation Loss Current: 7.8558, Validation Loss AVG: 9.2596, lr: 0.001
Epoch [17/200], Training Loss: 25.3790, Validation Loss Current: 7.6964, Validation Loss AVG: 9.8681, lr: 0.001
Epoch [18/200], Training Loss: 22.7800, Validation Loss Current: 6.6044, Validation Loss AVG: 9.8282, lr: 0.001
Epoch [19/200], Training Loss: 22.6191, Validation Loss Current: 6.1349, Validation Loss AVG: 9.0177, lr: 0.001
Epoch [20/200], Training Loss: 21.7954, Validation Loss Current: 6.4030, Validation Loss AVG: 10.5328, lr: 0.001
Epoch [21/200], Training Loss: 22.1231, Validation Loss Current: 6.1323, Validation Loss AVG: 10.7892, lr: 0.001
Epoch [22/200], Training Loss: 19.5354, Validation Loss Current: 6.6657, Validation Loss AVG: 9.8769, lr: 0.001
Epoch [23/200], Training Loss: 19.4177, Validation Loss Current: 6.1597, Validation Loss AVG: 9.0864, lr: 0.001
Epoch [24/200], Training Loss: 18.6163, Validation Loss Current: 5.8134, Validation Loss AVG: 9.2148, lr: 0.001
Epoch [25/200], Training Loss: 17.8046, Validation Loss Current: 5.9293, Validation Loss AVG: 8.7535, lr: 0.001
Epoch [26/200], Training Loss: 17.2939, Validation Loss Current: 6.8890, Validation Loss AVG: 10.3778, lr: 0.001
Epoch [27/200], Training Loss: 16.8269, Validation Loss Current: 7.0257, Validation Loss AVG: 12.0450, lr: 0.001
Epoch [28/200], Training Loss: 16.1230, Validation Loss Current: 5.7968, Validation Loss AVG: 8.4212, lr: 0.001
Epoch [29/200], Training Loss: 15.6064, Validation Loss Current: 8.4454, Validation Loss AVG: 18.5882, lr: 0.001
Epoch [30/200], Training Loss: 14.9941, Validation Loss Current: 6.2603, Validation Loss AVG: 9.7167, lr: 0.001
Epoch [31/200], Training Loss: 15.0428, Validation Loss Current: 6.1034, Validation Loss AVG: 11.2988, lr: 0.001
Epoch [32/200], Training Loss: 14.5814, Validation Loss Current: 6.2735, Validation Loss AVG: 8.9581, lr: 0.001
Epoch [33/200], Training Loss: 13.5125, Validation Loss Current: 5.6574, Validation Loss AVG: 8.8096, lr: 0.001
Epoch [34/200], Training Loss: 12.9191, Validation Loss Current: 5.8253, Validation Loss AVG: 8.1499, lr: 0.001
Epoch [35/200], Training Loss: 12.9679, Validation Loss Current: 5.6149, Validation Loss AVG: 8.3896, lr: 0.001
Epoch [36/200], Training Loss: 11.4991, Validation Loss Current: 6.9198, Validation Loss AVG: 13.1734, lr: 0.001
Epoch [37/200], Training Loss: 10.9701, Validation Loss Current: 7.5057, Validation Loss AVG: 9.9505, lr: 0.001
Epoch [38/200], Training Loss: 11.2596, Validation Loss Current: 8.2417, Validation Loss AVG: 12.8375, lr: 0.001
Epoch [39/200], Training Loss: 9.0828, Validation Loss Current: 5.6008, Validation Loss AVG: 9.4062, lr: 0.001
Epoch [40/200], Training Loss: 8.3294, Validation Loss Current: 6.7636, Validation Loss AVG: 14.1211, lr: 0.001
Epoch [41/200], Training Loss: 11.8880, Validation Loss Current: 7.5130, Validation Loss AVG: 9.6117, lr: 0.001
Epoch [42/200], Training Loss: 10.7018, Validation Loss Current: 6.5395, Validation Loss AVG: 12.5739, lr: 0.001
Epoch [43/200], Training Loss: 11.9842, Validation Loss Current: 6.3677, Validation Loss AVG: 11.7124, lr: 0.001
Epoch [44/200], Training Loss: 10.3373, Validation Loss Current: 6.1807, Validation Loss AVG: 9.6387, lr: 0.001
Epoch [45/200], Training Loss: 8.7226, Validation Loss Current: 6.4842, Validation Loss AVG: 9.7279, lr: 0.001
Epoch [46/200], Training Loss: 7.3752, Validation Loss Current: 5.5511, Validation Loss AVG: 11.5638, lr: 0.001
Epoch [47/200], Training Loss: 7.7935, Validation Loss Current: 7.5634, Validation Loss AVG: 9.9089, lr: 0.001
Epoch [48/200], Training Loss: 8.6275, Validation Loss Current: 6.1330, Validation Loss AVG: 8.6723, lr: 0.001
Epoch [49/200], Training Loss: 7.2706, Validation Loss Current: 6.7392, Validation Loss AVG: 10.1859, lr: 0.001
Epoch [50/200], Training Loss: 6.8735, Validation Loss Current: 6.4896, Validation Loss AVG: 10.2940, lr: 0.001
Epoch [51/200], Training Loss: 7.5144, Validation Loss Current: 7.4024, Validation Loss AVG: 14.1813, lr: 0.001
Epoch [52/200], Training Loss: 6.0023, Validation Loss Current: 7.6672, Validation Loss AVG: 13.3216, lr: 0.001
Epoch [53/200], Training Loss: 7.6301, Validation Loss Current: 6.7748, Validation Loss AVG: 10.5918, lr: 0.001
Epoch [54/200], Training Loss: 6.9265, Validation Loss Current: 6.3670, Validation Loss AVG: 12.7170, lr: 0.001
Epoch [55/200], Training Loss: 7.3395, Validation Loss Current: 6.7967, Validation Loss AVG: 9.9908, lr: 0.001
Epoch [56/200], Training Loss: 6.5044, Validation Loss Current: 7.2272, Validation Loss AVG: 15.1642, lr: 0.001
Epoch [57/200], Training Loss: 6.2185, Validation Loss Current: 6.9336, Validation Loss AVG: 11.3930, lr: 0.001
Epoch [58/200], Training Loss: 4.3224, Validation Loss Current: 6.1399, Validation Loss AVG: 11.3252, lr: 0.001
Epoch [59/200], Training Loss: 3.3544, Validation Loss Current: 6.8782, Validation Loss AVG: 10.3688, lr: 0.001
Epoch [60/200], Training Loss: 4.6648, Validation Loss Current: 6.3790, Validation Loss AVG: 9.9401, lr: 0.001
Epoch [61/200], Training Loss: 3.7403, Validation Loss Current: 7.0735, Validation Loss AVG: 12.6200, lr: 0.001
Epoch [62/200], Training Loss: 3.0324, Validation Loss Current: 6.6848, Validation Loss AVG: 12.4840, lr: 0.001
Epoch [63/200], Training Loss: 2.7230, Validation Loss Current: 6.3401, Validation Loss AVG: 11.8322, lr: 0.001
Epoch [64/200], Training Loss: 2.4868, Validation Loss Current: 6.8662, Validation Loss AVG: 12.2721, lr: 0.001
Epoch [65/200], Training Loss: 2.4854, Validation Loss Current: 7.8292, Validation Loss AVG: 12.0543, lr: 0.001
Epoch [66/200], Training Loss: 4.8696, Validation Loss Current: 7.0787, Validation Loss AVG: 12.5849, lr: 0.001
Epoch [67/200], Training Loss: 4.5251, Validation Loss Current: 7.6841, Validation Loss AVG: 12.7236, lr: 0.001
Epoch [68/200], Training Loss: 7.0077, Validation Loss Current: 8.9845, Validation Loss AVG: 14.8446, lr: 0.001
Epoch [69/200], Training Loss: 3.6488, Validation Loss Current: 7.5512, Validation Loss AVG: 13.7375, lr: 0.001
Epoch [70/200], Training Loss: 3.9634, Validation Loss Current: 6.6787, Validation Loss AVG: 11.9478, lr: 0.001
Epoch [71/200], Training Loss: 3.9881, Validation Loss Current: 12.8871, Validation Loss AVG: 18.2402, lr: 0.001
Epoch [72/200], Training Loss: 7.5333, Validation Loss Current: 9.6052, Validation Loss AVG: 13.8040, lr: 0.001
Epoch [73/200], Training Loss: 4.0463, Validation Loss Current: 6.9018, Validation Loss AVG: 12.1014, lr: 0.001
Epoch [74/200], Training Loss: 2.9235, Validation Loss Current: 6.5661, Validation Loss AVG: 12.9049, lr: 0.001
Epoch [75/200], Training Loss: 3.7210, Validation Loss Current: 7.1245, Validation Loss AVG: 12.3458, lr: 0.001
Epoch [76/200], Training Loss: 3.6087, Validation Loss Current: 7.7809, Validation Loss AVG: 15.1101, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 46 Best val accuracy: [0.24671052631578946, 0.3092105263157895, 0.3223684210526316, 0.35855263157894735, 0.41118421052631576, 0.40625, 0.4161184210526316, 0.45394736842105265, 0.46875, 0.4720394736842105, 0.4967105263157895, 0.49835526315789475, 0.5230263157894737, 0.5411184210526315, 0.48026315789473684, 0.4555921052631579, 0.4819078947368421, 0.5328947368421053, 0.5789473684210527, 0.5575657894736842, 0.5822368421052632, 0.5657894736842105, 0.5740131578947368, 0.6069078947368421, 0.59375, 0.53125, 0.5427631578947368, 0.5904605263157895, 0.5098684210526315, 0.5921052631578947, 0.5575657894736842, 0.5756578947368421, 0.6069078947368421, 0.5723684210526315, 0.6167763157894737, 0.5641447368421053, 0.5361842105263158, 0.5361842105263158, 0.6118421052631579, 0.555921052631579, 0.5213815789473685, 0.5460526315789473, 0.5674342105263158, 0.5789473684210527, 0.5953947368421053, 0.6365131578947368, 0.5148026315789473, 0.5921052631578947, 0.5756578947368421, 0.5953947368421053, 0.5427631578947368, 0.555921052631579, 0.5625, 0.6069078947368421, 0.5756578947368421, 0.569078947368421, 0.5773026315789473, 0.5953947368421053, 0.5805921052631579, 0.5888157894736842, 0.6085526315789473, 0.59375, 0.6233552631578947, 0.6036184210526315, 0.5625, 0.6052631578947368, 0.6200657894736842, 0.5197368421052632, 0.5657894736842105, 0.6085526315789473, 0.5164473684210527, 0.5032894736842105, 0.5838815789473685, 0.6052631578947368, 0.6052631578947368, 0.5608552631578947] Best val loss: 5.551105618476868


Current group: 0.8
Epoch [1/200], Training Loss: 21.7190, Validation Loss Current: 10.1648, Validation Loss AVG: 10.1648, lr: 0.001
Epoch [2/200], Training Loss: 17.3020, Validation Loss Current: 12.7591, Validation Loss AVG: 12.7591, lr: 0.001
Epoch [3/200], Training Loss: 14.7256, Validation Loss Current: 10.9460, Validation Loss AVG: 10.9460, lr: 0.001
Epoch [4/200], Training Loss: 11.5826, Validation Loss Current: 10.7827, Validation Loss AVG: 10.7827, lr: 0.001
Epoch [5/200], Training Loss: 11.2509, Validation Loss Current: 10.8998, Validation Loss AVG: 10.8998, lr: 0.001
Epoch [6/200], Training Loss: 10.6869, Validation Loss Current: 10.9023, Validation Loss AVG: 10.9023, lr: 0.001
Epoch [7/200], Training Loss: 7.6121, Validation Loss Current: 12.3323, Validation Loss AVG: 12.3323, lr: 0.001
Epoch [8/200], Training Loss: 7.4263, Validation Loss Current: 11.0518, Validation Loss AVG: 11.0518, lr: 0.001
Epoch [9/200], Training Loss: 8.2574, Validation Loss Current: 12.1202, Validation Loss AVG: 12.1202, lr: 0.001
Epoch [10/200], Training Loss: 8.3666, Validation Loss Current: 11.3924, Validation Loss AVG: 11.3924, lr: 0.001
Epoch [11/200], Training Loss: 6.6518, Validation Loss Current: 11.2425, Validation Loss AVG: 11.2425, lr: 0.001
Epoch [12/200], Training Loss: 4.1425, Validation Loss Current: 12.6400, Validation Loss AVG: 12.6400, lr: 0.001
Epoch [13/200], Training Loss: 4.3205, Validation Loss Current: 12.2246, Validation Loss AVG: 12.2246, lr: 0.001
Epoch [14/200], Training Loss: 7.0516, Validation Loss Current: 12.5740, Validation Loss AVG: 12.5740, lr: 0.001
Epoch [15/200], Training Loss: 4.2256, Validation Loss Current: 11.6427, Validation Loss AVG: 11.6427, lr: 0.001
Epoch [16/200], Training Loss: 3.3937, Validation Loss Current: 13.7025, Validation Loss AVG: 13.7025, lr: 0.001
Epoch [17/200], Training Loss: 2.2030, Validation Loss Current: 10.0862, Validation Loss AVG: 10.0862, lr: 0.001
Epoch [18/200], Training Loss: 2.1421, Validation Loss Current: 11.6387, Validation Loss AVG: 11.6387, lr: 0.001
Epoch [19/200], Training Loss: 2.2234, Validation Loss Current: 11.7590, Validation Loss AVG: 11.7590, lr: 0.001
Epoch [20/200], Training Loss: 2.8795, Validation Loss Current: 11.7938, Validation Loss AVG: 11.7938, lr: 0.001
Epoch [21/200], Training Loss: 5.5866, Validation Loss Current: 11.2893, Validation Loss AVG: 11.2893, lr: 0.001
Epoch [22/200], Training Loss: 4.7913, Validation Loss Current: 11.1815, Validation Loss AVG: 11.1815, lr: 0.001
Epoch [23/200], Training Loss: 6.1660, Validation Loss Current: 12.2687, Validation Loss AVG: 12.2687, lr: 0.001
Epoch [24/200], Training Loss: 3.3719, Validation Loss Current: 12.8971, Validation Loss AVG: 12.8971, lr: 0.001
Epoch [25/200], Training Loss: 4.6354, Validation Loss Current: 14.2293, Validation Loss AVG: 14.2293, lr: 0.001
Epoch [26/200], Training Loss: 5.5994, Validation Loss Current: 13.0373, Validation Loss AVG: 13.0373, lr: 0.001
Epoch [27/200], Training Loss: 4.2648, Validation Loss Current: 12.2111, Validation Loss AVG: 12.2111, lr: 0.001
Epoch [28/200], Training Loss: 2.3427, Validation Loss Current: 12.7313, Validation Loss AVG: 12.7313, lr: 0.001
Epoch [29/200], Training Loss: 2.5523, Validation Loss Current: 12.6538, Validation Loss AVG: 12.6538, lr: 0.001
Epoch [30/200], Training Loss: 5.1409, Validation Loss Current: 12.5458, Validation Loss AVG: 12.5458, lr: 0.001
Epoch [31/200], Training Loss: 7.0257, Validation Loss Current: 15.5224, Validation Loss AVG: 15.5224, lr: 0.001
Epoch [32/200], Training Loss: 5.7391, Validation Loss Current: 12.0789, Validation Loss AVG: 12.0789, lr: 0.001
Epoch [33/200], Training Loss: 2.9194, Validation Loss Current: 13.6736, Validation Loss AVG: 13.6736, lr: 0.001
Epoch [34/200], Training Loss: 2.7608, Validation Loss Current: 14.1648, Validation Loss AVG: 14.1648, lr: 0.001
Epoch [35/200], Training Loss: 2.7824, Validation Loss Current: 17.0929, Validation Loss AVG: 17.0929, lr: 0.001
Epoch [36/200], Training Loss: 3.3479, Validation Loss Current: 13.7314, Validation Loss AVG: 13.7314, lr: 0.001
Epoch [37/200], Training Loss: 7.1847, Validation Loss Current: 15.1437, Validation Loss AVG: 15.1437, lr: 0.001
Epoch [38/200], Training Loss: 4.7484, Validation Loss Current: 13.4067, Validation Loss AVG: 13.4067, lr: 0.001
Epoch [39/200], Training Loss: 5.0564, Validation Loss Current: 12.9772, Validation Loss AVG: 12.9772, lr: 0.001
Epoch [40/200], Training Loss: 5.1440, Validation Loss Current: 12.7267, Validation Loss AVG: 12.7267, lr: 0.001
Epoch [41/200], Training Loss: 2.5167, Validation Loss Current: 12.9292, Validation Loss AVG: 12.9292, lr: 0.001
Epoch [42/200], Training Loss: 1.4001, Validation Loss Current: 13.5067, Validation Loss AVG: 13.5067, lr: 0.001
Epoch [43/200], Training Loss: 1.5862, Validation Loss Current: 12.7128, Validation Loss AVG: 12.7128, lr: 0.001
Epoch [44/200], Training Loss: 1.8217, Validation Loss Current: 13.6130, Validation Loss AVG: 13.6130, lr: 0.001
Epoch [45/200], Training Loss: 2.8872, Validation Loss Current: 11.6850, Validation Loss AVG: 11.6850, lr: 0.001
Epoch [46/200], Training Loss: 4.1284, Validation Loss Current: 16.3568, Validation Loss AVG: 16.3568, lr: 0.001
Epoch [47/200], Training Loss: 2.7064, Validation Loss Current: 11.1734, Validation Loss AVG: 11.1734, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 17 Best val accuracy: [0.43157894736842106, 0.42072368421052636, 0.42072368421052636, 0.43355263157894736, 0.38980263157894735, 0.4496710526315789, 0.4171052631578947, 0.43486842105263157, 0.41217105263157905, 0.4223684210526316, 0.4128289473684211, 0.438157894736842, 0.4223684210526316, 0.4220394736842105, 0.43980263157894733, 0.4223684210526316, 0.4671052631578947, 0.44342105263157905, 0.4447368421052631, 0.44046052631578947, 0.4411184210526316, 0.436842105263158, 0.43552631578947365, 0.43618421052631584, 0.4029605263157895, 0.41907894736842105, 0.4338815789473684, 0.4108552631578948, 0.44078947368421045, 0.4072368421052632, 0.4098684210526315, 0.4141447368421053, 0.42467105263157895, 0.38256578947368425, 0.4141447368421053, 0.4256578947368421, 0.3940789473684211, 0.40855263157894733, 0.43453947368421053, 0.44013157894736843, 0.42269736842105254, 0.45, 0.43125, 0.4496710526315789, 0.4588815789473684, 0.3940789473684211, 0.46315789473684205] Best val loss: 10.086185598373413


----- Training resnet18 with sequence: [1, 0.8, 0.6] -----
Current group: 1
Epoch [1/134], Training Loss: 41.1323, Validation Loss Current: 9.9728, Validation Loss AVG: 10.0334, lr: 0.001
Epoch [2/134], Training Loss: 38.4056, Validation Loss Current: 9.6447, Validation Loss AVG: 9.9533, lr: 0.001
Epoch [3/134], Training Loss: 37.7757, Validation Loss Current: 9.2071, Validation Loss AVG: 9.7377, lr: 0.001
Epoch [4/134], Training Loss: 36.7965, Validation Loss Current: 8.8053, Validation Loss AVG: 9.5658, lr: 0.001
Epoch [5/134], Training Loss: 35.4400, Validation Loss Current: 8.5269, Validation Loss AVG: 9.3926, lr: 0.001
Epoch [6/134], Training Loss: 33.6886, Validation Loss Current: 8.2502, Validation Loss AVG: 9.1797, lr: 0.001
Epoch [7/134], Training Loss: 31.4598, Validation Loss Current: 7.9142, Validation Loss AVG: 8.9965, lr: 0.001
Epoch [8/134], Training Loss: 31.5165, Validation Loss Current: 7.6867, Validation Loss AVG: 9.1597, lr: 0.001
Epoch [9/134], Training Loss: 29.9053, Validation Loss Current: 7.5683, Validation Loss AVG: 9.2381, lr: 0.001
Epoch [10/134], Training Loss: 28.2895, Validation Loss Current: 8.1482, Validation Loss AVG: 9.5402, lr: 0.001
Epoch [11/134], Training Loss: 28.1303, Validation Loss Current: 7.1422, Validation Loss AVG: 9.9459, lr: 0.001
Epoch [12/134], Training Loss: 25.8243, Validation Loss Current: 6.9475, Validation Loss AVG: 9.3011, lr: 0.001
Epoch [13/134], Training Loss: 26.8060, Validation Loss Current: 7.4754, Validation Loss AVG: 9.2626, lr: 0.001
Epoch [14/134], Training Loss: 25.9487, Validation Loss Current: 6.7925, Validation Loss AVG: 9.3460, lr: 0.001
Epoch [15/134], Training Loss: 24.3999, Validation Loss Current: 6.5144, Validation Loss AVG: 8.5010, lr: 0.001
Epoch [16/134], Training Loss: 23.5821, Validation Loss Current: 6.6948, Validation Loss AVG: 10.1330, lr: 0.001
Epoch [17/134], Training Loss: 22.9939, Validation Loss Current: 6.9233, Validation Loss AVG: 10.1926, lr: 0.001
Epoch [18/134], Training Loss: 22.9569, Validation Loss Current: 6.6730, Validation Loss AVG: 10.3897, lr: 0.001
Epoch [19/134], Training Loss: 22.0167, Validation Loss Current: 6.5783, Validation Loss AVG: 9.0647, lr: 0.001
Epoch [20/134], Training Loss: 21.5636, Validation Loss Current: 6.8014, Validation Loss AVG: 10.3843, lr: 0.001
Epoch [21/134], Training Loss: 20.4259, Validation Loss Current: 6.2360, Validation Loss AVG: 10.3124, lr: 0.001
Epoch [22/134], Training Loss: 20.2392, Validation Loss Current: 7.2759, Validation Loss AVG: 11.2706, lr: 0.001
Epoch [23/134], Training Loss: 21.6695, Validation Loss Current: 9.4288, Validation Loss AVG: 20.8435, lr: 0.001
Epoch [24/134], Training Loss: 20.4153, Validation Loss Current: 6.2902, Validation Loss AVG: 8.9818, lr: 0.001
Epoch [25/134], Training Loss: 19.5701, Validation Loss Current: 6.1062, Validation Loss AVG: 9.1806, lr: 0.001
Epoch [26/134], Training Loss: 21.0201, Validation Loss Current: 6.3466, Validation Loss AVG: 10.6163, lr: 0.001
Epoch [27/134], Training Loss: 18.2216, Validation Loss Current: 6.0827, Validation Loss AVG: 9.4384, lr: 0.001
Epoch [28/134], Training Loss: 17.3565, Validation Loss Current: 6.3043, Validation Loss AVG: 11.9035, lr: 0.001
Epoch [29/134], Training Loss: 17.1443, Validation Loss Current: 5.9827, Validation Loss AVG: 8.8947, lr: 0.001
Epoch [30/134], Training Loss: 15.0280, Validation Loss Current: 5.6979, Validation Loss AVG: 10.0419, lr: 0.001
Epoch [31/134], Training Loss: 16.6915, Validation Loss Current: 5.7677, Validation Loss AVG: 9.0556, lr: 0.001
Epoch [32/134], Training Loss: 15.0721, Validation Loss Current: 6.7833, Validation Loss AVG: 9.0406, lr: 0.001
Epoch [33/134], Training Loss: 14.6523, Validation Loss Current: 6.7425, Validation Loss AVG: 11.6083, lr: 0.001
Epoch [34/134], Training Loss: 13.9695, Validation Loss Current: 6.9899, Validation Loss AVG: 11.8164, lr: 0.001
Epoch [35/134], Training Loss: 12.4920, Validation Loss Current: 6.2018, Validation Loss AVG: 7.9935, lr: 0.001
Epoch [36/134], Training Loss: 11.1541, Validation Loss Current: 6.0300, Validation Loss AVG: 9.0743, lr: 0.001
Epoch [37/134], Training Loss: 12.0761, Validation Loss Current: 6.1681, Validation Loss AVG: 9.3054, lr: 0.001
Epoch [38/134], Training Loss: 13.2314, Validation Loss Current: 8.9833, Validation Loss AVG: 13.8722, lr: 0.001
Epoch [39/134], Training Loss: 11.2646, Validation Loss Current: 6.7280, Validation Loss AVG: 11.1899, lr: 0.001
Epoch [40/134], Training Loss: 11.3630, Validation Loss Current: 6.7388, Validation Loss AVG: 12.4168, lr: 0.001
Epoch [41/134], Training Loss: 9.3344, Validation Loss Current: 5.5686, Validation Loss AVG: 8.9874, lr: 0.001
Epoch [42/134], Training Loss: 8.4977, Validation Loss Current: 6.1506, Validation Loss AVG: 8.9692, lr: 0.001
Epoch [43/134], Training Loss: 9.1121, Validation Loss Current: 7.8522, Validation Loss AVG: 11.8040, lr: 0.001
Epoch [44/134], Training Loss: 7.4904, Validation Loss Current: 6.1651, Validation Loss AVG: 9.8165, lr: 0.001
Epoch [45/134], Training Loss: 8.2735, Validation Loss Current: 6.5989, Validation Loss AVG: 12.5196, lr: 0.001
Epoch [46/134], Training Loss: 11.2622, Validation Loss Current: 6.6487, Validation Loss AVG: 10.7555, lr: 0.001
Epoch [47/134], Training Loss: 7.6642, Validation Loss Current: 6.2510, Validation Loss AVG: 12.5924, lr: 0.001
Epoch [48/134], Training Loss: 7.2877, Validation Loss Current: 6.3530, Validation Loss AVG: 11.9668, lr: 0.001
Epoch [49/134], Training Loss: 5.7167, Validation Loss Current: 5.9579, Validation Loss AVG: 10.5732, lr: 0.001
Epoch [50/134], Training Loss: 6.3281, Validation Loss Current: 5.9352, Validation Loss AVG: 10.4625, lr: 0.001
Epoch [51/134], Training Loss: 4.9591, Validation Loss Current: 6.2838, Validation Loss AVG: 14.8946, lr: 0.001
Epoch [52/134], Training Loss: 3.6914, Validation Loss Current: 5.7618, Validation Loss AVG: 10.2254, lr: 0.001
Epoch [53/134], Training Loss: 2.9835, Validation Loss Current: 6.1025, Validation Loss AVG: 9.7383, lr: 0.001
Epoch [54/134], Training Loss: 2.5271, Validation Loss Current: 6.1494, Validation Loss AVG: 11.2313, lr: 0.001
Epoch [55/134], Training Loss: 2.4786, Validation Loss Current: 6.6214, Validation Loss AVG: 14.0852, lr: 0.001
Epoch [56/134], Training Loss: 4.2388, Validation Loss Current: 6.0854, Validation Loss AVG: 10.9539, lr: 0.001
Epoch [57/134], Training Loss: 4.6053, Validation Loss Current: 6.8052, Validation Loss AVG: 10.6638, lr: 0.001
Epoch [58/134], Training Loss: 7.2887, Validation Loss Current: 7.5086, Validation Loss AVG: 10.1290, lr: 0.001
Epoch [59/134], Training Loss: 5.4527, Validation Loss Current: 6.5390, Validation Loss AVG: 12.5172, lr: 0.001
Epoch [60/134], Training Loss: 3.4044, Validation Loss Current: 6.9042, Validation Loss AVG: 14.4120, lr: 0.001
Epoch [61/134], Training Loss: 2.7229, Validation Loss Current: 8.3541, Validation Loss AVG: 18.3232, lr: 0.001
Epoch [62/134], Training Loss: 6.6624, Validation Loss Current: 9.3980, Validation Loss AVG: 14.5110, lr: 0.001
Epoch [63/134], Training Loss: 13.5875, Validation Loss Current: 11.6442, Validation Loss AVG: 18.0984, lr: 0.001
Epoch [64/134], Training Loss: 8.8659, Validation Loss Current: 7.4274, Validation Loss AVG: 13.5049, lr: 0.001
Epoch [65/134], Training Loss: 7.9799, Validation Loss Current: 9.3080, Validation Loss AVG: 15.0331, lr: 0.001
Epoch [66/134], Training Loss: 11.0018, Validation Loss Current: 7.6261, Validation Loss AVG: 16.9649, lr: 0.001
Epoch [67/134], Training Loss: 6.2254, Validation Loss Current: 7.8808, Validation Loss AVG: 10.7843, lr: 0.001
Epoch [68/134], Training Loss: 6.3002, Validation Loss Current: 8.5044, Validation Loss AVG: 14.0567, lr: 0.001
Epoch [69/134], Training Loss: 5.4640, Validation Loss Current: 7.6323, Validation Loss AVG: 10.9552, lr: 0.001
Epoch [70/134], Training Loss: 4.1311, Validation Loss Current: 8.2599, Validation Loss AVG: 14.9419, lr: 0.001
Epoch [71/134], Training Loss: 5.0106, Validation Loss Current: 7.0223, Validation Loss AVG: 10.6000, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 41 Best val accuracy: [0.25, 0.3338815789473684, 0.34375, 0.38651315789473684, 0.41118421052631576, 0.43256578947368424, 0.4868421052631579, 0.4621710526315789, 0.4654605263157895, 0.4161184210526316, 0.4786184210526316, 0.5164473684210527, 0.48355263157894735, 0.5411184210526315, 0.5427631578947368, 0.5164473684210527, 0.5131578947368421, 0.5296052631578947, 0.537828947368421, 0.53125, 0.5592105263157895, 0.5098684210526315, 0.4654605263157895, 0.5641447368421053, 0.5542763157894737, 0.5756578947368421, 0.5625, 0.5756578947368421, 0.6052631578947368, 0.5986842105263158, 0.6085526315789473, 0.5526315789473685, 0.5263157894736842, 0.5509868421052632, 0.6069078947368421, 0.587171052631579, 0.5986842105263158, 0.4342105263157895, 0.5526315789473685, 0.5740131578947368, 0.6217105263157895, 0.6069078947368421, 0.5493421052631579, 0.6069078947368421, 0.5838815789473685, 0.5723684210526315, 0.5953947368421053, 0.5855263157894737, 0.5970394736842105, 0.618421052631579, 0.6151315789473685, 0.6365131578947368, 0.6217105263157895, 0.618421052631579, 0.6134868421052632, 0.6167763157894737, 0.6134868421052632, 0.569078947368421, 0.6052631578947368, 0.5838815789473685, 0.5493421052631579, 0.4753289473684211, 0.4309210526315789, 0.5707236842105263, 0.506578947368421, 0.5805921052631579, 0.5460526315789473, 0.5394736842105263, 0.5773026315789473, 0.5197368421052632, 0.5789473684210527] Best val loss: 5.568567872047424


Current group: 0.8
Epoch [1/134], Training Loss: 22.0996, Validation Loss Current: 10.3516, Validation Loss AVG: 10.3516, lr: 0.001
Epoch [2/134], Training Loss: 16.3442, Validation Loss Current: 12.9081, Validation Loss AVG: 12.9081, lr: 0.001
Epoch [3/134], Training Loss: 13.1929, Validation Loss Current: 11.1025, Validation Loss AVG: 11.1025, lr: 0.001
Epoch [4/134], Training Loss: 11.3185, Validation Loss Current: 9.9026, Validation Loss AVG: 9.9026, lr: 0.001
Epoch [5/134], Training Loss: 10.4130, Validation Loss Current: 12.0721, Validation Loss AVG: 12.0721, lr: 0.001
Epoch [6/134], Training Loss: 15.2468, Validation Loss Current: 10.1310, Validation Loss AVG: 10.1310, lr: 0.001
Epoch [7/134], Training Loss: 17.6042, Validation Loss Current: 10.4476, Validation Loss AVG: 10.4476, lr: 0.001
Epoch [8/134], Training Loss: 10.5246, Validation Loss Current: 10.2574, Validation Loss AVG: 10.2574, lr: 0.001
Epoch [9/134], Training Loss: 9.3272, Validation Loss Current: 11.0630, Validation Loss AVG: 11.0630, lr: 0.001
Epoch [10/134], Training Loss: 8.5722, Validation Loss Current: 9.8655, Validation Loss AVG: 9.8655, lr: 0.001
Epoch [11/134], Training Loss: 6.7624, Validation Loss Current: 10.3819, Validation Loss AVG: 10.3819, lr: 0.001
Epoch [12/134], Training Loss: 6.7879, Validation Loss Current: 12.7446, Validation Loss AVG: 12.7446, lr: 0.001
Epoch [13/134], Training Loss: 10.7669, Validation Loss Current: 11.3677, Validation Loss AVG: 11.3677, lr: 0.001
Epoch [14/134], Training Loss: 5.9383, Validation Loss Current: 13.6740, Validation Loss AVG: 13.6740, lr: 0.001
Epoch [15/134], Training Loss: 3.8185, Validation Loss Current: 9.9205, Validation Loss AVG: 9.9205, lr: 0.001
Epoch [16/134], Training Loss: 3.3434, Validation Loss Current: 11.0028, Validation Loss AVG: 11.0028, lr: 0.001
Epoch [17/134], Training Loss: 2.9070, Validation Loss Current: 11.7111, Validation Loss AVG: 11.7111, lr: 0.001
Epoch [18/134], Training Loss: 2.7256, Validation Loss Current: 12.2935, Validation Loss AVG: 12.2935, lr: 0.001
Epoch [19/134], Training Loss: 3.9630, Validation Loss Current: 13.2863, Validation Loss AVG: 13.2863, lr: 0.001
Epoch [20/134], Training Loss: 2.9281, Validation Loss Current: 10.8421, Validation Loss AVG: 10.8421, lr: 0.001
Epoch [21/134], Training Loss: 4.4546, Validation Loss Current: 10.3335, Validation Loss AVG: 10.3335, lr: 0.001
Epoch [22/134], Training Loss: 4.3967, Validation Loss Current: 12.6613, Validation Loss AVG: 12.6613, lr: 0.001
Epoch [23/134], Training Loss: 3.6437, Validation Loss Current: 10.9843, Validation Loss AVG: 10.9843, lr: 0.001
Epoch [24/134], Training Loss: 3.2528, Validation Loss Current: 12.4105, Validation Loss AVG: 12.4105, lr: 0.001
Epoch [25/134], Training Loss: 2.4639, Validation Loss Current: 12.3301, Validation Loss AVG: 12.3301, lr: 0.001
Epoch [26/134], Training Loss: 1.3983, Validation Loss Current: 11.6278, Validation Loss AVG: 11.6278, lr: 0.001
Epoch [27/134], Training Loss: 3.5407, Validation Loss Current: 13.2796, Validation Loss AVG: 13.2796, lr: 0.001
Epoch [28/134], Training Loss: 4.6416, Validation Loss Current: 13.4326, Validation Loss AVG: 13.4326, lr: 0.001
Epoch [29/134], Training Loss: 4.2148, Validation Loss Current: 15.4636, Validation Loss AVG: 15.4636, lr: 0.001
Epoch [30/134], Training Loss: 4.6944, Validation Loss Current: 10.7839, Validation Loss AVG: 10.7839, lr: 0.001
Epoch [31/134], Training Loss: 5.9844, Validation Loss Current: 12.8332, Validation Loss AVG: 12.8332, lr: 0.001
Epoch [32/134], Training Loss: 6.1227, Validation Loss Current: 12.0173, Validation Loss AVG: 12.0173, lr: 0.001
Epoch [33/134], Training Loss: 4.6590, Validation Loss Current: 12.0744, Validation Loss AVG: 12.0744, lr: 0.001
Epoch [34/134], Training Loss: 2.7343, Validation Loss Current: 12.0807, Validation Loss AVG: 12.0807, lr: 0.001
Epoch [35/134], Training Loss: 4.3925, Validation Loss Current: 12.1201, Validation Loss AVG: 12.1201, lr: 0.001
Epoch [36/134], Training Loss: 5.2549, Validation Loss Current: 12.5009, Validation Loss AVG: 12.5009, lr: 0.001
Epoch [37/134], Training Loss: 2.7668, Validation Loss Current: 12.2276, Validation Loss AVG: 12.2276, lr: 0.001
Epoch [38/134], Training Loss: 4.2373, Validation Loss Current: 12.8474, Validation Loss AVG: 12.8474, lr: 0.001
Epoch [39/134], Training Loss: 4.2945, Validation Loss Current: 15.6821, Validation Loss AVG: 15.6821, lr: 0.001
Epoch [40/134], Training Loss: 2.8827, Validation Loss Current: 12.1059, Validation Loss AVG: 12.1059, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 10 Best val accuracy: [0.4279605263157894, 0.3796052631578947, 0.39473684210526316, 0.45065789473684215, 0.39013157894736844, 0.4197368421052632, 0.4282894736842106, 0.42072368421052636, 0.40328947368421053, 0.4164473684210527, 0.4220394736842105, 0.3884868421052632, 0.4213815789473684, 0.39934210526315794, 0.4348684210526315, 0.44506578947368425, 0.42796052631578946, 0.4256578947368421, 0.40131578947368424, 0.4375, 0.4480263157894736, 0.42105263157894735, 0.4437499999999999, 0.4180921052631579, 0.44671052631578956, 0.4572368421052631, 0.45493421052631583, 0.4223684210526316, 0.38815789473684215, 0.4513157894736842, 0.37697368421052635, 0.4203947368421053, 0.436842105263158, 0.4266447368421053, 0.43618421052631573, 0.42993421052631575, 0.42927631578947373, 0.4608552631578947, 0.3845394736842106, 0.4496710526315789] Best val loss: 9.865477061271667


Current group: 0.6
Epoch [1/134], Training Loss: 28.1302, Validation Loss Current: 13.1315, Validation Loss AVG: 13.1315, lr: 0.001
Epoch [2/134], Training Loss: 18.8060, Validation Loss Current: 13.7153, Validation Loss AVG: 13.7153, lr: 0.001
Epoch [3/134], Training Loss: 14.1691, Validation Loss Current: 12.6688, Validation Loss AVG: 12.6688, lr: 0.001
Epoch [4/134], Training Loss: 10.5648, Validation Loss Current: 10.2537, Validation Loss AVG: 10.2537, lr: 0.001
Epoch [5/134], Training Loss: 8.5246, Validation Loss Current: 10.3749, Validation Loss AVG: 10.3749, lr: 0.001
Epoch [6/134], Training Loss: 6.7555, Validation Loss Current: 9.8962, Validation Loss AVG: 9.8962, lr: 0.001
Epoch [7/134], Training Loss: 4.8217, Validation Loss Current: 9.0694, Validation Loss AVG: 9.0694, lr: 0.001
Epoch [8/134], Training Loss: 7.2595, Validation Loss Current: 10.3810, Validation Loss AVG: 10.3810, lr: 0.001
Epoch [9/134], Training Loss: 4.4619, Validation Loss Current: 10.5713, Validation Loss AVG: 10.5713, lr: 0.001
Epoch [10/134], Training Loss: 5.7093, Validation Loss Current: 12.4593, Validation Loss AVG: 12.4593, lr: 0.001
Epoch [11/134], Training Loss: 6.3058, Validation Loss Current: 10.1739, Validation Loss AVG: 10.1739, lr: 0.001
Epoch [12/134], Training Loss: 4.1701, Validation Loss Current: 11.7974, Validation Loss AVG: 11.7974, lr: 0.001
Epoch [13/134], Training Loss: 5.0397, Validation Loss Current: 13.5445, Validation Loss AVG: 13.5445, lr: 0.001
Epoch [14/134], Training Loss: 8.8955, Validation Loss Current: 14.4318, Validation Loss AVG: 14.4318, lr: 0.001
Epoch [15/134], Training Loss: 7.9648, Validation Loss Current: 16.5884, Validation Loss AVG: 16.5884, lr: 0.001
Epoch [16/134], Training Loss: 6.0868, Validation Loss Current: 14.8174, Validation Loss AVG: 14.8174, lr: 0.001
Epoch [17/134], Training Loss: 4.4850, Validation Loss Current: 11.6317, Validation Loss AVG: 11.6317, lr: 0.001
Epoch [18/134], Training Loss: 5.1158, Validation Loss Current: 11.2838, Validation Loss AVG: 11.2838, lr: 0.001
Epoch [19/134], Training Loss: 4.2816, Validation Loss Current: 12.2688, Validation Loss AVG: 12.2688, lr: 0.001
Epoch [20/134], Training Loss: 3.3356, Validation Loss Current: 12.3630, Validation Loss AVG: 12.3630, lr: 0.001
Epoch [21/134], Training Loss: 3.7676, Validation Loss Current: 11.7686, Validation Loss AVG: 11.7686, lr: 0.001
Epoch [22/134], Training Loss: 5.6023, Validation Loss Current: 11.1098, Validation Loss AVG: 11.1098, lr: 0.001
Epoch [23/134], Training Loss: 2.6494, Validation Loss Current: 12.8864, Validation Loss AVG: 12.8864, lr: 0.001
Epoch [24/134], Training Loss: 2.1415, Validation Loss Current: 11.6434, Validation Loss AVG: 11.6434, lr: 0.001
Epoch [25/134], Training Loss: 6.7240, Validation Loss Current: 11.8555, Validation Loss AVG: 11.8555, lr: 0.001
Epoch [26/134], Training Loss: 5.8946, Validation Loss Current: 13.7938, Validation Loss AVG: 13.7938, lr: 0.001
Epoch [27/134], Training Loss: 3.3648, Validation Loss Current: 11.9096, Validation Loss AVG: 11.9096, lr: 0.001
Epoch [28/134], Training Loss: 2.7437, Validation Loss Current: 13.3957, Validation Loss AVG: 13.3957, lr: 0.001
Epoch [29/134], Training Loss: 4.4627, Validation Loss Current: 14.8832, Validation Loss AVG: 14.8832, lr: 0.001
Epoch [30/134], Training Loss: 5.5984, Validation Loss Current: 14.4096, Validation Loss AVG: 14.4096, lr: 0.001
Epoch [31/134], Training Loss: 5.1245, Validation Loss Current: 11.8499, Validation Loss AVG: 11.8499, lr: 0.001
Epoch [32/134], Training Loss: 3.3318, Validation Loss Current: 12.6550, Validation Loss AVG: 12.6550, lr: 0.001
Epoch [33/134], Training Loss: 2.1989, Validation Loss Current: 13.0027, Validation Loss AVG: 13.0027, lr: 0.001
Epoch [34/134], Training Loss: 3.2434, Validation Loss Current: 12.1603, Validation Loss AVG: 12.1603, lr: 0.001
Epoch [35/134], Training Loss: 3.5363, Validation Loss Current: 12.9178, Validation Loss AVG: 12.9178, lr: 0.001
Epoch [36/134], Training Loss: 4.1519, Validation Loss Current: 11.6913, Validation Loss AVG: 11.6913, lr: 0.001
Epoch [37/134], Training Loss: 2.3561, Validation Loss Current: 12.3679, Validation Loss AVG: 12.3679, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 7 Best val accuracy: [0.4391447368421052, 0.4305921052631579, 0.4167763157894737, 0.4546052631578948, 0.4756578947368421, 0.46809210526315786, 0.47796052631578956, 0.47368421052631576, 0.4697368421052631, 0.44309210526315795, 0.4884868421052631, 0.4437499999999999, 0.4391447368421052, 0.4526315789473685, 0.3611842105263158, 0.3756578947368421, 0.47434210526315795, 0.4703947368421053, 0.4654605263157895, 0.4536184210526316, 0.47697368421052627, 0.48519736842105277, 0.45855263157894743, 0.4789473684210527, 0.4641447368421052, 0.42467105263157895, 0.4838815789473684, 0.4582236842105263, 0.4483552631578947, 0.45032894736842105, 0.44539473684210523, 0.42796052631578946, 0.47006578947368427, 0.4595394736842106, 0.46940789473684214, 0.45197368421052636, 0.4516447368421052] Best val loss: 9.069418358802796


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4] -----
Current group: 1
Epoch [1/100], Training Loss: 40.6480, Validation Loss Current: 9.8358, Validation Loss AVG: 9.9092, lr: 0.001
Epoch [2/100], Training Loss: 38.4898, Validation Loss Current: 9.5033, Validation Loss AVG: 9.8872, lr: 0.001
Epoch [3/100], Training Loss: 37.0879, Validation Loss Current: 9.1249, Validation Loss AVG: 9.6445, lr: 0.001
Epoch [4/100], Training Loss: 35.5365, Validation Loss Current: 8.6439, Validation Loss AVG: 9.3978, lr: 0.001
Epoch [5/100], Training Loss: 34.1843, Validation Loss Current: 8.2806, Validation Loss AVG: 9.3987, lr: 0.001
Epoch [6/100], Training Loss: 33.1078, Validation Loss Current: 8.1419, Validation Loss AVG: 10.2728, lr: 0.001
Epoch [7/100], Training Loss: 32.0588, Validation Loss Current: 7.8749, Validation Loss AVG: 8.8926, lr: 0.001
Epoch [8/100], Training Loss: 30.5343, Validation Loss Current: 8.0634, Validation Loss AVG: 12.6635, lr: 0.001
Epoch [9/100], Training Loss: 29.3142, Validation Loss Current: 7.6006, Validation Loss AVG: 10.6449, lr: 0.001
Epoch [10/100], Training Loss: 28.8063, Validation Loss Current: 7.5923, Validation Loss AVG: 9.0052, lr: 0.001
Epoch [11/100], Training Loss: 27.0717, Validation Loss Current: 7.3361, Validation Loss AVG: 9.7154, lr: 0.001
Epoch [12/100], Training Loss: 26.0204, Validation Loss Current: 6.9478, Validation Loss AVG: 8.7454, lr: 0.001
Epoch [13/100], Training Loss: 25.6133, Validation Loss Current: 6.8126, Validation Loss AVG: 9.1243, lr: 0.001
Epoch [14/100], Training Loss: 25.0244, Validation Loss Current: 6.7502, Validation Loss AVG: 9.3267, lr: 0.001
Epoch [15/100], Training Loss: 24.7788, Validation Loss Current: 6.5628, Validation Loss AVG: 9.1955, lr: 0.001
Epoch [16/100], Training Loss: 24.8542, Validation Loss Current: 7.0009, Validation Loss AVG: 9.5183, lr: 0.001
Epoch [17/100], Training Loss: 22.4237, Validation Loss Current: 6.3728, Validation Loss AVG: 8.6688, lr: 0.001
Epoch [18/100], Training Loss: 20.7046, Validation Loss Current: 6.0328, Validation Loss AVG: 8.3985, lr: 0.001
Epoch [19/100], Training Loss: 20.5140, Validation Loss Current: 6.6787, Validation Loss AVG: 9.7867, lr: 0.001
Epoch [20/100], Training Loss: 20.6630, Validation Loss Current: 8.2730, Validation Loss AVG: 13.7932, lr: 0.001
Epoch [21/100], Training Loss: 19.6901, Validation Loss Current: 6.4945, Validation Loss AVG: 8.9474, lr: 0.001
Epoch [22/100], Training Loss: 18.8858, Validation Loss Current: 5.8457, Validation Loss AVG: 8.2822, lr: 0.001
Epoch [23/100], Training Loss: 17.8372, Validation Loss Current: 5.8229, Validation Loss AVG: 9.2405, lr: 0.001
Epoch [24/100], Training Loss: 19.0814, Validation Loss Current: 6.8575, Validation Loss AVG: 10.3195, lr: 0.001
Epoch [25/100], Training Loss: 17.4974, Validation Loss Current: 5.6214, Validation Loss AVG: 9.7289, lr: 0.001
Epoch [26/100], Training Loss: 16.1568, Validation Loss Current: 6.0318, Validation Loss AVG: 9.0737, lr: 0.001
Epoch [27/100], Training Loss: 18.0954, Validation Loss Current: 8.4309, Validation Loss AVG: 13.0479, lr: 0.001
Epoch [28/100], Training Loss: 18.0506, Validation Loss Current: 5.9737, Validation Loss AVG: 9.5937, lr: 0.001
Epoch [29/100], Training Loss: 15.1286, Validation Loss Current: 5.8033, Validation Loss AVG: 9.5767, lr: 0.001
Epoch [30/100], Training Loss: 13.5336, Validation Loss Current: 5.5557, Validation Loss AVG: 8.1247, lr: 0.001
Epoch [31/100], Training Loss: 13.1160, Validation Loss Current: 6.3160, Validation Loss AVG: 8.8793, lr: 0.001
Epoch [32/100], Training Loss: 14.2347, Validation Loss Current: 6.2015, Validation Loss AVG: 9.2437, lr: 0.001
Epoch [33/100], Training Loss: 11.8316, Validation Loss Current: 5.8798, Validation Loss AVG: 9.4602, lr: 0.001
Epoch [34/100], Training Loss: 10.8222, Validation Loss Current: 5.4802, Validation Loss AVG: 8.9131, lr: 0.001
Epoch [35/100], Training Loss: 11.4985, Validation Loss Current: 6.4801, Validation Loss AVG: 9.1823, lr: 0.001
Epoch [36/100], Training Loss: 11.2630, Validation Loss Current: 6.5682, Validation Loss AVG: 13.0598, lr: 0.001
Epoch [37/100], Training Loss: 9.7114, Validation Loss Current: 5.7564, Validation Loss AVG: 10.9133, lr: 0.001
Epoch [38/100], Training Loss: 11.4598, Validation Loss Current: 5.6387, Validation Loss AVG: 10.1975, lr: 0.001
Epoch [39/100], Training Loss: 11.9810, Validation Loss Current: 5.9541, Validation Loss AVG: 11.0592, lr: 0.001
Epoch [40/100], Training Loss: 9.6484, Validation Loss Current: 5.9042, Validation Loss AVG: 8.9186, lr: 0.001
Epoch [41/100], Training Loss: 7.8626, Validation Loss Current: 5.7534, Validation Loss AVG: 10.3466, lr: 0.001
Epoch [42/100], Training Loss: 6.0591, Validation Loss Current: 5.5213, Validation Loss AVG: 9.8736, lr: 0.001
Epoch [43/100], Training Loss: 5.6983, Validation Loss Current: 6.9450, Validation Loss AVG: 9.5713, lr: 0.001
Epoch [44/100], Training Loss: 8.0011, Validation Loss Current: 7.4364, Validation Loss AVG: 10.3187, lr: 0.001
Epoch [45/100], Training Loss: 7.0654, Validation Loss Current: 7.8061, Validation Loss AVG: 12.6794, lr: 0.001
Epoch [46/100], Training Loss: 6.0574, Validation Loss Current: 6.5451, Validation Loss AVG: 11.8417, lr: 0.001
Epoch [47/100], Training Loss: 5.5214, Validation Loss Current: 6.6751, Validation Loss AVG: 11.1333, lr: 0.001
Epoch [48/100], Training Loss: 6.2499, Validation Loss Current: 7.2413, Validation Loss AVG: 13.8886, lr: 0.001
Epoch [49/100], Training Loss: 6.9224, Validation Loss Current: 6.4477, Validation Loss AVG: 9.8161, lr: 0.001
Epoch [50/100], Training Loss: 4.7208, Validation Loss Current: 6.4533, Validation Loss AVG: 13.3596, lr: 0.001
Epoch [51/100], Training Loss: 5.9945, Validation Loss Current: 6.5409, Validation Loss AVG: 11.1419, lr: 0.001
Epoch [52/100], Training Loss: 4.5652, Validation Loss Current: 6.1554, Validation Loss AVG: 12.7317, lr: 0.001
Epoch [53/100], Training Loss: 3.4534, Validation Loss Current: 6.3670, Validation Loss AVG: 13.6514, lr: 0.001
Epoch [54/100], Training Loss: 3.9141, Validation Loss Current: 6.4683, Validation Loss AVG: 10.2294, lr: 0.001
Epoch [55/100], Training Loss: 4.2172, Validation Loss Current: 6.5381, Validation Loss AVG: 10.8878, lr: 0.001
Epoch [56/100], Training Loss: 3.7122, Validation Loss Current: 6.6079, Validation Loss AVG: 11.6054, lr: 0.001
Epoch [57/100], Training Loss: 4.7538, Validation Loss Current: 6.4011, Validation Loss AVG: 11.4430, lr: 0.001
Epoch [58/100], Training Loss: 4.7023, Validation Loss Current: 7.5427, Validation Loss AVG: 11.8843, lr: 0.001
Epoch [59/100], Training Loss: 6.0205, Validation Loss Current: 9.1875, Validation Loss AVG: 11.0645, lr: 0.001
Epoch [60/100], Training Loss: 8.5719, Validation Loss Current: 8.6714, Validation Loss AVG: 13.5509, lr: 0.001
Epoch [61/100], Training Loss: 5.4280, Validation Loss Current: 8.6762, Validation Loss AVG: 12.5027, lr: 0.001
Epoch [62/100], Training Loss: 4.7587, Validation Loss Current: 8.2479, Validation Loss AVG: 14.7442, lr: 0.001
Epoch [63/100], Training Loss: 3.1333, Validation Loss Current: 6.4584, Validation Loss AVG: 10.5114, lr: 0.001
Epoch [64/100], Training Loss: 3.4761, Validation Loss Current: 6.9118, Validation Loss AVG: 15.0004, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 34 Best val accuracy: [0.24671052631578946, 0.3157894736842105, 0.3355263157894737, 0.37993421052631576, 0.4161184210526316, 0.42598684210526316, 0.43256578947368424, 0.4128289473684211, 0.4934210526315789, 0.44901315789473684, 0.48519736842105265, 0.5180921052631579, 0.5098684210526315, 0.5296052631578947, 0.5460526315789473, 0.5328947368421053, 0.5707236842105263, 0.5822368421052632, 0.5460526315789473, 0.4868421052631579, 0.5427631578947368, 0.5970394736842105, 0.6019736842105263, 0.5460526315789473, 0.6085526315789473, 0.5756578947368421, 0.46710526315789475, 0.5773026315789473, 0.569078947368421, 0.6036184210526315, 0.5575657894736842, 0.5773026315789473, 0.6118421052631579, 0.6365131578947368, 0.5279605263157895, 0.5723684210526315, 0.5888157894736842, 0.6266447368421053, 0.6019736842105263, 0.6085526315789473, 0.5986842105263158, 0.618421052631579, 0.5460526315789473, 0.5493421052631579, 0.5049342105263158, 0.6069078947368421, 0.600328947368421, 0.5526315789473685, 0.5888157894736842, 0.5756578947368421, 0.5773026315789473, 0.6101973684210527, 0.5855263157894737, 0.5970394736842105, 0.5904605263157895, 0.5855263157894737, 0.6167763157894737, 0.5476973684210527, 0.5345394736842105, 0.53125, 0.5526315789473685, 0.5411184210526315, 0.5970394736842105, 0.5838815789473685] Best val loss: 5.480183243751526


Current group: 0.8
Epoch [1/100], Training Loss: 22.0899, Validation Loss Current: 12.0467, Validation Loss AVG: 12.0467, lr: 0.001
Epoch [2/100], Training Loss: 17.7527, Validation Loss Current: 12.4788, Validation Loss AVG: 12.4788, lr: 0.001
Epoch [3/100], Training Loss: 12.2596, Validation Loss Current: 9.1572, Validation Loss AVG: 9.1572, lr: 0.001
Epoch [4/100], Training Loss: 10.0057, Validation Loss Current: 9.5395, Validation Loss AVG: 9.5395, lr: 0.001
Epoch [5/100], Training Loss: 11.9070, Validation Loss Current: 11.5702, Validation Loss AVG: 11.5702, lr: 0.001
Epoch [6/100], Training Loss: 8.9899, Validation Loss Current: 13.1109, Validation Loss AVG: 13.1109, lr: 0.001
Epoch [7/100], Training Loss: 6.6023, Validation Loss Current: 10.7399, Validation Loss AVG: 10.7399, lr: 0.001
Epoch [8/100], Training Loss: 4.5143, Validation Loss Current: 9.2825, Validation Loss AVG: 9.2825, lr: 0.001
Epoch [9/100], Training Loss: 4.4634, Validation Loss Current: 9.4957, Validation Loss AVG: 9.4957, lr: 0.001
Epoch [10/100], Training Loss: 10.1310, Validation Loss Current: 10.9154, Validation Loss AVG: 10.9154, lr: 0.001
Epoch [11/100], Training Loss: 7.2755, Validation Loss Current: 10.7396, Validation Loss AVG: 10.7396, lr: 0.001
Epoch [12/100], Training Loss: 6.4954, Validation Loss Current: 11.8938, Validation Loss AVG: 11.8938, lr: 0.001
Epoch [13/100], Training Loss: 5.9518, Validation Loss Current: 10.6906, Validation Loss AVG: 10.6906, lr: 0.001
Epoch [14/100], Training Loss: 4.5732, Validation Loss Current: 11.8785, Validation Loss AVG: 11.8785, lr: 0.001
Epoch [15/100], Training Loss: 3.2156, Validation Loss Current: 11.5689, Validation Loss AVG: 11.5689, lr: 0.001
Epoch [16/100], Training Loss: 3.3330, Validation Loss Current: 12.9372, Validation Loss AVG: 12.9372, lr: 0.001
Epoch [17/100], Training Loss: 3.0877, Validation Loss Current: 11.0498, Validation Loss AVG: 11.0498, lr: 0.001
Epoch [18/100], Training Loss: 5.2836, Validation Loss Current: 12.6848, Validation Loss AVG: 12.6848, lr: 0.001
Epoch [19/100], Training Loss: 5.3742, Validation Loss Current: 15.5272, Validation Loss AVG: 15.5272, lr: 0.001
Epoch [20/100], Training Loss: 8.1880, Validation Loss Current: 25.6925, Validation Loss AVG: 25.6925, lr: 0.001
Epoch [21/100], Training Loss: 15.8624, Validation Loss Current: 13.0513, Validation Loss AVG: 13.0513, lr: 0.001
Epoch [22/100], Training Loss: 8.2931, Validation Loss Current: 13.1578, Validation Loss AVG: 13.1578, lr: 0.001
Epoch [23/100], Training Loss: 4.0438, Validation Loss Current: 11.4837, Validation Loss AVG: 11.4837, lr: 0.001
Epoch [24/100], Training Loss: 3.3566, Validation Loss Current: 10.7400, Validation Loss AVG: 10.7400, lr: 0.001
Epoch [25/100], Training Loss: 5.7080, Validation Loss Current: 12.5156, Validation Loss AVG: 12.5156, lr: 0.001
Epoch [26/100], Training Loss: 3.2488, Validation Loss Current: 11.0392, Validation Loss AVG: 11.0392, lr: 0.001
Epoch [27/100], Training Loss: 2.6796, Validation Loss Current: 11.6940, Validation Loss AVG: 11.6940, lr: 0.001
Epoch [28/100], Training Loss: 3.9172, Validation Loss Current: 11.8771, Validation Loss AVG: 11.8771, lr: 0.001
Epoch [29/100], Training Loss: 5.1003, Validation Loss Current: 11.8895, Validation Loss AVG: 11.8895, lr: 0.001
Epoch [30/100], Training Loss: 9.0260, Validation Loss Current: 12.9817, Validation Loss AVG: 12.9817, lr: 0.001
Epoch [31/100], Training Loss: 10.6374, Validation Loss Current: 12.5691, Validation Loss AVG: 12.5691, lr: 0.001
Epoch [32/100], Training Loss: 7.4357, Validation Loss Current: 11.6749, Validation Loss AVG: 11.6749, lr: 0.001
Epoch [33/100], Training Loss: 4.5919, Validation Loss Current: 10.3213, Validation Loss AVG: 10.3213, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 3 Best val accuracy: [0.37467105263157896, 0.4, 0.45230263157894735, 0.4713815789473685, 0.39506578947368426, 0.37927631578947374, 0.44013157894736843, 0.4529605263157895, 0.45723684210526316, 0.42434210526315785, 0.43618421052631584, 0.387828947368421, 0.4180921052631579, 0.4131578947368421, 0.36447368421052634, 0.44177631578947374, 0.4240131578947368, 0.4240131578947368, 0.3792763157894737, 0.2667763157894737, 0.3585526315789474, 0.38026315789473686, 0.41875, 0.4338815789473684, 0.3861842105263158, 0.43980263157894744, 0.43717105263157896, 0.44013157894736843, 0.4355263157894737, 0.39407894736842103, 0.4240131578947368, 0.3957236842105263, 0.4375] Best val loss: 9.157235956192016


Current group: 0.6
Epoch [1/100], Training Loss: 27.0581, Validation Loss Current: 9.9129, Validation Loss AVG: 9.9129, lr: 0.001
Epoch [2/100], Training Loss: 17.4581, Validation Loss Current: 9.9021, Validation Loss AVG: 9.9021, lr: 0.001
Epoch [3/100], Training Loss: 11.8724, Validation Loss Current: 9.9641, Validation Loss AVG: 9.9641, lr: 0.001
Epoch [4/100], Training Loss: 9.8236, Validation Loss Current: 18.2593, Validation Loss AVG: 18.2593, lr: 0.001
Epoch [5/100], Training Loss: 18.4077, Validation Loss Current: 17.2963, Validation Loss AVG: 17.2963, lr: 0.001
Epoch [6/100], Training Loss: 10.4543, Validation Loss Current: 9.8676, Validation Loss AVG: 9.8676, lr: 0.001
Epoch [7/100], Training Loss: 7.7919, Validation Loss Current: 11.1199, Validation Loss AVG: 11.1199, lr: 0.001
Epoch [8/100], Training Loss: 9.3907, Validation Loss Current: 11.2424, Validation Loss AVG: 11.2424, lr: 0.001
Epoch [9/100], Training Loss: 9.2256, Validation Loss Current: 11.7181, Validation Loss AVG: 11.7181, lr: 0.001
Epoch [10/100], Training Loss: 6.0473, Validation Loss Current: 9.9392, Validation Loss AVG: 9.9392, lr: 0.001
Epoch [11/100], Training Loss: 6.0426, Validation Loss Current: 9.7332, Validation Loss AVG: 9.7332, lr: 0.001
Epoch [12/100], Training Loss: 4.2082, Validation Loss Current: 9.9897, Validation Loss AVG: 9.9897, lr: 0.001
Epoch [13/100], Training Loss: 3.8090, Validation Loss Current: 10.5951, Validation Loss AVG: 10.5951, lr: 0.001
Epoch [14/100], Training Loss: 3.8669, Validation Loss Current: 10.0071, Validation Loss AVG: 10.0071, lr: 0.001
Epoch [15/100], Training Loss: 5.2234, Validation Loss Current: 16.2011, Validation Loss AVG: 16.2011, lr: 0.001
Epoch [16/100], Training Loss: 6.5146, Validation Loss Current: 10.3578, Validation Loss AVG: 10.3578, lr: 0.001
Epoch [17/100], Training Loss: 5.9435, Validation Loss Current: 12.6718, Validation Loss AVG: 12.6718, lr: 0.001
Epoch [18/100], Training Loss: 4.7082, Validation Loss Current: 12.1774, Validation Loss AVG: 12.1774, lr: 0.001
Epoch [19/100], Training Loss: 3.1563, Validation Loss Current: 10.4318, Validation Loss AVG: 10.4318, lr: 0.001
Epoch [20/100], Training Loss: 2.3327, Validation Loss Current: 10.4765, Validation Loss AVG: 10.4765, lr: 0.001
Epoch [21/100], Training Loss: 4.2119, Validation Loss Current: 12.1506, Validation Loss AVG: 12.1506, lr: 0.001
Epoch [22/100], Training Loss: 6.3622, Validation Loss Current: 13.1078, Validation Loss AVG: 13.1078, lr: 0.001
Epoch [23/100], Training Loss: 6.9486, Validation Loss Current: 12.7223, Validation Loss AVG: 12.7223, lr: 0.001
Epoch [24/100], Training Loss: 6.2302, Validation Loss Current: 14.3992, Validation Loss AVG: 14.3992, lr: 0.001
Epoch [25/100], Training Loss: 4.7311, Validation Loss Current: 13.0335, Validation Loss AVG: 13.0335, lr: 0.001
Epoch [26/100], Training Loss: 8.2346, Validation Loss Current: 14.7928, Validation Loss AVG: 14.7928, lr: 0.001
Epoch [27/100], Training Loss: 5.5093, Validation Loss Current: 13.7956, Validation Loss AVG: 13.7956, lr: 0.001
Epoch [28/100], Training Loss: 2.8852, Validation Loss Current: 10.5135, Validation Loss AVG: 10.5135, lr: 0.001
Epoch [29/100], Training Loss: 2.0560, Validation Loss Current: 10.4626, Validation Loss AVG: 10.4626, lr: 0.001
Epoch [30/100], Training Loss: 5.3777, Validation Loss Current: 11.1488, Validation Loss AVG: 11.1488, lr: 0.001
Epoch [31/100], Training Loss: 2.5075, Validation Loss Current: 11.2168, Validation Loss AVG: 11.2168, lr: 0.001
Epoch [32/100], Training Loss: 1.7065, Validation Loss Current: 11.3357, Validation Loss AVG: 11.3357, lr: 0.001
Epoch [33/100], Training Loss: 1.5502, Validation Loss Current: 10.6651, Validation Loss AVG: 10.6651, lr: 0.001
Epoch [34/100], Training Loss: 2.2885, Validation Loss Current: 12.5873, Validation Loss AVG: 12.5873, lr: 0.001
Epoch [35/100], Training Loss: 3.9230, Validation Loss Current: 14.2871, Validation Loss AVG: 14.2871, lr: 0.001
Epoch [36/100], Training Loss: 2.5437, Validation Loss Current: 12.0513, Validation Loss AVG: 12.0513, lr: 0.001
Epoch [37/100], Training Loss: 2.0493, Validation Loss Current: 12.7275, Validation Loss AVG: 12.7275, lr: 0.001
Epoch [38/100], Training Loss: 2.2314, Validation Loss Current: 12.4773, Validation Loss AVG: 12.4773, lr: 0.001
Epoch [39/100], Training Loss: 3.2716, Validation Loss Current: 12.3911, Validation Loss AVG: 12.3911, lr: 0.001
Epoch [40/100], Training Loss: 3.8589, Validation Loss Current: 13.6152, Validation Loss AVG: 13.6152, lr: 0.001
Epoch [41/100], Training Loss: 4.1502, Validation Loss Current: 14.7401, Validation Loss AVG: 14.7401, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 11 Best val accuracy: [0.468092105263158, 0.46611842105263157, 0.47006578947368427, 0.37730263157894733, 0.3131578947368421, 0.45756578947368415, 0.4598684210526316, 0.43157894736842106, 0.45032894736842105, 0.4394736842105263, 0.4786184210526316, 0.4697368421052631, 0.46282894736842095, 0.48190789473684215, 0.3430921052631579, 0.46447368421052626, 0.43684210526315786, 0.4519736842105263, 0.47894736842105257, 0.5042763157894737, 0.4358552631578947, 0.47368421052631576, 0.45065789473684215, 0.38092105263157894, 0.4463815789473684, 0.3786184210526316, 0.42006578947368417, 0.48684210526315785, 0.47006578947368416, 0.47828947368421054, 0.4493421052631579, 0.47993421052631585, 0.4937500000000001, 0.46875, 0.4256578947368421, 0.4631578947368421, 0.42927631578947373, 0.4740131578947368, 0.47072368421052635, 0.4483552631578947, 0.38684210526315793] Best val loss: 9.733187437057495


Current group: 0.4
Epoch [1/100], Training Loss: 36.5517, Validation Loss Current: 16.9717, Validation Loss AVG: 16.9717, lr: 0.001
Epoch [2/100], Training Loss: 23.6068, Validation Loss Current: 16.0232, Validation Loss AVG: 16.0232, lr: 0.001
Epoch [3/100], Training Loss: 16.3937, Validation Loss Current: 10.1592, Validation Loss AVG: 10.1592, lr: 0.001
Epoch [4/100], Training Loss: 13.2616, Validation Loss Current: 13.5556, Validation Loss AVG: 13.5556, lr: 0.001
Epoch [5/100], Training Loss: 10.5791, Validation Loss Current: 10.2633, Validation Loss AVG: 10.2633, lr: 0.001
Epoch [6/100], Training Loss: 8.2502, Validation Loss Current: 9.9748, Validation Loss AVG: 9.9748, lr: 0.001
Epoch [7/100], Training Loss: 11.7003, Validation Loss Current: 13.0373, Validation Loss AVG: 13.0373, lr: 0.001
Epoch [8/100], Training Loss: 7.4455, Validation Loss Current: 11.8421, Validation Loss AVG: 11.8421, lr: 0.001
Epoch [9/100], Training Loss: 7.4358, Validation Loss Current: 11.5627, Validation Loss AVG: 11.5627, lr: 0.001
Epoch [10/100], Training Loss: 4.9347, Validation Loss Current: 10.6444, Validation Loss AVG: 10.6444, lr: 0.001
Epoch [11/100], Training Loss: 3.9248, Validation Loss Current: 10.3362, Validation Loss AVG: 10.3362, lr: 0.001
Epoch [12/100], Training Loss: 5.0474, Validation Loss Current: 13.1615, Validation Loss AVG: 13.1615, lr: 0.001
Epoch [13/100], Training Loss: 4.0958, Validation Loss Current: 13.5937, Validation Loss AVG: 13.5937, lr: 0.001
Epoch [14/100], Training Loss: 6.7913, Validation Loss Current: 11.8509, Validation Loss AVG: 11.8509, lr: 0.001
Epoch [15/100], Training Loss: 5.0301, Validation Loss Current: 13.8450, Validation Loss AVG: 13.8450, lr: 0.001
Epoch [16/100], Training Loss: 5.3454, Validation Loss Current: 13.1924, Validation Loss AVG: 13.1924, lr: 0.001
Epoch [17/100], Training Loss: 6.8401, Validation Loss Current: 13.4916, Validation Loss AVG: 13.4916, lr: 0.001
Epoch [18/100], Training Loss: 5.0875, Validation Loss Current: 11.8112, Validation Loss AVG: 11.8112, lr: 0.001
Epoch [19/100], Training Loss: 5.5097, Validation Loss Current: 13.0818, Validation Loss AVG: 13.0818, lr: 0.001
Epoch [20/100], Training Loss: 7.5516, Validation Loss Current: 13.6000, Validation Loss AVG: 13.6000, lr: 0.001
Epoch [21/100], Training Loss: 4.8561, Validation Loss Current: 12.2868, Validation Loss AVG: 12.2868, lr: 0.001
Epoch [22/100], Training Loss: 4.2970, Validation Loss Current: 11.0276, Validation Loss AVG: 11.0276, lr: 0.001
Epoch [23/100], Training Loss: 3.0191, Validation Loss Current: 12.2695, Validation Loss AVG: 12.2695, lr: 0.001
Epoch [24/100], Training Loss: 2.2897, Validation Loss Current: 11.5923, Validation Loss AVG: 11.5923, lr: 0.001
Epoch [25/100], Training Loss: 2.2822, Validation Loss Current: 14.1034, Validation Loss AVG: 14.1034, lr: 0.001
Epoch [26/100], Training Loss: 3.0592, Validation Loss Current: 14.1966, Validation Loss AVG: 14.1966, lr: 0.001
Epoch [27/100], Training Loss: 5.9983, Validation Loss Current: 12.3252, Validation Loss AVG: 12.3252, lr: 0.001
Epoch [28/100], Training Loss: 5.9225, Validation Loss Current: 14.2169, Validation Loss AVG: 14.2169, lr: 0.001
Epoch [29/100], Training Loss: 5.8516, Validation Loss Current: 13.9404, Validation Loss AVG: 13.9404, lr: 0.001
Epoch [30/100], Training Loss: 5.7708, Validation Loss Current: 20.6371, Validation Loss AVG: 20.6371, lr: 0.001
Epoch [31/100], Training Loss: 4.1029, Validation Loss Current: 15.0025, Validation Loss AVG: 15.0025, lr: 0.001
Epoch [32/100], Training Loss: 5.3753, Validation Loss Current: 15.7549, Validation Loss AVG: 15.7549, lr: 0.001
Epoch [33/100], Training Loss: 4.2542, Validation Loss Current: 16.9884, Validation Loss AVG: 16.9884, lr: 0.001
Epoch [34/100], Training Loss: 6.2535, Validation Loss Current: 17.4165, Validation Loss AVG: 17.4165, lr: 0.001
Epoch [35/100], Training Loss: 7.4226, Validation Loss Current: 15.1273, Validation Loss AVG: 15.1273, lr: 0.001
Epoch [36/100], Training Loss: 6.4697, Validation Loss Current: 14.6654, Validation Loss AVG: 14.6654, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 6 Best val accuracy: [0.375, 0.35197368421052627, 0.4598684210526316, 0.39375, 0.46282894736842095, 0.5121710526315789, 0.43552631578947365, 0.39473684210526316, 0.4917763157894736, 0.4625, 0.4947368421052632, 0.4598684210526316, 0.43717105263157896, 0.46381578947368424, 0.3940789473684211, 0.4697368421052632, 0.3980263157894736, 0.4723684210526316, 0.4223684210526316, 0.43980263157894733, 0.43322368421052637, 0.46447368421052637, 0.4651315789473684, 0.4756578947368421, 0.44243421052631576, 0.46282894736842106, 0.4625, 0.42894736842105263, 0.44375, 0.3282894736842105, 0.4322368421052632, 0.4203947368421053, 0.35427631578947366, 0.4444078947368421, 0.4023026315789474, 0.4125] Best val loss: 9.97478370666504


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4, 0.2] -----
Current group: 1
Epoch [1/80], Training Loss: 41.8067, Validation Loss Current: 9.8657, Validation Loss AVG: 9.9522, lr: 0.001
Epoch [2/80], Training Loss: 39.1264, Validation Loss Current: 9.6524, Validation Loss AVG: 9.9508, lr: 0.001
Epoch [3/80], Training Loss: 37.5053, Validation Loss Current: 9.3139, Validation Loss AVG: 10.0566, lr: 0.001
Epoch [4/80], Training Loss: 36.5063, Validation Loss Current: 8.9000, Validation Loss AVG: 9.6136, lr: 0.001
Epoch [5/80], Training Loss: 35.1368, Validation Loss Current: 8.5341, Validation Loss AVG: 9.6839, lr: 0.001
Epoch [6/80], Training Loss: 34.0622, Validation Loss Current: 8.2605, Validation Loss AVG: 9.6097, lr: 0.001
Epoch [7/80], Training Loss: 32.7153, Validation Loss Current: 8.0937, Validation Loss AVG: 9.2186, lr: 0.001
Epoch [8/80], Training Loss: 32.0224, Validation Loss Current: 8.0408, Validation Loss AVG: 9.2569, lr: 0.001
Epoch [9/80], Training Loss: 29.4675, Validation Loss Current: 7.3868, Validation Loss AVG: 8.7774, lr: 0.001
Epoch [10/80], Training Loss: 28.9701, Validation Loss Current: 7.4073, Validation Loss AVG: 8.9124, lr: 0.001
Epoch [11/80], Training Loss: 27.2500, Validation Loss Current: 7.1709, Validation Loss AVG: 8.9633, lr: 0.001
Epoch [12/80], Training Loss: 26.9026, Validation Loss Current: 6.7686, Validation Loss AVG: 9.0498, lr: 0.001
Epoch [13/80], Training Loss: 25.5157, Validation Loss Current: 6.7125, Validation Loss AVG: 8.7458, lr: 0.001
Epoch [14/80], Training Loss: 23.6610, Validation Loss Current: 6.5259, Validation Loss AVG: 8.4114, lr: 0.001
Epoch [15/80], Training Loss: 23.3970, Validation Loss Current: 6.8565, Validation Loss AVG: 8.3430, lr: 0.001
Epoch [16/80], Training Loss: 22.9364, Validation Loss Current: 7.0793, Validation Loss AVG: 9.0322, lr: 0.001
Epoch [17/80], Training Loss: 22.8792, Validation Loss Current: 7.2206, Validation Loss AVG: 9.4889, lr: 0.001
Epoch [18/80], Training Loss: 21.0725, Validation Loss Current: 6.3231, Validation Loss AVG: 8.9160, lr: 0.001
Epoch [19/80], Training Loss: 21.4388, Validation Loss Current: 6.5083, Validation Loss AVG: 9.6180, lr: 0.001
Epoch [20/80], Training Loss: 21.8394, Validation Loss Current: 7.0869, Validation Loss AVG: 10.0981, lr: 0.001
Epoch [21/80], Training Loss: 22.2703, Validation Loss Current: 6.6657, Validation Loss AVG: 10.3236, lr: 0.001
Epoch [22/80], Training Loss: 20.7566, Validation Loss Current: 7.1915, Validation Loss AVG: 9.8950, lr: 0.001
Epoch [23/80], Training Loss: 20.5771, Validation Loss Current: 6.7739, Validation Loss AVG: 9.8376, lr: 0.001
Epoch [24/80], Training Loss: 19.4606, Validation Loss Current: 6.0078, Validation Loss AVG: 9.3021, lr: 0.001
Epoch [25/80], Training Loss: 18.3720, Validation Loss Current: 6.1138, Validation Loss AVG: 8.7257, lr: 0.001
Epoch [26/80], Training Loss: 19.1619, Validation Loss Current: 6.0208, Validation Loss AVG: 9.0638, lr: 0.001
Epoch [27/80], Training Loss: 17.2381, Validation Loss Current: 5.9905, Validation Loss AVG: 8.3733, lr: 0.001
Epoch [28/80], Training Loss: 15.0740, Validation Loss Current: 5.8882, Validation Loss AVG: 9.1649, lr: 0.001
Epoch [29/80], Training Loss: 14.8110, Validation Loss Current: 6.1057, Validation Loss AVG: 10.0759, lr: 0.001
Epoch [30/80], Training Loss: 14.3216, Validation Loss Current: 6.0140, Validation Loss AVG: 10.0239, lr: 0.001
Epoch [31/80], Training Loss: 14.3936, Validation Loss Current: 6.3424, Validation Loss AVG: 10.0864, lr: 0.001
Epoch [32/80], Training Loss: 15.5984, Validation Loss Current: 6.7337, Validation Loss AVG: 9.0942, lr: 0.001
Epoch [33/80], Training Loss: 14.1735, Validation Loss Current: 7.2411, Validation Loss AVG: 10.4400, lr: 0.001
Epoch [34/80], Training Loss: 18.3539, Validation Loss Current: 6.6362, Validation Loss AVG: 10.0718, lr: 0.001
Epoch [35/80], Training Loss: 16.1647, Validation Loss Current: 7.1447, Validation Loss AVG: 9.8064, lr: 0.001
Epoch [36/80], Training Loss: 17.1547, Validation Loss Current: 6.2676, Validation Loss AVG: 9.4236, lr: 0.001
Epoch [37/80], Training Loss: 13.2049, Validation Loss Current: 5.8542, Validation Loss AVG: 8.5484, lr: 0.001
Epoch [38/80], Training Loss: 12.0252, Validation Loss Current: 6.3260, Validation Loss AVG: 10.4167, lr: 0.001
Epoch [39/80], Training Loss: 11.6449, Validation Loss Current: 6.6243, Validation Loss AVG: 8.9599, lr: 0.001
Epoch [40/80], Training Loss: 10.3839, Validation Loss Current: 6.0354, Validation Loss AVG: 10.0939, lr: 0.001
Epoch [41/80], Training Loss: 9.7921, Validation Loss Current: 6.9099, Validation Loss AVG: 9.4662, lr: 0.001
Epoch [42/80], Training Loss: 11.6636, Validation Loss Current: 7.0669, Validation Loss AVG: 11.8033, lr: 0.001
Epoch [43/80], Training Loss: 9.1449, Validation Loss Current: 6.3282, Validation Loss AVG: 12.7523, lr: 0.001
Epoch [44/80], Training Loss: 9.0197, Validation Loss Current: 5.9098, Validation Loss AVG: 10.1908, lr: 0.001
Epoch [45/80], Training Loss: 10.3960, Validation Loss Current: 6.1868, Validation Loss AVG: 11.0862, lr: 0.001
Epoch [46/80], Training Loss: 7.1490, Validation Loss Current: 5.8370, Validation Loss AVG: 9.9958, lr: 0.001
Epoch [47/80], Training Loss: 6.2886, Validation Loss Current: 5.9614, Validation Loss AVG: 9.8113, lr: 0.001
Epoch [48/80], Training Loss: 8.4231, Validation Loss Current: 7.6020, Validation Loss AVG: 10.0020, lr: 0.001
Epoch [49/80], Training Loss: 9.9743, Validation Loss Current: 6.7229, Validation Loss AVG: 11.2451, lr: 0.001
Epoch [50/80], Training Loss: 10.4756, Validation Loss Current: 5.9995, Validation Loss AVG: 11.7671, lr: 0.001
Epoch [51/80], Training Loss: 7.5590, Validation Loss Current: 6.4871, Validation Loss AVG: 13.2850, lr: 0.001
Epoch [52/80], Training Loss: 8.8699, Validation Loss Current: 11.1972, Validation Loss AVG: 16.9268, lr: 0.001
Epoch [53/80], Training Loss: 9.6566, Validation Loss Current: 7.7126, Validation Loss AVG: 15.9633, lr: 0.001
Epoch [54/80], Training Loss: 6.0758, Validation Loss Current: 6.4268, Validation Loss AVG: 10.9364, lr: 0.001
Epoch [55/80], Training Loss: 5.9855, Validation Loss Current: 6.4894, Validation Loss AVG: 10.5779, lr: 0.001
Epoch [56/80], Training Loss: 5.3948, Validation Loss Current: 6.2639, Validation Loss AVG: 11.0811, lr: 0.001
Epoch [57/80], Training Loss: 6.2312, Validation Loss Current: 6.6152, Validation Loss AVG: 10.1601, lr: 0.001
Epoch [58/80], Training Loss: 10.5384, Validation Loss Current: 7.5467, Validation Loss AVG: 13.7998, lr: 0.001
Epoch [59/80], Training Loss: 4.8765, Validation Loss Current: 6.6678, Validation Loss AVG: 11.6244, lr: 0.001
Epoch [60/80], Training Loss: 6.0871, Validation Loss Current: 6.4778, Validation Loss AVG: 10.2910, lr: 0.001
Epoch [61/80], Training Loss: 4.4203, Validation Loss Current: 6.9461, Validation Loss AVG: 11.8417, lr: 0.001
Epoch [62/80], Training Loss: 3.8305, Validation Loss Current: 6.3116, Validation Loss AVG: 12.2334, lr: 0.001
Epoch [63/80], Training Loss: 4.2305, Validation Loss Current: 8.9620, Validation Loss AVG: 12.6892, lr: 0.001
Epoch [64/80], Training Loss: 11.2357, Validation Loss Current: 8.2741, Validation Loss AVG: 11.3468, lr: 0.001
Epoch [65/80], Training Loss: 8.2682, Validation Loss Current: 7.4597, Validation Loss AVG: 10.5565, lr: 0.001
Epoch [66/80], Training Loss: 7.8938, Validation Loss Current: 9.1175, Validation Loss AVG: 11.5049, lr: 0.001
Epoch [67/80], Training Loss: 7.8880, Validation Loss Current: 9.3218, Validation Loss AVG: 16.1854, lr: 0.001
Epoch [68/80], Training Loss: 5.3233, Validation Loss Current: 7.9746, Validation Loss AVG: 12.7363, lr: 0.001
Epoch [69/80], Training Loss: 4.5286, Validation Loss Current: 8.5288, Validation Loss AVG: 12.1907, lr: 0.001
Epoch [70/80], Training Loss: 5.2813, Validation Loss Current: 7.6125, Validation Loss AVG: 16.0392, lr: 0.001
Epoch [71/80], Training Loss: 7.9880, Validation Loss Current: 7.5686, Validation Loss AVG: 10.7685, lr: 0.001
Epoch [72/80], Training Loss: 4.4233, Validation Loss Current: 8.0833, Validation Loss AVG: 12.8893, lr: 0.001
Epoch [73/80], Training Loss: 4.6734, Validation Loss Current: 6.6022, Validation Loss AVG: 11.4716, lr: 0.001
Epoch [74/80], Training Loss: 3.1093, Validation Loss Current: 6.9823, Validation Loss AVG: 13.6254, lr: 0.001
Epoch [75/80], Training Loss: 2.8911, Validation Loss Current: 6.8595, Validation Loss AVG: 11.7961, lr: 0.001
Epoch [76/80], Training Loss: 3.1449, Validation Loss Current: 8.0184, Validation Loss AVG: 15.0061, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 46 Best val accuracy: [0.2631578947368421, 0.2680921052631579, 0.32401315789473684, 0.3536184210526316, 0.39144736842105265, 0.4194078947368421, 0.41776315789473684, 0.4161184210526316, 0.4753289473684211, 0.4819078947368421, 0.49835526315789475, 0.5411184210526315, 0.5328947368421053, 0.5279605263157895, 0.4934210526315789, 0.53125, 0.49506578947368424, 0.5592105263157895, 0.5476973684210527, 0.5213815789473685, 0.5279605263157895, 0.5098684210526315, 0.5411184210526315, 0.5904605263157895, 0.5838815789473685, 0.5822368421052632, 0.5838815789473685, 0.59375, 0.555921052631579, 0.5773026315789473, 0.5838815789473685, 0.5575657894736842, 0.5575657894736842, 0.5674342105263158, 0.5180921052631579, 0.5822368421052632, 0.59375, 0.5904605263157895, 0.5394736842105263, 0.6036184210526315, 0.5411184210526315, 0.5756578947368421, 0.5904605263157895, 0.6151315789473685, 0.5986842105263158, 0.6134868421052632, 0.5855263157894737, 0.5263157894736842, 0.6052631578947368, 0.6282894736842105, 0.587171052631579, 0.4457236842105263, 0.5526315789473685, 0.6036184210526315, 0.5805921052631579, 0.6069078947368421, 0.59375, 0.5427631578947368, 0.5986842105263158, 0.6019736842105263, 0.6151315789473685, 0.6134868421052632, 0.5361842105263158, 0.5296052631578947, 0.5888157894736842, 0.49835526315789475, 0.5148026315789473, 0.5953947368421053, 0.5592105263157895, 0.5526315789473685, 0.5855263157894737, 0.6036184210526315, 0.618421052631579, 0.6233552631578947, 0.6200657894736842, 0.5674342105263158] Best val loss: 5.837043285369873


Current group: 0.8
Epoch [1/80], Training Loss: 20.3369, Validation Loss Current: 11.2601, Validation Loss AVG: 11.2601, lr: 0.001
Epoch [2/80], Training Loss: 15.8612, Validation Loss Current: 10.2406, Validation Loss AVG: 10.2406, lr: 0.001
Epoch [3/80], Training Loss: 16.0285, Validation Loss Current: 12.9946, Validation Loss AVG: 12.9946, lr: 0.001
Epoch [4/80], Training Loss: 10.3733, Validation Loss Current: 10.2479, Validation Loss AVG: 10.2479, lr: 0.001
Epoch [5/80], Training Loss: 9.3140, Validation Loss Current: 12.3994, Validation Loss AVG: 12.3994, lr: 0.001
Epoch [6/80], Training Loss: 6.4055, Validation Loss Current: 10.1601, Validation Loss AVG: 10.1601, lr: 0.001
Epoch [7/80], Training Loss: 7.0920, Validation Loss Current: 12.9269, Validation Loss AVG: 12.9269, lr: 0.001
Epoch [8/80], Training Loss: 8.6059, Validation Loss Current: 11.8669, Validation Loss AVG: 11.8669, lr: 0.001
Epoch [9/80], Training Loss: 7.2202, Validation Loss Current: 12.2120, Validation Loss AVG: 12.2120, lr: 0.001
Epoch [10/80], Training Loss: 7.5253, Validation Loss Current: 10.8079, Validation Loss AVG: 10.8079, lr: 0.001
Epoch [11/80], Training Loss: 8.0704, Validation Loss Current: 13.7075, Validation Loss AVG: 13.7075, lr: 0.001
Epoch [12/80], Training Loss: 6.9487, Validation Loss Current: 13.1537, Validation Loss AVG: 13.1537, lr: 0.001
Epoch [13/80], Training Loss: 5.4994, Validation Loss Current: 12.1597, Validation Loss AVG: 12.1597, lr: 0.001
Epoch [14/80], Training Loss: 4.4517, Validation Loss Current: 15.2326, Validation Loss AVG: 15.2326, lr: 0.001
Epoch [15/80], Training Loss: 5.0189, Validation Loss Current: 10.6991, Validation Loss AVG: 10.6991, lr: 0.001
Epoch [16/80], Training Loss: 7.1755, Validation Loss Current: 13.8670, Validation Loss AVG: 13.8670, lr: 0.001
Epoch [17/80], Training Loss: 4.1719, Validation Loss Current: 11.6058, Validation Loss AVG: 11.6058, lr: 0.001
Epoch [18/80], Training Loss: 2.3903, Validation Loss Current: 13.6163, Validation Loss AVG: 13.6163, lr: 0.001
Epoch [19/80], Training Loss: 4.4372, Validation Loss Current: 14.4252, Validation Loss AVG: 14.4252, lr: 0.001
Epoch [20/80], Training Loss: 6.9396, Validation Loss Current: 12.7772, Validation Loss AVG: 12.7772, lr: 0.001
Epoch [21/80], Training Loss: 8.3371, Validation Loss Current: 13.4833, Validation Loss AVG: 13.4833, lr: 0.001
Epoch [22/80], Training Loss: 5.4499, Validation Loss Current: 11.6371, Validation Loss AVG: 11.6371, lr: 0.001
Epoch [23/80], Training Loss: 2.6426, Validation Loss Current: 11.3176, Validation Loss AVG: 11.3176, lr: 0.001
Epoch [24/80], Training Loss: 1.9311, Validation Loss Current: 11.4894, Validation Loss AVG: 11.4894, lr: 0.001
Epoch [25/80], Training Loss: 2.1490, Validation Loss Current: 12.2723, Validation Loss AVG: 12.2723, lr: 0.001
Epoch [26/80], Training Loss: 2.7421, Validation Loss Current: 12.6607, Validation Loss AVG: 12.6607, lr: 0.001
Epoch [27/80], Training Loss: 4.1897, Validation Loss Current: 12.5417, Validation Loss AVG: 12.5417, lr: 0.001
Epoch [28/80], Training Loss: 6.3969, Validation Loss Current: 11.8628, Validation Loss AVG: 11.8628, lr: 0.001
Epoch [29/80], Training Loss: 6.6550, Validation Loss Current: 16.3212, Validation Loss AVG: 16.3212, lr: 0.001
Epoch [30/80], Training Loss: 5.8436, Validation Loss Current: 10.6354, Validation Loss AVG: 10.6354, lr: 0.001
Epoch [31/80], Training Loss: 4.0220, Validation Loss Current: 15.1189, Validation Loss AVG: 15.1189, lr: 0.001
Epoch [32/80], Training Loss: 2.0742, Validation Loss Current: 11.7887, Validation Loss AVG: 11.7887, lr: 0.001
Epoch [33/80], Training Loss: 2.4016, Validation Loss Current: 11.9531, Validation Loss AVG: 11.9531, lr: 0.001
Epoch [34/80], Training Loss: 4.9980, Validation Loss Current: 11.7808, Validation Loss AVG: 11.7808, lr: 0.001
Epoch [35/80], Training Loss: 6.5140, Validation Loss Current: 12.7449, Validation Loss AVG: 12.7449, lr: 0.001
Epoch [36/80], Training Loss: 3.9150, Validation Loss Current: 12.8913, Validation Loss AVG: 12.8913, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 6 Best val accuracy: [0.4546052631578947, 0.40328947368421053, 0.41217105263157894, 0.4460526315789474, 0.39440789473684207, 0.41381578947368425, 0.42006578947368417, 0.4098684210526316, 0.450328947368421, 0.43717105263157896, 0.39374999999999993, 0.42434210526315785, 0.41414473684210523, 0.3799342105263158, 0.4618421052631579, 0.42993421052631575, 0.4296052631578947, 0.4305921052631579, 0.36973684210526325, 0.40361842105263157, 0.3986842105263158, 0.4276315789473684, 0.45394736842105265, 0.4526315789473684, 0.4144736842105264, 0.43552631578947365, 0.4171052631578947, 0.4253289473684211, 0.41085526315789467, 0.4490131578947369, 0.42631578947368415, 0.4453947368421053, 0.41578947368421054, 0.43519736842105267, 0.4325657894736842, 0.4338815789473684] Best val loss: 10.160058426856995


Current group: 0.6
Epoch [1/80], Training Loss: 25.4204, Validation Loss Current: 14.3272, Validation Loss AVG: 14.3272, lr: 0.001
Epoch [2/80], Training Loss: 22.6923, Validation Loss Current: 13.8188, Validation Loss AVG: 13.8188, lr: 0.001
Epoch [3/80], Training Loss: 19.1252, Validation Loss Current: 10.9880, Validation Loss AVG: 10.9880, lr: 0.001
Epoch [4/80], Training Loss: 12.8194, Validation Loss Current: 9.9589, Validation Loss AVG: 9.9589, lr: 0.001
Epoch [5/80], Training Loss: 8.6850, Validation Loss Current: 10.5569, Validation Loss AVG: 10.5569, lr: 0.001
Epoch [6/80], Training Loss: 8.5421, Validation Loss Current: 10.6608, Validation Loss AVG: 10.6608, lr: 0.001
Epoch [7/80], Training Loss: 9.1386, Validation Loss Current: 11.3605, Validation Loss AVG: 11.3605, lr: 0.001
Epoch [8/80], Training Loss: 8.3295, Validation Loss Current: 10.3016, Validation Loss AVG: 10.3016, lr: 0.001
Epoch [9/80], Training Loss: 5.3048, Validation Loss Current: 9.7439, Validation Loss AVG: 9.7439, lr: 0.001
Epoch [10/80], Training Loss: 3.6093, Validation Loss Current: 10.7611, Validation Loss AVG: 10.7611, lr: 0.001
Epoch [11/80], Training Loss: 5.6211, Validation Loss Current: 12.4403, Validation Loss AVG: 12.4403, lr: 0.001
Epoch [12/80], Training Loss: 10.5887, Validation Loss Current: 11.4397, Validation Loss AVG: 11.4397, lr: 0.001
Epoch [13/80], Training Loss: 4.9174, Validation Loss Current: 9.8249, Validation Loss AVG: 9.8249, lr: 0.001
Epoch [14/80], Training Loss: 5.1155, Validation Loss Current: 10.8263, Validation Loss AVG: 10.8263, lr: 0.001
Epoch [15/80], Training Loss: 5.0450, Validation Loss Current: 12.2652, Validation Loss AVG: 12.2652, lr: 0.001
Epoch [16/80], Training Loss: 4.9149, Validation Loss Current: 11.6956, Validation Loss AVG: 11.6956, lr: 0.001
Epoch [17/80], Training Loss: 6.2728, Validation Loss Current: 11.2416, Validation Loss AVG: 11.2416, lr: 0.001
Epoch [18/80], Training Loss: 2.8702, Validation Loss Current: 11.5717, Validation Loss AVG: 11.5717, lr: 0.001
Epoch [19/80], Training Loss: 3.0546, Validation Loss Current: 11.2347, Validation Loss AVG: 11.2347, lr: 0.001
Epoch [20/80], Training Loss: 6.0209, Validation Loss Current: 11.2285, Validation Loss AVG: 11.2285, lr: 0.001
Epoch [21/80], Training Loss: 2.9972, Validation Loss Current: 10.6021, Validation Loss AVG: 10.6021, lr: 0.001
Epoch [22/80], Training Loss: 3.3968, Validation Loss Current: 10.8075, Validation Loss AVG: 10.8075, lr: 0.001
Epoch [23/80], Training Loss: 2.8624, Validation Loss Current: 11.8786, Validation Loss AVG: 11.8786, lr: 0.001
Epoch [24/80], Training Loss: 8.0239, Validation Loss Current: 15.3441, Validation Loss AVG: 15.3441, lr: 0.001
Epoch [25/80], Training Loss: 4.0571, Validation Loss Current: 12.1062, Validation Loss AVG: 12.1062, lr: 0.001
Epoch [26/80], Training Loss: 1.5669, Validation Loss Current: 10.8272, Validation Loss AVG: 10.8272, lr: 0.001
Epoch [27/80], Training Loss: 1.1067, Validation Loss Current: 10.9873, Validation Loss AVG: 10.9873, lr: 0.001
Epoch [28/80], Training Loss: 4.4676, Validation Loss Current: 11.8734, Validation Loss AVG: 11.8734, lr: 0.001
Epoch [29/80], Training Loss: 3.1410, Validation Loss Current: 12.5151, Validation Loss AVG: 12.5151, lr: 0.001
Epoch [30/80], Training Loss: 5.5890, Validation Loss Current: 13.0164, Validation Loss AVG: 13.0164, lr: 0.001
Epoch [31/80], Training Loss: 2.0568, Validation Loss Current: 10.8976, Validation Loss AVG: 10.8976, lr: 0.001
Epoch [32/80], Training Loss: 2.0675, Validation Loss Current: 11.8613, Validation Loss AVG: 11.8613, lr: 0.001
Epoch [33/80], Training Loss: 4.2263, Validation Loss Current: 14.0299, Validation Loss AVG: 14.0299, lr: 0.001
Epoch [34/80], Training Loss: 2.3968, Validation Loss Current: 13.8557, Validation Loss AVG: 13.8557, lr: 0.001
Epoch [35/80], Training Loss: 2.0226, Validation Loss Current: 12.9785, Validation Loss AVG: 12.9785, lr: 0.001
Epoch [36/80], Training Loss: 2.0425, Validation Loss Current: 12.3820, Validation Loss AVG: 12.3820, lr: 0.001
Epoch [37/80], Training Loss: 1.2216, Validation Loss Current: 12.6170, Validation Loss AVG: 12.6170, lr: 0.001
Epoch [38/80], Training Loss: 0.7508, Validation Loss Current: 11.9727, Validation Loss AVG: 11.9727, lr: 0.001
Epoch [39/80], Training Loss: 2.3449, Validation Loss Current: 13.3361, Validation Loss AVG: 13.3361, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 9 Best val accuracy: [0.42828947368421055, 0.3470394736842105, 0.42631578947368415, 0.4894736842105263, 0.4407894736842105, 0.4759868421052632, 0.47302631578947363, 0.46217105263157887, 0.4828947368421053, 0.47171052631578947, 0.40592105263157896, 0.47302631578947363, 0.4740131578947368, 0.47138157894736843, 0.44769736842105257, 0.4621710526315789, 0.46940789473684214, 0.4509868421052631, 0.46611842105263157, 0.47467105263157894, 0.4743421052631579, 0.49177631578947373, 0.4582236842105264, 0.40328947368421053, 0.4453947368421053, 0.47072368421052635, 0.4769736842105264, 0.47796052631578945, 0.45625, 0.45197368421052636, 0.4858552631578948, 0.47138157894736843, 0.4095394736842105, 0.43355263157894736, 0.4542763157894737, 0.45855263157894743, 0.4516447368421052, 0.49210526315789477, 0.4588815789473685] Best val loss: 9.743850708007812


Current group: 0.4
Epoch [1/80], Training Loss: 35.5347, Validation Loss Current: 16.5012, Validation Loss AVG: 16.5012, lr: 0.001
Epoch [2/80], Training Loss: 22.2787, Validation Loss Current: 13.6972, Validation Loss AVG: 13.6972, lr: 0.001
Epoch [3/80], Training Loss: 19.3511, Validation Loss Current: 14.0075, Validation Loss AVG: 14.0075, lr: 0.001
Epoch [4/80], Training Loss: 12.7151, Validation Loss Current: 10.1287, Validation Loss AVG: 10.1287, lr: 0.001
Epoch [5/80], Training Loss: 10.0926, Validation Loss Current: 10.5764, Validation Loss AVG: 10.5764, lr: 0.001
Epoch [6/80], Training Loss: 7.3676, Validation Loss Current: 11.7444, Validation Loss AVG: 11.7444, lr: 0.001
Epoch [7/80], Training Loss: 8.7399, Validation Loss Current: 11.3549, Validation Loss AVG: 11.3549, lr: 0.001
Epoch [8/80], Training Loss: 11.6364, Validation Loss Current: 13.3801, Validation Loss AVG: 13.3801, lr: 0.001
Epoch [9/80], Training Loss: 8.6367, Validation Loss Current: 10.2721, Validation Loss AVG: 10.2721, lr: 0.001
Epoch [10/80], Training Loss: 7.4151, Validation Loss Current: 11.2333, Validation Loss AVG: 11.2333, lr: 0.001
Epoch [11/80], Training Loss: 6.8631, Validation Loss Current: 12.2814, Validation Loss AVG: 12.2814, lr: 0.001
Epoch [12/80], Training Loss: 8.4980, Validation Loss Current: 13.3430, Validation Loss AVG: 13.3430, lr: 0.001
Epoch [13/80], Training Loss: 9.0112, Validation Loss Current: 13.4424, Validation Loss AVG: 13.4424, lr: 0.001
Epoch [14/80], Training Loss: 5.7711, Validation Loss Current: 17.2576, Validation Loss AVG: 17.2576, lr: 0.001
Epoch [15/80], Training Loss: 5.9624, Validation Loss Current: 11.9168, Validation Loss AVG: 11.9168, lr: 0.001
Epoch [16/80], Training Loss: 6.9227, Validation Loss Current: 11.8341, Validation Loss AVG: 11.8341, lr: 0.001
Epoch [17/80], Training Loss: 10.4291, Validation Loss Current: 23.3402, Validation Loss AVG: 23.3402, lr: 0.001
Epoch [18/80], Training Loss: 6.2298, Validation Loss Current: 12.5352, Validation Loss AVG: 12.5352, lr: 0.001
Epoch [19/80], Training Loss: 4.9447, Validation Loss Current: 12.2928, Validation Loss AVG: 12.2928, lr: 0.001
Epoch [20/80], Training Loss: 5.4551, Validation Loss Current: 12.8607, Validation Loss AVG: 12.8607, lr: 0.001
Epoch [21/80], Training Loss: 5.1593, Validation Loss Current: 18.4486, Validation Loss AVG: 18.4486, lr: 0.001
Epoch [22/80], Training Loss: 5.7307, Validation Loss Current: 16.7503, Validation Loss AVG: 16.7503, lr: 0.001
Epoch [23/80], Training Loss: 8.1317, Validation Loss Current: 13.4744, Validation Loss AVG: 13.4744, lr: 0.001
Epoch [24/80], Training Loss: 7.2990, Validation Loss Current: 14.2630, Validation Loss AVG: 14.2630, lr: 0.001
Epoch [25/80], Training Loss: 7.1389, Validation Loss Current: 13.1009, Validation Loss AVG: 13.1009, lr: 0.001
Epoch [26/80], Training Loss: 3.3497, Validation Loss Current: 11.7638, Validation Loss AVG: 11.7638, lr: 0.001
Epoch [27/80], Training Loss: 2.1807, Validation Loss Current: 13.4469, Validation Loss AVG: 13.4469, lr: 0.001
Epoch [28/80], Training Loss: 1.9538, Validation Loss Current: 12.1045, Validation Loss AVG: 12.1045, lr: 0.001
Epoch [29/80], Training Loss: 4.0603, Validation Loss Current: 12.2435, Validation Loss AVG: 12.2435, lr: 0.001
Epoch [30/80], Training Loss: 3.0179, Validation Loss Current: 12.8778, Validation Loss AVG: 12.8778, lr: 0.001
Epoch [31/80], Training Loss: 2.0729, Validation Loss Current: 12.8813, Validation Loss AVG: 12.8813, lr: 0.001
Epoch [32/80], Training Loss: 5.8781, Validation Loss Current: 12.2777, Validation Loss AVG: 12.2777, lr: 0.001
Epoch [33/80], Training Loss: 3.9880, Validation Loss Current: 13.0141, Validation Loss AVG: 13.0141, lr: 0.001
Epoch [34/80], Training Loss: 3.8678, Validation Loss Current: 12.7440, Validation Loss AVG: 12.7440, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 4 Best val accuracy: [0.3707236842105263, 0.4207236842105263, 0.349671052631579, 0.46019736842105263, 0.44671052631578945, 0.44243421052631576, 0.4549342105263158, 0.4625000000000001, 0.4756578947368421, 0.46875, 0.45361842105263167, 0.40690789473684214, 0.4723684210526316, 0.36217105263157895, 0.4338815789473684, 0.42598684210526316, 0.2855263157894737, 0.4358552631578947, 0.46743421052631573, 0.47105263157894744, 0.3371710526315789, 0.3703947368421052, 0.4391447368421053, 0.4440789473684211, 0.43881578947368416, 0.47302631578947374, 0.43618421052631573, 0.4546052631578947, 0.46611842105263157, 0.4914473684210526, 0.4529605263157895, 0.4667763157894737, 0.44703947368421054, 0.46809210526315786] Best val loss: 10.128692626953125


Current group: 0.2
Epoch [1/80], Training Loss: 42.8832, Validation Loss Current: 18.0539, Validation Loss AVG: 18.0539, lr: 0.001
Epoch [2/80], Training Loss: 27.1503, Validation Loss Current: 19.3563, Validation Loss AVG: 19.3563, lr: 0.001
Epoch [3/80], Training Loss: 24.2214, Validation Loss Current: 12.8955, Validation Loss AVG: 12.8955, lr: 0.001
Epoch [4/80], Training Loss: 19.1941, Validation Loss Current: 18.7149, Validation Loss AVG: 18.7149, lr: 0.001
Epoch [5/80], Training Loss: 16.0985, Validation Loss Current: 15.5701, Validation Loss AVG: 15.5701, lr: 0.001
Epoch [6/80], Training Loss: 14.6431, Validation Loss Current: 19.8103, Validation Loss AVG: 19.8103, lr: 0.001
Epoch [7/80], Training Loss: 12.0379, Validation Loss Current: 14.4642, Validation Loss AVG: 14.4642, lr: 0.001
Epoch [8/80], Training Loss: 11.2988, Validation Loss Current: 15.8963, Validation Loss AVG: 15.8963, lr: 0.001
Epoch [9/80], Training Loss: 7.9839, Validation Loss Current: 16.2521, Validation Loss AVG: 16.2521, lr: 0.001
Epoch [10/80], Training Loss: 8.8603, Validation Loss Current: 15.6266, Validation Loss AVG: 15.6266, lr: 0.001
Epoch [11/80], Training Loss: 9.6305, Validation Loss Current: 15.0820, Validation Loss AVG: 15.0820, lr: 0.001
Epoch [12/80], Training Loss: 7.3032, Validation Loss Current: 15.7730, Validation Loss AVG: 15.7730, lr: 0.001
Epoch [13/80], Training Loss: 9.1366, Validation Loss Current: 25.2188, Validation Loss AVG: 25.2188, lr: 0.001
Epoch [14/80], Training Loss: 9.2199, Validation Loss Current: 17.4836, Validation Loss AVG: 17.4836, lr: 0.001
Epoch [15/80], Training Loss: 9.4509, Validation Loss Current: 24.8703, Validation Loss AVG: 24.8703, lr: 0.001
Epoch [16/80], Training Loss: 9.8636, Validation Loss Current: 20.4083, Validation Loss AVG: 20.4083, lr: 0.001
Epoch [17/80], Training Loss: 7.1443, Validation Loss Current: 25.3952, Validation Loss AVG: 25.3952, lr: 0.001
Epoch [18/80], Training Loss: 4.1985, Validation Loss Current: 15.0363, Validation Loss AVG: 15.0363, lr: 0.001
Epoch [19/80], Training Loss: 2.7595, Validation Loss Current: 17.4179, Validation Loss AVG: 17.4179, lr: 0.001
Epoch [20/80], Training Loss: 1.6252, Validation Loss Current: 15.2882, Validation Loss AVG: 15.2882, lr: 0.001
Epoch [21/80], Training Loss: 2.8034, Validation Loss Current: 19.5215, Validation Loss AVG: 19.5215, lr: 0.001
Epoch [22/80], Training Loss: 6.3165, Validation Loss Current: 24.6705, Validation Loss AVG: 24.6705, lr: 0.001
Epoch [23/80], Training Loss: 3.8956, Validation Loss Current: 17.9004, Validation Loss AVG: 17.9004, lr: 0.001
Epoch [24/80], Training Loss: 4.4889, Validation Loss Current: 22.4931, Validation Loss AVG: 22.4931, lr: 0.001
Epoch [25/80], Training Loss: 2.8253, Validation Loss Current: 19.1214, Validation Loss AVG: 19.1214, lr: 0.001
Epoch [26/80], Training Loss: 3.3473, Validation Loss Current: 16.7319, Validation Loss AVG: 16.7319, lr: 0.001
Epoch [27/80], Training Loss: 9.2033, Validation Loss Current: 24.7006, Validation Loss AVG: 24.7006, lr: 0.001
Epoch [28/80], Training Loss: 6.9419, Validation Loss Current: 24.8256, Validation Loss AVG: 24.8256, lr: 0.001
Epoch [29/80], Training Loss: 7.1839, Validation Loss Current: 35.0026, Validation Loss AVG: 35.0026, lr: 0.001
Epoch [30/80], Training Loss: 9.6298, Validation Loss Current: 31.9999, Validation Loss AVG: 31.9999, lr: 0.001
Epoch [31/80], Training Loss: 15.2189, Validation Loss Current: 40.5137, Validation Loss AVG: 40.5137, lr: 0.001
Epoch [32/80], Training Loss: 8.9288, Validation Loss Current: 19.8759, Validation Loss AVG: 19.8759, lr: 0.001
Epoch [33/80], Training Loss: 4.4416, Validation Loss Current: 17.7730, Validation Loss AVG: 17.7730, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 3 Best val accuracy: [0.3101973684210526, 0.36546052631578946, 0.4029605263157895, 0.2667763157894737, 0.3674342105263158, 0.30328947368421055, 0.3851973684210527, 0.2878289473684211, 0.39769736842105263, 0.3592105263157895, 0.4101973684210526, 0.35526315789473684, 0.24605263157894738, 0.34671052631578947, 0.3115131578947368, 0.2963815789473684, 0.25625, 0.3861842105263158, 0.41118421052631576, 0.41940789473684215, 0.38388157894736846, 0.28519736842105264, 0.38618421052631585, 0.30296052631578946, 0.37105263157894736, 0.41578947368421054, 0.25855263157894737, 0.30855263157894736, 0.22434210526315787, 0.21085526315789474, 0.2075657894736842, 0.33552631578947373, 0.4128289473684211] Best val loss: 12.895536327362061


Fold: 2
----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.1788, Validation Loss Current: 9.9919, Validation Loss AVG: 10.0693, lr: 0.001
Epoch [2/400], Training Loss: 39.0924, Validation Loss Current: 9.8516, Validation Loss AVG: 10.0942, lr: 0.001
Epoch [3/400], Training Loss: 37.3587, Validation Loss Current: 9.3948, Validation Loss AVG: 9.8874, lr: 0.001
Epoch [4/400], Training Loss: 36.5417, Validation Loss Current: 9.2552, Validation Loss AVG: 10.3721, lr: 0.001
Epoch [5/400], Training Loss: 34.3863, Validation Loss Current: 8.8477, Validation Loss AVG: 9.7244, lr: 0.001
Epoch [6/400], Training Loss: 33.7520, Validation Loss Current: 8.6956, Validation Loss AVG: 9.7762, lr: 0.001
Epoch [7/400], Training Loss: 32.6759, Validation Loss Current: 8.6182, Validation Loss AVG: 9.7889, lr: 0.001
Epoch [8/400], Training Loss: 31.7235, Validation Loss Current: 8.1291, Validation Loss AVG: 9.4644, lr: 0.001
Epoch [9/400], Training Loss: 30.1092, Validation Loss Current: 8.1590, Validation Loss AVG: 9.6980, lr: 0.001
Epoch [10/400], Training Loss: 28.6586, Validation Loss Current: 9.8439, Validation Loss AVG: 15.5399, lr: 0.001
Epoch [11/400], Training Loss: 29.4109, Validation Loss Current: 7.7809, Validation Loss AVG: 9.1626, lr: 0.001
Epoch [12/400], Training Loss: 27.4279, Validation Loss Current: 7.6959, Validation Loss AVG: 9.2013, lr: 0.001
Epoch [13/400], Training Loss: 26.5814, Validation Loss Current: 7.6935, Validation Loss AVG: 10.3588, lr: 0.001
Epoch [14/400], Training Loss: 25.4655, Validation Loss Current: 7.2614, Validation Loss AVG: 10.0768, lr: 0.001
Epoch [15/400], Training Loss: 25.2120, Validation Loss Current: 7.2165, Validation Loss AVG: 9.5847, lr: 0.001
Epoch [16/400], Training Loss: 26.1843, Validation Loss Current: 8.8392, Validation Loss AVG: 14.4204, lr: 0.001
Epoch [17/400], Training Loss: 25.4421, Validation Loss Current: 7.1077, Validation Loss AVG: 9.8475, lr: 0.001
Epoch [18/400], Training Loss: 24.8284, Validation Loss Current: 7.4110, Validation Loss AVG: 11.2438, lr: 0.001
Epoch [19/400], Training Loss: 23.0278, Validation Loss Current: 6.8812, Validation Loss AVG: 12.2291, lr: 0.001
Epoch [20/400], Training Loss: 21.8633, Validation Loss Current: 7.1553, Validation Loss AVG: 10.3154, lr: 0.001
Epoch [21/400], Training Loss: 21.4820, Validation Loss Current: 6.5692, Validation Loss AVG: 12.4104, lr: 0.001
Epoch [22/400], Training Loss: 21.2814, Validation Loss Current: 7.1567, Validation Loss AVG: 8.5897, lr: 0.001
Epoch [23/400], Training Loss: 19.7378, Validation Loss Current: 6.4863, Validation Loss AVG: 9.5730, lr: 0.001
Epoch [24/400], Training Loss: 20.0755, Validation Loss Current: 6.1810, Validation Loss AVG: 9.6610, lr: 0.001
Epoch [25/400], Training Loss: 19.6418, Validation Loss Current: 7.6672, Validation Loss AVG: 12.2036, lr: 0.001
Epoch [26/400], Training Loss: 21.1787, Validation Loss Current: 7.7949, Validation Loss AVG: 10.2861, lr: 0.001
Epoch [27/400], Training Loss: 18.4421, Validation Loss Current: 6.3378, Validation Loss AVG: 9.6503, lr: 0.001
Epoch [28/400], Training Loss: 17.5066, Validation Loss Current: 6.1686, Validation Loss AVG: 8.2535, lr: 0.001
Epoch [29/400], Training Loss: 17.7715, Validation Loss Current: 6.0759, Validation Loss AVG: 9.0757, lr: 0.001
Epoch [30/400], Training Loss: 15.1388, Validation Loss Current: 6.2598, Validation Loss AVG: 8.6424, lr: 0.001
Epoch [31/400], Training Loss: 15.7333, Validation Loss Current: 6.1828, Validation Loss AVG: 9.4640, lr: 0.001
Epoch [32/400], Training Loss: 16.6734, Validation Loss Current: 6.8170, Validation Loss AVG: 8.4183, lr: 0.001
Epoch [33/400], Training Loss: 17.6138, Validation Loss Current: 6.6796, Validation Loss AVG: 8.7975, lr: 0.001
Epoch [34/400], Training Loss: 13.9578, Validation Loss Current: 6.1825, Validation Loss AVG: 10.8446, lr: 0.001
Epoch [35/400], Training Loss: 12.3670, Validation Loss Current: 6.0784, Validation Loss AVG: 8.8840, lr: 0.001
Epoch [36/400], Training Loss: 12.0264, Validation Loss Current: 6.4005, Validation Loss AVG: 8.7990, lr: 0.001
Epoch [37/400], Training Loss: 11.5919, Validation Loss Current: 5.9621, Validation Loss AVG: 9.7267, lr: 0.001
Epoch [38/400], Training Loss: 10.6518, Validation Loss Current: 5.9947, Validation Loss AVG: 8.8113, lr: 0.001
Epoch [39/400], Training Loss: 9.7540, Validation Loss Current: 6.0618, Validation Loss AVG: 9.5046, lr: 0.001
Epoch [40/400], Training Loss: 9.6392, Validation Loss Current: 6.4199, Validation Loss AVG: 12.1978, lr: 0.001
Epoch [41/400], Training Loss: 10.3900, Validation Loss Current: 5.9412, Validation Loss AVG: 10.2747, lr: 0.001
Epoch [42/400], Training Loss: 10.8475, Validation Loss Current: 6.6896, Validation Loss AVG: 12.4347, lr: 0.001
Epoch [43/400], Training Loss: 8.1803, Validation Loss Current: 6.7461, Validation Loss AVG: 12.1356, lr: 0.001
Epoch [44/400], Training Loss: 8.4512, Validation Loss Current: 7.6488, Validation Loss AVG: 10.3597, lr: 0.001
Epoch [45/400], Training Loss: 9.9712, Validation Loss Current: 6.2310, Validation Loss AVG: 12.3454, lr: 0.001
Epoch [46/400], Training Loss: 8.9618, Validation Loss Current: 6.9467, Validation Loss AVG: 11.6669, lr: 0.001
Epoch [47/400], Training Loss: 6.4514, Validation Loss Current: 6.6997, Validation Loss AVG: 10.0407, lr: 0.001
Epoch [48/400], Training Loss: 5.9121, Validation Loss Current: 6.4639, Validation Loss AVG: 10.0073, lr: 0.001
Epoch [49/400], Training Loss: 7.8262, Validation Loss Current: 7.0752, Validation Loss AVG: 12.3444, lr: 0.001
Epoch [50/400], Training Loss: 6.4975, Validation Loss Current: 6.2947, Validation Loss AVG: 9.4422, lr: 0.001
Epoch [51/400], Training Loss: 5.7810, Validation Loss Current: 6.1478, Validation Loss AVG: 10.4958, lr: 0.001
Epoch [52/400], Training Loss: 4.3501, Validation Loss Current: 6.6754, Validation Loss AVG: 12.7011, lr: 0.001
Epoch [53/400], Training Loss: 5.6258, Validation Loss Current: 6.7300, Validation Loss AVG: 12.2268, lr: 0.001
Epoch [54/400], Training Loss: 4.3850, Validation Loss Current: 8.3999, Validation Loss AVG: 15.2451, lr: 0.001
Epoch [55/400], Training Loss: 2.7736, Validation Loss Current: 6.4185, Validation Loss AVG: 11.1782, lr: 0.001
Epoch [56/400], Training Loss: 3.1897, Validation Loss Current: 6.5135, Validation Loss AVG: 9.8649, lr: 0.001
Epoch [57/400], Training Loss: 4.9988, Validation Loss Current: 6.9548, Validation Loss AVG: 10.4159, lr: 0.001
Epoch [58/400], Training Loss: 4.1513, Validation Loss Current: 9.9976, Validation Loss AVG: 19.2210, lr: 0.001
Epoch [59/400], Training Loss: 6.1834, Validation Loss Current: 7.5101, Validation Loss AVG: 10.9117, lr: 0.001
Epoch [60/400], Training Loss: 6.0612, Validation Loss Current: 13.1643, Validation Loss AVG: 23.4091, lr: 0.001
Epoch [61/400], Training Loss: 6.9199, Validation Loss Current: 7.4365, Validation Loss AVG: 12.0510, lr: 0.001
Epoch [62/400], Training Loss: 9.5637, Validation Loss Current: 7.5877, Validation Loss AVG: 15.7751, lr: 0.001
Epoch [63/400], Training Loss: 12.7142, Validation Loss Current: 8.5149, Validation Loss AVG: 12.3477, lr: 0.001
Epoch [64/400], Training Loss: 8.1490, Validation Loss Current: 8.4458, Validation Loss AVG: 14.6072, lr: 0.001
Epoch [65/400], Training Loss: 9.1781, Validation Loss Current: 8.3378, Validation Loss AVG: 21.2258, lr: 0.001
Epoch [66/400], Training Loss: 5.8882, Validation Loss Current: 6.4564, Validation Loss AVG: 12.3441, lr: 0.001
Epoch [67/400], Training Loss: 8.2993, Validation Loss Current: 7.8453, Validation Loss AVG: 10.9341, lr: 0.001
Epoch [68/400], Training Loss: 9.9017, Validation Loss Current: 7.9212, Validation Loss AVG: 14.6664, lr: 0.001
Epoch [69/400], Training Loss: 6.5367, Validation Loss Current: 7.3957, Validation Loss AVG: 11.0903, lr: 0.001
Epoch [70/400], Training Loss: 5.9405, Validation Loss Current: 8.5087, Validation Loss AVG: 15.7229, lr: 0.001
Epoch [71/400], Training Loss: 5.0947, Validation Loss Current: 6.8933, Validation Loss AVG: 12.1765, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 41 Best val accuracy: [0.23026315789473684, 0.26973684210526316, 0.34375, 0.3519736842105263, 0.37664473684210525, 0.3881578947368421, 0.39473684210526316, 0.43585526315789475, 0.4309210526315789, 0.3470394736842105, 0.45723684210526316, 0.4654605263157895, 0.46710526315789475, 0.5115131578947368, 0.48355263157894735, 0.4144736842105263, 0.5197368421052632, 0.4753289473684211, 0.5263157894736842, 0.5, 0.5575657894736842, 0.5032894736842105, 0.5526315789473685, 0.5921052631578947, 0.5197368421052632, 0.48519736842105265, 0.569078947368421, 0.5953947368421053, 0.6036184210526315, 0.5723684210526315, 0.5723684210526315, 0.5345394736842105, 0.5822368421052632, 0.5838815789473685, 0.6134868421052632, 0.5773026315789473, 0.6052631578947368, 0.5986842105263158, 0.6085526315789473, 0.5888157894736842, 0.59375, 0.5970394736842105, 0.600328947368421, 0.5328947368421053, 0.6200657894736842, 0.5822368421052632, 0.6036184210526315, 0.6217105263157895, 0.569078947368421, 0.6101973684210527, 0.631578947368421, 0.5888157894736842, 0.6052631578947368, 0.5394736842105263, 0.6233552631578947, 0.6069078947368421, 0.5986842105263158, 0.5328947368421053, 0.5493421052631579, 0.49506578947368424, 0.5805921052631579, 0.5263157894736842, 0.524671052631579, 0.5345394736842105, 0.5411184210526315, 0.5822368421052632, 0.5526315789473685, 0.5805921052631579, 0.5707236842105263, 0.555921052631579, 0.5756578947368421] Best val loss: 5.941233396530151


----- Training resnet18 with sequence: [1, 0.8] -----
Current group: 1
Epoch [1/200], Training Loss: 40.6938, Validation Loss Current: 10.1681, Validation Loss AVG: 10.2141, lr: 0.001
Epoch [2/200], Training Loss: 38.3181, Validation Loss Current: 9.5431, Validation Loss AVG: 9.9406, lr: 0.001
Epoch [3/200], Training Loss: 37.7363, Validation Loss Current: 9.4857, Validation Loss AVG: 9.9401, lr: 0.001
Epoch [4/200], Training Loss: 36.2805, Validation Loss Current: 9.0244, Validation Loss AVG: 9.6755, lr: 0.001
Epoch [5/200], Training Loss: 34.5556, Validation Loss Current: 8.8991, Validation Loss AVG: 9.6322, lr: 0.001
Epoch [6/200], Training Loss: 33.0812, Validation Loss Current: 8.7977, Validation Loss AVG: 9.7063, lr: 0.001
Epoch [7/200], Training Loss: 32.3313, Validation Loss Current: 8.0699, Validation Loss AVG: 9.1471, lr: 0.001
Epoch [8/200], Training Loss: 31.4358, Validation Loss Current: 8.1156, Validation Loss AVG: 9.4840, lr: 0.001
Epoch [9/200], Training Loss: 30.3710, Validation Loss Current: 7.8405, Validation Loss AVG: 10.9017, lr: 0.001
Epoch [10/200], Training Loss: 27.7885, Validation Loss Current: 7.9167, Validation Loss AVG: 9.0376, lr: 0.001
Epoch [11/200], Training Loss: 28.0998, Validation Loss Current: 7.6214, Validation Loss AVG: 8.9331, lr: 0.001
Epoch [12/200], Training Loss: 26.7587, Validation Loss Current: 7.4644, Validation Loss AVG: 9.0797, lr: 0.001
Epoch [13/200], Training Loss: 26.6117, Validation Loss Current: 7.1598, Validation Loss AVG: 8.8369, lr: 0.001
Epoch [14/200], Training Loss: 25.6211, Validation Loss Current: 7.4315, Validation Loss AVG: 11.9908, lr: 0.001
Epoch [15/200], Training Loss: 24.0889, Validation Loss Current: 6.9602, Validation Loss AVG: 11.2784, lr: 0.001
Epoch [16/200], Training Loss: 23.0862, Validation Loss Current: 7.0111, Validation Loss AVG: 8.6597, lr: 0.001
Epoch [17/200], Training Loss: 24.3482, Validation Loss Current: 7.6256, Validation Loss AVG: 9.6331, lr: 0.001
Epoch [18/200], Training Loss: 23.1630, Validation Loss Current: 6.7315, Validation Loss AVG: 8.9812, lr: 0.001
Epoch [19/200], Training Loss: 23.4248, Validation Loss Current: 7.6353, Validation Loss AVG: 13.3455, lr: 0.001
Epoch [20/200], Training Loss: 23.6764, Validation Loss Current: 6.8893, Validation Loss AVG: 10.4518, lr: 0.001
Epoch [21/200], Training Loss: 21.4712, Validation Loss Current: 6.6171, Validation Loss AVG: 8.8532, lr: 0.001
Epoch [22/200], Training Loss: 19.6089, Validation Loss Current: 6.4981, Validation Loss AVG: 9.2885, lr: 0.001
Epoch [23/200], Training Loss: 19.8249, Validation Loss Current: 6.4679, Validation Loss AVG: 10.4644, lr: 0.001
Epoch [24/200], Training Loss: 18.4009, Validation Loss Current: 6.0468, Validation Loss AVG: 9.0013, lr: 0.001
Epoch [25/200], Training Loss: 18.2488, Validation Loss Current: 7.2444, Validation Loss AVG: 12.6461, lr: 0.001
Epoch [26/200], Training Loss: 19.2002, Validation Loss Current: 6.1692, Validation Loss AVG: 8.8682, lr: 0.001
Epoch [27/200], Training Loss: 17.3058, Validation Loss Current: 6.2419, Validation Loss AVG: 10.7628, lr: 0.001
Epoch [28/200], Training Loss: 15.5570, Validation Loss Current: 5.8371, Validation Loss AVG: 9.2504, lr: 0.001
Epoch [29/200], Training Loss: 15.2397, Validation Loss Current: 6.0422, Validation Loss AVG: 8.5862, lr: 0.001
Epoch [30/200], Training Loss: 15.9139, Validation Loss Current: 6.0790, Validation Loss AVG: 10.3192, lr: 0.001
Epoch [31/200], Training Loss: 14.5911, Validation Loss Current: 6.0415, Validation Loss AVG: 11.0639, lr: 0.001
Epoch [32/200], Training Loss: 13.1903, Validation Loss Current: 7.2729, Validation Loss AVG: 13.6495, lr: 0.001
Epoch [33/200], Training Loss: 13.3891, Validation Loss Current: 5.6672, Validation Loss AVG: 10.1374, lr: 0.001
Epoch [34/200], Training Loss: 11.3569, Validation Loss Current: 6.7019, Validation Loss AVG: 11.5534, lr: 0.001
Epoch [35/200], Training Loss: 11.6282, Validation Loss Current: 7.8986, Validation Loss AVG: 10.3744, lr: 0.001
Epoch [36/200], Training Loss: 10.7990, Validation Loss Current: 5.4786, Validation Loss AVG: 9.8601, lr: 0.001
Epoch [37/200], Training Loss: 9.2036, Validation Loss Current: 6.1592, Validation Loss AVG: 8.9632, lr: 0.001
Epoch [38/200], Training Loss: 9.6851, Validation Loss Current: 5.4835, Validation Loss AVG: 9.1392, lr: 0.001
Epoch [39/200], Training Loss: 10.4283, Validation Loss Current: 6.0728, Validation Loss AVG: 9.6458, lr: 0.001
Epoch [40/200], Training Loss: 9.5414, Validation Loss Current: 5.7379, Validation Loss AVG: 9.5060, lr: 0.001
Epoch [41/200], Training Loss: 9.7096, Validation Loss Current: 6.6921, Validation Loss AVG: 10.3695, lr: 0.001
Epoch [42/200], Training Loss: 10.4899, Validation Loss Current: 7.6777, Validation Loss AVG: 17.0630, lr: 0.001
Epoch [43/200], Training Loss: 9.9710, Validation Loss Current: 5.8179, Validation Loss AVG: 10.3319, lr: 0.001
Epoch [44/200], Training Loss: 7.9155, Validation Loss Current: 6.3792, Validation Loss AVG: 8.7062, lr: 0.001
Epoch [45/200], Training Loss: 6.1096, Validation Loss Current: 6.3907, Validation Loss AVG: 9.6948, lr: 0.001
Epoch [46/200], Training Loss: 5.6262, Validation Loss Current: 5.7739, Validation Loss AVG: 10.5650, lr: 0.001
Epoch [47/200], Training Loss: 4.5197, Validation Loss Current: 5.8948, Validation Loss AVG: 10.2897, lr: 0.001
Epoch [48/200], Training Loss: 6.2057, Validation Loss Current: 5.7753, Validation Loss AVG: 11.3779, lr: 0.001
Epoch [49/200], Training Loss: 5.3564, Validation Loss Current: 6.7268, Validation Loss AVG: 13.5555, lr: 0.001
Epoch [50/200], Training Loss: 6.9663, Validation Loss Current: 7.5642, Validation Loss AVG: 9.9307, lr: 0.001
Epoch [51/200], Training Loss: 6.7221, Validation Loss Current: 7.5783, Validation Loss AVG: 16.0604, lr: 0.001
Epoch [52/200], Training Loss: 6.9087, Validation Loss Current: 8.9554, Validation Loss AVG: 19.9512, lr: 0.001
Epoch [53/200], Training Loss: 7.3188, Validation Loss Current: 7.1962, Validation Loss AVG: 10.3841, lr: 0.001
Epoch [54/200], Training Loss: 7.7792, Validation Loss Current: 7.0852, Validation Loss AVG: 10.5087, lr: 0.001
Epoch [55/200], Training Loss: 4.2176, Validation Loss Current: 9.5406, Validation Loss AVG: 18.5542, lr: 0.001
Epoch [56/200], Training Loss: 5.4973, Validation Loss Current: 7.2363, Validation Loss AVG: 11.1191, lr: 0.001
Epoch [57/200], Training Loss: 5.0291, Validation Loss Current: 10.4332, Validation Loss AVG: 26.5865, lr: 0.001
Epoch [58/200], Training Loss: 6.1918, Validation Loss Current: 8.2120, Validation Loss AVG: 17.6652, lr: 0.001
Epoch [59/200], Training Loss: 7.7498, Validation Loss Current: 8.3977, Validation Loss AVG: 18.3468, lr: 0.001
Epoch [60/200], Training Loss: 5.6160, Validation Loss Current: 9.2492, Validation Loss AVG: 20.5574, lr: 0.001
Epoch [61/200], Training Loss: 8.4118, Validation Loss Current: 8.1772, Validation Loss AVG: 13.7628, lr: 0.001
Epoch [62/200], Training Loss: 4.9910, Validation Loss Current: 8.6734, Validation Loss AVG: 13.9485, lr: 0.001
Epoch [63/200], Training Loss: 5.6040, Validation Loss Current: 8.5471, Validation Loss AVG: 13.8723, lr: 0.001
Epoch [64/200], Training Loss: 2.8664, Validation Loss Current: 7.6905, Validation Loss AVG: 11.8560, lr: 0.001
Epoch [65/200], Training Loss: 4.6467, Validation Loss Current: 7.5672, Validation Loss AVG: 11.6315, lr: 0.001
Epoch [66/200], Training Loss: 7.6522, Validation Loss Current: 8.2057, Validation Loss AVG: 14.2336, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 36 Best val accuracy: [0.2450657894736842, 0.2894736842105263, 0.29769736842105265, 0.36019736842105265, 0.37006578947368424, 0.39473684210526316, 0.4407894736842105, 0.45723684210526316, 0.4342105263157895, 0.46875, 0.4654605263157895, 0.49835526315789475, 0.5164473684210527, 0.48848684210526316, 0.5230263157894737, 0.506578947368421, 0.49835526315789475, 0.5509868421052632, 0.46381578947368424, 0.5131578947368421, 0.5444078947368421, 0.5427631578947368, 0.5493421052631579, 0.5674342105263158, 0.5115131578947368, 0.587171052631579, 0.5575657894736842, 0.6085526315789473, 0.5921052631578947, 0.5773026315789473, 0.5773026315789473, 0.5427631578947368, 0.600328947368421, 0.5723684210526315, 0.5411184210526315, 0.6233552631578947, 0.5723684210526315, 0.6381578947368421, 0.6217105263157895, 0.6233552631578947, 0.5707236842105263, 0.5526315789473685, 0.6151315789473685, 0.59375, 0.6052631578947368, 0.6118421052631579, 0.6167763157894737, 0.6233552631578947, 0.587171052631579, 0.5740131578947368, 0.5575657894736842, 0.5016447368421053, 0.5707236842105263, 0.5608552631578947, 0.5, 0.5773026315789473, 0.5180921052631579, 0.5460526315789473, 0.5361842105263158, 0.506578947368421, 0.5444078947368421, 0.5542763157894737, 0.524671052631579, 0.5740131578947368, 0.5740131578947368, 0.5263157894736842] Best val loss: 5.478600561618805


Current group: 0.8
Epoch [1/200], Training Loss: 25.1426, Validation Loss Current: 9.8302, Validation Loss AVG: 9.8302, lr: 0.001
Epoch [2/200], Training Loss: 18.3781, Validation Loss Current: 13.2863, Validation Loss AVG: 13.2863, lr: 0.001
Epoch [3/200], Training Loss: 18.1458, Validation Loss Current: 10.2703, Validation Loss AVG: 10.2703, lr: 0.001
Epoch [4/200], Training Loss: 15.9485, Validation Loss Current: 11.1030, Validation Loss AVG: 11.1030, lr: 0.001
Epoch [5/200], Training Loss: 12.8111, Validation Loss Current: 11.3070, Validation Loss AVG: 11.3070, lr: 0.001
Epoch [6/200], Training Loss: 12.0380, Validation Loss Current: 11.0819, Validation Loss AVG: 11.0819, lr: 0.001
Epoch [7/200], Training Loss: 8.6248, Validation Loss Current: 10.5695, Validation Loss AVG: 10.5695, lr: 0.001
Epoch [8/200], Training Loss: 6.3264, Validation Loss Current: 8.9338, Validation Loss AVG: 8.9338, lr: 0.001
Epoch [9/200], Training Loss: 4.9608, Validation Loss Current: 9.4180, Validation Loss AVG: 9.4180, lr: 0.001
Epoch [10/200], Training Loss: 5.2758, Validation Loss Current: 9.5627, Validation Loss AVG: 9.5627, lr: 0.001
Epoch [11/200], Training Loss: 8.3029, Validation Loss Current: 14.0753, Validation Loss AVG: 14.0753, lr: 0.001
Epoch [12/200], Training Loss: 6.8944, Validation Loss Current: 11.5893, Validation Loss AVG: 11.5893, lr: 0.001
Epoch [13/200], Training Loss: 6.8936, Validation Loss Current: 10.4922, Validation Loss AVG: 10.4922, lr: 0.001
Epoch [14/200], Training Loss: 7.0041, Validation Loss Current: 10.6455, Validation Loss AVG: 10.6455, lr: 0.001
Epoch [15/200], Training Loss: 6.4719, Validation Loss Current: 10.5505, Validation Loss AVG: 10.5505, lr: 0.001
Epoch [16/200], Training Loss: 6.2159, Validation Loss Current: 10.9427, Validation Loss AVG: 10.9427, lr: 0.001
Epoch [17/200], Training Loss: 4.9913, Validation Loss Current: 13.3101, Validation Loss AVG: 13.3101, lr: 0.001
Epoch [18/200], Training Loss: 3.7007, Validation Loss Current: 9.8393, Validation Loss AVG: 9.8393, lr: 0.001
Epoch [19/200], Training Loss: 4.6780, Validation Loss Current: 11.6799, Validation Loss AVG: 11.6799, lr: 0.001
Epoch [20/200], Training Loss: 5.0729, Validation Loss Current: 14.6547, Validation Loss AVG: 14.6547, lr: 0.001
Epoch [21/200], Training Loss: 4.5402, Validation Loss Current: 17.2903, Validation Loss AVG: 17.2903, lr: 0.001
Epoch [22/200], Training Loss: 3.9318, Validation Loss Current: 13.6211, Validation Loss AVG: 13.6211, lr: 0.001
Epoch [23/200], Training Loss: 5.3150, Validation Loss Current: 13.2585, Validation Loss AVG: 13.2585, lr: 0.001
Epoch [24/200], Training Loss: 6.4370, Validation Loss Current: 12.0241, Validation Loss AVG: 12.0241, lr: 0.001
Epoch [25/200], Training Loss: 4.0099, Validation Loss Current: 12.7345, Validation Loss AVG: 12.7345, lr: 0.001
Epoch [26/200], Training Loss: 6.3534, Validation Loss Current: 14.1008, Validation Loss AVG: 14.1008, lr: 0.001
Epoch [27/200], Training Loss: 2.3039, Validation Loss Current: 11.0056, Validation Loss AVG: 11.0056, lr: 0.001
Epoch [28/200], Training Loss: 3.8689, Validation Loss Current: 11.3480, Validation Loss AVG: 11.3480, lr: 0.001
Epoch [29/200], Training Loss: 2.6424, Validation Loss Current: 11.3618, Validation Loss AVG: 11.3618, lr: 0.001
Epoch [30/200], Training Loss: 2.8241, Validation Loss Current: 11.8356, Validation Loss AVG: 11.8356, lr: 0.001
Epoch [31/200], Training Loss: 3.8526, Validation Loss Current: 13.8754, Validation Loss AVG: 13.8754, lr: 0.001
Epoch [32/200], Training Loss: 2.9792, Validation Loss Current: 11.5584, Validation Loss AVG: 11.5584, lr: 0.001
Epoch [33/200], Training Loss: 2.2192, Validation Loss Current: 10.4518, Validation Loss AVG: 10.4518, lr: 0.001
Epoch [34/200], Training Loss: 5.0683, Validation Loss Current: 12.2360, Validation Loss AVG: 12.2360, lr: 0.001
Epoch [35/200], Training Loss: 3.0860, Validation Loss Current: 10.8267, Validation Loss AVG: 10.8267, lr: 0.001
Epoch [36/200], Training Loss: 2.3276, Validation Loss Current: 11.2292, Validation Loss AVG: 11.2292, lr: 0.001
Epoch [37/200], Training Loss: 1.7160, Validation Loss Current: 11.8693, Validation Loss AVG: 11.8693, lr: 0.001
Epoch [38/200], Training Loss: 3.4343, Validation Loss Current: 12.0025, Validation Loss AVG: 12.0025, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 8 Best val accuracy: [0.4151315789473684, 0.3365131578947368, 0.4125000000000001, 0.40756578947368416, 0.3973684210526316, 0.3861842105263158, 0.43453947368421053, 0.43618421052631584, 0.4457236842105264, 0.4427631578947368, 0.42269736842105265, 0.4098684210526316, 0.44177631578947363, 0.4197368421052632, 0.46480263157894736, 0.4394736842105262, 0.42631578947368426, 0.46381578947368424, 0.4476973684210527, 0.40032894736842106, 0.4115131578947368, 0.4269736842105263, 0.4328947368421052, 0.43782894736842104, 0.44342105263157894, 0.4101973684210526, 0.45559210526315785, 0.4677631578947368, 0.4440789473684211, 0.45230263157894735, 0.4078947368421052, 0.4476973684210527, 0.4638157894736842, 0.4447368421052632, 0.46578947368421064, 0.4319078947368421, 0.42828947368421044, 0.42434210526315785] Best val loss: 8.933791756629944


----- Training resnet18 with sequence: [1, 0.8, 0.6] -----
Current group: 1
Epoch [1/134], Training Loss: 40.1090, Validation Loss Current: 10.0769, Validation Loss AVG: 10.1336, lr: 0.001
Epoch [2/134], Training Loss: 37.5111, Validation Loss Current: 9.5188, Validation Loss AVG: 9.9087, lr: 0.001
Epoch [3/134], Training Loss: 36.7827, Validation Loss Current: 9.3498, Validation Loss AVG: 10.2941, lr: 0.001
Epoch [4/134], Training Loss: 35.8006, Validation Loss Current: 9.0828, Validation Loss AVG: 9.7886, lr: 0.001
Epoch [5/134], Training Loss: 34.1080, Validation Loss Current: 8.6230, Validation Loss AVG: 9.3833, lr: 0.001
Epoch [6/134], Training Loss: 33.2147, Validation Loss Current: 8.3106, Validation Loss AVG: 9.3602, lr: 0.001
Epoch [7/134], Training Loss: 31.8057, Validation Loss Current: 8.1926, Validation Loss AVG: 9.1507, lr: 0.001
Epoch [8/134], Training Loss: 30.6079, Validation Loss Current: 8.1518, Validation Loss AVG: 10.0555, lr: 0.001
Epoch [9/134], Training Loss: 29.3966, Validation Loss Current: 8.2717, Validation Loss AVG: 11.6556, lr: 0.001
Epoch [10/134], Training Loss: 27.9187, Validation Loss Current: 7.5324, Validation Loss AVG: 9.5768, lr: 0.001
Epoch [11/134], Training Loss: 26.5787, Validation Loss Current: 7.3895, Validation Loss AVG: 9.9457, lr: 0.001
Epoch [12/134], Training Loss: 25.8675, Validation Loss Current: 7.3628, Validation Loss AVG: 8.6002, lr: 0.001
Epoch [13/134], Training Loss: 25.2587, Validation Loss Current: 7.1361, Validation Loss AVG: 10.4184, lr: 0.001
Epoch [14/134], Training Loss: 24.9389, Validation Loss Current: 6.8611, Validation Loss AVG: 9.6255, lr: 0.001
Epoch [15/134], Training Loss: 24.5771, Validation Loss Current: 6.7308, Validation Loss AVG: 9.1563, lr: 0.001
Epoch [16/134], Training Loss: 24.2622, Validation Loss Current: 7.1870, Validation Loss AVG: 9.0579, lr: 0.001
Epoch [17/134], Training Loss: 24.5828, Validation Loss Current: 7.0295, Validation Loss AVG: 8.9720, lr: 0.001
Epoch [18/134], Training Loss: 23.5851, Validation Loss Current: 6.3400, Validation Loss AVG: 9.8400, lr: 0.001
Epoch [19/134], Training Loss: 22.3580, Validation Loss Current: 7.1960, Validation Loss AVG: 9.6646, lr: 0.001
Epoch [20/134], Training Loss: 21.7644, Validation Loss Current: 6.8478, Validation Loss AVG: 9.0011, lr: 0.001
Epoch [21/134], Training Loss: 20.2271, Validation Loss Current: 8.0232, Validation Loss AVG: 12.4944, lr: 0.001
Epoch [22/134], Training Loss: 20.7415, Validation Loss Current: 6.3486, Validation Loss AVG: 8.6159, lr: 0.001
Epoch [23/134], Training Loss: 20.0271, Validation Loss Current: 6.1442, Validation Loss AVG: 8.9459, lr: 0.001
Epoch [24/134], Training Loss: 18.4423, Validation Loss Current: 6.2795, Validation Loss AVG: 9.6971, lr: 0.001
Epoch [25/134], Training Loss: 20.0923, Validation Loss Current: 6.2812, Validation Loss AVG: 9.1011, lr: 0.001
Epoch [26/134], Training Loss: 17.8597, Validation Loss Current: 6.2280, Validation Loss AVG: 10.8058, lr: 0.001
Epoch [27/134], Training Loss: 16.6498, Validation Loss Current: 6.3401, Validation Loss AVG: 8.8144, lr: 0.001
Epoch [28/134], Training Loss: 16.8993, Validation Loss Current: 7.5312, Validation Loss AVG: 10.4785, lr: 0.001
Epoch [29/134], Training Loss: 15.8010, Validation Loss Current: 6.1735, Validation Loss AVG: 12.2954, lr: 0.001
Epoch [30/134], Training Loss: 14.3325, Validation Loss Current: 5.6369, Validation Loss AVG: 9.4326, lr: 0.001
Epoch [31/134], Training Loss: 13.7826, Validation Loss Current: 5.7126, Validation Loss AVG: 9.7278, lr: 0.001
Epoch [32/134], Training Loss: 13.1701, Validation Loss Current: 5.5165, Validation Loss AVG: 9.8886, lr: 0.001
Epoch [33/134], Training Loss: 13.4191, Validation Loss Current: 5.9727, Validation Loss AVG: 10.6568, lr: 0.001
Epoch [34/134], Training Loss: 12.2769, Validation Loss Current: 5.6277, Validation Loss AVG: 9.1527, lr: 0.001
Epoch [35/134], Training Loss: 11.2810, Validation Loss Current: 5.5711, Validation Loss AVG: 8.5323, lr: 0.001
Epoch [36/134], Training Loss: 11.7236, Validation Loss Current: 5.7608, Validation Loss AVG: 11.0090, lr: 0.001
Epoch [37/134], Training Loss: 9.7741, Validation Loss Current: 5.8434, Validation Loss AVG: 11.6678, lr: 0.001
Epoch [38/134], Training Loss: 8.7580, Validation Loss Current: 5.6724, Validation Loss AVG: 10.8862, lr: 0.001
Epoch [39/134], Training Loss: 9.4653, Validation Loss Current: 6.1139, Validation Loss AVG: 9.3886, lr: 0.001
Epoch [40/134], Training Loss: 9.9564, Validation Loss Current: 5.7638, Validation Loss AVG: 8.4899, lr: 0.001
Epoch [41/134], Training Loss: 9.4424, Validation Loss Current: 7.3542, Validation Loss AVG: 13.9073, lr: 0.001
Epoch [42/134], Training Loss: 11.1317, Validation Loss Current: 6.2676, Validation Loss AVG: 9.3774, lr: 0.001
Epoch [43/134], Training Loss: 9.9045, Validation Loss Current: 5.4063, Validation Loss AVG: 9.1699, lr: 0.001
Epoch [44/134], Training Loss: 8.3077, Validation Loss Current: 6.0503, Validation Loss AVG: 12.1623, lr: 0.001
Epoch [45/134], Training Loss: 8.8497, Validation Loss Current: 5.6028, Validation Loss AVG: 10.5754, lr: 0.001
Epoch [46/134], Training Loss: 6.2726, Validation Loss Current: 5.7380, Validation Loss AVG: 11.0867, lr: 0.001
Epoch [47/134], Training Loss: 5.4625, Validation Loss Current: 5.8373, Validation Loss AVG: 14.9114, lr: 0.001
Epoch [48/134], Training Loss: 6.8579, Validation Loss Current: 6.1560, Validation Loss AVG: 9.5940, lr: 0.001
Epoch [49/134], Training Loss: 5.6705, Validation Loss Current: 5.4463, Validation Loss AVG: 10.8332, lr: 0.001
Epoch [50/134], Training Loss: 4.4728, Validation Loss Current: 5.4598, Validation Loss AVG: 11.2438, lr: 0.001
Epoch [51/134], Training Loss: 4.5657, Validation Loss Current: 8.2596, Validation Loss AVG: 12.4356, lr: 0.001
Epoch [52/134], Training Loss: 8.9037, Validation Loss Current: 8.7041, Validation Loss AVG: 17.7457, lr: 0.001
Epoch [53/134], Training Loss: 7.5430, Validation Loss Current: 6.5408, Validation Loss AVG: 15.5509, lr: 0.001
Epoch [54/134], Training Loss: 6.6303, Validation Loss Current: 5.7005, Validation Loss AVG: 10.9363, lr: 0.001
Epoch [55/134], Training Loss: 6.0342, Validation Loss Current: 6.6228, Validation Loss AVG: 10.7669, lr: 0.001
Epoch [56/134], Training Loss: 5.3721, Validation Loss Current: 6.8755, Validation Loss AVG: 11.4580, lr: 0.001
Epoch [57/134], Training Loss: 4.1868, Validation Loss Current: 6.1752, Validation Loss AVG: 11.1970, lr: 0.001
Epoch [58/134], Training Loss: 3.4810, Validation Loss Current: 5.9160, Validation Loss AVG: 11.1251, lr: 0.001
Epoch [59/134], Training Loss: 6.1040, Validation Loss Current: 6.1607, Validation Loss AVG: 12.3209, lr: 0.001
Epoch [60/134], Training Loss: 3.6390, Validation Loss Current: 6.4096, Validation Loss AVG: 11.3238, lr: 0.001
Epoch [61/134], Training Loss: 2.2753, Validation Loss Current: 5.7821, Validation Loss AVG: 13.5408, lr: 0.001
Epoch [62/134], Training Loss: 2.5190, Validation Loss Current: 6.6797, Validation Loss AVG: 12.3951, lr: 0.001
Epoch [63/134], Training Loss: 3.3832, Validation Loss Current: 7.8917, Validation Loss AVG: 14.5921, lr: 0.001
Epoch [64/134], Training Loss: 8.2339, Validation Loss Current: 9.7659, Validation Loss AVG: 16.6465, lr: 0.001
Epoch [65/134], Training Loss: 5.7781, Validation Loss Current: 9.4333, Validation Loss AVG: 15.0921, lr: 0.001
Epoch [66/134], Training Loss: 6.2298, Validation Loss Current: 6.8855, Validation Loss AVG: 13.7342, lr: 0.001
Epoch [67/134], Training Loss: 4.6700, Validation Loss Current: 7.7381, Validation Loss AVG: 14.8376, lr: 0.001
Epoch [68/134], Training Loss: 8.1331, Validation Loss Current: 6.3453, Validation Loss AVG: 9.8540, lr: 0.001
Epoch [69/134], Training Loss: 4.1726, Validation Loss Current: 7.0455, Validation Loss AVG: 12.7592, lr: 0.001
Epoch [70/134], Training Loss: 3.4650, Validation Loss Current: 6.9457, Validation Loss AVG: 13.9946, lr: 0.001
Epoch [71/134], Training Loss: 3.7355, Validation Loss Current: 7.0059, Validation Loss AVG: 13.4621, lr: 0.001
Epoch [72/134], Training Loss: 2.7864, Validation Loss Current: 7.2306, Validation Loss AVG: 13.2565, lr: 0.001
Epoch [73/134], Training Loss: 3.3884, Validation Loss Current: 6.8801, Validation Loss AVG: 9.6889, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 43 Best val accuracy: [0.24342105263157895, 0.28125, 0.33223684210526316, 0.3667763157894737, 0.3848684210526316, 0.4144736842105263, 0.42105263157894735, 0.41118421052631576, 0.40625, 0.4654605263157895, 0.4588815789473684, 0.4901315789473684, 0.48848684210526316, 0.5148026315789473, 0.5328947368421053, 0.4917763157894737, 0.5115131578947368, 0.5444078947368421, 0.4901315789473684, 0.5411184210526315, 0.5180921052631579, 0.5361842105263158, 0.5707236842105263, 0.5625, 0.555921052631579, 0.555921052631579, 0.5953947368421053, 0.5427631578947368, 0.5608552631578947, 0.6036184210526315, 0.6019736842105263, 0.6019736842105263, 0.5805921052631579, 0.6217105263157895, 0.6200657894736842, 0.5986842105263158, 0.6151315789473685, 0.6200657894736842, 0.6282894736842105, 0.618421052631579, 0.5345394736842105, 0.6101973684210527, 0.6233552631578947, 0.625, 0.6085526315789473, 0.6299342105263158, 0.6217105263157895, 0.6134868421052632, 0.65625, 0.6611842105263158, 0.5476973684210527, 0.524671052631579, 0.6299342105263158, 0.6365131578947368, 0.6266447368421053, 0.600328947368421, 0.6069078947368421, 0.6381578947368421, 0.6266447368421053, 0.6233552631578947, 0.649671052631579, 0.6282894736842105, 0.5740131578947368, 0.5444078947368421, 0.5328947368421053, 0.6299342105263158, 0.587171052631579, 0.6233552631578947, 0.6118421052631579, 0.6069078947368421, 0.6217105263157895, 0.5888157894736842, 0.6134868421052632] Best val loss: 5.406269729137421


Current group: 0.8
Epoch [1/134], Training Loss: 21.4922, Validation Loss Current: 9.5097, Validation Loss AVG: 9.5097, lr: 0.001
Epoch [2/134], Training Loss: 19.4162, Validation Loss Current: 11.8964, Validation Loss AVG: 11.8964, lr: 0.001
Epoch [3/134], Training Loss: 14.0330, Validation Loss Current: 10.3906, Validation Loss AVG: 10.3906, lr: 0.001
Epoch [4/134], Training Loss: 11.4705, Validation Loss Current: 11.8341, Validation Loss AVG: 11.8341, lr: 0.001
Epoch [5/134], Training Loss: 11.9439, Validation Loss Current: 9.7401, Validation Loss AVG: 9.7401, lr: 0.001
Epoch [6/134], Training Loss: 8.2759, Validation Loss Current: 11.2075, Validation Loss AVG: 11.2075, lr: 0.001
Epoch [7/134], Training Loss: 10.1173, Validation Loss Current: 10.7016, Validation Loss AVG: 10.7016, lr: 0.001
Epoch [8/134], Training Loss: 6.6299, Validation Loss Current: 10.3811, Validation Loss AVG: 10.3811, lr: 0.001
Epoch [9/134], Training Loss: 5.8606, Validation Loss Current: 9.6972, Validation Loss AVG: 9.6972, lr: 0.001
Epoch [10/134], Training Loss: 5.7266, Validation Loss Current: 10.3348, Validation Loss AVG: 10.3348, lr: 0.001
Epoch [11/134], Training Loss: 6.7171, Validation Loss Current: 11.4190, Validation Loss AVG: 11.4190, lr: 0.001
Epoch [12/134], Training Loss: 7.1094, Validation Loss Current: 11.9560, Validation Loss AVG: 11.9560, lr: 0.001
Epoch [13/134], Training Loss: 11.2389, Validation Loss Current: 13.7260, Validation Loss AVG: 13.7260, lr: 0.001
Epoch [14/134], Training Loss: 11.4566, Validation Loss Current: 11.9694, Validation Loss AVG: 11.9694, lr: 0.001
Epoch [15/134], Training Loss: 7.7244, Validation Loss Current: 13.0213, Validation Loss AVG: 13.0213, lr: 0.001
Epoch [16/134], Training Loss: 5.3773, Validation Loss Current: 12.8640, Validation Loss AVG: 12.8640, lr: 0.001
Epoch [17/134], Training Loss: 5.8811, Validation Loss Current: 9.5221, Validation Loss AVG: 9.5221, lr: 0.001
Epoch [18/134], Training Loss: 2.5671, Validation Loss Current: 10.4143, Validation Loss AVG: 10.4143, lr: 0.001
Epoch [19/134], Training Loss: 2.2688, Validation Loss Current: 10.6517, Validation Loss AVG: 10.6517, lr: 0.001
Epoch [20/134], Training Loss: 6.0567, Validation Loss Current: 13.0120, Validation Loss AVG: 13.0120, lr: 0.001
Epoch [21/134], Training Loss: 3.5473, Validation Loss Current: 11.3804, Validation Loss AVG: 11.3804, lr: 0.001
Epoch [22/134], Training Loss: 4.1457, Validation Loss Current: 10.3612, Validation Loss AVG: 10.3612, lr: 0.001
Epoch [23/134], Training Loss: 3.1742, Validation Loss Current: 9.4889, Validation Loss AVG: 9.4889, lr: 0.001
Epoch [24/134], Training Loss: 3.3754, Validation Loss Current: 11.7144, Validation Loss AVG: 11.7144, lr: 0.001
Epoch [25/134], Training Loss: 1.7011, Validation Loss Current: 11.7177, Validation Loss AVG: 11.7177, lr: 0.001
Epoch [26/134], Training Loss: 0.9251, Validation Loss Current: 12.3290, Validation Loss AVG: 12.3290, lr: 0.001
Epoch [27/134], Training Loss: 1.6440, Validation Loss Current: 12.7004, Validation Loss AVG: 12.7004, lr: 0.001
Epoch [28/134], Training Loss: 2.8214, Validation Loss Current: 13.8267, Validation Loss AVG: 13.8267, lr: 0.001
Epoch [29/134], Training Loss: 4.3680, Validation Loss Current: 13.1131, Validation Loss AVG: 13.1131, lr: 0.001
Epoch [30/134], Training Loss: 5.3533, Validation Loss Current: 14.1765, Validation Loss AVG: 14.1765, lr: 0.001
Epoch [31/134], Training Loss: 5.2999, Validation Loss Current: 11.5739, Validation Loss AVG: 11.5739, lr: 0.001
Epoch [32/134], Training Loss: 4.9691, Validation Loss Current: 11.4519, Validation Loss AVG: 11.4519, lr: 0.001
Epoch [33/134], Training Loss: 3.5463, Validation Loss Current: 11.3966, Validation Loss AVG: 11.3966, lr: 0.001
Epoch [34/134], Training Loss: 3.2889, Validation Loss Current: 12.8344, Validation Loss AVG: 12.8344, lr: 0.001
Epoch [35/134], Training Loss: 3.9925, Validation Loss Current: 16.7919, Validation Loss AVG: 16.7919, lr: 0.001
Epoch [36/134], Training Loss: 6.2342, Validation Loss Current: 14.0306, Validation Loss AVG: 14.0306, lr: 0.001
Epoch [37/134], Training Loss: 3.9802, Validation Loss Current: 11.9606, Validation Loss AVG: 11.9606, lr: 0.001
Epoch [38/134], Training Loss: 1.4930, Validation Loss Current: 11.2843, Validation Loss AVG: 11.2843, lr: 0.001
Epoch [39/134], Training Loss: 3.5035, Validation Loss Current: 12.9247, Validation Loss AVG: 12.9247, lr: 0.001
Epoch [40/134], Training Loss: 5.3324, Validation Loss Current: 10.7755, Validation Loss AVG: 10.7755, lr: 0.001
Epoch [41/134], Training Loss: 3.0606, Validation Loss Current: 14.8074, Validation Loss AVG: 14.8074, lr: 0.001
Epoch [42/134], Training Loss: 5.4425, Validation Loss Current: 12.6165, Validation Loss AVG: 12.6165, lr: 0.001
Epoch [43/134], Training Loss: 6.9464, Validation Loss Current: 11.2809, Validation Loss AVG: 11.2809, lr: 0.001
Epoch [44/134], Training Loss: 5.3240, Validation Loss Current: 12.2232, Validation Loss AVG: 12.2232, lr: 0.001
Epoch [45/134], Training Loss: 4.7507, Validation Loss Current: 12.6170, Validation Loss AVG: 12.6170, lr: 0.001
Epoch [46/134], Training Loss: 6.5540, Validation Loss Current: 19.7880, Validation Loss AVG: 19.7880, lr: 0.001
Epoch [47/134], Training Loss: 3.3682, Validation Loss Current: 11.5923, Validation Loss AVG: 11.5923, lr: 0.001
Epoch [48/134], Training Loss: 2.6788, Validation Loss Current: 12.5584, Validation Loss AVG: 12.5584, lr: 0.001
Epoch [49/134], Training Loss: 3.9782, Validation Loss Current: 12.3955, Validation Loss AVG: 12.3955, lr: 0.001
Epoch [50/134], Training Loss: 4.8756, Validation Loss Current: 11.8792, Validation Loss AVG: 11.8792, lr: 0.001
Epoch [51/134], Training Loss: 4.9680, Validation Loss Current: 12.8031, Validation Loss AVG: 12.8031, lr: 0.001
Epoch [52/134], Training Loss: 7.3055, Validation Loss Current: 11.1986, Validation Loss AVG: 11.1986, lr: 0.001
Epoch [53/134], Training Loss: 2.8062, Validation Loss Current: 13.0125, Validation Loss AVG: 13.0125, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 23 Best val accuracy: [0.4526315789473684, 0.4161184210526316, 0.41447368421052627, 0.42269736842105254, 0.45953947368421055, 0.44046052631578947, 0.45131578947368417, 0.44605263157894737, 0.4496710526315789, 0.4759868421052631, 0.46282894736842106, 0.44177631578947374, 0.38289473684210523, 0.4203947368421052, 0.39342105263157895, 0.42730263157894743, 0.4578947368421053, 0.4578947368421053, 0.48157894736842116, 0.41052631578947363, 0.4536184210526315, 0.45296052631578937, 0.4601973684210526, 0.4651315789473684, 0.4703947368421053, 0.46940789473684214, 0.47138157894736843, 0.42664473684210524, 0.40493421052631573, 0.4480263157894737, 0.4891447368421053, 0.4509868421052632, 0.4615131578947368, 0.4625, 0.39703947368421055, 0.4029605263157895, 0.43453947368421053, 0.4756578947368422, 0.4697368421052632, 0.4519736842105263, 0.42105263157894735, 0.44210526315789467, 0.43355263157894736, 0.41578947368421054, 0.42960526315789477, 0.3871710526315789, 0.46118421052631575, 0.4131578947368421, 0.4480263157894736, 0.46282894736842095, 0.4309210526315789, 0.4273026315789473, 0.4470394736842106] Best val loss: 9.488854169845581


Current group: 0.6
Epoch [1/134], Training Loss: 29.8372, Validation Loss Current: 9.0651, Validation Loss AVG: 9.0651, lr: 0.001
Epoch [2/134], Training Loss: 17.7276, Validation Loss Current: 10.5117, Validation Loss AVG: 10.5117, lr: 0.001
Epoch [3/134], Training Loss: 11.4352, Validation Loss Current: 9.0383, Validation Loss AVG: 9.0383, lr: 0.001
Epoch [4/134], Training Loss: 7.7146, Validation Loss Current: 9.0417, Validation Loss AVG: 9.0417, lr: 0.001
Epoch [5/134], Training Loss: 8.2566, Validation Loss Current: 11.3088, Validation Loss AVG: 11.3088, lr: 0.001
Epoch [6/134], Training Loss: 7.3524, Validation Loss Current: 10.9326, Validation Loss AVG: 10.9326, lr: 0.001
Epoch [7/134], Training Loss: 5.1508, Validation Loss Current: 9.7750, Validation Loss AVG: 9.7750, lr: 0.001
Epoch [8/134], Training Loss: 3.8939, Validation Loss Current: 9.8136, Validation Loss AVG: 9.8136, lr: 0.001
Epoch [9/134], Training Loss: 4.1430, Validation Loss Current: 9.6664, Validation Loss AVG: 9.6664, lr: 0.001
Epoch [10/134], Training Loss: 3.0947, Validation Loss Current: 9.8571, Validation Loss AVG: 9.8571, lr: 0.001
Epoch [11/134], Training Loss: 3.1752, Validation Loss Current: 10.6200, Validation Loss AVG: 10.6200, lr: 0.001
Epoch [12/134], Training Loss: 3.8046, Validation Loss Current: 12.6995, Validation Loss AVG: 12.6995, lr: 0.001
Epoch [13/134], Training Loss: 3.1921, Validation Loss Current: 10.8421, Validation Loss AVG: 10.8421, lr: 0.001
Epoch [14/134], Training Loss: 4.2553, Validation Loss Current: 10.9104, Validation Loss AVG: 10.9104, lr: 0.001
Epoch [15/134], Training Loss: 2.0453, Validation Loss Current: 10.4629, Validation Loss AVG: 10.4629, lr: 0.001
Epoch [16/134], Training Loss: 1.0458, Validation Loss Current: 11.0877, Validation Loss AVG: 11.0877, lr: 0.001
Epoch [17/134], Training Loss: 1.3069, Validation Loss Current: 10.5770, Validation Loss AVG: 10.5770, lr: 0.001
Epoch [18/134], Training Loss: 7.4571, Validation Loss Current: 12.4359, Validation Loss AVG: 12.4359, lr: 0.001
Epoch [19/134], Training Loss: 3.1279, Validation Loss Current: 10.6883, Validation Loss AVG: 10.6883, lr: 0.001
Epoch [20/134], Training Loss: 5.7624, Validation Loss Current: 12.7602, Validation Loss AVG: 12.7602, lr: 0.001
Epoch [21/134], Training Loss: 11.3733, Validation Loss Current: 15.4872, Validation Loss AVG: 15.4872, lr: 0.001
Epoch [22/134], Training Loss: 8.3446, Validation Loss Current: 13.3159, Validation Loss AVG: 13.3159, lr: 0.001
Epoch [23/134], Training Loss: 4.4287, Validation Loss Current: 12.1990, Validation Loss AVG: 12.1990, lr: 0.001
Epoch [24/134], Training Loss: 3.2997, Validation Loss Current: 10.4914, Validation Loss AVG: 10.4914, lr: 0.001
Epoch [25/134], Training Loss: 5.3933, Validation Loss Current: 13.3210, Validation Loss AVG: 13.3210, lr: 0.001
Epoch [26/134], Training Loss: 4.1926, Validation Loss Current: 11.2091, Validation Loss AVG: 11.2091, lr: 0.001
Epoch [27/134], Training Loss: 6.1818, Validation Loss Current: 11.8409, Validation Loss AVG: 11.8409, lr: 0.001
Epoch [28/134], Training Loss: 4.4999, Validation Loss Current: 10.1666, Validation Loss AVG: 10.1666, lr: 0.001
Epoch [29/134], Training Loss: 2.3813, Validation Loss Current: 10.9704, Validation Loss AVG: 10.9704, lr: 0.001
Epoch [30/134], Training Loss: 3.4492, Validation Loss Current: 10.4732, Validation Loss AVG: 10.4732, lr: 0.001
Epoch [31/134], Training Loss: 4.5251, Validation Loss Current: 12.8956, Validation Loss AVG: 12.8956, lr: 0.001
Epoch [32/134], Training Loss: 4.0675, Validation Loss Current: 11.8639, Validation Loss AVG: 11.8639, lr: 0.001
Epoch [33/134], Training Loss: 4.2411, Validation Loss Current: 14.5631, Validation Loss AVG: 14.5631, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 3 Best val accuracy: [0.5023026315789474, 0.4542763157894737, 0.5009868421052632, 0.48388157894736833, 0.4375, 0.4990131578947368, 0.5088815789473685, 0.5164473684210525, 0.49638157894736834, 0.5065789473684211, 0.5085526315789473, 0.46940789473684214, 0.4878289473684211, 0.5016447368421053, 0.4934210526315789, 0.5154605263157894, 0.50625, 0.46546052631578955, 0.4615131578947369, 0.4875, 0.40328947368421053, 0.4118421052631579, 0.4720394736842105, 0.48519736842105277, 0.47730263157894726, 0.5016447368421053, 0.48519736842105254, 0.4615131578947369, 0.4855263157894737, 0.49539473684210533, 0.4845394736842105, 0.4519736842105263, 0.46085526315789477] Best val loss: 9.038306856155396


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4] -----
Current group: 1
Epoch [1/100], Training Loss: 39.3482, Validation Loss Current: 10.0533, Validation Loss AVG: 10.1460, lr: 0.001
Epoch [2/100], Training Loss: 38.3378, Validation Loss Current: 9.8759, Validation Loss AVG: 10.5809, lr: 0.001
Epoch [3/100], Training Loss: 37.0172, Validation Loss Current: 9.1407, Validation Loss AVG: 9.7981, lr: 0.001
Epoch [4/100], Training Loss: 35.5113, Validation Loss Current: 9.1894, Validation Loss AVG: 9.7900, lr: 0.001
Epoch [5/100], Training Loss: 34.3572, Validation Loss Current: 8.7666, Validation Loss AVG: 9.8644, lr: 0.001
Epoch [6/100], Training Loss: 32.7957, Validation Loss Current: 8.5024, Validation Loss AVG: 10.0787, lr: 0.001
Epoch [7/100], Training Loss: 31.9953, Validation Loss Current: 11.8388, Validation Loss AVG: 18.4473, lr: 0.001
Epoch [8/100], Training Loss: 29.8631, Validation Loss Current: 7.8345, Validation Loss AVG: 9.3511, lr: 0.001
Epoch [9/100], Training Loss: 28.8690, Validation Loss Current: 8.4942, Validation Loss AVG: 10.7794, lr: 0.001
Epoch [10/100], Training Loss: 28.2867, Validation Loss Current: 7.4773, Validation Loss AVG: 8.9027, lr: 0.001
Epoch [11/100], Training Loss: 25.8232, Validation Loss Current: 7.3809, Validation Loss AVG: 9.1114, lr: 0.001
Epoch [12/100], Training Loss: 24.9005, Validation Loss Current: 7.0702, Validation Loss AVG: 11.3375, lr: 0.001
Epoch [13/100], Training Loss: 24.5887, Validation Loss Current: 6.8812, Validation Loss AVG: 9.3450, lr: 0.001
Epoch [14/100], Training Loss: 23.5264, Validation Loss Current: 7.1934, Validation Loss AVG: 10.4944, lr: 0.001
Epoch [15/100], Training Loss: 23.0912, Validation Loss Current: 6.7445, Validation Loss AVG: 8.7076, lr: 0.001
Epoch [16/100], Training Loss: 22.7556, Validation Loss Current: 7.3352, Validation Loss AVG: 13.6158, lr: 0.001
Epoch [17/100], Training Loss: 22.4151, Validation Loss Current: 7.2560, Validation Loss AVG: 11.2170, lr: 0.001
Epoch [18/100], Training Loss: 21.7043, Validation Loss Current: 7.1633, Validation Loss AVG: 8.9682, lr: 0.001
Epoch [19/100], Training Loss: 20.7670, Validation Loss Current: 6.8805, Validation Loss AVG: 10.7368, lr: 0.001
Epoch [20/100], Training Loss: 21.8050, Validation Loss Current: 6.6576, Validation Loss AVG: 9.0608, lr: 0.001
Epoch [21/100], Training Loss: 20.1640, Validation Loss Current: 6.6829, Validation Loss AVG: 9.1132, lr: 0.001
Epoch [22/100], Training Loss: 18.9250, Validation Loss Current: 6.2723, Validation Loss AVG: 8.6015, lr: 0.001
Epoch [23/100], Training Loss: 19.1539, Validation Loss Current: 6.9196, Validation Loss AVG: 10.7910, lr: 0.001
Epoch [24/100], Training Loss: 18.5724, Validation Loss Current: 7.1937, Validation Loss AVG: 10.3114, lr: 0.001
Epoch [25/100], Training Loss: 18.3050, Validation Loss Current: 6.7072, Validation Loss AVG: 10.7071, lr: 0.001
Epoch [26/100], Training Loss: 17.7622, Validation Loss Current: 6.0303, Validation Loss AVG: 9.2388, lr: 0.001
Epoch [27/100], Training Loss: 15.8824, Validation Loss Current: 5.7728, Validation Loss AVG: 9.0127, lr: 0.001
Epoch [28/100], Training Loss: 15.7341, Validation Loss Current: 6.2827, Validation Loss AVG: 9.1928, lr: 0.001
Epoch [29/100], Training Loss: 15.3201, Validation Loss Current: 6.8675, Validation Loss AVG: 10.5999, lr: 0.001
Epoch [30/100], Training Loss: 17.6964, Validation Loss Current: 6.8766, Validation Loss AVG: 8.6167, lr: 0.001
Epoch [31/100], Training Loss: 16.7096, Validation Loss Current: 6.6714, Validation Loss AVG: 13.2091, lr: 0.001
Epoch [32/100], Training Loss: 14.1250, Validation Loss Current: 5.7731, Validation Loss AVG: 8.9841, lr: 0.001
Epoch [33/100], Training Loss: 13.7044, Validation Loss Current: 5.7721, Validation Loss AVG: 9.8417, lr: 0.001
Epoch [34/100], Training Loss: 14.0990, Validation Loss Current: 6.4682, Validation Loss AVG: 12.3681, lr: 0.001
Epoch [35/100], Training Loss: 11.7937, Validation Loss Current: 5.8613, Validation Loss AVG: 8.7569, lr: 0.001
Epoch [36/100], Training Loss: 10.9191, Validation Loss Current: 5.9792, Validation Loss AVG: 8.4562, lr: 0.001
Epoch [37/100], Training Loss: 10.1618, Validation Loss Current: 5.6198, Validation Loss AVG: 9.4329, lr: 0.001
Epoch [38/100], Training Loss: 11.6866, Validation Loss Current: 5.6207, Validation Loss AVG: 10.6679, lr: 0.001
Epoch [39/100], Training Loss: 8.8812, Validation Loss Current: 5.9186, Validation Loss AVG: 12.9016, lr: 0.001
Epoch [40/100], Training Loss: 9.1164, Validation Loss Current: 6.3401, Validation Loss AVG: 9.7039, lr: 0.001
Epoch [41/100], Training Loss: 9.0905, Validation Loss Current: 6.7256, Validation Loss AVG: 11.0873, lr: 0.001
Epoch [42/100], Training Loss: 7.3276, Validation Loss Current: 6.3217, Validation Loss AVG: 9.4096, lr: 0.001
Epoch [43/100], Training Loss: 7.7782, Validation Loss Current: 7.2181, Validation Loss AVG: 11.0463, lr: 0.001
Epoch [44/100], Training Loss: 12.9508, Validation Loss Current: 6.8898, Validation Loss AVG: 16.8495, lr: 0.001
Epoch [45/100], Training Loss: 12.6477, Validation Loss Current: 6.7473, Validation Loss AVG: 10.6379, lr: 0.001
Epoch [46/100], Training Loss: 7.8855, Validation Loss Current: 6.1989, Validation Loss AVG: 10.2753, lr: 0.001
Epoch [47/100], Training Loss: 5.9229, Validation Loss Current: 6.1839, Validation Loss AVG: 12.3997, lr: 0.001
Epoch [48/100], Training Loss: 7.1019, Validation Loss Current: 6.7705, Validation Loss AVG: 10.6602, lr: 0.001
Epoch [49/100], Training Loss: 4.8670, Validation Loss Current: 6.6315, Validation Loss AVG: 10.0166, lr: 0.001
Epoch [50/100], Training Loss: 5.0284, Validation Loss Current: 6.3194, Validation Loss AVG: 11.0393, lr: 0.001
Epoch [51/100], Training Loss: 5.2714, Validation Loss Current: 6.3365, Validation Loss AVG: 11.8637, lr: 0.001
Epoch [52/100], Training Loss: 4.5310, Validation Loss Current: 7.3819, Validation Loss AVG: 13.3029, lr: 0.001
Epoch [53/100], Training Loss: 5.8843, Validation Loss Current: 8.9536, Validation Loss AVG: 11.7478, lr: 0.001
Epoch [54/100], Training Loss: 8.0962, Validation Loss Current: 10.4418, Validation Loss AVG: 17.2584, lr: 0.001
Epoch [55/100], Training Loss: 4.2377, Validation Loss Current: 6.5866, Validation Loss AVG: 14.5191, lr: 0.001
Epoch [56/100], Training Loss: 3.2819, Validation Loss Current: 5.9825, Validation Loss AVG: 11.3725, lr: 0.001
Epoch [57/100], Training Loss: 5.4734, Validation Loss Current: 7.3579, Validation Loss AVG: 12.3720, lr: 0.001
Epoch [58/100], Training Loss: 6.6094, Validation Loss Current: 7.7479, Validation Loss AVG: 11.0846, lr: 0.001
Epoch [59/100], Training Loss: 6.9150, Validation Loss Current: 10.1969, Validation Loss AVG: 17.0964, lr: 0.001
Epoch [60/100], Training Loss: 4.1347, Validation Loss Current: 6.7368, Validation Loss AVG: 10.6022, lr: 0.001
Epoch [61/100], Training Loss: 3.8648, Validation Loss Current: 8.1969, Validation Loss AVG: 11.3119, lr: 0.001
Epoch [62/100], Training Loss: 5.3333, Validation Loss Current: 6.8832, Validation Loss AVG: 13.4928, lr: 0.001
Epoch [63/100], Training Loss: 3.3080, Validation Loss Current: 6.6034, Validation Loss AVG: 12.2164, lr: 0.001
Epoch [64/100], Training Loss: 3.1102, Validation Loss Current: 7.7383, Validation Loss AVG: 14.5821, lr: 0.001
Epoch [65/100], Training Loss: 4.1985, Validation Loss Current: 8.3500, Validation Loss AVG: 17.3881, lr: 0.001
Epoch [66/100], Training Loss: 4.8860, Validation Loss Current: 7.2332, Validation Loss AVG: 10.7655, lr: 0.001
Epoch [67/100], Training Loss: 6.4870, Validation Loss Current: 7.7588, Validation Loss AVG: 12.8512, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 37 Best val accuracy: [0.23848684210526316, 0.24342105263157895, 0.35855263157894735, 0.3355263157894737, 0.3782894736842105, 0.38980263157894735, 0.2944078947368421, 0.46875, 0.4144736842105263, 0.4917763157894737, 0.48848684210526316, 0.5016447368421053, 0.5345394736842105, 0.5148026315789473, 0.5197368421052632, 0.5049342105263158, 0.5164473684210527, 0.5131578947368421, 0.5476973684210527, 0.555921052631579, 0.5279605263157895, 0.5542763157894737, 0.5641447368421053, 0.5230263157894737, 0.5657894736842105, 0.5822368421052632, 0.600328947368421, 0.5707236842105263, 0.5509868421052632, 0.5148026315789473, 0.5394736842105263, 0.600328947368421, 0.6069078947368421, 0.5542763157894737, 0.618421052631579, 0.6052631578947368, 0.6266447368421053, 0.6134868421052632, 0.6036184210526315, 0.5707236842105263, 0.587171052631579, 0.59375, 0.555921052631579, 0.5608552631578947, 0.5707236842105263, 0.6069078947368421, 0.6101973684210527, 0.5921052631578947, 0.6069078947368421, 0.600328947368421, 0.6019736842105263, 0.5904605263157895, 0.5444078947368421, 0.4342105263157895, 0.6151315789473685, 0.6529605263157895, 0.6052631578947368, 0.5509868421052632, 0.5230263157894737, 0.6069078947368421, 0.5838815789473685, 0.618421052631579, 0.6217105263157895, 0.5822368421052632, 0.5740131578947368, 0.5838815789473685, 0.555921052631579] Best val loss: 5.619771420955658


Current group: 0.8
Epoch [1/100], Training Loss: 23.0422, Validation Loss Current: 13.0874, Validation Loss AVG: 13.0874, lr: 0.001
Epoch [2/100], Training Loss: 15.8327, Validation Loss Current: 18.2671, Validation Loss AVG: 18.2671, lr: 0.001
Epoch [3/100], Training Loss: 15.0123, Validation Loss Current: 12.5018, Validation Loss AVG: 12.5018, lr: 0.001
Epoch [4/100], Training Loss: 10.7606, Validation Loss Current: 12.2682, Validation Loss AVG: 12.2682, lr: 0.001
Epoch [5/100], Training Loss: 11.1412, Validation Loss Current: 11.3487, Validation Loss AVG: 11.3487, lr: 0.001
Epoch [6/100], Training Loss: 12.9824, Validation Loss Current: 12.6945, Validation Loss AVG: 12.6945, lr: 0.001
Epoch [7/100], Training Loss: 8.7652, Validation Loss Current: 10.5241, Validation Loss AVG: 10.5241, lr: 0.001
Epoch [8/100], Training Loss: 8.2793, Validation Loss Current: 10.5984, Validation Loss AVG: 10.5984, lr: 0.001
Epoch [9/100], Training Loss: 10.1388, Validation Loss Current: 13.5747, Validation Loss AVG: 13.5747, lr: 0.001
Epoch [10/100], Training Loss: 6.2197, Validation Loss Current: 11.3907, Validation Loss AVG: 11.3907, lr: 0.001
Epoch [11/100], Training Loss: 6.4277, Validation Loss Current: 11.8758, Validation Loss AVG: 11.8758, lr: 0.001
Epoch [12/100], Training Loss: 5.5930, Validation Loss Current: 10.0072, Validation Loss AVG: 10.0072, lr: 0.001
Epoch [13/100], Training Loss: 7.4050, Validation Loss Current: 13.0665, Validation Loss AVG: 13.0665, lr: 0.001
Epoch [14/100], Training Loss: 7.1643, Validation Loss Current: 11.9228, Validation Loss AVG: 11.9228, lr: 0.001
Epoch [15/100], Training Loss: 4.0008, Validation Loss Current: 9.8121, Validation Loss AVG: 9.8121, lr: 0.001
Epoch [16/100], Training Loss: 3.4236, Validation Loss Current: 12.7445, Validation Loss AVG: 12.7445, lr: 0.001
Epoch [17/100], Training Loss: 5.6136, Validation Loss Current: 15.9655, Validation Loss AVG: 15.9655, lr: 0.001
Epoch [18/100], Training Loss: 6.8958, Validation Loss Current: 13.0328, Validation Loss AVG: 13.0328, lr: 0.001
Epoch [19/100], Training Loss: 6.5450, Validation Loss Current: 10.9069, Validation Loss AVG: 10.9069, lr: 0.001
Epoch [20/100], Training Loss: 4.3408, Validation Loss Current: 13.2692, Validation Loss AVG: 13.2692, lr: 0.001
Epoch [21/100], Training Loss: 5.4818, Validation Loss Current: 11.2974, Validation Loss AVG: 11.2974, lr: 0.001
Epoch [22/100], Training Loss: 4.1633, Validation Loss Current: 11.7840, Validation Loss AVG: 11.7840, lr: 0.001
Epoch [23/100], Training Loss: 4.7571, Validation Loss Current: 11.1082, Validation Loss AVG: 11.1082, lr: 0.001
Epoch [24/100], Training Loss: 6.1158, Validation Loss Current: 12.3839, Validation Loss AVG: 12.3839, lr: 0.001
Epoch [25/100], Training Loss: 6.0300, Validation Loss Current: 13.0761, Validation Loss AVG: 13.0761, lr: 0.001
Epoch [26/100], Training Loss: 5.6741, Validation Loss Current: 11.8247, Validation Loss AVG: 11.8247, lr: 0.001
Epoch [27/100], Training Loss: 3.8382, Validation Loss Current: 12.9261, Validation Loss AVG: 12.9261, lr: 0.001
Epoch [28/100], Training Loss: 3.4394, Validation Loss Current: 12.6720, Validation Loss AVG: 12.6720, lr: 0.001
Epoch [29/100], Training Loss: 4.1928, Validation Loss Current: 12.1666, Validation Loss AVG: 12.1666, lr: 0.001
Epoch [30/100], Training Loss: 6.8600, Validation Loss Current: 15.2141, Validation Loss AVG: 15.2141, lr: 0.001
Epoch [31/100], Training Loss: 5.8974, Validation Loss Current: 10.4974, Validation Loss AVG: 10.4974, lr: 0.001
Epoch [32/100], Training Loss: 5.4324, Validation Loss Current: 16.9605, Validation Loss AVG: 16.9605, lr: 0.001
Epoch [33/100], Training Loss: 6.2385, Validation Loss Current: 11.1795, Validation Loss AVG: 11.1795, lr: 0.001
Epoch [34/100], Training Loss: 4.9375, Validation Loss Current: 13.7953, Validation Loss AVG: 13.7953, lr: 0.001
Epoch [35/100], Training Loss: 2.5957, Validation Loss Current: 12.3924, Validation Loss AVG: 12.3924, lr: 0.001
Epoch [36/100], Training Loss: 2.3909, Validation Loss Current: 13.7922, Validation Loss AVG: 13.7922, lr: 0.001
Epoch [37/100], Training Loss: 3.4535, Validation Loss Current: 14.4114, Validation Loss AVG: 14.4114, lr: 0.001
Epoch [38/100], Training Loss: 3.7431, Validation Loss Current: 12.0858, Validation Loss AVG: 12.0858, lr: 0.001
Epoch [39/100], Training Loss: 4.0494, Validation Loss Current: 15.8545, Validation Loss AVG: 15.8545, lr: 0.001
Epoch [40/100], Training Loss: 5.7296, Validation Loss Current: 14.8899, Validation Loss AVG: 14.8899, lr: 0.001
Epoch [41/100], Training Loss: 3.7771, Validation Loss Current: 12.5201, Validation Loss AVG: 12.5201, lr: 0.001
Epoch [42/100], Training Loss: 4.3234, Validation Loss Current: 13.2922, Validation Loss AVG: 13.2922, lr: 0.001
Epoch [43/100], Training Loss: 6.9833, Validation Loss Current: 15.1241, Validation Loss AVG: 15.1241, lr: 0.001
Epoch [44/100], Training Loss: 3.4328, Validation Loss Current: 11.8670, Validation Loss AVG: 11.8670, lr: 0.001
Epoch [45/100], Training Loss: 3.0030, Validation Loss Current: 13.7330, Validation Loss AVG: 13.7330, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 15 Best val accuracy: [0.40592105263157896, 0.3417763157894737, 0.40690789473684214, 0.4302631578947368, 0.39868421052631575, 0.3976973684210526, 0.44572368421052627, 0.44375, 0.3648026315789474, 0.4269736842105264, 0.4427631578947369, 0.42467105263157895, 0.40032894736842106, 0.44144736842105264, 0.4776315789473684, 0.42467105263157895, 0.39868421052631575, 0.4131578947368421, 0.44342105263157894, 0.4217105263157895, 0.4338815789473684, 0.42993421052631575, 0.38782894736842105, 0.4565789473684211, 0.4223684210526316, 0.4424342105263158, 0.4309210526315789, 0.4365131578947368, 0.4648026315789474, 0.39309210526315785, 0.46282894736842106, 0.3851973684210526, 0.40756578947368427, 0.4365131578947369, 0.46907894736842104, 0.43289473684210533, 0.4240131578947368, 0.43947368421052635, 0.4223684210526316, 0.3842105263157895, 0.4555921052631578, 0.4240131578947368, 0.40592105263157896, 0.4671052631578947, 0.4151315789473684] Best val loss: 9.812137579917907


Current group: 0.6
Epoch [1/100], Training Loss: 27.2829, Validation Loss Current: 13.4233, Validation Loss AVG: 13.4233, lr: 0.001
Epoch [2/100], Training Loss: 17.7136, Validation Loss Current: 10.2472, Validation Loss AVG: 10.2472, lr: 0.001
Epoch [3/100], Training Loss: 11.4230, Validation Loss Current: 10.1887, Validation Loss AVG: 10.1887, lr: 0.001
Epoch [4/100], Training Loss: 7.7437, Validation Loss Current: 10.4018, Validation Loss AVG: 10.4018, lr: 0.001
Epoch [5/100], Training Loss: 6.7340, Validation Loss Current: 9.2444, Validation Loss AVG: 9.2444, lr: 0.001
Epoch [6/100], Training Loss: 7.2709, Validation Loss Current: 13.6504, Validation Loss AVG: 13.6504, lr: 0.001
Epoch [7/100], Training Loss: 5.8419, Validation Loss Current: 10.7262, Validation Loss AVG: 10.7262, lr: 0.001
Epoch [8/100], Training Loss: 8.2809, Validation Loss Current: 11.6971, Validation Loss AVG: 11.6971, lr: 0.001
Epoch [9/100], Training Loss: 5.6969, Validation Loss Current: 11.9421, Validation Loss AVG: 11.9421, lr: 0.001
Epoch [10/100], Training Loss: 4.3735, Validation Loss Current: 10.1081, Validation Loss AVG: 10.1081, lr: 0.001
Epoch [11/100], Training Loss: 3.8464, Validation Loss Current: 11.8577, Validation Loss AVG: 11.8577, lr: 0.001
Epoch [12/100], Training Loss: 6.1772, Validation Loss Current: 12.2959, Validation Loss AVG: 12.2959, lr: 0.001
Epoch [13/100], Training Loss: 5.4733, Validation Loss Current: 11.2351, Validation Loss AVG: 11.2351, lr: 0.001
Epoch [14/100], Training Loss: 4.4304, Validation Loss Current: 10.9129, Validation Loss AVG: 10.9129, lr: 0.001
Epoch [15/100], Training Loss: 5.6464, Validation Loss Current: 10.9512, Validation Loss AVG: 10.9512, lr: 0.001
Epoch [16/100], Training Loss: 8.7173, Validation Loss Current: 11.1930, Validation Loss AVG: 11.1930, lr: 0.001
Epoch [17/100], Training Loss: 5.9977, Validation Loss Current: 11.4220, Validation Loss AVG: 11.4220, lr: 0.001
Epoch [18/100], Training Loss: 4.8717, Validation Loss Current: 10.7510, Validation Loss AVG: 10.7510, lr: 0.001
Epoch [19/100], Training Loss: 2.9162, Validation Loss Current: 12.4667, Validation Loss AVG: 12.4667, lr: 0.001
Epoch [20/100], Training Loss: 3.3308, Validation Loss Current: 11.6452, Validation Loss AVG: 11.6452, lr: 0.001
Epoch [21/100], Training Loss: 5.4408, Validation Loss Current: 10.9436, Validation Loss AVG: 10.9436, lr: 0.001
Epoch [22/100], Training Loss: 3.6273, Validation Loss Current: 11.9281, Validation Loss AVG: 11.9281, lr: 0.001
Epoch [23/100], Training Loss: 3.0680, Validation Loss Current: 12.2529, Validation Loss AVG: 12.2529, lr: 0.001
Epoch [24/100], Training Loss: 1.8643, Validation Loss Current: 10.0495, Validation Loss AVG: 10.0495, lr: 0.001
Epoch [25/100], Training Loss: 2.4448, Validation Loss Current: 14.6929, Validation Loss AVG: 14.6929, lr: 0.001
Epoch [26/100], Training Loss: 5.3094, Validation Loss Current: 10.9083, Validation Loss AVG: 10.9083, lr: 0.001
Epoch [27/100], Training Loss: 3.3816, Validation Loss Current: 13.9266, Validation Loss AVG: 13.9266, lr: 0.001
Epoch [28/100], Training Loss: 3.1669, Validation Loss Current: 13.5571, Validation Loss AVG: 13.5571, lr: 0.001
Epoch [29/100], Training Loss: 2.1798, Validation Loss Current: 11.3828, Validation Loss AVG: 11.3828, lr: 0.001
Epoch [30/100], Training Loss: 4.4714, Validation Loss Current: 13.4404, Validation Loss AVG: 13.4404, lr: 0.001
Epoch [31/100], Training Loss: 4.7000, Validation Loss Current: 11.6115, Validation Loss AVG: 11.6115, lr: 0.001
Epoch [32/100], Training Loss: 3.0959, Validation Loss Current: 10.3763, Validation Loss AVG: 10.3763, lr: 0.001
Epoch [33/100], Training Loss: 2.0699, Validation Loss Current: 11.6302, Validation Loss AVG: 11.6302, lr: 0.001
Epoch [34/100], Training Loss: 1.5643, Validation Loss Current: 11.9367, Validation Loss AVG: 11.9367, lr: 0.001
Epoch [35/100], Training Loss: 2.5419, Validation Loss Current: 11.9129, Validation Loss AVG: 11.9129, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 5 Best val accuracy: [0.43355263157894736, 0.46085526315789477, 0.45328947368421063, 0.4901315789473684, 0.4865131578947368, 0.4391447368421053, 0.475, 0.45921052631578946, 0.45756578947368415, 0.4809210526315789, 0.4578947368421053, 0.4526315789473685, 0.4677631578947368, 0.49407894736842106, 0.49078947368421055, 0.4631578947368421, 0.49046052631578946, 0.4651315789473684, 0.43782894736842104, 0.4825657894736842, 0.49144736842105263, 0.48519736842105265, 0.44703947368421054, 0.5105263157894737, 0.4634868421052632, 0.4901315789473684, 0.4723684210526316, 0.39999999999999997, 0.48421052631578954, 0.4391447368421053, 0.4894736842105263, 0.4894736842105264, 0.5075657894736842, 0.49144736842105263, 0.49506578947368424] Best val loss: 9.244386124610902


Current group: 0.4
Epoch [1/100], Training Loss: 36.0091, Validation Loss Current: 14.1525, Validation Loss AVG: 14.1525, lr: 0.001
Epoch [2/100], Training Loss: 19.7477, Validation Loss Current: 13.2495, Validation Loss AVG: 13.2495, lr: 0.001
Epoch [3/100], Training Loss: 14.0047, Validation Loss Current: 10.3453, Validation Loss AVG: 10.3453, lr: 0.001
Epoch [4/100], Training Loss: 13.9129, Validation Loss Current: 12.5664, Validation Loss AVG: 12.5664, lr: 0.001
Epoch [5/100], Training Loss: 12.3740, Validation Loss Current: 10.7057, Validation Loss AVG: 10.7057, lr: 0.001
Epoch [6/100], Training Loss: 9.7333, Validation Loss Current: 10.9171, Validation Loss AVG: 10.9171, lr: 0.001
Epoch [7/100], Training Loss: 8.9463, Validation Loss Current: 10.2961, Validation Loss AVG: 10.2961, lr: 0.001
Epoch [8/100], Training Loss: 9.4470, Validation Loss Current: 10.8798, Validation Loss AVG: 10.8798, lr: 0.001
Epoch [9/100], Training Loss: 7.2369, Validation Loss Current: 10.4270, Validation Loss AVG: 10.4270, lr: 0.001
Epoch [10/100], Training Loss: 5.1762, Validation Loss Current: 10.4213, Validation Loss AVG: 10.4213, lr: 0.001
Epoch [11/100], Training Loss: 3.4261, Validation Loss Current: 10.5216, Validation Loss AVG: 10.5216, lr: 0.001
Epoch [12/100], Training Loss: 3.5667, Validation Loss Current: 11.9742, Validation Loss AVG: 11.9742, lr: 0.001
Epoch [13/100], Training Loss: 6.0289, Validation Loss Current: 12.1564, Validation Loss AVG: 12.1564, lr: 0.001
Epoch [14/100], Training Loss: 5.2154, Validation Loss Current: 13.2969, Validation Loss AVG: 13.2969, lr: 0.001
Epoch [15/100], Training Loss: 6.9695, Validation Loss Current: 15.1670, Validation Loss AVG: 15.1670, lr: 0.001
Epoch [16/100], Training Loss: 4.9927, Validation Loss Current: 16.6455, Validation Loss AVG: 16.6455, lr: 0.001
Epoch [17/100], Training Loss: 4.0738, Validation Loss Current: 11.5030, Validation Loss AVG: 11.5030, lr: 0.001
Epoch [18/100], Training Loss: 5.1249, Validation Loss Current: 10.8054, Validation Loss AVG: 10.8054, lr: 0.001
Epoch [19/100], Training Loss: 5.5301, Validation Loss Current: 14.0974, Validation Loss AVG: 14.0974, lr: 0.001
Epoch [20/100], Training Loss: 2.8195, Validation Loss Current: 15.5855, Validation Loss AVG: 15.5855, lr: 0.001
Epoch [21/100], Training Loss: 1.6099, Validation Loss Current: 11.9699, Validation Loss AVG: 11.9699, lr: 0.001
Epoch [22/100], Training Loss: 2.2304, Validation Loss Current: 11.1426, Validation Loss AVG: 11.1426, lr: 0.001
Epoch [23/100], Training Loss: 3.1400, Validation Loss Current: 11.3488, Validation Loss AVG: 11.3488, lr: 0.001
Epoch [24/100], Training Loss: 1.4934, Validation Loss Current: 11.8510, Validation Loss AVG: 11.8510, lr: 0.001
Epoch [25/100], Training Loss: 1.2979, Validation Loss Current: 11.9601, Validation Loss AVG: 11.9601, lr: 0.001
Epoch [26/100], Training Loss: 3.1119, Validation Loss Current: 41.1840, Validation Loss AVG: 41.1840, lr: 0.001
Epoch [27/100], Training Loss: 9.6279, Validation Loss Current: 28.3808, Validation Loss AVG: 28.3808, lr: 0.001
Epoch [28/100], Training Loss: 4.7316, Validation Loss Current: 14.7249, Validation Loss AVG: 14.7249, lr: 0.001
Epoch [29/100], Training Loss: 4.1644, Validation Loss Current: 16.8315, Validation Loss AVG: 16.8315, lr: 0.001
Epoch [30/100], Training Loss: 3.0972, Validation Loss Current: 11.9938, Validation Loss AVG: 11.9938, lr: 0.001
Epoch [31/100], Training Loss: 1.2189, Validation Loss Current: 11.4691, Validation Loss AVG: 11.4691, lr: 0.001
Epoch [32/100], Training Loss: 1.3795, Validation Loss Current: 14.4185, Validation Loss AVG: 14.4185, lr: 0.001
Epoch [33/100], Training Loss: 3.6688, Validation Loss Current: 13.8463, Validation Loss AVG: 13.8463, lr: 0.001
Epoch [34/100], Training Loss: 3.6463, Validation Loss Current: 15.5927, Validation Loss AVG: 15.5927, lr: 0.001
Epoch [35/100], Training Loss: 2.4275, Validation Loss Current: 12.0488, Validation Loss AVG: 12.0488, lr: 0.001
Epoch [36/100], Training Loss: 7.9255, Validation Loss Current: 13.7744, Validation Loss AVG: 13.7744, lr: 0.001
Epoch [37/100], Training Loss: 3.1594, Validation Loss Current: 13.1863, Validation Loss AVG: 13.1863, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 7 Best val accuracy: [0.3904605263157895, 0.42927631578947373, 0.5154605263157894, 0.4509868421052632, 0.49407894736842106, 0.4776315789473684, 0.4967105263157895, 0.511842105263158, 0.5161184210526316, 0.4983552631578947, 0.4990131578947369, 0.4944078947368421, 0.48026315789473684, 0.4200657894736842, 0.4457236842105264, 0.45625, 0.5134868421052632, 0.5121710526315789, 0.4407894736842105, 0.47269736842105264, 0.49144736842105263, 0.5134868421052632, 0.5072368421052631, 0.49078947368421055, 0.47828947368421054, 0.2799342105263158, 0.25888157894736846, 0.41480263157894737, 0.44013157894736843, 0.4746710526315788, 0.5006578947368421, 0.4526315789473685, 0.4546052631578947, 0.4338815789473684, 0.4947368421052632, 0.4509868421052632, 0.4585526315789473] Best val loss: 10.296072363853455


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4, 0.2] -----
Current group: 1
Epoch [1/80], Training Loss: 41.1447, Validation Loss Current: 10.0388, Validation Loss AVG: 10.1181, lr: 0.001
Epoch [2/80], Training Loss: 39.0063, Validation Loss Current: 9.5725, Validation Loss AVG: 9.8847, lr: 0.001
Epoch [3/80], Training Loss: 36.4555, Validation Loss Current: 9.2140, Validation Loss AVG: 9.7462, lr: 0.001
Epoch [4/80], Training Loss: 35.4584, Validation Loss Current: 8.9921, Validation Loss AVG: 9.6460, lr: 0.001
Epoch [5/80], Training Loss: 33.8028, Validation Loss Current: 8.5572, Validation Loss AVG: 9.4320, lr: 0.001
Epoch [6/80], Training Loss: 31.3036, Validation Loss Current: 8.6790, Validation Loss AVG: 10.0703, lr: 0.001
Epoch [7/80], Training Loss: 30.8887, Validation Loss Current: 8.0610, Validation Loss AVG: 9.0113, lr: 0.001
Epoch [8/80], Training Loss: 29.9990, Validation Loss Current: 7.9183, Validation Loss AVG: 9.1631, lr: 0.001
Epoch [9/80], Training Loss: 28.0365, Validation Loss Current: 7.6589, Validation Loss AVG: 8.8400, lr: 0.001
Epoch [10/80], Training Loss: 27.4496, Validation Loss Current: 7.6640, Validation Loss AVG: 9.0508, lr: 0.001
Epoch [11/80], Training Loss: 27.1120, Validation Loss Current: 7.4384, Validation Loss AVG: 8.9779, lr: 0.001
Epoch [12/80], Training Loss: 25.7006, Validation Loss Current: 7.3178, Validation Loss AVG: 10.1168, lr: 0.001
Epoch [13/80], Training Loss: 25.3294, Validation Loss Current: 7.3951, Validation Loss AVG: 10.6161, lr: 0.001
Epoch [14/80], Training Loss: 25.1183, Validation Loss Current: 8.2571, Validation Loss AVG: 11.5070, lr: 0.001
Epoch [15/80], Training Loss: 26.2298, Validation Loss Current: 7.4900, Validation Loss AVG: 9.7099, lr: 0.001
Epoch [16/80], Training Loss: 23.6067, Validation Loss Current: 6.8147, Validation Loss AVG: 9.2019, lr: 0.001
Epoch [17/80], Training Loss: 23.6179, Validation Loss Current: 6.8181, Validation Loss AVG: 9.7401, lr: 0.001
Epoch [18/80], Training Loss: 21.9195, Validation Loss Current: 6.8358, Validation Loss AVG: 9.5654, lr: 0.001
Epoch [19/80], Training Loss: 22.1262, Validation Loss Current: 6.8746, Validation Loss AVG: 8.6561, lr: 0.001
Epoch [20/80], Training Loss: 22.4176, Validation Loss Current: 8.8992, Validation Loss AVG: 13.2033, lr: 0.001
Epoch [21/80], Training Loss: 23.1786, Validation Loss Current: 6.8856, Validation Loss AVG: 9.1651, lr: 0.001
Epoch [22/80], Training Loss: 21.0071, Validation Loss Current: 7.0593, Validation Loss AVG: 9.0702, lr: 0.001
Epoch [23/80], Training Loss: 20.0226, Validation Loss Current: 6.7268, Validation Loss AVG: 9.3289, lr: 0.001
Epoch [24/80], Training Loss: 19.0670, Validation Loss Current: 6.0885, Validation Loss AVG: 9.2811, lr: 0.001
Epoch [25/80], Training Loss: 18.3525, Validation Loss Current: 6.7731, Validation Loss AVG: 9.9691, lr: 0.001
Epoch [26/80], Training Loss: 17.7229, Validation Loss Current: 6.3543, Validation Loss AVG: 9.3534, lr: 0.001
Epoch [27/80], Training Loss: 18.7338, Validation Loss Current: 6.6509, Validation Loss AVG: 10.2311, lr: 0.001
Epoch [28/80], Training Loss: 17.2625, Validation Loss Current: 6.0272, Validation Loss AVG: 8.6487, lr: 0.001
Epoch [29/80], Training Loss: 16.0618, Validation Loss Current: 6.8389, Validation Loss AVG: 11.2661, lr: 0.001
Epoch [30/80], Training Loss: 16.3571, Validation Loss Current: 7.7249, Validation Loss AVG: 12.7969, lr: 0.001
Epoch [31/80], Training Loss: 14.9009, Validation Loss Current: 6.8524, Validation Loss AVG: 10.0591, lr: 0.001
Epoch [32/80], Training Loss: 15.6442, Validation Loss Current: 8.0434, Validation Loss AVG: 16.7276, lr: 0.001
Epoch [33/80], Training Loss: 14.0105, Validation Loss Current: 6.1779, Validation Loss AVG: 10.0509, lr: 0.001
Epoch [34/80], Training Loss: 13.7553, Validation Loss Current: 6.5305, Validation Loss AVG: 11.9504, lr: 0.001
Epoch [35/80], Training Loss: 13.4701, Validation Loss Current: 6.3958, Validation Loss AVG: 9.9070, lr: 0.001
Epoch [36/80], Training Loss: 14.6699, Validation Loss Current: 7.5698, Validation Loss AVG: 10.2676, lr: 0.001
Epoch [37/80], Training Loss: 10.9887, Validation Loss Current: 6.9467, Validation Loss AVG: 12.8972, lr: 0.001
Epoch [38/80], Training Loss: 10.2338, Validation Loss Current: 5.7668, Validation Loss AVG: 11.3936, lr: 0.001
Epoch [39/80], Training Loss: 10.1590, Validation Loss Current: 5.8686, Validation Loss AVG: 9.0141, lr: 0.001
Epoch [40/80], Training Loss: 9.1598, Validation Loss Current: 5.8307, Validation Loss AVG: 10.0440, lr: 0.001
Epoch [41/80], Training Loss: 8.8599, Validation Loss Current: 6.8293, Validation Loss AVG: 12.1600, lr: 0.001
Epoch [42/80], Training Loss: 10.7216, Validation Loss Current: 7.0199, Validation Loss AVG: 12.9863, lr: 0.001
Epoch [43/80], Training Loss: 9.3600, Validation Loss Current: 6.8749, Validation Loss AVG: 10.9180, lr: 0.001
Epoch [44/80], Training Loss: 8.7695, Validation Loss Current: 7.9021, Validation Loss AVG: 14.0531, lr: 0.001
Epoch [45/80], Training Loss: 7.8563, Validation Loss Current: 6.7946, Validation Loss AVG: 12.8332, lr: 0.001
Epoch [46/80], Training Loss: 7.1372, Validation Loss Current: 7.6106, Validation Loss AVG: 13.0089, lr: 0.001
Epoch [47/80], Training Loss: 9.5743, Validation Loss Current: 7.1373, Validation Loss AVG: 11.7942, lr: 0.001
Epoch [48/80], Training Loss: 9.8207, Validation Loss Current: 11.5015, Validation Loss AVG: 27.5084, lr: 0.001
Epoch [49/80], Training Loss: 6.9783, Validation Loss Current: 6.2043, Validation Loss AVG: 11.1591, lr: 0.001
Epoch [50/80], Training Loss: 4.7157, Validation Loss Current: 6.2783, Validation Loss AVG: 13.6999, lr: 0.001
Epoch [51/80], Training Loss: 3.9555, Validation Loss Current: 6.1900, Validation Loss AVG: 11.9504, lr: 0.001
Epoch [52/80], Training Loss: 3.6308, Validation Loss Current: 6.2231, Validation Loss AVG: 10.4255, lr: 0.001
Epoch [53/80], Training Loss: 5.1292, Validation Loss Current: 7.0839, Validation Loss AVG: 14.2165, lr: 0.001
Epoch [54/80], Training Loss: 6.3652, Validation Loss Current: 9.1347, Validation Loss AVG: 20.2903, lr: 0.001
Epoch [55/80], Training Loss: 5.7667, Validation Loss Current: 6.3695, Validation Loss AVG: 10.3295, lr: 0.001
Epoch [56/80], Training Loss: 4.5245, Validation Loss Current: 7.2794, Validation Loss AVG: 9.7827, lr: 0.001
Epoch [57/80], Training Loss: 4.0125, Validation Loss Current: 7.1021, Validation Loss AVG: 11.6078, lr: 0.001
Epoch [58/80], Training Loss: 3.1477, Validation Loss Current: 6.9102, Validation Loss AVG: 14.9232, lr: 0.001
Epoch [59/80], Training Loss: 3.2090, Validation Loss Current: 8.7157, Validation Loss AVG: 16.4943, lr: 0.001
Epoch [60/80], Training Loss: 6.0986, Validation Loss Current: 7.0589, Validation Loss AVG: 14.2405, lr: 0.001
Epoch [61/80], Training Loss: 5.2861, Validation Loss Current: 7.1749, Validation Loss AVG: 13.7223, lr: 0.001
Epoch [62/80], Training Loss: 6.2243, Validation Loss Current: 7.4358, Validation Loss AVG: 11.5004, lr: 0.001
Epoch [63/80], Training Loss: 4.6115, Validation Loss Current: 8.3560, Validation Loss AVG: 16.9672, lr: 0.001
Epoch [64/80], Training Loss: 4.0717, Validation Loss Current: 8.0091, Validation Loss AVG: 11.1719, lr: 0.001
Epoch [65/80], Training Loss: 5.9535, Validation Loss Current: 7.5501, Validation Loss AVG: 13.6435, lr: 0.001
Epoch [66/80], Training Loss: 3.8666, Validation Loss Current: 7.9672, Validation Loss AVG: 12.7647, lr: 0.001
Epoch [67/80], Training Loss: 3.4237, Validation Loss Current: 6.9644, Validation Loss AVG: 10.9947, lr: 0.001
Epoch [68/80], Training Loss: 8.6704, Validation Loss Current: 8.3481, Validation Loss AVG: 13.3986, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 38 Best val accuracy: [0.25493421052631576, 0.29769736842105265, 0.3404605263157895, 0.3684210526315789, 0.39144736842105265, 0.3667763157894737, 0.4555921052631579, 0.4457236842105263, 0.4621710526315789, 0.4605263157894737, 0.5098684210526315, 0.48848684210526316, 0.48848684210526316, 0.46710526315789475, 0.49506578947368424, 0.5411184210526315, 0.5361842105263158, 0.53125, 0.5180921052631579, 0.44243421052631576, 0.5509868421052632, 0.5, 0.5361842105263158, 0.569078947368421, 0.5444078947368421, 0.5641447368421053, 0.5592105263157895, 0.59375, 0.5394736842105263, 0.5328947368421053, 0.5509868421052632, 0.5131578947368421, 0.6019736842105263, 0.5608552631578947, 0.59375, 0.5082236842105263, 0.5657894736842105, 0.6118421052631579, 0.6085526315789473, 0.6134868421052632, 0.5904605263157895, 0.5641447368421053, 0.5855263157894737, 0.5394736842105263, 0.59375, 0.5213815789473685, 0.5411184210526315, 0.5082236842105263, 0.5855263157894737, 0.6282894736842105, 0.625, 0.6414473684210527, 0.5674342105263158, 0.5230263157894737, 0.6036184210526315, 0.5986842105263158, 0.618421052631579, 0.6036184210526315, 0.524671052631579, 0.5904605263157895, 0.5953947368421053, 0.5707236842105263, 0.5707236842105263, 0.5888157894736842, 0.5921052631578947, 0.5953947368421053, 0.6052631578947368, 0.5493421052631579] Best val loss: 5.766840696334839


Current group: 0.8
Epoch [1/80], Training Loss: 23.5227, Validation Loss Current: 17.6198, Validation Loss AVG: 17.6198, lr: 0.001
Epoch [2/80], Training Loss: 15.5057, Validation Loss Current: 9.6539, Validation Loss AVG: 9.6539, lr: 0.001
Epoch [3/80], Training Loss: 12.3803, Validation Loss Current: 10.1748, Validation Loss AVG: 10.1748, lr: 0.001
Epoch [4/80], Training Loss: 11.6157, Validation Loss Current: 14.0467, Validation Loss AVG: 14.0467, lr: 0.001
Epoch [5/80], Training Loss: 10.6165, Validation Loss Current: 8.9989, Validation Loss AVG: 8.9989, lr: 0.001
Epoch [6/80], Training Loss: 7.3944, Validation Loss Current: 9.8923, Validation Loss AVG: 9.8923, lr: 0.001
Epoch [7/80], Training Loss: 6.8214, Validation Loss Current: 9.5976, Validation Loss AVG: 9.5976, lr: 0.001
Epoch [8/80], Training Loss: 6.9795, Validation Loss Current: 9.3625, Validation Loss AVG: 9.3625, lr: 0.001
Epoch [9/80], Training Loss: 8.8230, Validation Loss Current: 10.9596, Validation Loss AVG: 10.9596, lr: 0.001
Epoch [10/80], Training Loss: 5.7482, Validation Loss Current: 12.1093, Validation Loss AVG: 12.1093, lr: 0.001
Epoch [11/80], Training Loss: 5.6407, Validation Loss Current: 10.2823, Validation Loss AVG: 10.2823, lr: 0.001
Epoch [12/80], Training Loss: 4.7342, Validation Loss Current: 10.8461, Validation Loss AVG: 10.8461, lr: 0.001
Epoch [13/80], Training Loss: 4.7352, Validation Loss Current: 13.2659, Validation Loss AVG: 13.2659, lr: 0.001
Epoch [14/80], Training Loss: 5.9627, Validation Loss Current: 11.8678, Validation Loss AVG: 11.8678, lr: 0.001
Epoch [15/80], Training Loss: 10.3822, Validation Loss Current: 15.9668, Validation Loss AVG: 15.9668, lr: 0.001
Epoch [16/80], Training Loss: 7.3889, Validation Loss Current: 14.7454, Validation Loss AVG: 14.7454, lr: 0.001
Epoch [17/80], Training Loss: 6.1354, Validation Loss Current: 11.6567, Validation Loss AVG: 11.6567, lr: 0.001
Epoch [18/80], Training Loss: 6.5657, Validation Loss Current: 12.3563, Validation Loss AVG: 12.3563, lr: 0.001
Epoch [19/80], Training Loss: 4.7497, Validation Loss Current: 15.3455, Validation Loss AVG: 15.3455, lr: 0.001
Epoch [20/80], Training Loss: 4.5623, Validation Loss Current: 14.2417, Validation Loss AVG: 14.2417, lr: 0.001
Epoch [21/80], Training Loss: 9.9798, Validation Loss Current: 14.5730, Validation Loss AVG: 14.5730, lr: 0.001
Epoch [22/80], Training Loss: 6.2703, Validation Loss Current: 13.4430, Validation Loss AVG: 13.4430, lr: 0.001
Epoch [23/80], Training Loss: 9.3714, Validation Loss Current: 15.8932, Validation Loss AVG: 15.8932, lr: 0.001
Epoch [24/80], Training Loss: 12.9530, Validation Loss Current: 15.4705, Validation Loss AVG: 15.4705, lr: 0.001
Epoch [25/80], Training Loss: 7.5013, Validation Loss Current: 12.0294, Validation Loss AVG: 12.0294, lr: 0.001
Epoch [26/80], Training Loss: 4.9952, Validation Loss Current: 10.8919, Validation Loss AVG: 10.8919, lr: 0.001
Epoch [27/80], Training Loss: 3.9048, Validation Loss Current: 13.2853, Validation Loss AVG: 13.2853, lr: 0.001
Epoch [28/80], Training Loss: 6.3826, Validation Loss Current: 11.9755, Validation Loss AVG: 11.9755, lr: 0.001
Epoch [29/80], Training Loss: 5.8207, Validation Loss Current: 12.9924, Validation Loss AVG: 12.9924, lr: 0.001
Epoch [30/80], Training Loss: 7.7588, Validation Loss Current: 11.4744, Validation Loss AVG: 11.4744, lr: 0.001
Epoch [31/80], Training Loss: 3.4930, Validation Loss Current: 10.9484, Validation Loss AVG: 10.9484, lr: 0.001
Epoch [32/80], Training Loss: 2.8371, Validation Loss Current: 12.3714, Validation Loss AVG: 12.3714, lr: 0.001
Epoch [33/80], Training Loss: 3.9660, Validation Loss Current: 12.2463, Validation Loss AVG: 12.2463, lr: 0.001
Epoch [34/80], Training Loss: 3.3543, Validation Loss Current: 10.1936, Validation Loss AVG: 10.1936, lr: 0.001
Epoch [35/80], Training Loss: 2.4283, Validation Loss Current: 11.7801, Validation Loss AVG: 11.7801, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 5 Best val accuracy: [0.41414473684210523, 0.41907894736842105, 0.44210526315789467, 0.3575657894736842, 0.4496710526315789, 0.42894736842105263, 0.4516447368421053, 0.47171052631578947, 0.4197368421052632, 0.4180921052631579, 0.41447368421052627, 0.4493421052631579, 0.4042763157894737, 0.4375, 0.40657894736842104, 0.40230263157894736, 0.4305921052631579, 0.42269736842105265, 0.39473684210526316, 0.44703947368421054, 0.42434210526315785, 0.3608552631578948, 0.3582236842105263, 0.3615131578947368, 0.41414473684210523, 0.44506578947368414, 0.38815789473684215, 0.38914473684210527, 0.4200657894736842, 0.4134868421052632, 0.44868421052631574, 0.4286184210526316, 0.4207236842105263, 0.4424342105263158, 0.43519736842105267] Best val loss: 8.998946166038513


Current group: 0.6
Epoch [1/80], Training Loss: 27.8022, Validation Loss Current: 11.5578, Validation Loss AVG: 11.5578, lr: 0.001
Epoch [2/80], Training Loss: 15.4090, Validation Loss Current: 10.0175, Validation Loss AVG: 10.0175, lr: 0.001
Epoch [3/80], Training Loss: 10.3998, Validation Loss Current: 9.9735, Validation Loss AVG: 9.9735, lr: 0.001
Epoch [4/80], Training Loss: 8.8171, Validation Loss Current: 9.1234, Validation Loss AVG: 9.1234, lr: 0.001
Epoch [5/80], Training Loss: 8.7535, Validation Loss Current: 13.1993, Validation Loss AVG: 13.1993, lr: 0.001
Epoch [6/80], Training Loss: 9.6321, Validation Loss Current: 13.8853, Validation Loss AVG: 13.8853, lr: 0.001
Epoch [7/80], Training Loss: 8.7590, Validation Loss Current: 11.5979, Validation Loss AVG: 11.5979, lr: 0.001
Epoch [8/80], Training Loss: 7.9499, Validation Loss Current: 11.2771, Validation Loss AVG: 11.2771, lr: 0.001
Epoch [9/80], Training Loss: 6.8563, Validation Loss Current: 12.1142, Validation Loss AVG: 12.1142, lr: 0.001
Epoch [10/80], Training Loss: 4.7917, Validation Loss Current: 11.0820, Validation Loss AVG: 11.0820, lr: 0.001
Epoch [11/80], Training Loss: 5.3276, Validation Loss Current: 10.6350, Validation Loss AVG: 10.6350, lr: 0.001
Epoch [12/80], Training Loss: 6.0841, Validation Loss Current: 12.3491, Validation Loss AVG: 12.3491, lr: 0.001
Epoch [13/80], Training Loss: 6.9967, Validation Loss Current: 11.5635, Validation Loss AVG: 11.5635, lr: 0.001
Epoch [14/80], Training Loss: 3.8135, Validation Loss Current: 13.7025, Validation Loss AVG: 13.7025, lr: 0.001
Epoch [15/80], Training Loss: 4.8241, Validation Loss Current: 12.8190, Validation Loss AVG: 12.8190, lr: 0.001
Epoch [16/80], Training Loss: 4.5258, Validation Loss Current: 12.0000, Validation Loss AVG: 12.0000, lr: 0.001
Epoch [17/80], Training Loss: 5.8529, Validation Loss Current: 12.2753, Validation Loss AVG: 12.2753, lr: 0.001
Epoch [18/80], Training Loss: 5.7810, Validation Loss Current: 13.7378, Validation Loss AVG: 13.7378, lr: 0.001
Epoch [19/80], Training Loss: 3.8129, Validation Loss Current: 11.8317, Validation Loss AVG: 11.8317, lr: 0.001
Epoch [20/80], Training Loss: 2.2330, Validation Loss Current: 10.7573, Validation Loss AVG: 10.7573, lr: 0.001
Epoch [21/80], Training Loss: 1.6400, Validation Loss Current: 10.1070, Validation Loss AVG: 10.1070, lr: 0.001
Epoch [22/80], Training Loss: 2.7273, Validation Loss Current: 15.7147, Validation Loss AVG: 15.7147, lr: 0.001
Epoch [23/80], Training Loss: 3.7553, Validation Loss Current: 14.3936, Validation Loss AVG: 14.3936, lr: 0.001
Epoch [24/80], Training Loss: 2.3395, Validation Loss Current: 11.7428, Validation Loss AVG: 11.7428, lr: 0.001
Epoch [25/80], Training Loss: 1.8369, Validation Loss Current: 11.2493, Validation Loss AVG: 11.2493, lr: 0.001
Epoch [26/80], Training Loss: 1.6392, Validation Loss Current: 12.1956, Validation Loss AVG: 12.1956, lr: 0.001
Epoch [27/80], Training Loss: 1.3893, Validation Loss Current: 10.7840, Validation Loss AVG: 10.7840, lr: 0.001
Epoch [28/80], Training Loss: 1.2606, Validation Loss Current: 12.0916, Validation Loss AVG: 12.0916, lr: 0.001
Epoch [29/80], Training Loss: 3.3348, Validation Loss Current: 10.4323, Validation Loss AVG: 10.4323, lr: 0.001
Epoch [30/80], Training Loss: 3.7562, Validation Loss Current: 16.1307, Validation Loss AVG: 16.1307, lr: 0.001
Epoch [31/80], Training Loss: 8.7405, Validation Loss Current: 11.3420, Validation Loss AVG: 11.3420, lr: 0.001
Epoch [32/80], Training Loss: 6.0069, Validation Loss Current: 13.3862, Validation Loss AVG: 13.3862, lr: 0.001
Epoch [33/80], Training Loss: 5.8115, Validation Loss Current: 15.1864, Validation Loss AVG: 15.1864, lr: 0.001
Epoch [34/80], Training Loss: 6.3297, Validation Loss Current: 14.2941, Validation Loss AVG: 14.2941, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 4 Best val accuracy: [0.4305921052631579, 0.48256578947368417, 0.4513157894736842, 0.45427631578947364, 0.42927631578947373, 0.3394736842105263, 0.45131578947368417, 0.4588815789473684, 0.44375, 0.4582236842105264, 0.4615131578947368, 0.4569078947368421, 0.44243421052631576, 0.4128289473684211, 0.47828947368421054, 0.45230263157894735, 0.4016447368421052, 0.4421052631578948, 0.47664473684210523, 0.4621710526315789, 0.4845394736842105, 0.43125, 0.4171052631578947, 0.47631578947368425, 0.4786184210526316, 0.4552631578947368, 0.4822368421052632, 0.46019736842105263, 0.5174342105263158, 0.3848684210526315, 0.47434210526315795, 0.4585526315789473, 0.4407894736842105, 0.43355263157894736] Best val loss: 9.123397564888


Current group: 0.4
Epoch [1/80], Training Loss: 35.3902, Validation Loss Current: 15.3825, Validation Loss AVG: 15.3825, lr: 0.001
Epoch [2/80], Training Loss: 21.0079, Validation Loss Current: 14.6894, Validation Loss AVG: 14.6894, lr: 0.001
Epoch [3/80], Training Loss: 17.3283, Validation Loss Current: 12.0178, Validation Loss AVG: 12.0178, lr: 0.001
Epoch [4/80], Training Loss: 17.2817, Validation Loss Current: 14.3009, Validation Loss AVG: 14.3009, lr: 0.001
Epoch [5/80], Training Loss: 12.3178, Validation Loss Current: 14.0331, Validation Loss AVG: 14.0331, lr: 0.001
Epoch [6/80], Training Loss: 10.4914, Validation Loss Current: 10.3579, Validation Loss AVG: 10.3579, lr: 0.001
Epoch [7/80], Training Loss: 7.2713, Validation Loss Current: 11.9505, Validation Loss AVG: 11.9505, lr: 0.001
Epoch [8/80], Training Loss: 4.3482, Validation Loss Current: 10.9000, Validation Loss AVG: 10.9000, lr: 0.001
Epoch [9/80], Training Loss: 4.9805, Validation Loss Current: 10.7767, Validation Loss AVG: 10.7767, lr: 0.001
Epoch [10/80], Training Loss: 4.2860, Validation Loss Current: 11.3780, Validation Loss AVG: 11.3780, lr: 0.001
Epoch [11/80], Training Loss: 3.4763, Validation Loss Current: 11.3658, Validation Loss AVG: 11.3658, lr: 0.001
Epoch [12/80], Training Loss: 5.6309, Validation Loss Current: 13.3684, Validation Loss AVG: 13.3684, lr: 0.001
Epoch [13/80], Training Loss: 3.2313, Validation Loss Current: 14.9172, Validation Loss AVG: 14.9172, lr: 0.001
Epoch [14/80], Training Loss: 4.9466, Validation Loss Current: 13.0030, Validation Loss AVG: 13.0030, lr: 0.001
Epoch [15/80], Training Loss: 7.9199, Validation Loss Current: 16.0601, Validation Loss AVG: 16.0601, lr: 0.001
Epoch [16/80], Training Loss: 4.2988, Validation Loss Current: 13.5059, Validation Loss AVG: 13.5059, lr: 0.001
Epoch [17/80], Training Loss: 3.7129, Validation Loss Current: 12.2155, Validation Loss AVG: 12.2155, lr: 0.001
Epoch [18/80], Training Loss: 3.6014, Validation Loss Current: 11.4126, Validation Loss AVG: 11.4126, lr: 0.001
Epoch [19/80], Training Loss: 2.1630, Validation Loss Current: 11.7084, Validation Loss AVG: 11.7084, lr: 0.001
Epoch [20/80], Training Loss: 2.9537, Validation Loss Current: 12.1598, Validation Loss AVG: 12.1598, lr: 0.001
Epoch [21/80], Training Loss: 4.8524, Validation Loss Current: 12.4919, Validation Loss AVG: 12.4919, lr: 0.001
Epoch [22/80], Training Loss: 5.5476, Validation Loss Current: 13.6835, Validation Loss AVG: 13.6835, lr: 0.001
Epoch [23/80], Training Loss: 4.1677, Validation Loss Current: 13.3171, Validation Loss AVG: 13.3171, lr: 0.001
Epoch [24/80], Training Loss: 3.7796, Validation Loss Current: 13.0289, Validation Loss AVG: 13.0289, lr: 0.001
Epoch [25/80], Training Loss: 4.0209, Validation Loss Current: 13.7699, Validation Loss AVG: 13.7699, lr: 0.001
Epoch [26/80], Training Loss: 3.8510, Validation Loss Current: 12.5905, Validation Loss AVG: 12.5905, lr: 0.001
Epoch [27/80], Training Loss: 1.8297, Validation Loss Current: 11.8843, Validation Loss AVG: 11.8843, lr: 0.001
Epoch [28/80], Training Loss: 1.3158, Validation Loss Current: 12.1021, Validation Loss AVG: 12.1021, lr: 0.001
Epoch [29/80], Training Loss: 1.4451, Validation Loss Current: 13.4969, Validation Loss AVG: 13.4969, lr: 0.001
Epoch [30/80], Training Loss: 1.0219, Validation Loss Current: 11.9453, Validation Loss AVG: 11.9453, lr: 0.001
Epoch [31/80], Training Loss: 3.5270, Validation Loss Current: 11.6140, Validation Loss AVG: 11.6140, lr: 0.001
Epoch [32/80], Training Loss: 3.8234, Validation Loss Current: 15.7337, Validation Loss AVG: 15.7337, lr: 0.001
Epoch [33/80], Training Loss: 5.6106, Validation Loss Current: 16.6591, Validation Loss AVG: 16.6591, lr: 0.001
Epoch [34/80], Training Loss: 3.4738, Validation Loss Current: 14.4288, Validation Loss AVG: 14.4288, lr: 0.001
Epoch [35/80], Training Loss: 6.8621, Validation Loss Current: 14.0202, Validation Loss AVG: 14.0202, lr: 0.001
Epoch [36/80], Training Loss: 3.9682, Validation Loss Current: 14.7789, Validation Loss AVG: 14.7789, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 6 Best val accuracy: [0.4276315789473684, 0.4167763157894736, 0.4598684210526316, 0.3710526315789474, 0.42269736842105265, 0.4569078947368421, 0.4703947368421052, 0.4536184210526316, 0.4631578947368421, 0.4552631578947368, 0.43618421052631584, 0.4473684210526315, 0.4286184210526315, 0.47368421052631576, 0.38125, 0.4134868421052632, 0.4476973684210527, 0.4861842105263158, 0.4598684210526315, 0.47203947368421045, 0.47105263157894744, 0.42828947368421055, 0.4934210526315789, 0.4809210526315789, 0.4167763157894736, 0.4753289473684211, 0.4717105263157896, 0.4822368421052632, 0.46875, 0.4894736842105264, 0.4911184210526316, 0.4365131578947369, 0.40328947368421053, 0.41743421052631574, 0.39572368421052634, 0.45723684210526316] Best val loss: 10.357943844795226


Current group: 0.2
Epoch [1/80], Training Loss: 45.0036, Validation Loss Current: 35.8242, Validation Loss AVG: 35.8242, lr: 0.001
Epoch [2/80], Training Loss: 28.1052, Validation Loss Current: 19.1761, Validation Loss AVG: 19.1761, lr: 0.001
Epoch [3/80], Training Loss: 23.3300, Validation Loss Current: 16.9678, Validation Loss AVG: 16.9678, lr: 0.001
Epoch [4/80], Training Loss: 21.6447, Validation Loss Current: 17.6951, Validation Loss AVG: 17.6951, lr: 0.001
Epoch [5/80], Training Loss: 16.3845, Validation Loss Current: 16.6004, Validation Loss AVG: 16.6004, lr: 0.001
Epoch [6/80], Training Loss: 14.9885, Validation Loss Current: 16.0662, Validation Loss AVG: 16.0662, lr: 0.001
Epoch [7/80], Training Loss: 14.7961, Validation Loss Current: 30.5856, Validation Loss AVG: 30.5856, lr: 0.001
Epoch [8/80], Training Loss: 10.0835, Validation Loss Current: 20.6258, Validation Loss AVG: 20.6258, lr: 0.001
Epoch [9/80], Training Loss: 9.2753, Validation Loss Current: 18.4947, Validation Loss AVG: 18.4947, lr: 0.001
Epoch [10/80], Training Loss: 8.4159, Validation Loss Current: 18.9127, Validation Loss AVG: 18.9127, lr: 0.001
Epoch [11/80], Training Loss: 5.7554, Validation Loss Current: 19.6696, Validation Loss AVG: 19.6696, lr: 0.001
Epoch [12/80], Training Loss: 10.9777, Validation Loss Current: 36.3875, Validation Loss AVG: 36.3875, lr: 0.001
Epoch [13/80], Training Loss: 14.0460, Validation Loss Current: 19.2719, Validation Loss AVG: 19.2719, lr: 0.001
Epoch [14/80], Training Loss: 9.0576, Validation Loss Current: 17.8673, Validation Loss AVG: 17.8673, lr: 0.001
Epoch [15/80], Training Loss: 9.1213, Validation Loss Current: 27.7054, Validation Loss AVG: 27.7054, lr: 0.001
Epoch [16/80], Training Loss: 7.9794, Validation Loss Current: 29.9836, Validation Loss AVG: 29.9836, lr: 0.001
Epoch [17/80], Training Loss: 9.5613, Validation Loss Current: 17.5183, Validation Loss AVG: 17.5183, lr: 0.001
Epoch [18/80], Training Loss: 6.7018, Validation Loss Current: 18.2242, Validation Loss AVG: 18.2242, lr: 0.001
Epoch [19/80], Training Loss: 6.3489, Validation Loss Current: 31.9231, Validation Loss AVG: 31.9231, lr: 0.001
Epoch [20/80], Training Loss: 4.4957, Validation Loss Current: 18.8711, Validation Loss AVG: 18.8711, lr: 0.001
Epoch [21/80], Training Loss: 4.8585, Validation Loss Current: 28.6961, Validation Loss AVG: 28.6961, lr: 0.001
Epoch [22/80], Training Loss: 7.3155, Validation Loss Current: 18.3436, Validation Loss AVG: 18.3436, lr: 0.001
Epoch [23/80], Training Loss: 11.6387, Validation Loss Current: 24.5060, Validation Loss AVG: 24.5060, lr: 0.001
Epoch [24/80], Training Loss: 7.2010, Validation Loss Current: 25.3290, Validation Loss AVG: 25.3290, lr: 0.001
Epoch [25/80], Training Loss: 9.4657, Validation Loss Current: 25.7604, Validation Loss AVG: 25.7604, lr: 0.001
Epoch [26/80], Training Loss: 6.8379, Validation Loss Current: 18.6902, Validation Loss AVG: 18.6902, lr: 0.001
Epoch [27/80], Training Loss: 5.8351, Validation Loss Current: 24.1164, Validation Loss AVG: 24.1164, lr: 0.001
Epoch [28/80], Training Loss: 3.1506, Validation Loss Current: 20.7018, Validation Loss AVG: 20.7018, lr: 0.001
Epoch [29/80], Training Loss: 2.9996, Validation Loss Current: 22.5181, Validation Loss AVG: 22.5181, lr: 0.001
Epoch [30/80], Training Loss: 2.8404, Validation Loss Current: 23.3215, Validation Loss AVG: 23.3215, lr: 0.001
Epoch [31/80], Training Loss: 7.3355, Validation Loss Current: 26.2901, Validation Loss AVG: 26.2901, lr: 0.001
Epoch [32/80], Training Loss: 6.8995, Validation Loss Current: 32.0373, Validation Loss AVG: 32.0373, lr: 0.001
Epoch [33/80], Training Loss: 5.1301, Validation Loss Current: 23.6572, Validation Loss AVG: 23.6572, lr: 0.001
Epoch [34/80], Training Loss: 4.2041, Validation Loss Current: 33.3488, Validation Loss AVG: 33.3488, lr: 0.001
Epoch [35/80], Training Loss: 8.9221, Validation Loss Current: 21.7847, Validation Loss AVG: 21.7847, lr: 0.001
Epoch [36/80], Training Loss: 9.0913, Validation Loss Current: 31.8580, Validation Loss AVG: 31.8580, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 6 Best val accuracy: [0.20756578947368426, 0.349671052631579, 0.3177631578947368, 0.2631578947368421, 0.3536184210526316, 0.35460526315789476, 0.21743421052631584, 0.31414473684210525, 0.31217105263157896, 0.3365131578947368, 0.3427631578947369, 0.19572368421052633, 0.3398026315789474, 0.30625, 0.25822368421052627, 0.22796052631578947, 0.37269736842105267, 0.3430921052631579, 0.26052631578947366, 0.3361842105263158, 0.2713815789473684, 0.3608552631578948, 0.29934210526315785, 0.25394736842105264, 0.3299342105263158, 0.34605263157894744, 0.2733552631578947, 0.3483552631578948, 0.3365131578947368, 0.3111842105263158, 0.2578947368421053, 0.22401315789473686, 0.2796052631578947, 0.23355263157894735, 0.3608552631578947, 0.2276315789473684] Best val loss: 16.06623182296753


Fold: 3
----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.0506, Validation Loss Current: 9.9448, Validation Loss AVG: 10.0669, lr: 0.001
Epoch [2/400], Training Loss: 38.4740, Validation Loss Current: 9.4266, Validation Loss AVG: 9.7536, lr: 0.001
Epoch [3/400], Training Loss: 36.9796, Validation Loss Current: 9.0128, Validation Loss AVG: 9.6157, lr: 0.001
Epoch [4/400], Training Loss: 34.6822, Validation Loss Current: 8.5482, Validation Loss AVG: 9.2835, lr: 0.001
Epoch [5/400], Training Loss: 33.7164, Validation Loss Current: 8.2312, Validation Loss AVG: 9.1127, lr: 0.001
Epoch [6/400], Training Loss: 31.8283, Validation Loss Current: 8.0057, Validation Loss AVG: 9.4375, lr: 0.001
Epoch [7/400], Training Loss: 31.0694, Validation Loss Current: 7.7270, Validation Loss AVG: 9.1417, lr: 0.001
Epoch [8/400], Training Loss: 29.7467, Validation Loss Current: 7.7665, Validation Loss AVG: 9.5460, lr: 0.001
Epoch [9/400], Training Loss: 29.0750, Validation Loss Current: 7.5176, Validation Loss AVG: 8.8726, lr: 0.001
Epoch [10/400], Training Loss: 28.4757, Validation Loss Current: 7.1633, Validation Loss AVG: 8.5601, lr: 0.001
Epoch [11/400], Training Loss: 27.4712, Validation Loss Current: 7.0481, Validation Loss AVG: 9.4745, lr: 0.001
Epoch [12/400], Training Loss: 27.1065, Validation Loss Current: 6.9623, Validation Loss AVG: 9.3250, lr: 0.001
Epoch [13/400], Training Loss: 25.6121, Validation Loss Current: 6.7667, Validation Loss AVG: 8.7356, lr: 0.001
Epoch [14/400], Training Loss: 25.2748, Validation Loss Current: 7.1301, Validation Loss AVG: 8.6917, lr: 0.001
Epoch [15/400], Training Loss: 25.8985, Validation Loss Current: 6.5825, Validation Loss AVG: 9.1456, lr: 0.001
Epoch [16/400], Training Loss: 24.3473, Validation Loss Current: 6.6646, Validation Loss AVG: 8.8564, lr: 0.001
Epoch [17/400], Training Loss: 24.6309, Validation Loss Current: 8.5824, Validation Loss AVG: 10.9778, lr: 0.001
Epoch [18/400], Training Loss: 23.9328, Validation Loss Current: 6.3778, Validation Loss AVG: 8.7783, lr: 0.001
Epoch [19/400], Training Loss: 24.8550, Validation Loss Current: 6.6638, Validation Loss AVG: 9.2436, lr: 0.001
Epoch [20/400], Training Loss: 20.9801, Validation Loss Current: 6.1619, Validation Loss AVG: 9.1790, lr: 0.001
Epoch [21/400], Training Loss: 20.6706, Validation Loss Current: 6.1238, Validation Loss AVG: 9.0087, lr: 0.001
Epoch [22/400], Training Loss: 19.6049, Validation Loss Current: 6.3419, Validation Loss AVG: 9.7091, lr: 0.001
Epoch [23/400], Training Loss: 20.9203, Validation Loss Current: 7.6571, Validation Loss AVG: 11.7978, lr: 0.001
Epoch [24/400], Training Loss: 21.3018, Validation Loss Current: 7.3969, Validation Loss AVG: 10.7746, lr: 0.001
Epoch [25/400], Training Loss: 18.4858, Validation Loss Current: 6.1944, Validation Loss AVG: 9.9586, lr: 0.001
Epoch [26/400], Training Loss: 16.9143, Validation Loss Current: 6.4787, Validation Loss AVG: 10.5641, lr: 0.001
Epoch [27/400], Training Loss: 15.5671, Validation Loss Current: 5.6038, Validation Loss AVG: 9.1287, lr: 0.001
Epoch [28/400], Training Loss: 15.9650, Validation Loss Current: 5.7811, Validation Loss AVG: 8.8477, lr: 0.001
Epoch [29/400], Training Loss: 16.6842, Validation Loss Current: 6.1273, Validation Loss AVG: 10.0065, lr: 0.001
Epoch [30/400], Training Loss: 15.5809, Validation Loss Current: 6.8033, Validation Loss AVG: 10.7002, lr: 0.001
Epoch [31/400], Training Loss: 16.3812, Validation Loss Current: 6.0722, Validation Loss AVG: 11.3738, lr: 0.001
Epoch [32/400], Training Loss: 15.0514, Validation Loss Current: 5.8829, Validation Loss AVG: 8.4703, lr: 0.001
Epoch [33/400], Training Loss: 13.3431, Validation Loss Current: 6.8127, Validation Loss AVG: 11.3768, lr: 0.001
Epoch [34/400], Training Loss: 12.2714, Validation Loss Current: 7.1007, Validation Loss AVG: 12.4988, lr: 0.001
Epoch [35/400], Training Loss: 12.1865, Validation Loss Current: 5.9948, Validation Loss AVG: 8.4535, lr: 0.001
Epoch [36/400], Training Loss: 10.8278, Validation Loss Current: 6.4529, Validation Loss AVG: 9.9307, lr: 0.001
Epoch [37/400], Training Loss: 11.2357, Validation Loss Current: 5.9376, Validation Loss AVG: 9.3962, lr: 0.001
Epoch [38/400], Training Loss: 11.3862, Validation Loss Current: 5.6136, Validation Loss AVG: 10.6754, lr: 0.001
Epoch [39/400], Training Loss: 8.5007, Validation Loss Current: 6.1303, Validation Loss AVG: 11.0172, lr: 0.001
Epoch [40/400], Training Loss: 7.9166, Validation Loss Current: 5.6421, Validation Loss AVG: 8.4659, lr: 0.001
Epoch [41/400], Training Loss: 7.7352, Validation Loss Current: 5.7927, Validation Loss AVG: 12.6877, lr: 0.001
Epoch [42/400], Training Loss: 9.5718, Validation Loss Current: 5.4315, Validation Loss AVG: 9.5640, lr: 0.001
Epoch [43/400], Training Loss: 8.3085, Validation Loss Current: 6.0376, Validation Loss AVG: 12.1883, lr: 0.001
Epoch [44/400], Training Loss: 7.6126, Validation Loss Current: 6.0679, Validation Loss AVG: 11.5284, lr: 0.001
Epoch [45/400], Training Loss: 6.9856, Validation Loss Current: 5.8385, Validation Loss AVG: 10.6339, lr: 0.001
Epoch [46/400], Training Loss: 7.7816, Validation Loss Current: 6.2419, Validation Loss AVG: 10.3367, lr: 0.001
Epoch [47/400], Training Loss: 6.6125, Validation Loss Current: 6.3183, Validation Loss AVG: 12.3518, lr: 0.001
Epoch [48/400], Training Loss: 5.4196, Validation Loss Current: 7.0680, Validation Loss AVG: 10.5250, lr: 0.001
Epoch [49/400], Training Loss: 5.2030, Validation Loss Current: 6.5429, Validation Loss AVG: 14.2643, lr: 0.001
Epoch [50/400], Training Loss: 6.4566, Validation Loss Current: 6.6678, Validation Loss AVG: 10.3409, lr: 0.001
Epoch [51/400], Training Loss: 9.5364, Validation Loss Current: 7.5723, Validation Loss AVG: 13.1476, lr: 0.001
Epoch [52/400], Training Loss: 8.5964, Validation Loss Current: 6.4847, Validation Loss AVG: 13.0081, lr: 0.001
Epoch [53/400], Training Loss: 8.0861, Validation Loss Current: 7.6708, Validation Loss AVG: 12.1439, lr: 0.001
Epoch [54/400], Training Loss: 10.4749, Validation Loss Current: 6.5342, Validation Loss AVG: 12.4925, lr: 0.001
Epoch [55/400], Training Loss: 8.6487, Validation Loss Current: 6.3418, Validation Loss AVG: 11.1626, lr: 0.001
Epoch [56/400], Training Loss: 9.3492, Validation Loss Current: 7.4995, Validation Loss AVG: 11.9766, lr: 0.001
Epoch [57/400], Training Loss: 10.8203, Validation Loss Current: 8.4030, Validation Loss AVG: 14.3749, lr: 0.001
Epoch [58/400], Training Loss: 9.7927, Validation Loss Current: 7.0489, Validation Loss AVG: 11.8404, lr: 0.001
Epoch [59/400], Training Loss: 8.6370, Validation Loss Current: 7.1843, Validation Loss AVG: 12.7551, lr: 0.001
Epoch [60/400], Training Loss: 6.8107, Validation Loss Current: 8.3247, Validation Loss AVG: 13.6355, lr: 0.001
Epoch [61/400], Training Loss: 7.4080, Validation Loss Current: 7.6655, Validation Loss AVG: 10.9271, lr: 0.001
Epoch [62/400], Training Loss: 7.3214, Validation Loss Current: 8.1975, Validation Loss AVG: 13.6094, lr: 0.001
Epoch [63/400], Training Loss: 4.4971, Validation Loss Current: 7.0893, Validation Loss AVG: 13.6702, lr: 0.001
Epoch [64/400], Training Loss: 2.7744, Validation Loss Current: 6.2764, Validation Loss AVG: 14.0378, lr: 0.001
Epoch [65/400], Training Loss: 2.4030, Validation Loss Current: 6.8070, Validation Loss AVG: 10.8151, lr: 0.001
Epoch [66/400], Training Loss: 2.9329, Validation Loss Current: 8.9341, Validation Loss AVG: 14.0704, lr: 0.001
Epoch [67/400], Training Loss: 5.3138, Validation Loss Current: 7.7623, Validation Loss AVG: 11.8398, lr: 0.001
Epoch [68/400], Training Loss: 5.3863, Validation Loss Current: 7.1394, Validation Loss AVG: 12.8468, lr: 0.001
Epoch [69/400], Training Loss: 3.4921, Validation Loss Current: 6.7385, Validation Loss AVG: 13.8824, lr: 0.001
Epoch [70/400], Training Loss: 3.9780, Validation Loss Current: 7.2344, Validation Loss AVG: 14.7217, lr: 0.001
Epoch [71/400], Training Loss: 3.9202, Validation Loss Current: 7.2407, Validation Loss AVG: 12.7379, lr: 0.001
Epoch [72/400], Training Loss: 3.1275, Validation Loss Current: 7.1311, Validation Loss AVG: 14.2667, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 42 Best val accuracy: [0.23684210526315788, 0.31743421052631576, 0.35855263157894735, 0.4128289473684211, 0.44243421052631576, 0.42105263157894735, 0.47368421052631576, 0.45230263157894735, 0.47368421052631576, 0.49835526315789475, 0.5016447368421053, 0.49835526315789475, 0.5296052631578947, 0.5082236842105263, 0.5427631578947368, 0.5476973684210527, 0.4588815789473684, 0.5476973684210527, 0.5263157894736842, 0.5740131578947368, 0.600328947368421, 0.5756578947368421, 0.5345394736842105, 0.5164473684210527, 0.587171052631579, 0.5838815789473685, 0.6282894736842105, 0.6151315789473685, 0.5953947368421053, 0.5740131578947368, 0.6101973684210527, 0.6052631578947368, 0.569078947368421, 0.5411184210526315, 0.6365131578947368, 0.59375, 0.6069078947368421, 0.6299342105263158, 0.5773026315789473, 0.6578947368421053, 0.6282894736842105, 0.649671052631579, 0.6036184210526315, 0.625, 0.6414473684210527, 0.59375, 0.6118421052631579, 0.5822368421052632, 0.6217105263157895, 0.6085526315789473, 0.5888157894736842, 0.6069078947368421, 0.5740131578947368, 0.6052631578947368, 0.5921052631578947, 0.5953947368421053, 0.5657894736842105, 0.6052631578947368, 0.6069078947368421, 0.5674342105263158, 0.555921052631579, 0.5509868421052632, 0.5953947368421053, 0.6414473684210527, 0.6036184210526315, 0.5740131578947368, 0.5756578947368421, 0.618421052631579, 0.6069078947368421, 0.6151315789473685, 0.6101973684210527, 0.6118421052631579] Best val loss: 5.431464612483978


----- Training resnet18 with sequence: [1, 0.8] -----
Current group: 1
Epoch [1/200], Training Loss: 41.4465, Validation Loss Current: 9.8467, Validation Loss AVG: 9.9473, lr: 0.001
Epoch [2/200], Training Loss: 38.9684, Validation Loss Current: 9.4470, Validation Loss AVG: 9.7344, lr: 0.001
Epoch [3/200], Training Loss: 36.5625, Validation Loss Current: 9.2548, Validation Loss AVG: 9.9723, lr: 0.001
Epoch [4/200], Training Loss: 36.2359, Validation Loss Current: 8.7295, Validation Loss AVG: 9.4283, lr: 0.001
Epoch [5/200], Training Loss: 34.3010, Validation Loss Current: 8.4740, Validation Loss AVG: 10.0997, lr: 0.001
Epoch [6/200], Training Loss: 32.3105, Validation Loss Current: 8.2497, Validation Loss AVG: 9.4879, lr: 0.001
Epoch [7/200], Training Loss: 32.2843, Validation Loss Current: 8.0212, Validation Loss AVG: 9.0936, lr: 0.001
Epoch [8/200], Training Loss: 31.5881, Validation Loss Current: 7.6836, Validation Loss AVG: 8.9284, lr: 0.001
Epoch [9/200], Training Loss: 29.3185, Validation Loss Current: 7.4902, Validation Loss AVG: 9.0493, lr: 0.001
Epoch [10/200], Training Loss: 29.1471, Validation Loss Current: 7.3186, Validation Loss AVG: 9.1101, lr: 0.001
Epoch [11/200], Training Loss: 28.1476, Validation Loss Current: 6.9886, Validation Loss AVG: 9.1062, lr: 0.001
Epoch [12/200], Training Loss: 26.8037, Validation Loss Current: 6.8266, Validation Loss AVG: 9.1217, lr: 0.001
Epoch [13/200], Training Loss: 25.5787, Validation Loss Current: 7.7144, Validation Loss AVG: 9.3680, lr: 0.001
Epoch [14/200], Training Loss: 25.9746, Validation Loss Current: 7.0588, Validation Loss AVG: 10.5984, lr: 0.001
Epoch [15/200], Training Loss: 25.1728, Validation Loss Current: 6.5561, Validation Loss AVG: 8.6350, lr: 0.001
Epoch [16/200], Training Loss: 23.0965, Validation Loss Current: 6.4317, Validation Loss AVG: 8.6966, lr: 0.001
Epoch [17/200], Training Loss: 23.5360, Validation Loss Current: 6.3525, Validation Loss AVG: 9.5730, lr: 0.001
Epoch [18/200], Training Loss: 22.1720, Validation Loss Current: 6.5237, Validation Loss AVG: 9.0586, lr: 0.001
Epoch [19/200], Training Loss: 21.0678, Validation Loss Current: 6.3316, Validation Loss AVG: 8.3721, lr: 0.001
Epoch [20/200], Training Loss: 21.2154, Validation Loss Current: 6.0002, Validation Loss AVG: 9.2469, lr: 0.001
Epoch [21/200], Training Loss: 20.2430, Validation Loss Current: 6.2228, Validation Loss AVG: 8.5183, lr: 0.001
Epoch [22/200], Training Loss: 19.3917, Validation Loss Current: 6.1994, Validation Loss AVG: 9.4382, lr: 0.001
Epoch [23/200], Training Loss: 18.2380, Validation Loss Current: 6.6236, Validation Loss AVG: 8.4782, lr: 0.001
Epoch [24/200], Training Loss: 17.0913, Validation Loss Current: 6.2878, Validation Loss AVG: 9.2981, lr: 0.001
Epoch [25/200], Training Loss: 16.0345, Validation Loss Current: 6.0933, Validation Loss AVG: 9.0402, lr: 0.001
Epoch [26/200], Training Loss: 15.9578, Validation Loss Current: 6.0946, Validation Loss AVG: 11.1110, lr: 0.001
Epoch [27/200], Training Loss: 17.5271, Validation Loss Current: 6.4126, Validation Loss AVG: 8.9769, lr: 0.001
Epoch [28/200], Training Loss: 16.5792, Validation Loss Current: 6.1622, Validation Loss AVG: 12.1169, lr: 0.001
Epoch [29/200], Training Loss: 15.7292, Validation Loss Current: 6.2557, Validation Loss AVG: 11.0707, lr: 0.001
Epoch [30/200], Training Loss: 14.0628, Validation Loss Current: 5.8568, Validation Loss AVG: 9.4668, lr: 0.001
Epoch [31/200], Training Loss: 12.6663, Validation Loss Current: 5.6961, Validation Loss AVG: 8.1468, lr: 0.001
Epoch [32/200], Training Loss: 12.7211, Validation Loss Current: 6.9799, Validation Loss AVG: 12.1952, lr: 0.001
Epoch [33/200], Training Loss: 14.9020, Validation Loss Current: 6.8694, Validation Loss AVG: 12.3164, lr: 0.001
Epoch [34/200], Training Loss: 13.8170, Validation Loss Current: 6.7432, Validation Loss AVG: 11.3695, lr: 0.001
Epoch [35/200], Training Loss: 13.3010, Validation Loss Current: 7.8154, Validation Loss AVG: 11.9214, lr: 0.001
Epoch [36/200], Training Loss: 10.5363, Validation Loss Current: 7.7363, Validation Loss AVG: 18.6276, lr: 0.001
Epoch [37/200], Training Loss: 9.8954, Validation Loss Current: 5.5923, Validation Loss AVG: 9.0162, lr: 0.001
Epoch [38/200], Training Loss: 10.7075, Validation Loss Current: 9.8127, Validation Loss AVG: 19.3768, lr: 0.001
Epoch [39/200], Training Loss: 12.0391, Validation Loss Current: 6.3865, Validation Loss AVG: 13.1134, lr: 0.001
Epoch [40/200], Training Loss: 9.4944, Validation Loss Current: 6.0021, Validation Loss AVG: 12.4615, lr: 0.001
Epoch [41/200], Training Loss: 10.4824, Validation Loss Current: 5.8888, Validation Loss AVG: 9.8362, lr: 0.001
Epoch [42/200], Training Loss: 10.7901, Validation Loss Current: 7.4511, Validation Loss AVG: 10.7294, lr: 0.001
Epoch [43/200], Training Loss: 8.6307, Validation Loss Current: 5.9435, Validation Loss AVG: 11.5494, lr: 0.001
Epoch [44/200], Training Loss: 6.4503, Validation Loss Current: 6.8316, Validation Loss AVG: 13.4020, lr: 0.001
Epoch [45/200], Training Loss: 6.5981, Validation Loss Current: 6.2756, Validation Loss AVG: 9.2189, lr: 0.001
Epoch [46/200], Training Loss: 5.0231, Validation Loss Current: 7.3398, Validation Loss AVG: 13.0732, lr: 0.001
Epoch [47/200], Training Loss: 5.2149, Validation Loss Current: 6.3119, Validation Loss AVG: 11.9751, lr: 0.001
Epoch [48/200], Training Loss: 5.6561, Validation Loss Current: 6.8955, Validation Loss AVG: 11.9448, lr: 0.001
Epoch [49/200], Training Loss: 7.1972, Validation Loss Current: 6.6675, Validation Loss AVG: 16.0623, lr: 0.001
Epoch [50/200], Training Loss: 6.1545, Validation Loss Current: 7.0377, Validation Loss AVG: 16.2977, lr: 0.001
Epoch [51/200], Training Loss: 7.3318, Validation Loss Current: 10.0026, Validation Loss AVG: 15.4883, lr: 0.001
Epoch [52/200], Training Loss: 7.2592, Validation Loss Current: 7.7581, Validation Loss AVG: 9.9869, lr: 0.001
Epoch [53/200], Training Loss: 7.7521, Validation Loss Current: 6.6715, Validation Loss AVG: 11.5031, lr: 0.001
Epoch [54/200], Training Loss: 7.7360, Validation Loss Current: 7.0245, Validation Loss AVG: 11.8216, lr: 0.001
Epoch [55/200], Training Loss: 6.0162, Validation Loss Current: 6.7223, Validation Loss AVG: 15.6604, lr: 0.001
Epoch [56/200], Training Loss: 4.3586, Validation Loss Current: 6.5951, Validation Loss AVG: 11.5148, lr: 0.001
Epoch [57/200], Training Loss: 6.4501, Validation Loss Current: 7.4576, Validation Loss AVG: 14.0434, lr: 0.001
Epoch [58/200], Training Loss: 7.0949, Validation Loss Current: 6.8494, Validation Loss AVG: 12.6681, lr: 0.001
Epoch [59/200], Training Loss: 6.2400, Validation Loss Current: 6.9457, Validation Loss AVG: 11.0145, lr: 0.001
Epoch [60/200], Training Loss: 4.3234, Validation Loss Current: 7.6597, Validation Loss AVG: 12.9136, lr: 0.001
Epoch [61/200], Training Loss: 4.0630, Validation Loss Current: 6.4103, Validation Loss AVG: 11.5459, lr: 0.001
Epoch [62/200], Training Loss: 3.8799, Validation Loss Current: 7.2770, Validation Loss AVG: 12.7265, lr: 0.001
Epoch [63/200], Training Loss: 3.5459, Validation Loss Current: 7.0397, Validation Loss AVG: 11.7513, lr: 0.001
Epoch [64/200], Training Loss: 3.5079, Validation Loss Current: 7.0990, Validation Loss AVG: 12.6893, lr: 0.001
Epoch [65/200], Training Loss: 5.2057, Validation Loss Current: 7.8327, Validation Loss AVG: 13.9959, lr: 0.001
Epoch [66/200], Training Loss: 4.7869, Validation Loss Current: 7.2454, Validation Loss AVG: 12.3421, lr: 0.001
Epoch [67/200], Training Loss: 4.6415, Validation Loss Current: 7.9516, Validation Loss AVG: 15.6387, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 37 Best val accuracy: [0.24342105263157895, 0.3157894736842105, 0.31085526315789475, 0.3881578947368421, 0.3996710526315789, 0.4029605263157895, 0.41776315789473684, 0.4555921052631579, 0.47039473684210525, 0.49506578947368424, 0.5032894736842105, 0.5164473684210527, 0.4605263157894737, 0.5263157894736842, 0.5444078947368421, 0.5411184210526315, 0.5460526315789473, 0.5394736842105263, 0.5592105263157895, 0.5789473684210527, 0.5723684210526315, 0.555921052631579, 0.5625, 0.5921052631578947, 0.59375, 0.5888157894736842, 0.5707236842105263, 0.5723684210526315, 0.5921052631578947, 0.600328947368421, 0.5904605263157895, 0.5460526315789473, 0.5296052631578947, 0.5608552631578947, 0.5345394736842105, 0.5279605263157895, 0.6134868421052632, 0.47039473684210525, 0.5838815789473685, 0.6069078947368421, 0.5888157894736842, 0.5460526315789473, 0.6134868421052632, 0.5888157894736842, 0.6101973684210527, 0.5592105263157895, 0.5921052631578947, 0.5756578947368421, 0.5789473684210527, 0.5625, 0.537828947368421, 0.5263157894736842, 0.587171052631579, 0.5773026315789473, 0.6052631578947368, 0.6200657894736842, 0.5707236842105263, 0.6134868421052632, 0.5888157894736842, 0.5608552631578947, 0.6118421052631579, 0.6019736842105263, 0.5822368421052632, 0.600328947368421, 0.5855263157894737, 0.5723684210526315, 0.5608552631578947] Best val loss: 5.592329025268555


Current group: 0.8
Epoch [1/200], Training Loss: 25.2925, Validation Loss Current: 10.0243, Validation Loss AVG: 10.0243, lr: 0.001
Epoch [2/200], Training Loss: 17.8669, Validation Loss Current: 13.5210, Validation Loss AVG: 13.5210, lr: 0.001
Epoch [3/200], Training Loss: 15.8476, Validation Loss Current: 14.4649, Validation Loss AVG: 14.4649, lr: 0.001
Epoch [4/200], Training Loss: 11.3022, Validation Loss Current: 11.8106, Validation Loss AVG: 11.8106, lr: 0.001
Epoch [5/200], Training Loss: 8.0073, Validation Loss Current: 10.3574, Validation Loss AVG: 10.3574, lr: 0.001
Epoch [6/200], Training Loss: 6.4925, Validation Loss Current: 9.6559, Validation Loss AVG: 9.6559, lr: 0.001
Epoch [7/200], Training Loss: 7.8238, Validation Loss Current: 10.0416, Validation Loss AVG: 10.0416, lr: 0.001
Epoch [8/200], Training Loss: 6.8503, Validation Loss Current: 11.7391, Validation Loss AVG: 11.7391, lr: 0.001
Epoch [9/200], Training Loss: 7.1016, Validation Loss Current: 13.7118, Validation Loss AVG: 13.7118, lr: 0.001
Epoch [10/200], Training Loss: 6.7168, Validation Loss Current: 9.9221, Validation Loss AVG: 9.9221, lr: 0.001
Epoch [11/200], Training Loss: 5.3904, Validation Loss Current: 15.3266, Validation Loss AVG: 15.3266, lr: 0.001
Epoch [12/200], Training Loss: 3.8342, Validation Loss Current: 11.2543, Validation Loss AVG: 11.2543, lr: 0.001
Epoch [13/200], Training Loss: 4.1962, Validation Loss Current: 12.2921, Validation Loss AVG: 12.2921, lr: 0.001
Epoch [14/200], Training Loss: 8.1542, Validation Loss Current: 17.9737, Validation Loss AVG: 17.9737, lr: 0.001
Epoch [15/200], Training Loss: 5.9167, Validation Loss Current: 11.1590, Validation Loss AVG: 11.1590, lr: 0.001
Epoch [16/200], Training Loss: 4.1711, Validation Loss Current: 10.5140, Validation Loss AVG: 10.5140, lr: 0.001
Epoch [17/200], Training Loss: 2.2707, Validation Loss Current: 11.0044, Validation Loss AVG: 11.0044, lr: 0.001
Epoch [18/200], Training Loss: 2.0131, Validation Loss Current: 10.9635, Validation Loss AVG: 10.9635, lr: 0.001
Epoch [19/200], Training Loss: 4.5936, Validation Loss Current: 12.6795, Validation Loss AVG: 12.6795, lr: 0.001
Epoch [20/200], Training Loss: 6.3489, Validation Loss Current: 12.5471, Validation Loss AVG: 12.5471, lr: 0.001
Epoch [21/200], Training Loss: 6.3136, Validation Loss Current: 14.1749, Validation Loss AVG: 14.1749, lr: 0.001
Epoch [22/200], Training Loss: 4.9938, Validation Loss Current: 11.5519, Validation Loss AVG: 11.5519, lr: 0.001
Epoch [23/200], Training Loss: 2.7180, Validation Loss Current: 15.2841, Validation Loss AVG: 15.2841, lr: 0.001
Epoch [24/200], Training Loss: 1.7003, Validation Loss Current: 11.8673, Validation Loss AVG: 11.8673, lr: 0.001
Epoch [25/200], Training Loss: 2.6101, Validation Loss Current: 11.5218, Validation Loss AVG: 11.5218, lr: 0.001
Epoch [26/200], Training Loss: 2.1065, Validation Loss Current: 11.4757, Validation Loss AVG: 11.4757, lr: 0.001
Epoch [27/200], Training Loss: 1.9857, Validation Loss Current: 12.1254, Validation Loss AVG: 12.1254, lr: 0.001
Epoch [28/200], Training Loss: 2.2166, Validation Loss Current: 12.0341, Validation Loss AVG: 12.0341, lr: 0.001
Epoch [29/200], Training Loss: 3.3507, Validation Loss Current: 11.8655, Validation Loss AVG: 11.8655, lr: 0.001
Epoch [30/200], Training Loss: 3.8886, Validation Loss Current: 15.7339, Validation Loss AVG: 15.7339, lr: 0.001
Epoch [31/200], Training Loss: 4.2133, Validation Loss Current: 21.4577, Validation Loss AVG: 21.4577, lr: 0.001
Epoch [32/200], Training Loss: 9.2480, Validation Loss Current: 13.0483, Validation Loss AVG: 13.0483, lr: 0.001
Epoch [33/200], Training Loss: 5.6764, Validation Loss Current: 12.1422, Validation Loss AVG: 12.1422, lr: 0.001
Epoch [34/200], Training Loss: 4.1496, Validation Loss Current: 10.8227, Validation Loss AVG: 10.8227, lr: 0.001
Epoch [35/200], Training Loss: 4.1191, Validation Loss Current: 11.3764, Validation Loss AVG: 11.3764, lr: 0.001
Epoch [36/200], Training Loss: 6.9750, Validation Loss Current: 13.3551, Validation Loss AVG: 13.3551, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 6 Best val accuracy: [0.42894736842105263, 0.33651315789473685, 0.39835526315789477, 0.38421052631578945, 0.4467105263157894, 0.43881578947368427, 0.4598684210526317, 0.42434210526315785, 0.3894736842105263, 0.4180921052631579, 0.41480263157894737, 0.4325657894736842, 0.4197368421052632, 0.37763157894736843, 0.4516447368421053, 0.42006578947368417, 0.4802631578947369, 0.4440789473684211, 0.40559210526315786, 0.4529605263157895, 0.4128289473684211, 0.4411184210526316, 0.43618421052631573, 0.4526315789473684, 0.4565789473684211, 0.4430921052631579, 0.4519736842105263, 0.4513157894736842, 0.43355263157894736, 0.4203947368421052, 0.3078947368421052, 0.4203947368421052, 0.4588815789473684, 0.4516447368421053, 0.4671052631578948, 0.44046052631578936] Best val loss: 9.65590009689331


----- Training resnet18 with sequence: [1, 0.8, 0.6] -----
Current group: 1
Epoch [1/134], Training Loss: 40.9462, Validation Loss Current: 9.9746, Validation Loss AVG: 10.0478, lr: 0.001
Epoch [2/134], Training Loss: 39.0025, Validation Loss Current: 9.4578, Validation Loss AVG: 9.8052, lr: 0.001
Epoch [3/134], Training Loss: 37.5848, Validation Loss Current: 9.0923, Validation Loss AVG: 9.6399, lr: 0.001
Epoch [4/134], Training Loss: 36.7464, Validation Loss Current: 8.9581, Validation Loss AVG: 9.8215, lr: 0.001
Epoch [5/134], Training Loss: 35.7453, Validation Loss Current: 8.6356, Validation Loss AVG: 9.4729, lr: 0.001
Epoch [6/134], Training Loss: 33.6654, Validation Loss Current: 8.3222, Validation Loss AVG: 9.7209, lr: 0.001
Epoch [7/134], Training Loss: 32.4507, Validation Loss Current: 7.9663, Validation Loss AVG: 9.0070, lr: 0.001
Epoch [8/134], Training Loss: 32.3256, Validation Loss Current: 7.6834, Validation Loss AVG: 8.9016, lr: 0.001
Epoch [9/134], Training Loss: 28.9741, Validation Loss Current: 7.5041, Validation Loss AVG: 9.8111, lr: 0.001
Epoch [10/134], Training Loss: 28.6131, Validation Loss Current: 7.0459, Validation Loss AVG: 8.8961, lr: 0.001
Epoch [11/134], Training Loss: 27.0117, Validation Loss Current: 7.1917, Validation Loss AVG: 8.9040, lr: 0.001
Epoch [12/134], Training Loss: 26.8394, Validation Loss Current: 6.7930, Validation Loss AVG: 8.5565, lr: 0.001
Epoch [13/134], Training Loss: 25.7575, Validation Loss Current: 6.5433, Validation Loss AVG: 9.2810, lr: 0.001
Epoch [14/134], Training Loss: 25.1929, Validation Loss Current: 6.3835, Validation Loss AVG: 8.6871, lr: 0.001
Epoch [15/134], Training Loss: 23.8149, Validation Loss Current: 6.2636, Validation Loss AVG: 8.5052, lr: 0.001
Epoch [16/134], Training Loss: 23.1308, Validation Loss Current: 6.1576, Validation Loss AVG: 8.2038, lr: 0.001
Epoch [17/134], Training Loss: 21.7151, Validation Loss Current: 6.2800, Validation Loss AVG: 9.5871, lr: 0.001
Epoch [18/134], Training Loss: 21.7374, Validation Loss Current: 6.0454, Validation Loss AVG: 10.4545, lr: 0.001
Epoch [19/134], Training Loss: 20.7596, Validation Loss Current: 5.8793, Validation Loss AVG: 9.4630, lr: 0.001
Epoch [20/134], Training Loss: 20.1332, Validation Loss Current: 5.8357, Validation Loss AVG: 8.2058, lr: 0.001
Epoch [21/134], Training Loss: 19.6918, Validation Loss Current: 6.5830, Validation Loss AVG: 10.6884, lr: 0.001
Epoch [22/134], Training Loss: 22.2206, Validation Loss Current: 6.1364, Validation Loss AVG: 10.5213, lr: 0.001
Epoch [23/134], Training Loss: 21.5445, Validation Loss Current: 9.1715, Validation Loss AVG: 18.0484, lr: 0.001
Epoch [24/134], Training Loss: 18.9684, Validation Loss Current: 5.7890, Validation Loss AVG: 8.4499, lr: 0.001
Epoch [25/134], Training Loss: 18.9648, Validation Loss Current: 6.1087, Validation Loss AVG: 10.0513, lr: 0.001
Epoch [26/134], Training Loss: 17.4462, Validation Loss Current: 6.1357, Validation Loss AVG: 8.2319, lr: 0.001
Epoch [27/134], Training Loss: 18.2753, Validation Loss Current: 5.7799, Validation Loss AVG: 8.4566, lr: 0.001
Epoch [28/134], Training Loss: 16.7000, Validation Loss Current: 5.7776, Validation Loss AVG: 8.4259, lr: 0.001
Epoch [29/134], Training Loss: 15.7794, Validation Loss Current: 5.3436, Validation Loss AVG: 10.3114, lr: 0.001
Epoch [30/134], Training Loss: 15.2078, Validation Loss Current: 5.2540, Validation Loss AVG: 10.2528, lr: 0.001
Epoch [31/134], Training Loss: 14.5914, Validation Loss Current: 5.3881, Validation Loss AVG: 8.1336, lr: 0.001
Epoch [32/134], Training Loss: 13.0577, Validation Loss Current: 6.3733, Validation Loss AVG: 9.0438, lr: 0.001
Epoch [33/134], Training Loss: 11.8572, Validation Loss Current: 6.3142, Validation Loss AVG: 8.3968, lr: 0.001
Epoch [34/134], Training Loss: 11.1168, Validation Loss Current: 5.4308, Validation Loss AVG: 13.2865, lr: 0.001
Epoch [35/134], Training Loss: 9.9844, Validation Loss Current: 5.0037, Validation Loss AVG: 9.2272, lr: 0.001
Epoch [36/134], Training Loss: 9.7750, Validation Loss Current: 5.5545, Validation Loss AVG: 8.6109, lr: 0.001
Epoch [37/134], Training Loss: 9.8069, Validation Loss Current: 8.5434, Validation Loss AVG: 10.6520, lr: 0.001
Epoch [38/134], Training Loss: 15.2275, Validation Loss Current: 6.2735, Validation Loss AVG: 9.3641, lr: 0.001
Epoch [39/134], Training Loss: 11.2788, Validation Loss Current: 6.3028, Validation Loss AVG: 8.7399, lr: 0.001
Epoch [40/134], Training Loss: 8.7246, Validation Loss Current: 5.1319, Validation Loss AVG: 10.4346, lr: 0.001
Epoch [41/134], Training Loss: 7.2055, Validation Loss Current: 5.3978, Validation Loss AVG: 8.7563, lr: 0.001
Epoch [42/134], Training Loss: 7.8516, Validation Loss Current: 5.5176, Validation Loss AVG: 14.9151, lr: 0.001
Epoch [43/134], Training Loss: 8.0346, Validation Loss Current: 5.5049, Validation Loss AVG: 8.9687, lr: 0.001
Epoch [44/134], Training Loss: 7.7648, Validation Loss Current: 6.0189, Validation Loss AVG: 12.3788, lr: 0.001
Epoch [45/134], Training Loss: 7.1649, Validation Loss Current: 6.2459, Validation Loss AVG: 14.6644, lr: 0.001
Epoch [46/134], Training Loss: 6.5542, Validation Loss Current: 5.5126, Validation Loss AVG: 9.6142, lr: 0.001
Epoch [47/134], Training Loss: 5.1065, Validation Loss Current: 5.3258, Validation Loss AVG: 10.4025, lr: 0.001
Epoch [48/134], Training Loss: 4.0696, Validation Loss Current: 5.4406, Validation Loss AVG: 12.2429, lr: 0.001
Epoch [49/134], Training Loss: 3.4762, Validation Loss Current: 5.5704, Validation Loss AVG: 11.4958, lr: 0.001
Epoch [50/134], Training Loss: 4.6234, Validation Loss Current: 8.1112, Validation Loss AVG: 14.5226, lr: 0.001
Epoch [51/134], Training Loss: 9.3762, Validation Loss Current: 10.7283, Validation Loss AVG: 12.8026, lr: 0.001
Epoch [52/134], Training Loss: 10.8070, Validation Loss Current: 7.1791, Validation Loss AVG: 10.6080, lr: 0.001
Epoch [53/134], Training Loss: 6.6970, Validation Loss Current: 6.6379, Validation Loss AVG: 12.7705, lr: 0.001
Epoch [54/134], Training Loss: 4.7741, Validation Loss Current: 6.1378, Validation Loss AVG: 9.3768, lr: 0.001
Epoch [55/134], Training Loss: 6.0476, Validation Loss Current: 6.8338, Validation Loss AVG: 10.0935, lr: 0.001
Epoch [56/134], Training Loss: 4.2836, Validation Loss Current: 6.5774, Validation Loss AVG: 10.4076, lr: 0.001
Epoch [57/134], Training Loss: 4.4017, Validation Loss Current: 5.8213, Validation Loss AVG: 14.3005, lr: 0.001
Epoch [58/134], Training Loss: 4.7853, Validation Loss Current: 6.4877, Validation Loss AVG: 12.4580, lr: 0.001
Epoch [59/134], Training Loss: 6.7969, Validation Loss Current: 6.3040, Validation Loss AVG: 15.5234, lr: 0.001
Epoch [60/134], Training Loss: 6.0369, Validation Loss Current: 6.7360, Validation Loss AVG: 12.1217, lr: 0.001
Epoch [61/134], Training Loss: 5.7409, Validation Loss Current: 7.6536, Validation Loss AVG: 25.7621, lr: 0.001
Epoch [62/134], Training Loss: 8.0703, Validation Loss Current: 7.2599, Validation Loss AVG: 11.1675, lr: 0.001
Epoch [63/134], Training Loss: 3.6480, Validation Loss Current: 6.2340, Validation Loss AVG: 12.0634, lr: 0.001
Epoch [64/134], Training Loss: 4.8760, Validation Loss Current: 5.3396, Validation Loss AVG: 10.8333, lr: 0.001
Epoch [65/134], Training Loss: 3.6718, Validation Loss Current: 6.2329, Validation Loss AVG: 13.1244, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 35 Best val accuracy: [0.2582236842105263, 0.2911184210526316, 0.33223684210526316, 0.3881578947368421, 0.38980263157894735, 0.4128289473684211, 0.4375, 0.4868421052631579, 0.4753289473684211, 0.5016447368421053, 0.4868421052631579, 0.5328947368421053, 0.5509868421052632, 0.5394736842105263, 0.5740131578947368, 0.5855263157894737, 0.5575657894736842, 0.5921052631578947, 0.5888157894736842, 0.6118421052631579, 0.569078947368421, 0.587171052631579, 0.46381578947368424, 0.6200657894736842, 0.5904605263157895, 0.5970394736842105, 0.6101973684210527, 0.6151315789473685, 0.6463815789473685, 0.6430921052631579, 0.6381578947368421, 0.5838815789473685, 0.6052631578947368, 0.649671052631579, 0.6710526315789473, 0.6217105263157895, 0.506578947368421, 0.5855263157894737, 0.600328947368421, 0.649671052631579, 0.6299342105263158, 0.6348684210526315, 0.6546052631578947, 0.6398026315789473, 0.600328947368421, 0.6694078947368421, 0.6611842105263158, 0.6398026315789473, 0.6447368421052632, 0.5263157894736842, 0.5098684210526315, 0.5625, 0.6085526315789473, 0.600328947368421, 0.6200657894736842, 0.6134868421052632, 0.6463815789473685, 0.618421052631579, 0.6200657894736842, 0.6101973684210527, 0.5756578947368421, 0.6134868421052632, 0.625, 0.6694078947368421, 0.6546052631578947] Best val loss: 5.003704845905304


Current group: 0.8
Epoch [1/134], Training Loss: 20.5913, Validation Loss Current: 10.8200, Validation Loss AVG: 10.8200, lr: 0.001
Epoch [2/134], Training Loss: 15.2325, Validation Loss Current: 10.0203, Validation Loss AVG: 10.0203, lr: 0.001
Epoch [3/134], Training Loss: 11.1425, Validation Loss Current: 10.5974, Validation Loss AVG: 10.5974, lr: 0.001
Epoch [4/134], Training Loss: 9.7189, Validation Loss Current: 9.8823, Validation Loss AVG: 9.8823, lr: 0.001
Epoch [5/134], Training Loss: 9.1333, Validation Loss Current: 10.7808, Validation Loss AVG: 10.7808, lr: 0.001
Epoch [6/134], Training Loss: 9.2979, Validation Loss Current: 11.8462, Validation Loss AVG: 11.8462, lr: 0.001
Epoch [7/134], Training Loss: 8.4566, Validation Loss Current: 11.5168, Validation Loss AVG: 11.5168, lr: 0.001
Epoch [8/134], Training Loss: 5.6241, Validation Loss Current: 10.8478, Validation Loss AVG: 10.8478, lr: 0.001
Epoch [9/134], Training Loss: 4.0633, Validation Loss Current: 9.6222, Validation Loss AVG: 9.6222, lr: 0.001
Epoch [10/134], Training Loss: 5.7524, Validation Loss Current: 10.8914, Validation Loss AVG: 10.8914, lr: 0.001
Epoch [11/134], Training Loss: 10.2911, Validation Loss Current: 10.6940, Validation Loss AVG: 10.6940, lr: 0.001
Epoch [12/134], Training Loss: 7.0953, Validation Loss Current: 10.7128, Validation Loss AVG: 10.7128, lr: 0.001
Epoch [13/134], Training Loss: 3.7576, Validation Loss Current: 10.4041, Validation Loss AVG: 10.4041, lr: 0.001
Epoch [14/134], Training Loss: 2.6179, Validation Loss Current: 10.0910, Validation Loss AVG: 10.0910, lr: 0.001
Epoch [15/134], Training Loss: 4.5050, Validation Loss Current: 10.9139, Validation Loss AVG: 10.9139, lr: 0.001
Epoch [16/134], Training Loss: 2.5969, Validation Loss Current: 12.2523, Validation Loss AVG: 12.2523, lr: 0.001
Epoch [17/134], Training Loss: 1.9380, Validation Loss Current: 11.8248, Validation Loss AVG: 11.8248, lr: 0.001
Epoch [18/134], Training Loss: 3.7088, Validation Loss Current: 11.5440, Validation Loss AVG: 11.5440, lr: 0.001
Epoch [19/134], Training Loss: 2.8838, Validation Loss Current: 10.4681, Validation Loss AVG: 10.4681, lr: 0.001
Epoch [20/134], Training Loss: 4.7619, Validation Loss Current: 11.5156, Validation Loss AVG: 11.5156, lr: 0.001
Epoch [21/134], Training Loss: 8.1518, Validation Loss Current: 17.7162, Validation Loss AVG: 17.7162, lr: 0.001
Epoch [22/134], Training Loss: 8.5293, Validation Loss Current: 13.4594, Validation Loss AVG: 13.4594, lr: 0.001
Epoch [23/134], Training Loss: 5.2940, Validation Loss Current: 12.5001, Validation Loss AVG: 12.5001, lr: 0.001
Epoch [24/134], Training Loss: 4.5134, Validation Loss Current: 13.5983, Validation Loss AVG: 13.5983, lr: 0.001
Epoch [25/134], Training Loss: 3.9228, Validation Loss Current: 13.0722, Validation Loss AVG: 13.0722, lr: 0.001
Epoch [26/134], Training Loss: 3.5492, Validation Loss Current: 13.2483, Validation Loss AVG: 13.2483, lr: 0.001
Epoch [27/134], Training Loss: 3.8655, Validation Loss Current: 13.7090, Validation Loss AVG: 13.7090, lr: 0.001
Epoch [28/134], Training Loss: 2.1270, Validation Loss Current: 13.5897, Validation Loss AVG: 13.5897, lr: 0.001
Epoch [29/134], Training Loss: 1.9922, Validation Loss Current: 10.3860, Validation Loss AVG: 10.3860, lr: 0.001
Epoch [30/134], Training Loss: 3.6667, Validation Loss Current: 13.9330, Validation Loss AVG: 13.9330, lr: 0.001
Epoch [31/134], Training Loss: 3.8675, Validation Loss Current: 15.4407, Validation Loss AVG: 15.4407, lr: 0.001
Epoch [32/134], Training Loss: 3.5693, Validation Loss Current: 12.8802, Validation Loss AVG: 12.8802, lr: 0.001
Epoch [33/134], Training Loss: 6.0491, Validation Loss Current: 15.5331, Validation Loss AVG: 15.5331, lr: 0.001
Epoch [34/134], Training Loss: 4.1885, Validation Loss Current: 11.7690, Validation Loss AVG: 11.7690, lr: 0.001
Epoch [35/134], Training Loss: 6.6664, Validation Loss Current: 13.1909, Validation Loss AVG: 13.1909, lr: 0.001
Epoch [36/134], Training Loss: 9.2660, Validation Loss Current: 11.9750, Validation Loss AVG: 11.9750, lr: 0.001
Epoch [37/134], Training Loss: 9.3636, Validation Loss Current: 12.9543, Validation Loss AVG: 12.9543, lr: 0.001
Epoch [38/134], Training Loss: 8.4634, Validation Loss Current: 12.2579, Validation Loss AVG: 12.2579, lr: 0.001
Epoch [39/134], Training Loss: 7.1260, Validation Loss Current: 11.6674, Validation Loss AVG: 11.6674, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 9 Best val accuracy: [0.4641447368421052, 0.4384868421052632, 0.4453947368421053, 0.46414473684210533, 0.42598684210526316, 0.4286184210526316, 0.4322368421052631, 0.4473684210526316, 0.4756578947368421, 0.4621710526315789, 0.45592105263157895, 0.4542763157894737, 0.4631578947368421, 0.46644736842105267, 0.4598684210526316, 0.4648026315789474, 0.4493421052631579, 0.46940789473684214, 0.4753289473684211, 0.4707236842105263, 0.3986842105263158, 0.4203947368421053, 0.4447368421052631, 0.45756578947368415, 0.42960526315789477, 0.4578947368421053, 0.3993421052631579, 0.4233552631578947, 0.4671052631578948, 0.43486842105263157, 0.4180921052631579, 0.4358552631578947, 0.4197368421052632, 0.45592105263157895, 0.4217105263157895, 0.47302631578947363, 0.4342105263157895, 0.4223684210526315, 0.44506578947368425] Best val loss: 9.622194027900695


Current group: 0.6
Epoch [1/134], Training Loss: 27.8431, Validation Loss Current: 10.1231, Validation Loss AVG: 10.1231, lr: 0.001
Epoch [2/134], Training Loss: 20.3811, Validation Loss Current: 13.7748, Validation Loss AVG: 13.7748, lr: 0.001
Epoch [3/134], Training Loss: 16.0904, Validation Loss Current: 10.7749, Validation Loss AVG: 10.7749, lr: 0.001
Epoch [4/134], Training Loss: 15.0393, Validation Loss Current: 10.0573, Validation Loss AVG: 10.0573, lr: 0.001
Epoch [5/134], Training Loss: 11.8071, Validation Loss Current: 8.8933, Validation Loss AVG: 8.8933, lr: 0.001
Epoch [6/134], Training Loss: 8.5956, Validation Loss Current: 10.8584, Validation Loss AVG: 10.8584, lr: 0.001
Epoch [7/134], Training Loss: 10.6267, Validation Loss Current: 9.4212, Validation Loss AVG: 9.4212, lr: 0.001
Epoch [8/134], Training Loss: 9.4618, Validation Loss Current: 9.5690, Validation Loss AVG: 9.5690, lr: 0.001
Epoch [9/134], Training Loss: 7.4362, Validation Loss Current: 9.8483, Validation Loss AVG: 9.8483, lr: 0.001
Epoch [10/134], Training Loss: 7.2574, Validation Loss Current: 9.9865, Validation Loss AVG: 9.9865, lr: 0.001
Epoch [11/134], Training Loss: 5.7079, Validation Loss Current: 12.0547, Validation Loss AVG: 12.0547, lr: 0.001
Epoch [12/134], Training Loss: 6.8905, Validation Loss Current: 10.2300, Validation Loss AVG: 10.2300, lr: 0.001
Epoch [13/134], Training Loss: 6.3670, Validation Loss Current: 9.3894, Validation Loss AVG: 9.3894, lr: 0.001
Epoch [14/134], Training Loss: 7.2133, Validation Loss Current: 11.6048, Validation Loss AVG: 11.6048, lr: 0.001
Epoch [15/134], Training Loss: 5.0562, Validation Loss Current: 10.8307, Validation Loss AVG: 10.8307, lr: 0.001
Epoch [16/134], Training Loss: 3.6243, Validation Loss Current: 10.2590, Validation Loss AVG: 10.2590, lr: 0.001
Epoch [17/134], Training Loss: 3.2065, Validation Loss Current: 9.4327, Validation Loss AVG: 9.4327, lr: 0.001
Epoch [18/134], Training Loss: 2.8173, Validation Loss Current: 9.7886, Validation Loss AVG: 9.7886, lr: 0.001
Epoch [19/134], Training Loss: 3.6762, Validation Loss Current: 9.9322, Validation Loss AVG: 9.9322, lr: 0.001
Epoch [20/134], Training Loss: 6.1731, Validation Loss Current: 11.0332, Validation Loss AVG: 11.0332, lr: 0.001
Epoch [21/134], Training Loss: 3.2152, Validation Loss Current: 10.9962, Validation Loss AVG: 10.9962, lr: 0.001
Epoch [22/134], Training Loss: 2.4295, Validation Loss Current: 10.8136, Validation Loss AVG: 10.8136, lr: 0.001
Epoch [23/134], Training Loss: 5.9375, Validation Loss Current: 11.9803, Validation Loss AVG: 11.9803, lr: 0.001
Epoch [24/134], Training Loss: 3.5218, Validation Loss Current: 11.3662, Validation Loss AVG: 11.3662, lr: 0.001
Epoch [25/134], Training Loss: 5.2191, Validation Loss Current: 13.8077, Validation Loss AVG: 13.8077, lr: 0.001
Epoch [26/134], Training Loss: 2.6794, Validation Loss Current: 11.0710, Validation Loss AVG: 11.0710, lr: 0.001
Epoch [27/134], Training Loss: 4.3342, Validation Loss Current: 11.6582, Validation Loss AVG: 11.6582, lr: 0.001
Epoch [28/134], Training Loss: 3.3364, Validation Loss Current: 12.9868, Validation Loss AVG: 12.9868, lr: 0.001
Epoch [29/134], Training Loss: 2.4226, Validation Loss Current: 11.8293, Validation Loss AVG: 11.8293, lr: 0.001
Epoch [30/134], Training Loss: 4.0594, Validation Loss Current: 14.8771, Validation Loss AVG: 14.8771, lr: 0.001
Epoch [31/134], Training Loss: 2.6073, Validation Loss Current: 12.8665, Validation Loss AVG: 12.8665, lr: 0.001
Epoch [32/134], Training Loss: 1.4404, Validation Loss Current: 11.1759, Validation Loss AVG: 11.1759, lr: 0.001
Epoch [33/134], Training Loss: 1.4524, Validation Loss Current: 11.0898, Validation Loss AVG: 11.0898, lr: 0.001
Epoch [34/134], Training Loss: 0.8367, Validation Loss Current: 11.0032, Validation Loss AVG: 11.0032, lr: 0.001
Epoch [35/134], Training Loss: 2.3699, Validation Loss Current: 12.7002, Validation Loss AVG: 12.7002, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 5 Best val accuracy: [0.4615131578947368, 0.4634868421052632, 0.4240131578947368, 0.48355263157894735, 0.5190789473684211, 0.47697368421052627, 0.4891447368421053, 0.5039473684210527, 0.4947368421052631, 0.5069078947368421, 0.4789473684210527, 0.5108552631578946, 0.5111842105263158, 0.43980263157894733, 0.5075657894736841, 0.5167763157894736, 0.5282894736842106, 0.5259868421052631, 0.5230263157894737, 0.49309210526315794, 0.49769736842105256, 0.5052631578947369, 0.5059210526315789, 0.48322368421052636, 0.4842105263157895, 0.5134868421052632, 0.500328947368421, 0.47368421052631576, 0.4911184210526315, 0.4582236842105264, 0.4921052631578949, 0.5167763157894737, 0.5200657894736842, 0.53125, 0.4848684210526316] Best val loss: 8.89325156211853


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4] -----
Current group: 1
Epoch [1/100], Training Loss: 41.5233, Validation Loss Current: 9.8966, Validation Loss AVG: 10.0031, lr: 0.001
Epoch [2/100], Training Loss: 38.8961, Validation Loss Current: 9.4267, Validation Loss AVG: 9.8035, lr: 0.001
Epoch [3/100], Training Loss: 37.7776, Validation Loss Current: 9.1481, Validation Loss AVG: 9.7137, lr: 0.001
Epoch [4/100], Training Loss: 36.1515, Validation Loss Current: 8.8057, Validation Loss AVG: 9.5284, lr: 0.001
Epoch [5/100], Training Loss: 34.0303, Validation Loss Current: 8.2981, Validation Loss AVG: 9.2169, lr: 0.001
Epoch [6/100], Training Loss: 32.9497, Validation Loss Current: 8.2125, Validation Loss AVG: 9.5146, lr: 0.001
Epoch [7/100], Training Loss: 31.8404, Validation Loss Current: 7.8431, Validation Loss AVG: 9.0433, lr: 0.001
Epoch [8/100], Training Loss: 29.7807, Validation Loss Current: 7.7805, Validation Loss AVG: 9.0204, lr: 0.001
Epoch [9/100], Training Loss: 28.6763, Validation Loss Current: 7.3530, Validation Loss AVG: 8.8024, lr: 0.001
Epoch [10/100], Training Loss: 28.4770, Validation Loss Current: 7.3496, Validation Loss AVG: 8.8113, lr: 0.001
Epoch [11/100], Training Loss: 26.8599, Validation Loss Current: 7.1428, Validation Loss AVG: 8.6608, lr: 0.001
Epoch [12/100], Training Loss: 26.3011, Validation Loss Current: 7.0817, Validation Loss AVG: 8.5579, lr: 0.001
Epoch [13/100], Training Loss: 25.2832, Validation Loss Current: 7.1099, Validation Loss AVG: 8.9291, lr: 0.001
Epoch [14/100], Training Loss: 24.6239, Validation Loss Current: 6.7099, Validation Loss AVG: 8.5740, lr: 0.001
Epoch [15/100], Training Loss: 24.6481, Validation Loss Current: 6.6375, Validation Loss AVG: 8.5605, lr: 0.001
Epoch [16/100], Training Loss: 25.2958, Validation Loss Current: 6.9043, Validation Loss AVG: 8.8810, lr: 0.001
Epoch [17/100], Training Loss: 23.9032, Validation Loss Current: 7.5292, Validation Loss AVG: 11.1625, lr: 0.001
Epoch [18/100], Training Loss: 23.8354, Validation Loss Current: 7.0327, Validation Loss AVG: 9.3331, lr: 0.001
Epoch [19/100], Training Loss: 22.2591, Validation Loss Current: 6.5507, Validation Loss AVG: 8.7561, lr: 0.001
Epoch [20/100], Training Loss: 22.7684, Validation Loss Current: 6.1796, Validation Loss AVG: 8.7722, lr: 0.001
Epoch [21/100], Training Loss: 22.4280, Validation Loss Current: 6.5684, Validation Loss AVG: 9.4541, lr: 0.001
Epoch [22/100], Training Loss: 20.3918, Validation Loss Current: 6.1776, Validation Loss AVG: 8.5921, lr: 0.001
Epoch [23/100], Training Loss: 19.1834, Validation Loss Current: 6.4245, Validation Loss AVG: 8.6345, lr: 0.001
Epoch [24/100], Training Loss: 19.2622, Validation Loss Current: 6.1042, Validation Loss AVG: 8.4790, lr: 0.001
Epoch [25/100], Training Loss: 19.4575, Validation Loss Current: 6.6662, Validation Loss AVG: 8.6782, lr: 0.001
Epoch [26/100], Training Loss: 19.5825, Validation Loss Current: 6.5218, Validation Loss AVG: 9.3701, lr: 0.001
Epoch [27/100], Training Loss: 17.4810, Validation Loss Current: 6.0826, Validation Loss AVG: 8.7562, lr: 0.001
Epoch [28/100], Training Loss: 16.9656, Validation Loss Current: 6.4843, Validation Loss AVG: 9.5591, lr: 0.001
Epoch [29/100], Training Loss: 16.9813, Validation Loss Current: 6.3557, Validation Loss AVG: 10.0618, lr: 0.001
Epoch [30/100], Training Loss: 14.4658, Validation Loss Current: 6.0642, Validation Loss AVG: 8.4454, lr: 0.001
Epoch [31/100], Training Loss: 14.1283, Validation Loss Current: 5.8109, Validation Loss AVG: 9.5898, lr: 0.001
Epoch [32/100], Training Loss: 13.7274, Validation Loss Current: 6.6063, Validation Loss AVG: 8.9141, lr: 0.001
Epoch [33/100], Training Loss: 12.6110, Validation Loss Current: 6.0329, Validation Loss AVG: 10.1240, lr: 0.001
Epoch [34/100], Training Loss: 11.6480, Validation Loss Current: 6.6507, Validation Loss AVG: 9.8227, lr: 0.001
Epoch [35/100], Training Loss: 11.2249, Validation Loss Current: 5.8585, Validation Loss AVG: 9.3539, lr: 0.001
Epoch [36/100], Training Loss: 12.2583, Validation Loss Current: 5.8464, Validation Loss AVG: 10.9580, lr: 0.001
Epoch [37/100], Training Loss: 11.0887, Validation Loss Current: 6.3065, Validation Loss AVG: 10.0901, lr: 0.001
Epoch [38/100], Training Loss: 11.0162, Validation Loss Current: 7.5914, Validation Loss AVG: 9.6084, lr: 0.001
Epoch [39/100], Training Loss: 11.4510, Validation Loss Current: 6.6758, Validation Loss AVG: 11.6120, lr: 0.001
Epoch [40/100], Training Loss: 10.0174, Validation Loss Current: 6.8895, Validation Loss AVG: 10.0818, lr: 0.001
Epoch [41/100], Training Loss: 11.5085, Validation Loss Current: 7.4631, Validation Loss AVG: 10.7809, lr: 0.001
Epoch [42/100], Training Loss: 10.6510, Validation Loss Current: 6.9764, Validation Loss AVG: 10.1612, lr: 0.001
Epoch [43/100], Training Loss: 10.9025, Validation Loss Current: 6.5120, Validation Loss AVG: 10.1804, lr: 0.001
Epoch [44/100], Training Loss: 10.3073, Validation Loss Current: 6.9254, Validation Loss AVG: 12.9891, lr: 0.001
Epoch [45/100], Training Loss: 8.7685, Validation Loss Current: 6.2521, Validation Loss AVG: 11.0428, lr: 0.001
Epoch [46/100], Training Loss: 6.1713, Validation Loss Current: 6.7434, Validation Loss AVG: 10.2367, lr: 0.001
Epoch [47/100], Training Loss: 4.8423, Validation Loss Current: 5.9193, Validation Loss AVG: 10.8229, lr: 0.001
Epoch [48/100], Training Loss: 6.1477, Validation Loss Current: 7.2874, Validation Loss AVG: 12.7597, lr: 0.001
Epoch [49/100], Training Loss: 3.9466, Validation Loss Current: 7.0228, Validation Loss AVG: 10.4548, lr: 0.001
Epoch [50/100], Training Loss: 3.2060, Validation Loss Current: 6.0885, Validation Loss AVG: 11.9434, lr: 0.001
Epoch [51/100], Training Loss: 3.1789, Validation Loss Current: 5.9635, Validation Loss AVG: 10.1270, lr: 0.001
Epoch [52/100], Training Loss: 4.8847, Validation Loss Current: 6.5052, Validation Loss AVG: 10.1733, lr: 0.001
Epoch [53/100], Training Loss: 4.8738, Validation Loss Current: 7.6520, Validation Loss AVG: 12.7753, lr: 0.001
Epoch [54/100], Training Loss: 3.1548, Validation Loss Current: 7.0795, Validation Loss AVG: 13.2076, lr: 0.001
Epoch [55/100], Training Loss: 3.2728, Validation Loss Current: 8.0565, Validation Loss AVG: 15.0891, lr: 0.001
Epoch [56/100], Training Loss: 5.3508, Validation Loss Current: 8.5879, Validation Loss AVG: 13.5051, lr: 0.001
Epoch [57/100], Training Loss: 10.8986, Validation Loss Current: 8.1785, Validation Loss AVG: 14.4447, lr: 0.001
Epoch [58/100], Training Loss: 8.6186, Validation Loss Current: 8.0726, Validation Loss AVG: 12.5905, lr: 0.001
Epoch [59/100], Training Loss: 5.0150, Validation Loss Current: 6.5879, Validation Loss AVG: 13.5959, lr: 0.001
Epoch [60/100], Training Loss: 4.4129, Validation Loss Current: 7.3255, Validation Loss AVG: 14.4059, lr: 0.001
Epoch [61/100], Training Loss: 4.1233, Validation Loss Current: 8.4763, Validation Loss AVG: 15.3458, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 31 Best val accuracy: [0.25493421052631576, 0.31414473684210525, 0.3207236842105263, 0.3684210526315789, 0.4194078947368421, 0.4128289473684211, 0.4473684210526316, 0.46381578947368424, 0.49835526315789475, 0.4967105263157895, 0.5263157894736842, 0.5328947368421053, 0.5213815789473685, 0.5279605263157895, 0.5542763157894737, 0.5263157894736842, 0.49506578947368424, 0.524671052631579, 0.5493421052631579, 0.5773026315789473, 0.5328947368421053, 0.5756578947368421, 0.5674342105263158, 0.5921052631578947, 0.5542763157894737, 0.5509868421052632, 0.5855263157894737, 0.5707236842105263, 0.5838815789473685, 0.5970394736842105, 0.6266447368421053, 0.5641447368421053, 0.6069078947368421, 0.5822368421052632, 0.6052631578947368, 0.6348684210526315, 0.5805921052631579, 0.5592105263157895, 0.5855263157894737, 0.5608552631578947, 0.569078947368421, 0.5773026315789473, 0.5888157894736842, 0.5493421052631579, 0.5953947368421053, 0.6085526315789473, 0.6069078947368421, 0.5657894736842105, 0.5888157894736842, 0.6200657894736842, 0.6348684210526315, 0.59375, 0.5805921052631579, 0.5773026315789473, 0.5509868421052632, 0.5575657894736842, 0.5526315789473685, 0.5773026315789473, 0.6134868421052632, 0.5773026315789473, 0.5592105263157895] Best val loss: 5.8109413385391235


Current group: 0.8
Epoch [1/100], Training Loss: 20.2635, Validation Loss Current: 9.9773, Validation Loss AVG: 9.9773, lr: 0.001
Epoch [2/100], Training Loss: 15.7032, Validation Loss Current: 10.4024, Validation Loss AVG: 10.4024, lr: 0.001
Epoch [3/100], Training Loss: 15.6830, Validation Loss Current: 11.2883, Validation Loss AVG: 11.2883, lr: 0.001
Epoch [4/100], Training Loss: 11.8033, Validation Loss Current: 8.9401, Validation Loss AVG: 8.9401, lr: 0.001
Epoch [5/100], Training Loss: 11.6898, Validation Loss Current: 12.7361, Validation Loss AVG: 12.7361, lr: 0.001
Epoch [6/100], Training Loss: 9.5950, Validation Loss Current: 10.3312, Validation Loss AVG: 10.3312, lr: 0.001
Epoch [7/100], Training Loss: 8.3324, Validation Loss Current: 12.3688, Validation Loss AVG: 12.3688, lr: 0.001
Epoch [8/100], Training Loss: 7.2441, Validation Loss Current: 10.8809, Validation Loss AVG: 10.8809, lr: 0.001
Epoch [9/100], Training Loss: 8.9946, Validation Loss Current: 10.6796, Validation Loss AVG: 10.6796, lr: 0.001
Epoch [10/100], Training Loss: 6.3432, Validation Loss Current: 10.8489, Validation Loss AVG: 10.8489, lr: 0.001
Epoch [11/100], Training Loss: 5.3598, Validation Loss Current: 11.0040, Validation Loss AVG: 11.0040, lr: 0.001
Epoch [12/100], Training Loss: 6.2353, Validation Loss Current: 10.9618, Validation Loss AVG: 10.9618, lr: 0.001
Epoch [13/100], Training Loss: 6.6729, Validation Loss Current: 10.9894, Validation Loss AVG: 10.9894, lr: 0.001
Epoch [14/100], Training Loss: 5.6983, Validation Loss Current: 17.0248, Validation Loss AVG: 17.0248, lr: 0.001
Epoch [15/100], Training Loss: 5.7221, Validation Loss Current: 13.0942, Validation Loss AVG: 13.0942, lr: 0.001
Epoch [16/100], Training Loss: 6.5591, Validation Loss Current: 12.9341, Validation Loss AVG: 12.9341, lr: 0.001
Epoch [17/100], Training Loss: 7.3761, Validation Loss Current: 12.9285, Validation Loss AVG: 12.9285, lr: 0.001
Epoch [18/100], Training Loss: 5.2274, Validation Loss Current: 12.8087, Validation Loss AVG: 12.8087, lr: 0.001
Epoch [19/100], Training Loss: 6.3341, Validation Loss Current: 13.2038, Validation Loss AVG: 13.2038, lr: 0.001
Epoch [20/100], Training Loss: 5.8449, Validation Loss Current: 11.4722, Validation Loss AVG: 11.4722, lr: 0.001
Epoch [21/100], Training Loss: 3.3598, Validation Loss Current: 11.5881, Validation Loss AVG: 11.5881, lr: 0.001
Epoch [22/100], Training Loss: 4.0279, Validation Loss Current: 10.9407, Validation Loss AVG: 10.9407, lr: 0.001
Epoch [23/100], Training Loss: 6.7186, Validation Loss Current: 12.2065, Validation Loss AVG: 12.2065, lr: 0.001
Epoch [24/100], Training Loss: 4.1217, Validation Loss Current: 13.1592, Validation Loss AVG: 13.1592, lr: 0.001
Epoch [25/100], Training Loss: 5.4366, Validation Loss Current: 13.6087, Validation Loss AVG: 13.6087, lr: 0.001
Epoch [26/100], Training Loss: 4.1911, Validation Loss Current: 15.5513, Validation Loss AVG: 15.5513, lr: 0.001
Epoch [27/100], Training Loss: 2.4810, Validation Loss Current: 10.7560, Validation Loss AVG: 10.7560, lr: 0.001
Epoch [28/100], Training Loss: 2.5028, Validation Loss Current: 11.3600, Validation Loss AVG: 11.3600, lr: 0.001
Epoch [29/100], Training Loss: 3.2051, Validation Loss Current: 13.3730, Validation Loss AVG: 13.3730, lr: 0.001
Epoch [30/100], Training Loss: 2.6849, Validation Loss Current: 12.1317, Validation Loss AVG: 12.1317, lr: 0.001
Epoch [31/100], Training Loss: 3.0092, Validation Loss Current: 13.7079, Validation Loss AVG: 13.7079, lr: 0.001
Epoch [32/100], Training Loss: 4.8434, Validation Loss Current: 11.9378, Validation Loss AVG: 11.9378, lr: 0.001
Epoch [33/100], Training Loss: 2.3759, Validation Loss Current: 12.1082, Validation Loss AVG: 12.1082, lr: 0.001
Epoch [34/100], Training Loss: 1.3091, Validation Loss Current: 11.5982, Validation Loss AVG: 11.5982, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.43980263157894733, 0.44868421052631574, 0.3819078947368421, 0.45921052631578946, 0.4151315789473685, 0.4391447368421053, 0.42105263157894746, 0.43125, 0.44703947368421054, 0.44769736842105257, 0.45394736842105277, 0.44572368421052627, 0.42927631578947373, 0.38980263157894735, 0.42631578947368426, 0.4184210526315789, 0.44375, 0.4200657894736842, 0.44342105263157894, 0.43618421052631584, 0.4661184210526315, 0.45427631578947364, 0.46085526315789477, 0.4440789473684211, 0.39539473684210524, 0.43519736842105267, 0.4776315789473685, 0.45559210526315796, 0.4578947368421053, 0.4519736842105263, 0.43519736842105256, 0.4582236842105264, 0.42631578947368426, 0.4598684210526315] Best val loss: 8.9400949716568


Current group: 0.6
Epoch [1/100], Training Loss: 25.1217, Validation Loss Current: 13.9434, Validation Loss AVG: 13.9434, lr: 0.001
Epoch [2/100], Training Loss: 16.8615, Validation Loss Current: 12.1085, Validation Loss AVG: 12.1085, lr: 0.001
Epoch [3/100], Training Loss: 14.9164, Validation Loss Current: 10.4005, Validation Loss AVG: 10.4005, lr: 0.001
Epoch [4/100], Training Loss: 14.6414, Validation Loss Current: 12.5640, Validation Loss AVG: 12.5640, lr: 0.001
Epoch [5/100], Training Loss: 11.2113, Validation Loss Current: 10.2454, Validation Loss AVG: 10.2454, lr: 0.001
Epoch [6/100], Training Loss: 9.1516, Validation Loss Current: 12.5400, Validation Loss AVG: 12.5400, lr: 0.001
Epoch [7/100], Training Loss: 9.7448, Validation Loss Current: 15.4732, Validation Loss AVG: 15.4732, lr: 0.001
Epoch [8/100], Training Loss: 10.7302, Validation Loss Current: 11.1469, Validation Loss AVG: 11.1469, lr: 0.001
Epoch [9/100], Training Loss: 6.0836, Validation Loss Current: 10.5054, Validation Loss AVG: 10.5054, lr: 0.001
Epoch [10/100], Training Loss: 3.9326, Validation Loss Current: 9.0594, Validation Loss AVG: 9.0594, lr: 0.001
Epoch [11/100], Training Loss: 2.9262, Validation Loss Current: 9.1802, Validation Loss AVG: 9.1802, lr: 0.001
Epoch [12/100], Training Loss: 2.5112, Validation Loss Current: 11.1144, Validation Loss AVG: 11.1144, lr: 0.001
Epoch [13/100], Training Loss: 3.4002, Validation Loss Current: 10.0641, Validation Loss AVG: 10.0641, lr: 0.001
Epoch [14/100], Training Loss: 2.6726, Validation Loss Current: 9.6122, Validation Loss AVG: 9.6122, lr: 0.001
Epoch [15/100], Training Loss: 7.2881, Validation Loss Current: 16.5996, Validation Loss AVG: 16.5996, lr: 0.001
Epoch [16/100], Training Loss: 11.3589, Validation Loss Current: 12.8873, Validation Loss AVG: 12.8873, lr: 0.001
Epoch [17/100], Training Loss: 9.0356, Validation Loss Current: 11.0505, Validation Loss AVG: 11.0505, lr: 0.001
Epoch [18/100], Training Loss: 8.7911, Validation Loss Current: 11.9912, Validation Loss AVG: 11.9912, lr: 0.001
Epoch [19/100], Training Loss: 8.6604, Validation Loss Current: 14.1682, Validation Loss AVG: 14.1682, lr: 0.001
Epoch [20/100], Training Loss: 5.9752, Validation Loss Current: 11.8825, Validation Loss AVG: 11.8825, lr: 0.001
Epoch [21/100], Training Loss: 3.6762, Validation Loss Current: 10.5638, Validation Loss AVG: 10.5638, lr: 0.001
Epoch [22/100], Training Loss: 3.1073, Validation Loss Current: 9.9572, Validation Loss AVG: 9.9572, lr: 0.001
Epoch [23/100], Training Loss: 3.1996, Validation Loss Current: 12.3588, Validation Loss AVG: 12.3588, lr: 0.001
Epoch [24/100], Training Loss: 4.7923, Validation Loss Current: 11.0695, Validation Loss AVG: 11.0695, lr: 0.001
Epoch [25/100], Training Loss: 5.6747, Validation Loss Current: 13.8161, Validation Loss AVG: 13.8161, lr: 0.001
Epoch [26/100], Training Loss: 7.7548, Validation Loss Current: 16.5070, Validation Loss AVG: 16.5070, lr: 0.001
Epoch [27/100], Training Loss: 10.0945, Validation Loss Current: 13.2752, Validation Loss AVG: 13.2752, lr: 0.001
Epoch [28/100], Training Loss: 8.4482, Validation Loss Current: 11.5911, Validation Loss AVG: 11.5911, lr: 0.001
Epoch [29/100], Training Loss: 4.3122, Validation Loss Current: 12.6496, Validation Loss AVG: 12.6496, lr: 0.001
Epoch [30/100], Training Loss: 3.6448, Validation Loss Current: 10.6045, Validation Loss AVG: 10.6045, lr: 0.001
Epoch [31/100], Training Loss: 6.4799, Validation Loss Current: 12.0663, Validation Loss AVG: 12.0663, lr: 0.001
Epoch [32/100], Training Loss: 5.5297, Validation Loss Current: 12.0731, Validation Loss AVG: 12.0731, lr: 0.001
Epoch [33/100], Training Loss: 5.5596, Validation Loss Current: 10.7675, Validation Loss AVG: 10.7675, lr: 0.001
Epoch [34/100], Training Loss: 5.0314, Validation Loss Current: 14.4418, Validation Loss AVG: 14.4418, lr: 0.001
Epoch [35/100], Training Loss: 6.4303, Validation Loss Current: 11.4333, Validation Loss AVG: 11.4333, lr: 0.001
Epoch [36/100], Training Loss: 6.2041, Validation Loss Current: 16.7096, Validation Loss AVG: 16.7096, lr: 0.001
Epoch [37/100], Training Loss: 4.9852, Validation Loss Current: 11.8303, Validation Loss AVG: 11.8303, lr: 0.001
Epoch [38/100], Training Loss: 3.1277, Validation Loss Current: 12.2428, Validation Loss AVG: 12.2428, lr: 0.001
Epoch [39/100], Training Loss: 5.2414, Validation Loss Current: 17.3198, Validation Loss AVG: 17.3198, lr: 0.001
Epoch [40/100], Training Loss: 8.6950, Validation Loss Current: 13.0760, Validation Loss AVG: 13.0760, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 10 Best val accuracy: [0.41743421052631574, 0.4697368421052632, 0.4427631578947368, 0.4026315789473684, 0.4733552631578948, 0.4598684210526316, 0.36611842105263154, 0.4309210526315789, 0.4552631578947368, 0.5026315789473684, 0.4990131578947368, 0.469078947368421, 0.5092105263157896, 0.5046052631578947, 0.34769736842105264, 0.4118421052631579, 0.48322368421052636, 0.4473684210526316, 0.43684210526315786, 0.4588815789473684, 0.4740131578947368, 0.5075657894736842, 0.4598684210526316, 0.45361842105263167, 0.43782894736842104, 0.40592105263157896, 0.44144736842105264, 0.44572368421052627, 0.46019736842105263, 0.49078947368421055, 0.45625, 0.4822368421052631, 0.48618421052631583, 0.43618421052631584, 0.45296052631578937, 0.40032894736842106, 0.4654605263157894, 0.45953947368421055, 0.40427631578947365, 0.4437500000000001] Best val loss: 9.059446597099305


Current group: 0.4
Epoch [1/100], Training Loss: 35.4770, Validation Loss Current: 16.3907, Validation Loss AVG: 16.3907, lr: 0.001
Epoch [2/100], Training Loss: 23.4473, Validation Loss Current: 14.2932, Validation Loss AVG: 14.2932, lr: 0.001
Epoch [3/100], Training Loss: 20.6532, Validation Loss Current: 12.2293, Validation Loss AVG: 12.2293, lr: 0.001
Epoch [4/100], Training Loss: 13.6131, Validation Loss Current: 10.3612, Validation Loss AVG: 10.3612, lr: 0.001
Epoch [5/100], Training Loss: 10.6123, Validation Loss Current: 11.3173, Validation Loss AVG: 11.3173, lr: 0.001
Epoch [6/100], Training Loss: 10.3626, Validation Loss Current: 9.6990, Validation Loss AVG: 9.6990, lr: 0.001
Epoch [7/100], Training Loss: 9.8395, Validation Loss Current: 10.5068, Validation Loss AVG: 10.5068, lr: 0.001
Epoch [8/100], Training Loss: 7.5922, Validation Loss Current: 9.5566, Validation Loss AVG: 9.5566, lr: 0.001
Epoch [9/100], Training Loss: 8.0557, Validation Loss Current: 11.5707, Validation Loss AVG: 11.5707, lr: 0.001
Epoch [10/100], Training Loss: 4.8911, Validation Loss Current: 9.5094, Validation Loss AVG: 9.5094, lr: 0.001
Epoch [11/100], Training Loss: 3.2964, Validation Loss Current: 11.0002, Validation Loss AVG: 11.0002, lr: 0.001
Epoch [12/100], Training Loss: 3.8602, Validation Loss Current: 10.4690, Validation Loss AVG: 10.4690, lr: 0.001
Epoch [13/100], Training Loss: 4.1600, Validation Loss Current: 11.2215, Validation Loss AVG: 11.2215, lr: 0.001
Epoch [14/100], Training Loss: 4.0439, Validation Loss Current: 10.7183, Validation Loss AVG: 10.7183, lr: 0.001
Epoch [15/100], Training Loss: 3.7813, Validation Loss Current: 14.8599, Validation Loss AVG: 14.8599, lr: 0.001
Epoch [16/100], Training Loss: 4.3827, Validation Loss Current: 11.8990, Validation Loss AVG: 11.8990, lr: 0.001
Epoch [17/100], Training Loss: 3.4258, Validation Loss Current: 13.1175, Validation Loss AVG: 13.1175, lr: 0.001
Epoch [18/100], Training Loss: 4.7674, Validation Loss Current: 12.7101, Validation Loss AVG: 12.7101, lr: 0.001
Epoch [19/100], Training Loss: 7.2393, Validation Loss Current: 13.0348, Validation Loss AVG: 13.0348, lr: 0.001
Epoch [20/100], Training Loss: 7.1643, Validation Loss Current: 13.7165, Validation Loss AVG: 13.7165, lr: 0.001
Epoch [21/100], Training Loss: 6.6002, Validation Loss Current: 15.0401, Validation Loss AVG: 15.0401, lr: 0.001
Epoch [22/100], Training Loss: 7.1096, Validation Loss Current: 11.7570, Validation Loss AVG: 11.7570, lr: 0.001
Epoch [23/100], Training Loss: 7.0345, Validation Loss Current: 11.8985, Validation Loss AVG: 11.8985, lr: 0.001
Epoch [24/100], Training Loss: 3.7502, Validation Loss Current: 13.8977, Validation Loss AVG: 13.8977, lr: 0.001
Epoch [25/100], Training Loss: 2.4851, Validation Loss Current: 11.5844, Validation Loss AVG: 11.5844, lr: 0.001
Epoch [26/100], Training Loss: 2.6658, Validation Loss Current: 11.9669, Validation Loss AVG: 11.9669, lr: 0.001
Epoch [27/100], Training Loss: 4.9828, Validation Loss Current: 13.2124, Validation Loss AVG: 13.2124, lr: 0.001
Epoch [28/100], Training Loss: 9.5210, Validation Loss Current: 14.6560, Validation Loss AVG: 14.6560, lr: 0.001
Epoch [29/100], Training Loss: 7.2212, Validation Loss Current: 12.0546, Validation Loss AVG: 12.0546, lr: 0.001
Epoch [30/100], Training Loss: 4.8737, Validation Loss Current: 13.6461, Validation Loss AVG: 13.6461, lr: 0.001
Epoch [31/100], Training Loss: 3.1662, Validation Loss Current: 11.8793, Validation Loss AVG: 11.8793, lr: 0.001
Epoch [32/100], Training Loss: 3.5559, Validation Loss Current: 12.9192, Validation Loss AVG: 12.9192, lr: 0.001
Epoch [33/100], Training Loss: 4.2236, Validation Loss Current: 13.7788, Validation Loss AVG: 13.7788, lr: 0.001
Epoch [34/100], Training Loss: 9.1026, Validation Loss Current: 16.5782, Validation Loss AVG: 16.5782, lr: 0.001
Epoch [35/100], Training Loss: 13.1200, Validation Loss Current: 17.9876, Validation Loss AVG: 17.9876, lr: 0.001
Epoch [36/100], Training Loss: 8.3988, Validation Loss Current: 14.2213, Validation Loss AVG: 14.2213, lr: 0.001
Epoch [37/100], Training Loss: 4.6853, Validation Loss Current: 12.9273, Validation Loss AVG: 12.9273, lr: 0.001
Epoch [38/100], Training Loss: 3.2225, Validation Loss Current: 11.7839, Validation Loss AVG: 11.7839, lr: 0.001
Epoch [39/100], Training Loss: 3.5514, Validation Loss Current: 16.0592, Validation Loss AVG: 16.0592, lr: 0.001
Epoch [40/100], Training Loss: 5.1138, Validation Loss Current: 13.3564, Validation Loss AVG: 13.3564, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 10 Best val accuracy: [0.3486842105263158, 0.4411184210526316, 0.42467105263157895, 0.48026315789473684, 0.45789473684210524, 0.5003289473684209, 0.4651315789473684, 0.4805921052631579, 0.48684210526315785, 0.5095394736842105, 0.4792763157894737, 0.4842105263157895, 0.4884868421052631, 0.4914473684210526, 0.4256578947368421, 0.4585526315789473, 0.46743421052631584, 0.4805921052631579, 0.4342105263157895, 0.4447368421052632, 0.3861842105263158, 0.4828947368421053, 0.49703947368421053, 0.4493421052631579, 0.49769736842105256, 0.47631578947368425, 0.4963815789473685, 0.40855263157894733, 0.46677631578947365, 0.4582236842105263, 0.47302631578947374, 0.5072368421052631, 0.4585526315789473, 0.4286184210526315, 0.3588815789473684, 0.4197368421052632, 0.4483552631578947, 0.4828947368421053, 0.4319078947368421, 0.46480263157894736] Best val loss: 9.509359455108642


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4, 0.2] -----
Current group: 1
Epoch [1/80], Training Loss: 41.2168, Validation Loss Current: 9.9276, Validation Loss AVG: 10.0122, lr: 0.001
Epoch [2/80], Training Loss: 38.6844, Validation Loss Current: 9.4470, Validation Loss AVG: 9.8807, lr: 0.001
Epoch [3/80], Training Loss: 36.6190, Validation Loss Current: 8.9879, Validation Loss AVG: 9.6646, lr: 0.001
Epoch [4/80], Training Loss: 34.5750, Validation Loss Current: 8.5586, Validation Loss AVG: 9.4221, lr: 0.001
Epoch [5/80], Training Loss: 33.6667, Validation Loss Current: 8.2721, Validation Loss AVG: 9.2717, lr: 0.001
Epoch [6/80], Training Loss: 32.4625, Validation Loss Current: 8.0760, Validation Loss AVG: 9.0987, lr: 0.001
Epoch [7/80], Training Loss: 31.5572, Validation Loss Current: 7.9396, Validation Loss AVG: 9.1272, lr: 0.001
Epoch [8/80], Training Loss: 30.5792, Validation Loss Current: 7.6146, Validation Loss AVG: 8.8626, lr: 0.001
Epoch [9/80], Training Loss: 29.9730, Validation Loss Current: 7.6164, Validation Loss AVG: 9.0037, lr: 0.001
Epoch [10/80], Training Loss: 28.9353, Validation Loss Current: 6.9998, Validation Loss AVG: 8.5367, lr: 0.001
Epoch [11/80], Training Loss: 26.0325, Validation Loss Current: 7.9229, Validation Loss AVG: 11.9322, lr: 0.001
Epoch [12/80], Training Loss: 25.4462, Validation Loss Current: 7.1380, Validation Loss AVG: 9.0370, lr: 0.001
Epoch [13/80], Training Loss: 24.7373, Validation Loss Current: 7.1719, Validation Loss AVG: 8.6800, lr: 0.001
Epoch [14/80], Training Loss: 23.7638, Validation Loss Current: 6.8163, Validation Loss AVG: 8.8328, lr: 0.001
Epoch [15/80], Training Loss: 23.5587, Validation Loss Current: 6.5879, Validation Loss AVG: 9.3958, lr: 0.001
Epoch [16/80], Training Loss: 23.4462, Validation Loss Current: 7.0026, Validation Loss AVG: 8.5695, lr: 0.001
Epoch [17/80], Training Loss: 22.6763, Validation Loss Current: 6.8789, Validation Loss AVG: 9.2256, lr: 0.001
Epoch [18/80], Training Loss: 22.4631, Validation Loss Current: 7.8956, Validation Loss AVG: 9.6670, lr: 0.001
Epoch [19/80], Training Loss: 21.6606, Validation Loss Current: 5.8706, Validation Loss AVG: 9.0730, lr: 0.001
Epoch [20/80], Training Loss: 20.6196, Validation Loss Current: 6.2153, Validation Loss AVG: 8.8734, lr: 0.001
Epoch [21/80], Training Loss: 21.1563, Validation Loss Current: 6.2660, Validation Loss AVG: 9.2517, lr: 0.001
Epoch [22/80], Training Loss: 19.5944, Validation Loss Current: 5.7899, Validation Loss AVG: 10.5182, lr: 0.001
Epoch [23/80], Training Loss: 19.6027, Validation Loss Current: 6.3543, Validation Loss AVG: 10.3593, lr: 0.001
Epoch [24/80], Training Loss: 20.2046, Validation Loss Current: 5.6306, Validation Loss AVG: 8.3000, lr: 0.001
Epoch [25/80], Training Loss: 20.1833, Validation Loss Current: 8.1701, Validation Loss AVG: 12.3253, lr: 0.001
Epoch [26/80], Training Loss: 20.7016, Validation Loss Current: 6.7419, Validation Loss AVG: 9.1551, lr: 0.001
Epoch [27/80], Training Loss: 18.2713, Validation Loss Current: 5.9072, Validation Loss AVG: 7.8714, lr: 0.001
Epoch [28/80], Training Loss: 16.7668, Validation Loss Current: 5.9815, Validation Loss AVG: 8.7496, lr: 0.001
Epoch [29/80], Training Loss: 16.5145, Validation Loss Current: 5.7939, Validation Loss AVG: 8.9701, lr: 0.001
Epoch [30/80], Training Loss: 15.5174, Validation Loss Current: 6.5903, Validation Loss AVG: 11.7684, lr: 0.001
Epoch [31/80], Training Loss: 17.6926, Validation Loss Current: 6.1497, Validation Loss AVG: 9.1986, lr: 0.001
Epoch [32/80], Training Loss: 14.6056, Validation Loss Current: 5.9299, Validation Loss AVG: 11.8821, lr: 0.001
Epoch [33/80], Training Loss: 12.8961, Validation Loss Current: 5.5645, Validation Loss AVG: 11.0026, lr: 0.001
Epoch [34/80], Training Loss: 12.0517, Validation Loss Current: 5.5119, Validation Loss AVG: 9.8728, lr: 0.001
Epoch [35/80], Training Loss: 12.2963, Validation Loss Current: 5.3697, Validation Loss AVG: 10.3666, lr: 0.001
Epoch [36/80], Training Loss: 13.7705, Validation Loss Current: 5.8815, Validation Loss AVG: 11.7874, lr: 0.001
Epoch [37/80], Training Loss: 12.7794, Validation Loss Current: 6.2780, Validation Loss AVG: 8.5962, lr: 0.001
Epoch [38/80], Training Loss: 9.5749, Validation Loss Current: 5.5110, Validation Loss AVG: 8.1251, lr: 0.001
Epoch [39/80], Training Loss: 9.5778, Validation Loss Current: 5.2569, Validation Loss AVG: 9.5295, lr: 0.001
Epoch [40/80], Training Loss: 9.3820, Validation Loss Current: 5.5999, Validation Loss AVG: 10.3452, lr: 0.001
Epoch [41/80], Training Loss: 9.7028, Validation Loss Current: 6.0738, Validation Loss AVG: 8.3234, lr: 0.001
Epoch [42/80], Training Loss: 9.8035, Validation Loss Current: 5.2764, Validation Loss AVG: 11.6750, lr: 0.001
Epoch [43/80], Training Loss: 9.2584, Validation Loss Current: 6.2136, Validation Loss AVG: 11.1027, lr: 0.001
Epoch [44/80], Training Loss: 9.2031, Validation Loss Current: 5.9205, Validation Loss AVG: 10.0594, lr: 0.001
Epoch [45/80], Training Loss: 7.0986, Validation Loss Current: 5.9293, Validation Loss AVG: 9.5288, lr: 0.001
Epoch [46/80], Training Loss: 7.6541, Validation Loss Current: 6.3660, Validation Loss AVG: 12.5396, lr: 0.001
Epoch [47/80], Training Loss: 7.2834, Validation Loss Current: 7.3838, Validation Loss AVG: 19.8448, lr: 0.001
Epoch [48/80], Training Loss: 9.7134, Validation Loss Current: 7.7431, Validation Loss AVG: 11.6805, lr: 0.001
Epoch [49/80], Training Loss: 6.7679, Validation Loss Current: 6.0567, Validation Loss AVG: 11.2489, lr: 0.001
Epoch [50/80], Training Loss: 7.2455, Validation Loss Current: 6.5214, Validation Loss AVG: 10.0837, lr: 0.001
Epoch [51/80], Training Loss: 6.6321, Validation Loss Current: 6.5975, Validation Loss AVG: 10.9296, lr: 0.001
Epoch [52/80], Training Loss: 5.3260, Validation Loss Current: 6.5280, Validation Loss AVG: 12.4669, lr: 0.001
Epoch [53/80], Training Loss: 4.0322, Validation Loss Current: 6.2564, Validation Loss AVG: 10.2072, lr: 0.001
Epoch [54/80], Training Loss: 4.2646, Validation Loss Current: 6.1900, Validation Loss AVG: 12.3081, lr: 0.001
Epoch [55/80], Training Loss: 4.2321, Validation Loss Current: 5.8496, Validation Loss AVG: 13.3270, lr: 0.001
Epoch [56/80], Training Loss: 6.3284, Validation Loss Current: 6.6029, Validation Loss AVG: 12.9706, lr: 0.001
Epoch [57/80], Training Loss: 4.9759, Validation Loss Current: 6.7460, Validation Loss AVG: 14.2788, lr: 0.001
Epoch [58/80], Training Loss: 6.0326, Validation Loss Current: 6.5231, Validation Loss AVG: 13.1069, lr: 0.001
Epoch [59/80], Training Loss: 4.1402, Validation Loss Current: 6.0508, Validation Loss AVG: 9.6945, lr: 0.001
Epoch [60/80], Training Loss: 5.8232, Validation Loss Current: 6.8694, Validation Loss AVG: 12.4231, lr: 0.001
Epoch [61/80], Training Loss: 4.2318, Validation Loss Current: 7.6328, Validation Loss AVG: 14.8813, lr: 0.001
Epoch [62/80], Training Loss: 5.2147, Validation Loss Current: 6.7217, Validation Loss AVG: 10.8810, lr: 0.001
Epoch [63/80], Training Loss: 7.0678, Validation Loss Current: 9.6120, Validation Loss AVG: 19.4564, lr: 0.001
Epoch [64/80], Training Loss: 10.5744, Validation Loss Current: 8.0742, Validation Loss AVG: 16.7845, lr: 0.001
Epoch [65/80], Training Loss: 7.6347, Validation Loss Current: 6.6862, Validation Loss AVG: 11.6072, lr: 0.001
Epoch [66/80], Training Loss: 6.5027, Validation Loss Current: 6.2104, Validation Loss AVG: 11.9862, lr: 0.001
Epoch [67/80], Training Loss: 5.6136, Validation Loss Current: 7.1983, Validation Loss AVG: 11.9135, lr: 0.001
Epoch [68/80], Training Loss: 4.3781, Validation Loss Current: 9.7746, Validation Loss AVG: 14.1891, lr: 0.001
Epoch [69/80], Training Loss: 3.5949, Validation Loss Current: 8.5493, Validation Loss AVG: 13.0905, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 39 Best val accuracy: [0.28125, 0.3470394736842105, 0.3618421052631579, 0.3815789473684211, 0.43256578947368424, 0.4375, 0.43256578947368424, 0.4621710526315789, 0.5032894736842105, 0.5164473684210527, 0.44243421052631576, 0.5279605263157895, 0.48026315789473684, 0.5345394736842105, 0.555921052631579, 0.5098684210526315, 0.5361842105263158, 0.48026315789473684, 0.6151315789473685, 0.5674342105263158, 0.5756578947368421, 0.618421052631579, 0.5756578947368421, 0.6069078947368421, 0.48355263157894735, 0.5411184210526315, 0.6019736842105263, 0.5953947368421053, 0.618421052631579, 0.5575657894736842, 0.5953947368421053, 0.6134868421052632, 0.631578947368421, 0.6430921052631579, 0.6430921052631579, 0.6266447368421053, 0.6052631578947368, 0.6414473684210527, 0.6513157894736842, 0.6200657894736842, 0.6332236842105263, 0.662828947368421, 0.6118421052631579, 0.6332236842105263, 0.6398026315789473, 0.5888157894736842, 0.5838815789473685, 0.5542763157894737, 0.6365131578947368, 0.6167763157894737, 0.5904605263157895, 0.6134868421052632, 0.6282894736842105, 0.6381578947368421, 0.6529605263157895, 0.5855263157894737, 0.6167763157894737, 0.618421052631579, 0.6233552631578947, 0.6036184210526315, 0.5493421052631579, 0.6167763157894737, 0.5180921052631579, 0.5805921052631579, 0.6069078947368421, 0.6069078947368421, 0.600328947368421, 0.5855263157894737, 0.5723684210526315] Best val loss: 5.2569326758384705


Current group: 0.8
Epoch [1/80], Training Loss: 20.0528, Validation Loss Current: 11.0776, Validation Loss AVG: 11.0776, lr: 0.001
Epoch [2/80], Training Loss: 16.6848, Validation Loss Current: 10.4180, Validation Loss AVG: 10.4180, lr: 0.001
Epoch [3/80], Training Loss: 14.9360, Validation Loss Current: 12.5868, Validation Loss AVG: 12.5868, lr: 0.001
Epoch [4/80], Training Loss: 14.1374, Validation Loss Current: 11.0364, Validation Loss AVG: 11.0364, lr: 0.001
Epoch [5/80], Training Loss: 10.5307, Validation Loss Current: 12.7376, Validation Loss AVG: 12.7376, lr: 0.001
Epoch [6/80], Training Loss: 10.5441, Validation Loss Current: 9.0306, Validation Loss AVG: 9.0306, lr: 0.001
Epoch [7/80], Training Loss: 9.2816, Validation Loss Current: 8.4887, Validation Loss AVG: 8.4887, lr: 0.001
Epoch [8/80], Training Loss: 7.7445, Validation Loss Current: 15.3188, Validation Loss AVG: 15.3188, lr: 0.001
Epoch [9/80], Training Loss: 5.5064, Validation Loss Current: 10.3202, Validation Loss AVG: 10.3202, lr: 0.001
Epoch [10/80], Training Loss: 3.6983, Validation Loss Current: 10.7960, Validation Loss AVG: 10.7960, lr: 0.001
Epoch [11/80], Training Loss: 5.1578, Validation Loss Current: 13.8865, Validation Loss AVG: 13.8865, lr: 0.001
Epoch [12/80], Training Loss: 5.8146, Validation Loss Current: 10.6488, Validation Loss AVG: 10.6488, lr: 0.001
Epoch [13/80], Training Loss: 5.9338, Validation Loss Current: 9.5113, Validation Loss AVG: 9.5113, lr: 0.001
Epoch [14/80], Training Loss: 7.7075, Validation Loss Current: 11.5942, Validation Loss AVG: 11.5942, lr: 0.001
Epoch [15/80], Training Loss: 8.4440, Validation Loss Current: 14.0809, Validation Loss AVG: 14.0809, lr: 0.001
Epoch [16/80], Training Loss: 4.9707, Validation Loss Current: 11.7080, Validation Loss AVG: 11.7080, lr: 0.001
Epoch [17/80], Training Loss: 4.4436, Validation Loss Current: 14.0441, Validation Loss AVG: 14.0441, lr: 0.001
Epoch [18/80], Training Loss: 3.8071, Validation Loss Current: 11.3826, Validation Loss AVG: 11.3826, lr: 0.001
Epoch [19/80], Training Loss: 5.4180, Validation Loss Current: 11.7007, Validation Loss AVG: 11.7007, lr: 0.001
Epoch [20/80], Training Loss: 5.8317, Validation Loss Current: 13.0174, Validation Loss AVG: 13.0174, lr: 0.001
Epoch [21/80], Training Loss: 3.4798, Validation Loss Current: 12.4516, Validation Loss AVG: 12.4516, lr: 0.001
Epoch [22/80], Training Loss: 3.0490, Validation Loss Current: 12.1535, Validation Loss AVG: 12.1535, lr: 0.001
Epoch [23/80], Training Loss: 2.9072, Validation Loss Current: 11.7544, Validation Loss AVG: 11.7544, lr: 0.001
Epoch [24/80], Training Loss: 3.3138, Validation Loss Current: 12.6591, Validation Loss AVG: 12.6591, lr: 0.001
Epoch [25/80], Training Loss: 2.7728, Validation Loss Current: 12.9441, Validation Loss AVG: 12.9441, lr: 0.001
Epoch [26/80], Training Loss: 3.1159, Validation Loss Current: 11.2823, Validation Loss AVG: 11.2823, lr: 0.001
Epoch [27/80], Training Loss: 3.4965, Validation Loss Current: 16.3357, Validation Loss AVG: 16.3357, lr: 0.001
Epoch [28/80], Training Loss: 3.1558, Validation Loss Current: 11.6298, Validation Loss AVG: 11.6298, lr: 0.001
Epoch [29/80], Training Loss: 1.8960, Validation Loss Current: 12.8988, Validation Loss AVG: 12.8988, lr: 0.001
Epoch [30/80], Training Loss: 0.9601, Validation Loss Current: 12.6532, Validation Loss AVG: 12.6532, lr: 0.001
Epoch [31/80], Training Loss: 1.3326, Validation Loss Current: 12.4157, Validation Loss AVG: 12.4157, lr: 0.001
Epoch [32/80], Training Loss: 3.1171, Validation Loss Current: 13.0164, Validation Loss AVG: 13.0164, lr: 0.001
Epoch [33/80], Training Loss: 3.7357, Validation Loss Current: 14.7607, Validation Loss AVG: 14.7607, lr: 0.001
Epoch [34/80], Training Loss: 1.6778, Validation Loss Current: 12.7068, Validation Loss AVG: 12.7068, lr: 0.001
Epoch [35/80], Training Loss: 3.3605, Validation Loss Current: 11.2735, Validation Loss AVG: 11.2735, lr: 0.001
Epoch [36/80], Training Loss: 2.9325, Validation Loss Current: 12.9347, Validation Loss AVG: 12.9347, lr: 0.001
Epoch [37/80], Training Loss: 1.6370, Validation Loss Current: 14.6410, Validation Loss AVG: 14.6410, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 7 Best val accuracy: [0.4276315789473684, 0.4565789473684211, 0.3759868421052631, 0.42631578947368426, 0.40328947368421053, 0.4631578947368421, 0.4707236842105263, 0.41546052631578956, 0.44309210526315795, 0.43717105263157896, 0.43157894736842106, 0.4546052631578948, 0.46118421052631575, 0.43782894736842104, 0.40822368421052635, 0.46118421052631575, 0.40888157894736843, 0.47467105263157894, 0.43881578947368416, 0.4269736842105263, 0.4493421052631579, 0.4621710526315789, 0.4582236842105263, 0.4342105263157895, 0.449671052631579, 0.4213815789473685, 0.41776315789473684, 0.45032894736842105, 0.4598684210526316, 0.4743421052631579, 0.4667763157894737, 0.42927631578947373, 0.4230263157894737, 0.4509868421052632, 0.47730263157894737, 0.4328947368421052, 0.4651315789473685] Best val loss: 8.488659286499024


Current group: 0.6
Epoch [1/80], Training Loss: 24.5459, Validation Loss Current: 10.1208, Validation Loss AVG: 10.1208, lr: 0.001
Epoch [2/80], Training Loss: 15.5669, Validation Loss Current: 15.5989, Validation Loss AVG: 15.5989, lr: 0.001
Epoch [3/80], Training Loss: 12.2520, Validation Loss Current: 11.6057, Validation Loss AVG: 11.6057, lr: 0.001
Epoch [4/80], Training Loss: 12.9003, Validation Loss Current: 12.4331, Validation Loss AVG: 12.4331, lr: 0.001
Epoch [5/80], Training Loss: 10.5923, Validation Loss Current: 10.5823, Validation Loss AVG: 10.5823, lr: 0.001
Epoch [6/80], Training Loss: 7.5157, Validation Loss Current: 9.6639, Validation Loss AVG: 9.6639, lr: 0.001
Epoch [7/80], Training Loss: 5.8532, Validation Loss Current: 8.7898, Validation Loss AVG: 8.7898, lr: 0.001
Epoch [8/80], Training Loss: 7.6314, Validation Loss Current: 9.9757, Validation Loss AVG: 9.9757, lr: 0.001
Epoch [9/80], Training Loss: 8.5263, Validation Loss Current: 12.1672, Validation Loss AVG: 12.1672, lr: 0.001
Epoch [10/80], Training Loss: 9.1237, Validation Loss Current: 15.7862, Validation Loss AVG: 15.7862, lr: 0.001
Epoch [11/80], Training Loss: 9.0545, Validation Loss Current: 14.5838, Validation Loss AVG: 14.5838, lr: 0.001
Epoch [12/80], Training Loss: 5.6245, Validation Loss Current: 10.5223, Validation Loss AVG: 10.5223, lr: 0.001
Epoch [13/80], Training Loss: 6.0631, Validation Loss Current: 11.6507, Validation Loss AVG: 11.6507, lr: 0.001
Epoch [14/80], Training Loss: 5.8584, Validation Loss Current: 10.0837, Validation Loss AVG: 10.0837, lr: 0.001
Epoch [15/80], Training Loss: 3.1214, Validation Loss Current: 10.7273, Validation Loss AVG: 10.7273, lr: 0.001
Epoch [16/80], Training Loss: 3.6360, Validation Loss Current: 11.0975, Validation Loss AVG: 11.0975, lr: 0.001
Epoch [17/80], Training Loss: 2.5164, Validation Loss Current: 11.0208, Validation Loss AVG: 11.0208, lr: 0.001
Epoch [18/80], Training Loss: 1.8152, Validation Loss Current: 9.8194, Validation Loss AVG: 9.8194, lr: 0.001
Epoch [19/80], Training Loss: 2.0672, Validation Loss Current: 13.1541, Validation Loss AVG: 13.1541, lr: 0.001
Epoch [20/80], Training Loss: 1.9274, Validation Loss Current: 10.2428, Validation Loss AVG: 10.2428, lr: 0.001
Epoch [21/80], Training Loss: 2.3545, Validation Loss Current: 10.5978, Validation Loss AVG: 10.5978, lr: 0.001
Epoch [22/80], Training Loss: 1.1437, Validation Loss Current: 10.9824, Validation Loss AVG: 10.9824, lr: 0.001
Epoch [23/80], Training Loss: 4.4779, Validation Loss Current: 9.8806, Validation Loss AVG: 9.8806, lr: 0.001
Epoch [24/80], Training Loss: 2.3718, Validation Loss Current: 11.0659, Validation Loss AVG: 11.0659, lr: 0.001
Epoch [25/80], Training Loss: 1.3753, Validation Loss Current: 9.9235, Validation Loss AVG: 9.9235, lr: 0.001
Epoch [26/80], Training Loss: 3.7439, Validation Loss Current: 9.8951, Validation Loss AVG: 9.8951, lr: 0.001
Epoch [27/80], Training Loss: 11.7817, Validation Loss Current: 13.4602, Validation Loss AVG: 13.4602, lr: 0.001
Epoch [28/80], Training Loss: 7.5179, Validation Loss Current: 10.9678, Validation Loss AVG: 10.9678, lr: 0.001
Epoch [29/80], Training Loss: 5.6590, Validation Loss Current: 11.9173, Validation Loss AVG: 11.9173, lr: 0.001
Epoch [30/80], Training Loss: 3.3956, Validation Loss Current: 13.3038, Validation Loss AVG: 13.3038, lr: 0.001
Epoch [31/80], Training Loss: 4.4810, Validation Loss Current: 12.5205, Validation Loss AVG: 12.5205, lr: 0.001
Epoch [32/80], Training Loss: 3.7280, Validation Loss Current: 11.6203, Validation Loss AVG: 11.6203, lr: 0.001
Epoch [33/80], Training Loss: 1.4443, Validation Loss Current: 10.2731, Validation Loss AVG: 10.2731, lr: 0.001
Epoch [34/80], Training Loss: 1.7696, Validation Loss Current: 10.4977, Validation Loss AVG: 10.4977, lr: 0.001
Epoch [35/80], Training Loss: 4.0423, Validation Loss Current: 13.2095, Validation Loss AVG: 13.2095, lr: 0.001
Epoch [36/80], Training Loss: 6.7862, Validation Loss Current: 12.9360, Validation Loss AVG: 12.9360, lr: 0.001
Epoch [37/80], Training Loss: 6.7432, Validation Loss Current: 14.7719, Validation Loss AVG: 14.7719, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 7 Best val accuracy: [0.47006578947368427, 0.3822368421052631, 0.49375, 0.45559210526315796, 0.4970394736842104, 0.4621710526315789, 0.5088815789473684, 0.4651315789473684, 0.47006578947368427, 0.4118421052631579, 0.4601973684210526, 0.4930921052631579, 0.4825657894736842, 0.5, 0.48717105263157895, 0.49572368421052626, 0.4858552631578948, 0.4983552631578947, 0.4796052631578947, 0.4898026315789473, 0.48157894736842105, 0.49506578947368407, 0.5055921052631579, 0.49736842105263157, 0.5177631578947368, 0.48749999999999993, 0.4519736842105263, 0.47730263157894737, 0.48881578947368426, 0.4499999999999999, 0.4588815789473684, 0.49177631578947373, 0.4802631578947369, 0.5092105263157894, 0.47467105263157894, 0.5036184210526315, 0.45756578947368426] Best val loss: 8.789782524108887


Current group: 0.4
Epoch [1/80], Training Loss: 35.3822, Validation Loss Current: 14.3235, Validation Loss AVG: 14.3235, lr: 0.001
Epoch [2/80], Training Loss: 19.5092, Validation Loss Current: 12.4148, Validation Loss AVG: 12.4148, lr: 0.001
Epoch [3/80], Training Loss: 18.1381, Validation Loss Current: 14.6774, Validation Loss AVG: 14.6774, lr: 0.001
Epoch [4/80], Training Loss: 16.5303, Validation Loss Current: 25.0398, Validation Loss AVG: 25.0398, lr: 0.001
Epoch [5/80], Training Loss: 16.7607, Validation Loss Current: 18.0509, Validation Loss AVG: 18.0509, lr: 0.001
Epoch [6/80], Training Loss: 14.5292, Validation Loss Current: 11.1264, Validation Loss AVG: 11.1264, lr: 0.001
Epoch [7/80], Training Loss: 12.7795, Validation Loss Current: 12.0815, Validation Loss AVG: 12.0815, lr: 0.001
Epoch [8/80], Training Loss: 8.1082, Validation Loss Current: 11.3062, Validation Loss AVG: 11.3062, lr: 0.001
Epoch [9/80], Training Loss: 4.8578, Validation Loss Current: 9.8498, Validation Loss AVG: 9.8498, lr: 0.001
Epoch [10/80], Training Loss: 3.6461, Validation Loss Current: 9.8896, Validation Loss AVG: 9.8896, lr: 0.001
Epoch [11/80], Training Loss: 3.6218, Validation Loss Current: 11.5824, Validation Loss AVG: 11.5824, lr: 0.001
Epoch [12/80], Training Loss: 5.7508, Validation Loss Current: 11.7138, Validation Loss AVG: 11.7138, lr: 0.001
Epoch [13/80], Training Loss: 7.8696, Validation Loss Current: 13.3966, Validation Loss AVG: 13.3966, lr: 0.001
Epoch [14/80], Training Loss: 5.7415, Validation Loss Current: 11.9301, Validation Loss AVG: 11.9301, lr: 0.001
Epoch [15/80], Training Loss: 9.9792, Validation Loss Current: 17.9485, Validation Loss AVG: 17.9485, lr: 0.001
Epoch [16/80], Training Loss: 8.9660, Validation Loss Current: 12.4956, Validation Loss AVG: 12.4956, lr: 0.001
Epoch [17/80], Training Loss: 7.2732, Validation Loss Current: 14.9810, Validation Loss AVG: 14.9810, lr: 0.001
Epoch [18/80], Training Loss: 6.8764, Validation Loss Current: 14.7433, Validation Loss AVG: 14.7433, lr: 0.001
Epoch [19/80], Training Loss: 5.2161, Validation Loss Current: 13.8837, Validation Loss AVG: 13.8837, lr: 0.001
Epoch [20/80], Training Loss: 4.6781, Validation Loss Current: 12.7422, Validation Loss AVG: 12.7422, lr: 0.001
Epoch [21/80], Training Loss: 4.9664, Validation Loss Current: 12.4121, Validation Loss AVG: 12.4121, lr: 0.001
Epoch [22/80], Training Loss: 3.0352, Validation Loss Current: 11.1756, Validation Loss AVG: 11.1756, lr: 0.001
Epoch [23/80], Training Loss: 5.6139, Validation Loss Current: 11.2359, Validation Loss AVG: 11.2359, lr: 0.001
Epoch [24/80], Training Loss: 3.1770, Validation Loss Current: 11.3658, Validation Loss AVG: 11.3658, lr: 0.001
Epoch [25/80], Training Loss: 4.8695, Validation Loss Current: 12.0799, Validation Loss AVG: 12.0799, lr: 0.001
Epoch [26/80], Training Loss: 8.0646, Validation Loss Current: 13.5149, Validation Loss AVG: 13.5149, lr: 0.001
Epoch [27/80], Training Loss: 2.8388, Validation Loss Current: 11.8473, Validation Loss AVG: 11.8473, lr: 0.001
Epoch [28/80], Training Loss: 1.5450, Validation Loss Current: 10.8807, Validation Loss AVG: 10.8807, lr: 0.001
Epoch [29/80], Training Loss: 2.9588, Validation Loss Current: 13.2488, Validation Loss AVG: 13.2488, lr: 0.001
Epoch [30/80], Training Loss: 10.2106, Validation Loss Current: 16.5898, Validation Loss AVG: 16.5898, lr: 0.001
Epoch [31/80], Training Loss: 5.9766, Validation Loss Current: 14.1469, Validation Loss AVG: 14.1469, lr: 0.001
Epoch [32/80], Training Loss: 2.9942, Validation Loss Current: 11.7572, Validation Loss AVG: 11.7572, lr: 0.001
Epoch [33/80], Training Loss: 3.4785, Validation Loss Current: 13.2884, Validation Loss AVG: 13.2884, lr: 0.001
Epoch [34/80], Training Loss: 4.8692, Validation Loss Current: 14.5609, Validation Loss AVG: 14.5609, lr: 0.001
Epoch [35/80], Training Loss: 4.1674, Validation Loss Current: 16.0088, Validation Loss AVG: 16.0088, lr: 0.001
Epoch [36/80], Training Loss: 5.3768, Validation Loss Current: 13.9902, Validation Loss AVG: 13.9902, lr: 0.001
Epoch [37/80], Training Loss: 6.1445, Validation Loss Current: 15.9189, Validation Loss AVG: 15.9189, lr: 0.001
Epoch [38/80], Training Loss: 3.3528, Validation Loss Current: 14.7424, Validation Loss AVG: 14.7424, lr: 0.001
Epoch [39/80], Training Loss: 3.7244, Validation Loss Current: 12.3878, Validation Loss AVG: 12.3878, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 9 Best val accuracy: [0.4776315789473684, 0.44210526315789467, 0.4375, 0.2282894736842105, 0.32105263157894737, 0.4769736842105262, 0.44177631578947374, 0.4990131578947369, 0.505921052631579, 0.5358552631578947, 0.48355263157894746, 0.4894736842105264, 0.4552631578947368, 0.4720394736842105, 0.38453947368421054, 0.47006578947368416, 0.4180921052631579, 0.41217105263157894, 0.40625, 0.49177631578947373, 0.4598684210526316, 0.5006578947368421, 0.4898026315789473, 0.49078947368421055, 0.5046052631578948, 0.48355263157894746, 0.5200657894736842, 0.5305921052631579, 0.4513157894736842, 0.42598684210526316, 0.4480263157894737, 0.5161184210526315, 0.46644736842105267, 0.46875, 0.45756578947368415, 0.4220394736842105, 0.4213815789473684, 0.43717105263157896, 0.47171052631578947] Best val loss: 9.849786686897279


Current group: 0.2
Epoch [1/80], Training Loss: 44.1260, Validation Loss Current: 21.0543, Validation Loss AVG: 21.0543, lr: 0.001
Epoch [2/80], Training Loss: 29.2860, Validation Loss Current: 16.9074, Validation Loss AVG: 16.9074, lr: 0.001
Epoch [3/80], Training Loss: 22.8013, Validation Loss Current: 15.7850, Validation Loss AVG: 15.7850, lr: 0.001
Epoch [4/80], Training Loss: 17.6252, Validation Loss Current: 14.0575, Validation Loss AVG: 14.0575, lr: 0.001
Epoch [5/80], Training Loss: 13.5733, Validation Loss Current: 14.9013, Validation Loss AVG: 14.9013, lr: 0.001
Epoch [6/80], Training Loss: 11.1942, Validation Loss Current: 15.4399, Validation Loss AVG: 15.4399, lr: 0.001
Epoch [7/80], Training Loss: 10.3260, Validation Loss Current: 16.7975, Validation Loss AVG: 16.7975, lr: 0.001
Epoch [8/80], Training Loss: 17.9312, Validation Loss Current: 24.6381, Validation Loss AVG: 24.6381, lr: 0.001
Epoch [9/80], Training Loss: 14.4182, Validation Loss Current: 24.5101, Validation Loss AVG: 24.5101, lr: 0.001
Epoch [10/80], Training Loss: 11.3740, Validation Loss Current: 20.4313, Validation Loss AVG: 20.4313, lr: 0.001
Epoch [11/80], Training Loss: 8.4498, Validation Loss Current: 28.7628, Validation Loss AVG: 28.7628, lr: 0.001
Epoch [12/80], Training Loss: 10.0256, Validation Loss Current: 19.9050, Validation Loss AVG: 19.9050, lr: 0.001
Epoch [13/80], Training Loss: 10.1944, Validation Loss Current: 18.6044, Validation Loss AVG: 18.6044, lr: 0.001
Epoch [14/80], Training Loss: 7.1185, Validation Loss Current: 19.8498, Validation Loss AVG: 19.8498, lr: 0.001
Epoch [15/80], Training Loss: 8.6862, Validation Loss Current: 23.8477, Validation Loss AVG: 23.8477, lr: 0.001
Epoch [16/80], Training Loss: 9.7277, Validation Loss Current: 23.9706, Validation Loss AVG: 23.9706, lr: 0.001
Epoch [17/80], Training Loss: 7.3583, Validation Loss Current: 20.2908, Validation Loss AVG: 20.2908, lr: 0.001
Epoch [18/80], Training Loss: 7.1743, Validation Loss Current: 24.2314, Validation Loss AVG: 24.2314, lr: 0.001
Epoch [19/80], Training Loss: 5.1687, Validation Loss Current: 17.3570, Validation Loss AVG: 17.3570, lr: 0.001
Epoch [20/80], Training Loss: 3.7868, Validation Loss Current: 19.1760, Validation Loss AVG: 19.1760, lr: 0.001
Epoch [21/80], Training Loss: 4.7030, Validation Loss Current: 19.8919, Validation Loss AVG: 19.8919, lr: 0.001
Epoch [22/80], Training Loss: 2.6885, Validation Loss Current: 20.2571, Validation Loss AVG: 20.2571, lr: 0.001
Epoch [23/80], Training Loss: 2.1119, Validation Loss Current: 20.9909, Validation Loss AVG: 20.9909, lr: 0.001
Epoch [24/80], Training Loss: 3.7920, Validation Loss Current: 92.5207, Validation Loss AVG: 92.5207, lr: 0.001
Epoch [25/80], Training Loss: 16.1133, Validation Loss Current: 39.0748, Validation Loss AVG: 39.0748, lr: 0.001
Epoch [26/80], Training Loss: 13.4260, Validation Loss Current: 24.4896, Validation Loss AVG: 24.4896, lr: 0.001
Epoch [27/80], Training Loss: 12.4384, Validation Loss Current: 25.9858, Validation Loss AVG: 25.9858, lr: 0.001
Epoch [28/80], Training Loss: 6.8458, Validation Loss Current: 22.9851, Validation Loss AVG: 22.9851, lr: 0.001
Epoch [29/80], Training Loss: 6.3829, Validation Loss Current: 23.6666, Validation Loss AVG: 23.6666, lr: 0.001
Epoch [30/80], Training Loss: 11.5614, Validation Loss Current: 39.1988, Validation Loss AVG: 39.1988, lr: 0.001
Epoch [31/80], Training Loss: 8.9967, Validation Loss Current: 37.3350, Validation Loss AVG: 37.3350, lr: 0.001
Epoch [32/80], Training Loss: 8.1665, Validation Loss Current: 24.8053, Validation Loss AVG: 24.8053, lr: 0.001
Epoch [33/80], Training Loss: 10.5837, Validation Loss Current: 18.5173, Validation Loss AVG: 18.5173, lr: 0.001
Epoch [34/80], Training Loss: 5.1586, Validation Loss Current: 21.0909, Validation Loss AVG: 21.0909, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 4 Best val accuracy: [0.34769736842105264, 0.33322368421052634, 0.4115131578947368, 0.39934210526315794, 0.425, 0.39276315789473687, 0.3503289473684211, 0.2763157894736842, 0.2868421052631579, 0.34901315789473686, 0.24375, 0.35690789473684215, 0.3549342105263158, 0.4009868421052632, 0.3332236842105263, 0.3282894736842105, 0.3180921052631579, 0.30625, 0.43453947368421053, 0.4023026315789474, 0.37730263157894733, 0.38585526315789476, 0.4223684210526316, 0.16348684210526315, 0.19375, 0.3473684210526316, 0.24078947368421053, 0.35131578947368425, 0.2651315789473684, 0.19572368421052633, 0.1983552631578947, 0.28881578947368425, 0.37631578947368427, 0.3197368421052632] Best val loss: 14.057501196861267


Fold: 4
----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 41.3978, Validation Loss Current: 9.8935, Validation Loss AVG: 9.9649, lr: 0.001
Epoch [2/400], Training Loss: 38.5693, Validation Loss Current: 9.4745, Validation Loss AVG: 9.8592, lr: 0.001
Epoch [3/400], Training Loss: 37.3502, Validation Loss Current: 8.8523, Validation Loss AVG: 9.5373, lr: 0.001
Epoch [4/400], Training Loss: 35.6964, Validation Loss Current: 8.6759, Validation Loss AVG: 9.7038, lr: 0.001
Epoch [5/400], Training Loss: 34.0973, Validation Loss Current: 8.4103, Validation Loss AVG: 9.2499, lr: 0.001
Epoch [6/400], Training Loss: 32.6381, Validation Loss Current: 7.9681, Validation Loss AVG: 8.9926, lr: 0.001
Epoch [7/400], Training Loss: 31.5838, Validation Loss Current: 7.7283, Validation Loss AVG: 9.0862, lr: 0.001
Epoch [8/400], Training Loss: 29.8144, Validation Loss Current: 7.5151, Validation Loss AVG: 10.6623, lr: 0.001
Epoch [9/400], Training Loss: 29.7705, Validation Loss Current: 7.2065, Validation Loss AVG: 8.6918, lr: 0.001
Epoch [10/400], Training Loss: 28.2335, Validation Loss Current: 7.2950, Validation Loss AVG: 8.6518, lr: 0.001
Epoch [11/400], Training Loss: 27.3883, Validation Loss Current: 7.0615, Validation Loss AVG: 8.5338, lr: 0.001
Epoch [12/400], Training Loss: 27.4097, Validation Loss Current: 7.2106, Validation Loss AVG: 11.2761, lr: 0.001
Epoch [13/400], Training Loss: 26.1114, Validation Loss Current: 6.9949, Validation Loss AVG: 9.5515, lr: 0.001
Epoch [14/400], Training Loss: 24.4757, Validation Loss Current: 7.0888, Validation Loss AVG: 8.7888, lr: 0.001
Epoch [15/400], Training Loss: 24.4232, Validation Loss Current: 7.1949, Validation Loss AVG: 11.0804, lr: 0.001
Epoch [16/400], Training Loss: 22.8366, Validation Loss Current: 6.3565, Validation Loss AVG: 9.7316, lr: 0.001
Epoch [17/400], Training Loss: 22.1211, Validation Loss Current: 6.1823, Validation Loss AVG: 8.8785, lr: 0.001
Epoch [18/400], Training Loss: 22.7670, Validation Loss Current: 6.3346, Validation Loss AVG: 10.0818, lr: 0.001
Epoch [19/400], Training Loss: 21.3110, Validation Loss Current: 6.6318, Validation Loss AVG: 8.6531, lr: 0.001
Epoch [20/400], Training Loss: 20.9456, Validation Loss Current: 6.0811, Validation Loss AVG: 8.4854, lr: 0.001
Epoch [21/400], Training Loss: 20.0709, Validation Loss Current: 6.3066, Validation Loss AVG: 10.2502, lr: 0.001
Epoch [22/400], Training Loss: 19.8261, Validation Loss Current: 7.3091, Validation Loss AVG: 10.0691, lr: 0.001
Epoch [23/400], Training Loss: 20.2776, Validation Loss Current: 5.9527, Validation Loss AVG: 10.0465, lr: 0.001
Epoch [24/400], Training Loss: 17.9412, Validation Loss Current: 5.8048, Validation Loss AVG: 8.0969, lr: 0.001
Epoch [25/400], Training Loss: 17.3538, Validation Loss Current: 6.0976, Validation Loss AVG: 9.0208, lr: 0.001
Epoch [26/400], Training Loss: 17.6527, Validation Loss Current: 5.6398, Validation Loss AVG: 9.6157, lr: 0.001
Epoch [27/400], Training Loss: 15.9431, Validation Loss Current: 5.8043, Validation Loss AVG: 10.0146, lr: 0.001
Epoch [28/400], Training Loss: 15.5885, Validation Loss Current: 5.5332, Validation Loss AVG: 10.5121, lr: 0.001
Epoch [29/400], Training Loss: 14.7068, Validation Loss Current: 6.3489, Validation Loss AVG: 9.6920, lr: 0.001
Epoch [30/400], Training Loss: 13.7991, Validation Loss Current: 5.9578, Validation Loss AVG: 10.8113, lr: 0.001
Epoch [31/400], Training Loss: 12.6881, Validation Loss Current: 5.4789, Validation Loss AVG: 9.7129, lr: 0.001
Epoch [32/400], Training Loss: 12.3039, Validation Loss Current: 5.4357, Validation Loss AVG: 10.1716, lr: 0.001
Epoch [33/400], Training Loss: 13.3539, Validation Loss Current: 6.4081, Validation Loss AVG: 9.8917, lr: 0.001
Epoch [34/400], Training Loss: 13.5499, Validation Loss Current: 5.5724, Validation Loss AVG: 13.9359, lr: 0.001
Epoch [35/400], Training Loss: 13.6534, Validation Loss Current: 6.7910, Validation Loss AVG: 13.0981, lr: 0.001
Epoch [36/400], Training Loss: 12.4178, Validation Loss Current: 6.3598, Validation Loss AVG: 13.0249, lr: 0.001
Epoch [37/400], Training Loss: 10.9798, Validation Loss Current: 5.6864, Validation Loss AVG: 8.4248, lr: 0.001
Epoch [38/400], Training Loss: 9.8132, Validation Loss Current: 6.9711, Validation Loss AVG: 17.5684, lr: 0.001
Epoch [39/400], Training Loss: 12.2547, Validation Loss Current: 6.2225, Validation Loss AVG: 13.2296, lr: 0.001
Epoch [40/400], Training Loss: 11.2777, Validation Loss Current: 6.8673, Validation Loss AVG: 13.0691, lr: 0.001
Epoch [41/400], Training Loss: 11.7409, Validation Loss Current: 6.0477, Validation Loss AVG: 9.1747, lr: 0.001
Epoch [42/400], Training Loss: 10.8543, Validation Loss Current: 5.8914, Validation Loss AVG: 11.9719, lr: 0.001
Epoch [43/400], Training Loss: 7.5456, Validation Loss Current: 5.8966, Validation Loss AVG: 10.0775, lr: 0.001
Epoch [44/400], Training Loss: 7.4700, Validation Loss Current: 6.0721, Validation Loss AVG: 9.7058, lr: 0.001
Epoch [45/400], Training Loss: 7.2546, Validation Loss Current: 6.4570, Validation Loss AVG: 16.8330, lr: 0.001
Epoch [46/400], Training Loss: 7.9777, Validation Loss Current: 7.9094, Validation Loss AVG: 9.2820, lr: 0.001
Epoch [47/400], Training Loss: 7.5557, Validation Loss Current: 6.8481, Validation Loss AVG: 14.1880, lr: 0.001
Epoch [48/400], Training Loss: 9.3597, Validation Loss Current: 8.3519, Validation Loss AVG: 18.0325, lr: 0.001
Epoch [49/400], Training Loss: 12.8031, Validation Loss Current: 7.7733, Validation Loss AVG: 13.5436, lr: 0.001
Epoch [50/400], Training Loss: 6.6714, Validation Loss Current: 6.1614, Validation Loss AVG: 9.9486, lr: 0.001
Epoch [51/400], Training Loss: 6.5490, Validation Loss Current: 6.2786, Validation Loss AVG: 15.2247, lr: 0.001
Epoch [52/400], Training Loss: 5.9331, Validation Loss Current: 6.4206, Validation Loss AVG: 9.9004, lr: 0.001
Epoch [53/400], Training Loss: 4.9706, Validation Loss Current: 6.0761, Validation Loss AVG: 9.9325, lr: 0.001
Epoch [54/400], Training Loss: 4.1741, Validation Loss Current: 6.2559, Validation Loss AVG: 12.8875, lr: 0.001
Epoch [55/400], Training Loss: 3.4359, Validation Loss Current: 6.7879, Validation Loss AVG: 11.1288, lr: 0.001
Epoch [56/400], Training Loss: 2.1036, Validation Loss Current: 5.9413, Validation Loss AVG: 11.7035, lr: 0.001
Epoch [57/400], Training Loss: 1.9186, Validation Loss Current: 6.1654, Validation Loss AVG: 11.2864, lr: 0.001
Epoch [58/400], Training Loss: 1.8577, Validation Loss Current: 6.5488, Validation Loss AVG: 12.9474, lr: 0.001
Epoch [59/400], Training Loss: 2.4052, Validation Loss Current: 6.3889, Validation Loss AVG: 14.0485, lr: 0.001
Epoch [60/400], Training Loss: 2.5057, Validation Loss Current: 6.6534, Validation Loss AVG: 14.2423, lr: 0.001
Epoch [61/400], Training Loss: 2.1500, Validation Loss Current: 6.2224, Validation Loss AVG: 11.1302, lr: 0.001
Epoch [62/400], Training Loss: 4.0138, Validation Loss Current: 6.9794, Validation Loss AVG: 12.1375, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 32 Best val accuracy: [0.2911184210526316, 0.3305921052631579, 0.3569078947368421, 0.3717105263157895, 0.3930921052631579, 0.4144736842105263, 0.4407894736842105, 0.47368421052631576, 0.4967105263157895, 0.4868421052631579, 0.4901315789473684, 0.4901315789473684, 0.5263157894736842, 0.49835526315789475, 0.5049342105263158, 0.5592105263157895, 0.5641447368421053, 0.5493421052631579, 0.5592105263157895, 0.5460526315789473, 0.5773026315789473, 0.5279605263157895, 0.5921052631578947, 0.5805921052631579, 0.5921052631578947, 0.6069078947368421, 0.6019736842105263, 0.6101973684210527, 0.5805921052631579, 0.6085526315789473, 0.6365131578947368, 0.6233552631578947, 0.5756578947368421, 0.6200657894736842, 0.5460526315789473, 0.6134868421052632, 0.6365131578947368, 0.5411184210526315, 0.5904605263157895, 0.5723684210526315, 0.6052631578947368, 0.631578947368421, 0.600328947368421, 0.6085526315789473, 0.6085526315789473, 0.524671052631579, 0.5838815789473685, 0.5296052631578947, 0.5180921052631579, 0.6085526315789473, 0.6019736842105263, 0.6118421052631579, 0.6398026315789473, 0.6233552631578947, 0.6348684210526315, 0.6381578947368421, 0.6480263157894737, 0.6480263157894737, 0.6430921052631579, 0.625, 0.6381578947368421, 0.6167763157894737] Best val loss: 5.435702443122864


----- Training resnet18 with sequence: [1, 0.8] -----
Current group: 1
Epoch [1/200], Training Loss: 39.5659, Validation Loss Current: 9.7493, Validation Loss AVG: 9.8621, lr: 0.001
Epoch [2/200], Training Loss: 37.8156, Validation Loss Current: 9.3313, Validation Loss AVG: 9.7420, lr: 0.001
Epoch [3/200], Training Loss: 36.2007, Validation Loss Current: 8.8277, Validation Loss AVG: 9.5404, lr: 0.001
Epoch [4/200], Training Loss: 35.6272, Validation Loss Current: 8.6800, Validation Loss AVG: 9.3438, lr: 0.001
Epoch [5/200], Training Loss: 34.8001, Validation Loss Current: 8.2885, Validation Loss AVG: 9.3153, lr: 0.001
Epoch [6/200], Training Loss: 33.4870, Validation Loss Current: 8.1961, Validation Loss AVG: 9.0910, lr: 0.001
Epoch [7/200], Training Loss: 32.8886, Validation Loss Current: 8.0643, Validation Loss AVG: 9.0559, lr: 0.001
Epoch [8/200], Training Loss: 31.9258, Validation Loss Current: 7.9077, Validation Loss AVG: 9.0666, lr: 0.001
Epoch [9/200], Training Loss: 29.1545, Validation Loss Current: 7.5869, Validation Loss AVG: 8.9113, lr: 0.001
Epoch [10/200], Training Loss: 29.2069, Validation Loss Current: 7.2214, Validation Loss AVG: 8.8903, lr: 0.001
Epoch [11/200], Training Loss: 27.9349, Validation Loss Current: 7.1487, Validation Loss AVG: 8.5829, lr: 0.001
Epoch [12/200], Training Loss: 27.7495, Validation Loss Current: 7.3629, Validation Loss AVG: 9.0362, lr: 0.001
Epoch [13/200], Training Loss: 27.2339, Validation Loss Current: 6.8989, Validation Loss AVG: 8.4171, lr: 0.001
Epoch [14/200], Training Loss: 26.6782, Validation Loss Current: 7.5775, Validation Loss AVG: 11.8045, lr: 0.001
Epoch [15/200], Training Loss: 24.8487, Validation Loss Current: 7.3332, Validation Loss AVG: 9.6535, lr: 0.001
Epoch [16/200], Training Loss: 23.8889, Validation Loss Current: 6.6774, Validation Loss AVG: 8.7251, lr: 0.001
Epoch [17/200], Training Loss: 22.4836, Validation Loss Current: 6.5913, Validation Loss AVG: 8.3388, lr: 0.001
Epoch [18/200], Training Loss: 21.3074, Validation Loss Current: 6.3555, Validation Loss AVG: 9.2272, lr: 0.001
Epoch [19/200], Training Loss: 21.4275, Validation Loss Current: 6.1644, Validation Loss AVG: 8.7367, lr: 0.001
Epoch [20/200], Training Loss: 22.3912, Validation Loss Current: 7.8968, Validation Loss AVG: 13.0587, lr: 0.001
Epoch [21/200], Training Loss: 22.0848, Validation Loss Current: 6.4002, Validation Loss AVG: 10.9770, lr: 0.001
Epoch [22/200], Training Loss: 21.2200, Validation Loss Current: 6.6730, Validation Loss AVG: 10.6884, lr: 0.001
Epoch [23/200], Training Loss: 20.5743, Validation Loss Current: 6.1722, Validation Loss AVG: 8.7836, lr: 0.001
Epoch [24/200], Training Loss: 20.3698, Validation Loss Current: 6.7389, Validation Loss AVG: 8.5781, lr: 0.001
Epoch [25/200], Training Loss: 19.9913, Validation Loss Current: 6.2727, Validation Loss AVG: 10.8095, lr: 0.001
Epoch [26/200], Training Loss: 19.7017, Validation Loss Current: 6.2481, Validation Loss AVG: 8.1398, lr: 0.001
Epoch [27/200], Training Loss: 17.2997, Validation Loss Current: 5.9729, Validation Loss AVG: 9.1588, lr: 0.001
Epoch [28/200], Training Loss: 15.8173, Validation Loss Current: 6.4366, Validation Loss AVG: 11.2401, lr: 0.001
Epoch [29/200], Training Loss: 13.8962, Validation Loss Current: 5.7420, Validation Loss AVG: 9.4067, lr: 0.001
Epoch [30/200], Training Loss: 15.6873, Validation Loss Current: 6.8023, Validation Loss AVG: 11.3388, lr: 0.001
Epoch [31/200], Training Loss: 13.9906, Validation Loss Current: 6.4098, Validation Loss AVG: 9.0647, lr: 0.001
Epoch [32/200], Training Loss: 13.0836, Validation Loss Current: 5.4480, Validation Loss AVG: 8.4935, lr: 0.001
Epoch [33/200], Training Loss: 11.4562, Validation Loss Current: 5.6305, Validation Loss AVG: 10.3610, lr: 0.001
Epoch [34/200], Training Loss: 12.2748, Validation Loss Current: 6.5621, Validation Loss AVG: 9.7750, lr: 0.001
Epoch [35/200], Training Loss: 11.8151, Validation Loss Current: 6.1911, Validation Loss AVG: 9.0323, lr: 0.001
Epoch [36/200], Training Loss: 13.4215, Validation Loss Current: 6.5338, Validation Loss AVG: 10.5488, lr: 0.001
Epoch [37/200], Training Loss: 10.6412, Validation Loss Current: 6.1389, Validation Loss AVG: 10.8276, lr: 0.001
Epoch [38/200], Training Loss: 9.9348, Validation Loss Current: 6.9959, Validation Loss AVG: 9.8477, lr: 0.001
Epoch [39/200], Training Loss: 8.7412, Validation Loss Current: 5.4583, Validation Loss AVG: 9.6195, lr: 0.001
Epoch [40/200], Training Loss: 8.7329, Validation Loss Current: 5.6327, Validation Loss AVG: 11.5158, lr: 0.001
Epoch [41/200], Training Loss: 7.0201, Validation Loss Current: 5.9888, Validation Loss AVG: 11.4037, lr: 0.001
Epoch [42/200], Training Loss: 6.8095, Validation Loss Current: 5.5971, Validation Loss AVG: 9.1642, lr: 0.001
Epoch [43/200], Training Loss: 7.4805, Validation Loss Current: 6.2775, Validation Loss AVG: 11.6200, lr: 0.001
Epoch [44/200], Training Loss: 6.5590, Validation Loss Current: 7.2904, Validation Loss AVG: 12.8663, lr: 0.001
Epoch [45/200], Training Loss: 6.7132, Validation Loss Current: 6.7363, Validation Loss AVG: 9.9640, lr: 0.001
Epoch [46/200], Training Loss: 5.5553, Validation Loss Current: 6.2786, Validation Loss AVG: 9.2488, lr: 0.001
Epoch [47/200], Training Loss: 7.2016, Validation Loss Current: 7.7978, Validation Loss AVG: 12.1785, lr: 0.001
Epoch [48/200], Training Loss: 6.9972, Validation Loss Current: 6.8821, Validation Loss AVG: 12.2124, lr: 0.001
Epoch [49/200], Training Loss: 8.0753, Validation Loss Current: 6.9534, Validation Loss AVG: 13.0541, lr: 0.001
Epoch [50/200], Training Loss: 6.8455, Validation Loss Current: 7.2557, Validation Loss AVG: 11.6065, lr: 0.001
Epoch [51/200], Training Loss: 11.2394, Validation Loss Current: 8.0205, Validation Loss AVG: 12.4567, lr: 0.001
Epoch [52/200], Training Loss: 6.3786, Validation Loss Current: 6.6956, Validation Loss AVG: 11.8048, lr: 0.001
Epoch [53/200], Training Loss: 7.4637, Validation Loss Current: 6.5697, Validation Loss AVG: 11.0368, lr: 0.001
Epoch [54/200], Training Loss: 5.0773, Validation Loss Current: 7.5943, Validation Loss AVG: 15.9048, lr: 0.001
Epoch [55/200], Training Loss: 3.3925, Validation Loss Current: 5.7415, Validation Loss AVG: 10.1859, lr: 0.001
Epoch [56/200], Training Loss: 6.3750, Validation Loss Current: 7.8395, Validation Loss AVG: 14.2371, lr: 0.001
Epoch [57/200], Training Loss: 4.2893, Validation Loss Current: 7.4023, Validation Loss AVG: 11.5389, lr: 0.001
Epoch [58/200], Training Loss: 2.8334, Validation Loss Current: 6.2985, Validation Loss AVG: 10.5345, lr: 0.001
Epoch [59/200], Training Loss: 2.4112, Validation Loss Current: 6.1495, Validation Loss AVG: 11.7814, lr: 0.001
Epoch [60/200], Training Loss: 3.6972, Validation Loss Current: 6.8930, Validation Loss AVG: 13.9557, lr: 0.001
Epoch [61/200], Training Loss: 3.1031, Validation Loss Current: 6.3801, Validation Loss AVG: 14.0609, lr: 0.001
Epoch [62/200], Training Loss: 2.1155, Validation Loss Current: 6.2054, Validation Loss AVG: 11.7137, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 32 Best val accuracy: [0.26151315789473684, 0.34210526315789475, 0.35855263157894735, 0.37664473684210525, 0.40625, 0.4128289473684211, 0.4095394736842105, 0.4292763157894737, 0.44901315789473684, 0.4917763157894737, 0.5148026315789473, 0.5049342105263158, 0.5197368421052632, 0.45394736842105265, 0.5, 0.524671052631579, 0.5608552631578947, 0.5608552631578947, 0.5608552631578947, 0.48848684210526316, 0.5444078947368421, 0.537828947368421, 0.5740131578947368, 0.524671052631579, 0.5888157894736842, 0.5674342105263158, 0.6085526315789473, 0.5641447368421053, 0.618421052631579, 0.5707236842105263, 0.587171052631579, 0.6381578947368421, 0.6167763157894737, 0.5756578947368421, 0.6134868421052632, 0.5674342105263158, 0.59375, 0.5805921052631579, 0.6447368421052632, 0.6463815789473685, 0.6299342105263158, 0.6151315789473685, 0.6118421052631579, 0.587171052631579, 0.5707236842105263, 0.5970394736842105, 0.5986842105263158, 0.600328947368421, 0.5904605263157895, 0.5707236842105263, 0.5641447368421053, 0.6069078947368421, 0.618421052631579, 0.5822368421052632, 0.6611842105263158, 0.569078947368421, 0.5723684210526315, 0.6430921052631579, 0.6463815789473685, 0.6036184210526315, 0.6365131578947368, 0.6661184210526315] Best val loss: 5.447960257530212


Current group: 0.8
Epoch [1/200], Training Loss: 21.1891, Validation Loss Current: 15.1482, Validation Loss AVG: 15.1482, lr: 0.001
Epoch [2/200], Training Loss: 18.8953, Validation Loss Current: 12.8508, Validation Loss AVG: 12.8508, lr: 0.001
Epoch [3/200], Training Loss: 16.8114, Validation Loss Current: 10.8630, Validation Loss AVG: 10.8630, lr: 0.001
Epoch [4/200], Training Loss: 14.2601, Validation Loss Current: 12.0080, Validation Loss AVG: 12.0080, lr: 0.001
Epoch [5/200], Training Loss: 11.8439, Validation Loss Current: 10.1847, Validation Loss AVG: 10.1847, lr: 0.001
Epoch [6/200], Training Loss: 9.6842, Validation Loss Current: 12.2208, Validation Loss AVG: 12.2208, lr: 0.001
Epoch [7/200], Training Loss: 10.0003, Validation Loss Current: 10.5199, Validation Loss AVG: 10.5199, lr: 0.001
Epoch [8/200], Training Loss: 8.1367, Validation Loss Current: 11.0346, Validation Loss AVG: 11.0346, lr: 0.001
Epoch [9/200], Training Loss: 8.7537, Validation Loss Current: 14.9116, Validation Loss AVG: 14.9116, lr: 0.001
Epoch [10/200], Training Loss: 8.3516, Validation Loss Current: 13.2795, Validation Loss AVG: 13.2795, lr: 0.001
Epoch [11/200], Training Loss: 9.6941, Validation Loss Current: 11.5912, Validation Loss AVG: 11.5912, lr: 0.001
Epoch [12/200], Training Loss: 7.0124, Validation Loss Current: 12.3979, Validation Loss AVG: 12.3979, lr: 0.001
Epoch [13/200], Training Loss: 5.8368, Validation Loss Current: 12.3238, Validation Loss AVG: 12.3238, lr: 0.001
Epoch [14/200], Training Loss: 8.8399, Validation Loss Current: 13.2705, Validation Loss AVG: 13.2705, lr: 0.001
Epoch [15/200], Training Loss: 7.5869, Validation Loss Current: 12.6856, Validation Loss AVG: 12.6856, lr: 0.001
Epoch [16/200], Training Loss: 5.9640, Validation Loss Current: 13.1851, Validation Loss AVG: 13.1851, lr: 0.001
Epoch [17/200], Training Loss: 5.6333, Validation Loss Current: 9.4938, Validation Loss AVG: 9.4938, lr: 0.001
Epoch [18/200], Training Loss: 11.4226, Validation Loss Current: 10.9753, Validation Loss AVG: 10.9753, lr: 0.001
Epoch [19/200], Training Loss: 5.9608, Validation Loss Current: 12.4298, Validation Loss AVG: 12.4298, lr: 0.001
Epoch [20/200], Training Loss: 3.1615, Validation Loss Current: 12.7330, Validation Loss AVG: 12.7330, lr: 0.001
Epoch [21/200], Training Loss: 3.3771, Validation Loss Current: 10.8068, Validation Loss AVG: 10.8068, lr: 0.001
Epoch [22/200], Training Loss: 5.3232, Validation Loss Current: 11.8252, Validation Loss AVG: 11.8252, lr: 0.001
Epoch [23/200], Training Loss: 4.9445, Validation Loss Current: 15.6978, Validation Loss AVG: 15.6978, lr: 0.001
Epoch [24/200], Training Loss: 2.8893, Validation Loss Current: 13.5996, Validation Loss AVG: 13.5996, lr: 0.001
Epoch [25/200], Training Loss: 4.6442, Validation Loss Current: 14.6212, Validation Loss AVG: 14.6212, lr: 0.001
Epoch [26/200], Training Loss: 5.2200, Validation Loss Current: 15.5101, Validation Loss AVG: 15.5101, lr: 0.001
Epoch [27/200], Training Loss: 8.0548, Validation Loss Current: 11.8506, Validation Loss AVG: 11.8506, lr: 0.001
Epoch [28/200], Training Loss: 3.8247, Validation Loss Current: 16.3751, Validation Loss AVG: 16.3751, lr: 0.001
Epoch [29/200], Training Loss: 5.2384, Validation Loss Current: 13.5648, Validation Loss AVG: 13.5648, lr: 0.001
Epoch [30/200], Training Loss: 3.1064, Validation Loss Current: 12.7394, Validation Loss AVG: 12.7394, lr: 0.001
Epoch [31/200], Training Loss: 4.8334, Validation Loss Current: 19.8423, Validation Loss AVG: 19.8423, lr: 0.001
Epoch [32/200], Training Loss: 6.6580, Validation Loss Current: 12.9848, Validation Loss AVG: 12.9848, lr: 0.001
Epoch [33/200], Training Loss: 5.9261, Validation Loss Current: 12.5481, Validation Loss AVG: 12.5481, lr: 0.001
Epoch [34/200], Training Loss: 4.9306, Validation Loss Current: 14.1026, Validation Loss AVG: 14.1026, lr: 0.001
Epoch [35/200], Training Loss: 2.2001, Validation Loss Current: 14.1793, Validation Loss AVG: 14.1793, lr: 0.001
Epoch [36/200], Training Loss: 2.4772, Validation Loss Current: 13.5607, Validation Loss AVG: 13.5607, lr: 0.001
Epoch [37/200], Training Loss: 3.1700, Validation Loss Current: 13.9489, Validation Loss AVG: 13.9489, lr: 0.001
Epoch [38/200], Training Loss: 1.4155, Validation Loss Current: 12.2565, Validation Loss AVG: 12.2565, lr: 0.001
Epoch [39/200], Training Loss: 1.0065, Validation Loss Current: 12.7702, Validation Loss AVG: 12.7702, lr: 0.001
Epoch [40/200], Training Loss: 1.8353, Validation Loss Current: 13.2932, Validation Loss AVG: 13.2932, lr: 0.001
Epoch [41/200], Training Loss: 3.6142, Validation Loss Current: 14.8487, Validation Loss AVG: 14.8487, lr: 0.001
Epoch [42/200], Training Loss: 7.2619, Validation Loss Current: 11.6241, Validation Loss AVG: 11.6241, lr: 0.001
Epoch [43/200], Training Loss: 4.7881, Validation Loss Current: 13.4496, Validation Loss AVG: 13.4496, lr: 0.001
Epoch [44/200], Training Loss: 3.7558, Validation Loss Current: 12.1752, Validation Loss AVG: 12.1752, lr: 0.001
Epoch [45/200], Training Loss: 4.3605, Validation Loss Current: 13.0448, Validation Loss AVG: 13.0448, lr: 0.001
Epoch [46/200], Training Loss: 4.8605, Validation Loss Current: 12.9655, Validation Loss AVG: 12.9655, lr: 0.001
Epoch [47/200], Training Loss: 5.7084, Validation Loss Current: 16.4794, Validation Loss AVG: 16.4794, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 17 Best val accuracy: [0.3631578947368421, 0.39342105263157895, 0.41085526315789467, 0.3904605263157895, 0.46875, 0.41052631578947363, 0.4565789473684211, 0.44342105263157894, 0.39638157894736836, 0.40131578947368424, 0.4532894736842105, 0.4411184210526315, 0.4375, 0.3967105263157895, 0.40164473684210533, 0.4305921052631579, 0.44769736842105257, 0.4256578947368421, 0.4197368421052632, 0.42730263157894743, 0.4473684210526315, 0.44046052631578947, 0.42730263157894743, 0.4394736842105263, 0.4098684210526316, 0.4200657894736842, 0.4072368421052632, 0.4233552631578948, 0.4276315789473684, 0.4322368421052632, 0.3605263157894737, 0.4322368421052632, 0.40690789473684214, 0.42434210526315785, 0.4296052631578947, 0.4269736842105264, 0.39868421052631586, 0.4549342105263158, 0.4733552631578948, 0.44835526315789476, 0.4233552631578947, 0.4582236842105263, 0.3963815789473684, 0.4302631578947368, 0.4108552631578948, 0.42072368421052636, 0.3838815789473684] Best val loss: 9.493817567825317


----- Training resnet18 with sequence: [1, 0.8, 0.6] -----
Current group: 1
Epoch [1/134], Training Loss: 40.8602, Validation Loss Current: 9.8198, Validation Loss AVG: 9.9322, lr: 0.001
Epoch [2/134], Training Loss: 38.7123, Validation Loss Current: 9.4386, Validation Loss AVG: 10.0381, lr: 0.001
Epoch [3/134], Training Loss: 37.2869, Validation Loss Current: 9.0914, Validation Loss AVG: 9.7361, lr: 0.001
Epoch [4/134], Training Loss: 36.8304, Validation Loss Current: 8.8308, Validation Loss AVG: 9.5997, lr: 0.001
Epoch [5/134], Training Loss: 35.0329, Validation Loss Current: 8.6980, Validation Loss AVG: 9.2841, lr: 0.001
Epoch [6/134], Training Loss: 33.7625, Validation Loss Current: 8.3167, Validation Loss AVG: 9.2659, lr: 0.001
Epoch [7/134], Training Loss: 32.5771, Validation Loss Current: 8.0615, Validation Loss AVG: 8.9762, lr: 0.001
Epoch [8/134], Training Loss: 30.9297, Validation Loss Current: 7.6353, Validation Loss AVG: 9.3474, lr: 0.001
Epoch [9/134], Training Loss: 28.6355, Validation Loss Current: 7.5729, Validation Loss AVG: 9.4439, lr: 0.001
Epoch [10/134], Training Loss: 28.6867, Validation Loss Current: 7.1946, Validation Loss AVG: 9.5759, lr: 0.001
Epoch [11/134], Training Loss: 28.3659, Validation Loss Current: 7.0796, Validation Loss AVG: 10.4587, lr: 0.001
Epoch [12/134], Training Loss: 27.5186, Validation Loss Current: 7.1573, Validation Loss AVG: 9.9928, lr: 0.001
Epoch [13/134], Training Loss: 26.4331, Validation Loss Current: 6.7748, Validation Loss AVG: 8.9452, lr: 0.001
Epoch [14/134], Training Loss: 25.2338, Validation Loss Current: 6.7099, Validation Loss AVG: 8.7998, lr: 0.001
Epoch [15/134], Training Loss: 25.7611, Validation Loss Current: 6.9455, Validation Loss AVG: 9.6079, lr: 0.001
Epoch [16/134], Training Loss: 25.0284, Validation Loss Current: 7.6680, Validation Loss AVG: 13.3668, lr: 0.001
Epoch [17/134], Training Loss: 24.3177, Validation Loss Current: 7.0917, Validation Loss AVG: 9.9967, lr: 0.001
Epoch [18/134], Training Loss: 23.9128, Validation Loss Current: 6.8976, Validation Loss AVG: 9.4736, lr: 0.001
Epoch [19/134], Training Loss: 23.9004, Validation Loss Current: 6.4101, Validation Loss AVG: 8.7869, lr: 0.001
Epoch [20/134], Training Loss: 23.3428, Validation Loss Current: 7.3942, Validation Loss AVG: 9.0555, lr: 0.001
Epoch [21/134], Training Loss: 23.0952, Validation Loss Current: 6.3607, Validation Loss AVG: 9.7103, lr: 0.001
Epoch [22/134], Training Loss: 22.4740, Validation Loss Current: 6.8273, Validation Loss AVG: 9.9883, lr: 0.001
Epoch [23/134], Training Loss: 21.8408, Validation Loss Current: 6.0620, Validation Loss AVG: 9.2571, lr: 0.001
Epoch [24/134], Training Loss: 19.7367, Validation Loss Current: 5.9412, Validation Loss AVG: 9.8009, lr: 0.001
Epoch [25/134], Training Loss: 18.4392, Validation Loss Current: 6.0030, Validation Loss AVG: 9.9799, lr: 0.001
Epoch [26/134], Training Loss: 17.7065, Validation Loss Current: 5.7784, Validation Loss AVG: 8.5600, lr: 0.001
Epoch [27/134], Training Loss: 17.0925, Validation Loss Current: 5.7271, Validation Loss AVG: 8.2572, lr: 0.001
Epoch [28/134], Training Loss: 16.5197, Validation Loss Current: 5.9073, Validation Loss AVG: 8.4251, lr: 0.001
Epoch [29/134], Training Loss: 15.3921, Validation Loss Current: 5.7018, Validation Loss AVG: 9.2922, lr: 0.001
Epoch [30/134], Training Loss: 15.5608, Validation Loss Current: 7.8267, Validation Loss AVG: 13.1973, lr: 0.001
Epoch [31/134], Training Loss: 13.8534, Validation Loss Current: 5.7030, Validation Loss AVG: 8.9944, lr: 0.001
Epoch [32/134], Training Loss: 12.4612, Validation Loss Current: 5.4838, Validation Loss AVG: 9.2516, lr: 0.001
Epoch [33/134], Training Loss: 12.1832, Validation Loss Current: 5.8378, Validation Loss AVG: 10.4892, lr: 0.001
Epoch [34/134], Training Loss: 13.8637, Validation Loss Current: 5.6027, Validation Loss AVG: 8.0964, lr: 0.001
Epoch [35/134], Training Loss: 11.9205, Validation Loss Current: 5.7518, Validation Loss AVG: 10.4837, lr: 0.001
Epoch [36/134], Training Loss: 11.9644, Validation Loss Current: 5.6657, Validation Loss AVG: 9.1443, lr: 0.001
Epoch [37/134], Training Loss: 12.6328, Validation Loss Current: 6.3304, Validation Loss AVG: 10.7622, lr: 0.001
Epoch [38/134], Training Loss: 13.3057, Validation Loss Current: 6.7075, Validation Loss AVG: 8.9095, lr: 0.001
Epoch [39/134], Training Loss: 13.9829, Validation Loss Current: 6.3748, Validation Loss AVG: 10.2656, lr: 0.001
Epoch [40/134], Training Loss: 10.9538, Validation Loss Current: 6.2339, Validation Loss AVG: 10.8113, lr: 0.001
Epoch [41/134], Training Loss: 10.5535, Validation Loss Current: 6.3967, Validation Loss AVG: 11.6234, lr: 0.001
Epoch [42/134], Training Loss: 9.5988, Validation Loss Current: 5.7236, Validation Loss AVG: 10.5474, lr: 0.001
Epoch [43/134], Training Loss: 7.9511, Validation Loss Current: 5.5516, Validation Loss AVG: 8.2791, lr: 0.001
Epoch [44/134], Training Loss: 7.6409, Validation Loss Current: 5.9304, Validation Loss AVG: 10.6915, lr: 0.001
Epoch [45/134], Training Loss: 6.7989, Validation Loss Current: 6.0951, Validation Loss AVG: 8.9317, lr: 0.001
Epoch [46/134], Training Loss: 6.9898, Validation Loss Current: 6.3843, Validation Loss AVG: 10.8113, lr: 0.001
Epoch [47/134], Training Loss: 5.1698, Validation Loss Current: 6.2646, Validation Loss AVG: 10.6541, lr: 0.001
Epoch [48/134], Training Loss: 5.6506, Validation Loss Current: 6.6675, Validation Loss AVG: 10.5023, lr: 0.001
Epoch [49/134], Training Loss: 7.9351, Validation Loss Current: 6.3029, Validation Loss AVG: 11.5065, lr: 0.001
Epoch [50/134], Training Loss: 6.6979, Validation Loss Current: 6.8252, Validation Loss AVG: 12.3465, lr: 0.001
Epoch [51/134], Training Loss: 5.8243, Validation Loss Current: 6.7251, Validation Loss AVG: 16.2387, lr: 0.001
Epoch [52/134], Training Loss: 8.2665, Validation Loss Current: 6.5696, Validation Loss AVG: 12.3705, lr: 0.001
Epoch [53/134], Training Loss: 8.8064, Validation Loss Current: 6.8348, Validation Loss AVG: 10.9253, lr: 0.001
Epoch [54/134], Training Loss: 6.0212, Validation Loss Current: 6.6762, Validation Loss AVG: 10.7392, lr: 0.001
Epoch [55/134], Training Loss: 5.9196, Validation Loss Current: 5.9091, Validation Loss AVG: 11.6517, lr: 0.001
Epoch [56/134], Training Loss: 7.3217, Validation Loss Current: 6.5068, Validation Loss AVG: 10.7353, lr: 0.001
Epoch [57/134], Training Loss: 4.7127, Validation Loss Current: 6.9327, Validation Loss AVG: 12.7495, lr: 0.001
Epoch [58/134], Training Loss: 3.9801, Validation Loss Current: 5.8810, Validation Loss AVG: 13.1905, lr: 0.001
Epoch [59/134], Training Loss: 2.4454, Validation Loss Current: 6.2969, Validation Loss AVG: 13.0612, lr: 0.001
Epoch [60/134], Training Loss: 4.9375, Validation Loss Current: 6.2299, Validation Loss AVG: 10.9473, lr: 0.001
Epoch [61/134], Training Loss: 2.6800, Validation Loss Current: 7.0552, Validation Loss AVG: 15.0511, lr: 0.001
Epoch [62/134], Training Loss: 4.0140, Validation Loss Current: 6.2719, Validation Loss AVG: 13.3817, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 32 Best val accuracy: [0.26151315789473684, 0.3223684210526316, 0.3338815789473684, 0.3569078947368421, 0.36019736842105265, 0.3881578947368421, 0.3881578947368421, 0.45230263157894735, 0.4605263157894737, 0.5032894736842105, 0.5213815789473685, 0.5032894736842105, 0.5263157894736842, 0.524671052631579, 0.5, 0.48519736842105265, 0.524671052631579, 0.5115131578947368, 0.5361842105263158, 0.4720394736842105, 0.587171052631579, 0.53125, 0.5789473684210527, 0.5740131578947368, 0.5674342105263158, 0.5756578947368421, 0.5888157894736842, 0.600328947368421, 0.6019736842105263, 0.5164473684210527, 0.6200657894736842, 0.6282894736842105, 0.6019736842105263, 0.6134868421052632, 0.5970394736842105, 0.5986842105263158, 0.5789473684210527, 0.5608552631578947, 0.569078947368421, 0.5805921052631579, 0.5773026315789473, 0.6233552631578947, 0.6233552631578947, 0.6101973684210527, 0.6101973684210527, 0.5921052631578947, 0.6101973684210527, 0.6019736842105263, 0.6134868421052632, 0.5855263157894737, 0.6069078947368421, 0.6085526315789473, 0.5838815789473685, 0.6118421052631579, 0.625, 0.6101973684210527, 0.5986842105263158, 0.625, 0.6217105263157895, 0.6348684210526315, 0.5904605263157895, 0.6282894736842105] Best val loss: 5.483750641345978


Current group: 0.8
Epoch [1/134], Training Loss: 20.8743, Validation Loss Current: 8.7435, Validation Loss AVG: 8.7435, lr: 0.001
Epoch [2/134], Training Loss: 18.8164, Validation Loss Current: 10.9742, Validation Loss AVG: 10.9742, lr: 0.001
Epoch [3/134], Training Loss: 13.9378, Validation Loss Current: 12.6261, Validation Loss AVG: 12.6261, lr: 0.001
Epoch [4/134], Training Loss: 13.3147, Validation Loss Current: 9.4251, Validation Loss AVG: 9.4251, lr: 0.001
Epoch [5/134], Training Loss: 10.2458, Validation Loss Current: 10.2154, Validation Loss AVG: 10.2154, lr: 0.001
Epoch [6/134], Training Loss: 9.8415, Validation Loss Current: 8.6789, Validation Loss AVG: 8.6789, lr: 0.001
Epoch [7/134], Training Loss: 9.2157, Validation Loss Current: 8.6519, Validation Loss AVG: 8.6519, lr: 0.001
Epoch [8/134], Training Loss: 8.5352, Validation Loss Current: 12.3613, Validation Loss AVG: 12.3613, lr: 0.001
Epoch [9/134], Training Loss: 7.4295, Validation Loss Current: 9.9846, Validation Loss AVG: 9.9846, lr: 0.001
Epoch [10/134], Training Loss: 6.8255, Validation Loss Current: 9.1489, Validation Loss AVG: 9.1489, lr: 0.001
Epoch [11/134], Training Loss: 11.8244, Validation Loss Current: 16.1826, Validation Loss AVG: 16.1826, lr: 0.001
Epoch [12/134], Training Loss: 20.0674, Validation Loss Current: 10.5019, Validation Loss AVG: 10.5019, lr: 0.001
Epoch [13/134], Training Loss: 11.7589, Validation Loss Current: 13.4678, Validation Loss AVG: 13.4678, lr: 0.001
Epoch [14/134], Training Loss: 7.3461, Validation Loss Current: 12.0292, Validation Loss AVG: 12.0292, lr: 0.001
Epoch [15/134], Training Loss: 4.5661, Validation Loss Current: 11.6000, Validation Loss AVG: 11.6000, lr: 0.001
Epoch [16/134], Training Loss: 6.8177, Validation Loss Current: 11.5757, Validation Loss AVG: 11.5757, lr: 0.001
Epoch [17/134], Training Loss: 4.1843, Validation Loss Current: 10.7301, Validation Loss AVG: 10.7301, lr: 0.001
Epoch [18/134], Training Loss: 5.2275, Validation Loss Current: 12.8496, Validation Loss AVG: 12.8496, lr: 0.001
Epoch [19/134], Training Loss: 5.8864, Validation Loss Current: 10.0888, Validation Loss AVG: 10.0888, lr: 0.001
Epoch [20/134], Training Loss: 5.7651, Validation Loss Current: 12.0244, Validation Loss AVG: 12.0244, lr: 0.001
Epoch [21/134], Training Loss: 4.9584, Validation Loss Current: 16.2199, Validation Loss AVG: 16.2199, lr: 0.001
Epoch [22/134], Training Loss: 6.5030, Validation Loss Current: 9.3707, Validation Loss AVG: 9.3707, lr: 0.001
Epoch [23/134], Training Loss: 5.8161, Validation Loss Current: 14.7647, Validation Loss AVG: 14.7647, lr: 0.001
Epoch [24/134], Training Loss: 4.7801, Validation Loss Current: 12.3547, Validation Loss AVG: 12.3547, lr: 0.001
Epoch [25/134], Training Loss: 4.2878, Validation Loss Current: 13.6912, Validation Loss AVG: 13.6912, lr: 0.001
Epoch [26/134], Training Loss: 3.2817, Validation Loss Current: 11.6396, Validation Loss AVG: 11.6396, lr: 0.001
Epoch [27/134], Training Loss: 3.9038, Validation Loss Current: 13.1117, Validation Loss AVG: 13.1117, lr: 0.001
Epoch [28/134], Training Loss: 2.9027, Validation Loss Current: 10.7770, Validation Loss AVG: 10.7770, lr: 0.001
Epoch [29/134], Training Loss: 2.4568, Validation Loss Current: 12.1459, Validation Loss AVG: 12.1459, lr: 0.001
Epoch [30/134], Training Loss: 4.2485, Validation Loss Current: 10.2993, Validation Loss AVG: 10.2993, lr: 0.001
Epoch [31/134], Training Loss: 7.7228, Validation Loss Current: 13.1120, Validation Loss AVG: 13.1120, lr: 0.001
Epoch [32/134], Training Loss: 4.0372, Validation Loss Current: 12.4412, Validation Loss AVG: 12.4412, lr: 0.001
Epoch [33/134], Training Loss: 5.6344, Validation Loss Current: 13.6351, Validation Loss AVG: 13.6351, lr: 0.001
Epoch [34/134], Training Loss: 7.9991, Validation Loss Current: 10.3482, Validation Loss AVG: 10.3482, lr: 0.001
Epoch [35/134], Training Loss: 8.2455, Validation Loss Current: 12.3390, Validation Loss AVG: 12.3390, lr: 0.001
Epoch [36/134], Training Loss: 3.5806, Validation Loss Current: 12.3785, Validation Loss AVG: 12.3785, lr: 0.001
Epoch [37/134], Training Loss: 3.4933, Validation Loss Current: 12.8735, Validation Loss AVG: 12.8735, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 7 Best val accuracy: [0.45921052631578957, 0.4131578947368422, 0.4391447368421053, 0.42993421052631586, 0.46118421052631586, 0.4542763157894737, 0.4697368421052632, 0.42960526315789477, 0.47796052631578945, 0.47171052631578947, 0.368421052631579, 0.40559210526315786, 0.4164473684210527, 0.4375, 0.4552631578947368, 0.45131578947368417, 0.4427631578947369, 0.42828947368421055, 0.45592105263157895, 0.4621710526315789, 0.4197368421052631, 0.46315789473684205, 0.4266447368421053, 0.4430921052631579, 0.41776315789473684, 0.4766447368421053, 0.4427631578947368, 0.46381578947368424, 0.45559210526315785, 0.4536184210526316, 0.4447368421052632, 0.4569078947368421, 0.46809210526315786, 0.45, 0.43881578947368416, 0.4608552631578947, 0.4546052631578947] Best val loss: 8.651885652542115


Current group: 0.6
Epoch [1/134], Training Loss: 25.4847, Validation Loss Current: 9.8421, Validation Loss AVG: 9.8421, lr: 0.001
Epoch [2/134], Training Loss: 16.4465, Validation Loss Current: 10.6655, Validation Loss AVG: 10.6655, lr: 0.001
Epoch [3/134], Training Loss: 15.4384, Validation Loss Current: 12.9843, Validation Loss AVG: 12.9843, lr: 0.001
Epoch [4/134], Training Loss: 14.3046, Validation Loss Current: 10.1585, Validation Loss AVG: 10.1585, lr: 0.001
Epoch [5/134], Training Loss: 10.8626, Validation Loss Current: 9.3038, Validation Loss AVG: 9.3038, lr: 0.001
Epoch [6/134], Training Loss: 10.0342, Validation Loss Current: 11.3961, Validation Loss AVG: 11.3961, lr: 0.001
Epoch [7/134], Training Loss: 7.9243, Validation Loss Current: 9.3270, Validation Loss AVG: 9.3270, lr: 0.001
Epoch [8/134], Training Loss: 5.4276, Validation Loss Current: 10.6161, Validation Loss AVG: 10.6161, lr: 0.001
Epoch [9/134], Training Loss: 4.3058, Validation Loss Current: 10.8361, Validation Loss AVG: 10.8361, lr: 0.001
Epoch [10/134], Training Loss: 5.7524, Validation Loss Current: 13.3204, Validation Loss AVG: 13.3204, lr: 0.001
Epoch [11/134], Training Loss: 5.6658, Validation Loss Current: 10.9913, Validation Loss AVG: 10.9913, lr: 0.001
Epoch [12/134], Training Loss: 6.7211, Validation Loss Current: 12.8779, Validation Loss AVG: 12.8779, lr: 0.001
Epoch [13/134], Training Loss: 3.9474, Validation Loss Current: 14.4591, Validation Loss AVG: 14.4591, lr: 0.001
Epoch [14/134], Training Loss: 4.1979, Validation Loss Current: 11.8026, Validation Loss AVG: 11.8026, lr: 0.001
Epoch [15/134], Training Loss: 3.0867, Validation Loss Current: 11.1949, Validation Loss AVG: 11.1949, lr: 0.001
Epoch [16/134], Training Loss: 3.6946, Validation Loss Current: 10.9831, Validation Loss AVG: 10.9831, lr: 0.001
Epoch [17/134], Training Loss: 6.8127, Validation Loss Current: 11.6182, Validation Loss AVG: 11.6182, lr: 0.001
Epoch [18/134], Training Loss: 4.1084, Validation Loss Current: 12.9630, Validation Loss AVG: 12.9630, lr: 0.001
Epoch [19/134], Training Loss: 2.2794, Validation Loss Current: 10.3067, Validation Loss AVG: 10.3067, lr: 0.001
Epoch [20/134], Training Loss: 1.2072, Validation Loss Current: 11.3880, Validation Loss AVG: 11.3880, lr: 0.001
Epoch [21/134], Training Loss: 1.0467, Validation Loss Current: 11.0534, Validation Loss AVG: 11.0534, lr: 0.001
Epoch [22/134], Training Loss: 1.0969, Validation Loss Current: 10.2397, Validation Loss AVG: 10.2397, lr: 0.001
Epoch [23/134], Training Loss: 1.6375, Validation Loss Current: 11.1356, Validation Loss AVG: 11.1356, lr: 0.001
Epoch [24/134], Training Loss: 2.6944, Validation Loss Current: 12.0217, Validation Loss AVG: 12.0217, lr: 0.001
Epoch [25/134], Training Loss: 1.6964, Validation Loss Current: 12.1397, Validation Loss AVG: 12.1397, lr: 0.001
Epoch [26/134], Training Loss: 2.5733, Validation Loss Current: 11.7446, Validation Loss AVG: 11.7446, lr: 0.001
Epoch [27/134], Training Loss: 1.2675, Validation Loss Current: 10.8540, Validation Loss AVG: 10.8540, lr: 0.001
Epoch [28/134], Training Loss: 0.8864, Validation Loss Current: 11.2072, Validation Loss AVG: 11.2072, lr: 0.001
Epoch [29/134], Training Loss: 0.6771, Validation Loss Current: 11.9176, Validation Loss AVG: 11.9176, lr: 0.001
Epoch [30/134], Training Loss: 0.8578, Validation Loss Current: 11.7117, Validation Loss AVG: 11.7117, lr: 0.001
Epoch [31/134], Training Loss: 5.2668, Validation Loss Current: 14.2428, Validation Loss AVG: 14.2428, lr: 0.001
Epoch [32/134], Training Loss: 8.6773, Validation Loss Current: 14.2994, Validation Loss AVG: 14.2994, lr: 0.001
Epoch [33/134], Training Loss: 8.0514, Validation Loss Current: 12.7139, Validation Loss AVG: 12.7139, lr: 0.001
Epoch [34/134], Training Loss: 5.8188, Validation Loss Current: 11.4685, Validation Loss AVG: 11.4685, lr: 0.001
Epoch [35/134], Training Loss: 3.7671, Validation Loss Current: 12.3063, Validation Loss AVG: 12.3063, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 5 Best val accuracy: [0.4845394736842105, 0.43322368421052626, 0.43322368421052626, 0.4802631578947369, 0.47171052631578947, 0.4375, 0.4930921052631579, 0.48848684210526316, 0.48125, 0.4355263157894737, 0.49144736842105263, 0.45328947368421063, 0.4203947368421053, 0.48519736842105265, 0.4953947368421052, 0.49144736842105263, 0.47138157894736843, 0.4473684210526315, 0.475, 0.5042763157894737, 0.5131578947368421, 0.5032894736842105, 0.5085526315789474, 0.48848684210526316, 0.475, 0.49243421052631586, 0.5289473684210526, 0.5230263157894737, 0.5151315789473684, 0.5154605263157895, 0.4720394736842105, 0.4391447368421053, 0.46578947368421053, 0.47960526315789476, 0.48881578947368415] Best val loss: 9.303845834732055


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4] -----
Current group: 1
Epoch [1/100], Training Loss: 41.2782, Validation Loss Current: 9.9056, Validation Loss AVG: 9.9786, lr: 0.001
Epoch [2/100], Training Loss: 39.3998, Validation Loss Current: 9.4824, Validation Loss AVG: 9.8145, lr: 0.001
Epoch [3/100], Training Loss: 37.0824, Validation Loss Current: 8.8947, Validation Loss AVG: 9.5880, lr: 0.001
Epoch [4/100], Training Loss: 35.9612, Validation Loss Current: 8.6177, Validation Loss AVG: 9.5504, lr: 0.001
Epoch [5/100], Training Loss: 34.8746, Validation Loss Current: 8.4299, Validation Loss AVG: 9.4017, lr: 0.001
Epoch [6/100], Training Loss: 33.2341, Validation Loss Current: 8.0936, Validation Loss AVG: 9.2080, lr: 0.001
Epoch [7/100], Training Loss: 32.4294, Validation Loss Current: 8.0156, Validation Loss AVG: 9.5894, lr: 0.001
Epoch [8/100], Training Loss: 30.6224, Validation Loss Current: 7.8232, Validation Loss AVG: 9.6164, lr: 0.001
Epoch [9/100], Training Loss: 29.2856, Validation Loss Current: 7.3848, Validation Loss AVG: 8.6640, lr: 0.001
Epoch [10/100], Training Loss: 28.2479, Validation Loss Current: 7.4136, Validation Loss AVG: 9.9782, lr: 0.001
Epoch [11/100], Training Loss: 27.2827, Validation Loss Current: 7.4321, Validation Loss AVG: 9.9644, lr: 0.001
Epoch [12/100], Training Loss: 26.9359, Validation Loss Current: 7.1495, Validation Loss AVG: 10.7376, lr: 0.001
Epoch [13/100], Training Loss: 25.8083, Validation Loss Current: 7.7534, Validation Loss AVG: 9.2530, lr: 0.001
Epoch [14/100], Training Loss: 25.2662, Validation Loss Current: 7.0545, Validation Loss AVG: 9.2627, lr: 0.001
Epoch [15/100], Training Loss: 26.1534, Validation Loss Current: 7.3053, Validation Loss AVG: 10.8724, lr: 0.001
Epoch [16/100], Training Loss: 24.6834, Validation Loss Current: 7.4706, Validation Loss AVG: 11.5767, lr: 0.001
Epoch [17/100], Training Loss: 25.8477, Validation Loss Current: 7.3946, Validation Loss AVG: 9.0079, lr: 0.001
Epoch [18/100], Training Loss: 24.8800, Validation Loss Current: 6.7166, Validation Loss AVG: 9.7815, lr: 0.001
Epoch [19/100], Training Loss: 22.1082, Validation Loss Current: 6.5706, Validation Loss AVG: 11.5580, lr: 0.001
Epoch [20/100], Training Loss: 21.4381, Validation Loss Current: 6.2906, Validation Loss AVG: 9.1367, lr: 0.001
Epoch [21/100], Training Loss: 20.0633, Validation Loss Current: 6.4731, Validation Loss AVG: 11.0336, lr: 0.001
Epoch [22/100], Training Loss: 19.1795, Validation Loss Current: 6.0746, Validation Loss AVG: 9.0073, lr: 0.001
Epoch [23/100], Training Loss: 19.3343, Validation Loss Current: 7.2673, Validation Loss AVG: 10.8723, lr: 0.001
Epoch [24/100], Training Loss: 18.3688, Validation Loss Current: 6.3051, Validation Loss AVG: 10.4120, lr: 0.001
Epoch [25/100], Training Loss: 18.0732, Validation Loss Current: 5.9595, Validation Loss AVG: 10.1579, lr: 0.001
Epoch [26/100], Training Loss: 16.2265, Validation Loss Current: 5.9944, Validation Loss AVG: 9.2688, lr: 0.001
Epoch [27/100], Training Loss: 16.2304, Validation Loss Current: 6.0668, Validation Loss AVG: 10.7388, lr: 0.001
Epoch [28/100], Training Loss: 17.7428, Validation Loss Current: 9.4624, Validation Loss AVG: 14.8697, lr: 0.001
Epoch [29/100], Training Loss: 16.9391, Validation Loss Current: 6.1638, Validation Loss AVG: 9.5116, lr: 0.001
Epoch [30/100], Training Loss: 16.2682, Validation Loss Current: 5.7938, Validation Loss AVG: 10.7482, lr: 0.001
Epoch [31/100], Training Loss: 13.5462, Validation Loss Current: 6.0702, Validation Loss AVG: 9.0241, lr: 0.001
Epoch [32/100], Training Loss: 14.4159, Validation Loss Current: 5.9837, Validation Loss AVG: 9.2486, lr: 0.001
Epoch [33/100], Training Loss: 13.2824, Validation Loss Current: 6.1725, Validation Loss AVG: 8.5182, lr: 0.001
Epoch [34/100], Training Loss: 11.9006, Validation Loss Current: 5.7426, Validation Loss AVG: 8.6829, lr: 0.001
Epoch [35/100], Training Loss: 10.5234, Validation Loss Current: 5.7157, Validation Loss AVG: 9.7737, lr: 0.001
Epoch [36/100], Training Loss: 11.4233, Validation Loss Current: 7.0465, Validation Loss AVG: 13.7798, lr: 0.001
Epoch [37/100], Training Loss: 11.7893, Validation Loss Current: 6.1283, Validation Loss AVG: 9.5553, lr: 0.001
Epoch [38/100], Training Loss: 11.9436, Validation Loss Current: 7.4158, Validation Loss AVG: 13.9069, lr: 0.001
Epoch [39/100], Training Loss: 13.9320, Validation Loss Current: 6.7610, Validation Loss AVG: 13.1249, lr: 0.001
Epoch [40/100], Training Loss: 13.1080, Validation Loss Current: 6.4258, Validation Loss AVG: 10.1662, lr: 0.001
Epoch [41/100], Training Loss: 12.6770, Validation Loss Current: 6.7226, Validation Loss AVG: 12.4796, lr: 0.001
Epoch [42/100], Training Loss: 10.5183, Validation Loss Current: 6.3048, Validation Loss AVG: 9.1696, lr: 0.001
Epoch [43/100], Training Loss: 7.7957, Validation Loss Current: 5.9096, Validation Loss AVG: 11.9001, lr: 0.001
Epoch [44/100], Training Loss: 8.4814, Validation Loss Current: 6.0632, Validation Loss AVG: 11.9522, lr: 0.001
Epoch [45/100], Training Loss: 8.9000, Validation Loss Current: 9.0415, Validation Loss AVG: 12.7765, lr: 0.001
Epoch [46/100], Training Loss: 10.2734, Validation Loss Current: 7.2315, Validation Loss AVG: 13.2328, lr: 0.001
Epoch [47/100], Training Loss: 7.0489, Validation Loss Current: 6.4076, Validation Loss AVG: 11.8176, lr: 0.001
Epoch [48/100], Training Loss: 5.5957, Validation Loss Current: 6.2372, Validation Loss AVG: 11.8880, lr: 0.001
Epoch [49/100], Training Loss: 7.7923, Validation Loss Current: 6.8322, Validation Loss AVG: 14.1598, lr: 0.001
Epoch [50/100], Training Loss: 7.1123, Validation Loss Current: 6.5117, Validation Loss AVG: 15.2025, lr: 0.001
Epoch [51/100], Training Loss: 6.6333, Validation Loss Current: 6.6047, Validation Loss AVG: 11.7960, lr: 0.001
Epoch [52/100], Training Loss: 5.4263, Validation Loss Current: 6.2627, Validation Loss AVG: 11.1795, lr: 0.001
Epoch [53/100], Training Loss: 3.9555, Validation Loss Current: 6.6115, Validation Loss AVG: 12.8585, lr: 0.001
Epoch [54/100], Training Loss: 2.9821, Validation Loss Current: 6.6872, Validation Loss AVG: 13.4980, lr: 0.001
Epoch [55/100], Training Loss: 3.4809, Validation Loss Current: 7.9732, Validation Loss AVG: 11.9702, lr: 0.001
Epoch [56/100], Training Loss: 9.8079, Validation Loss Current: 7.8470, Validation Loss AVG: 12.7851, lr: 0.001
Epoch [57/100], Training Loss: 7.1777, Validation Loss Current: 7.1146, Validation Loss AVG: 13.7634, lr: 0.001
Epoch [58/100], Training Loss: 6.6671, Validation Loss Current: 7.6897, Validation Loss AVG: 11.9052, lr: 0.001
Epoch [59/100], Training Loss: 6.3012, Validation Loss Current: 6.9780, Validation Loss AVG: 12.3538, lr: 0.001
Epoch [60/100], Training Loss: 3.4731, Validation Loss Current: 6.7893, Validation Loss AVG: 11.2666, lr: 0.001
Epoch [61/100], Training Loss: 3.7192, Validation Loss Current: 6.6025, Validation Loss AVG: 10.6134, lr: 0.001
Epoch [62/100], Training Loss: 4.4683, Validation Loss Current: 7.8079, Validation Loss AVG: 15.4334, lr: 0.001
Epoch [63/100], Training Loss: 7.7835, Validation Loss Current: 7.6095, Validation Loss AVG: 12.7172, lr: 0.001
Epoch [64/100], Training Loss: 5.7379, Validation Loss Current: 7.8677, Validation Loss AVG: 11.8022, lr: 0.001
Epoch [65/100], Training Loss: 4.7863, Validation Loss Current: 8.1006, Validation Loss AVG: 15.8715, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 35 Best val accuracy: [0.26480263157894735, 0.3092105263157895, 0.36348684210526316, 0.37664473684210525, 0.39144736842105265, 0.43256578947368424, 0.4161184210526316, 0.43585526315789475, 0.4967105263157895, 0.4967105263157895, 0.48355263157894735, 0.4934210526315789, 0.45723684210526316, 0.5, 0.4967105263157895, 0.5016447368421053, 0.4753289473684211, 0.537828947368421, 0.5263157894736842, 0.5805921052631579, 0.5526315789473685, 0.5838815789473685, 0.5608552631578947, 0.5805921052631579, 0.5921052631578947, 0.6036184210526315, 0.587171052631579, 0.4506578947368421, 0.5888157894736842, 0.625, 0.5805921052631579, 0.5855263157894737, 0.5970394736842105, 0.6151315789473685, 0.6151315789473685, 0.5444078947368421, 0.5953947368421053, 0.5098684210526315, 0.5756578947368421, 0.5921052631578947, 0.5986842105263158, 0.5838815789473685, 0.6266447368421053, 0.5822368421052632, 0.5115131578947368, 0.5608552631578947, 0.6200657894736842, 0.600328947368421, 0.5707236842105263, 0.6036184210526315, 0.5838815789473685, 0.6200657894736842, 0.6200657894736842, 0.5888157894736842, 0.5394736842105263, 0.5444078947368421, 0.5921052631578947, 0.5723684210526315, 0.6151315789473685, 0.6069078947368421, 0.6101973684210527, 0.5657894736842105, 0.5592105263157895, 0.5608552631578947, 0.5674342105263158] Best val loss: 5.715744972229004


Current group: 0.8
Epoch [1/100], Training Loss: 21.5527, Validation Loss Current: 10.0657, Validation Loss AVG: 10.0657, lr: 0.001
Epoch [2/100], Training Loss: 15.2677, Validation Loss Current: 12.9238, Validation Loss AVG: 12.9238, lr: 0.001
Epoch [3/100], Training Loss: 13.9872, Validation Loss Current: 13.6457, Validation Loss AVG: 13.6457, lr: 0.001
Epoch [4/100], Training Loss: 11.7218, Validation Loss Current: 12.6355, Validation Loss AVG: 12.6355, lr: 0.001
Epoch [5/100], Training Loss: 8.0995, Validation Loss Current: 9.5021, Validation Loss AVG: 9.5021, lr: 0.001
Epoch [6/100], Training Loss: 7.3422, Validation Loss Current: 10.3668, Validation Loss AVG: 10.3668, lr: 0.001
Epoch [7/100], Training Loss: 7.8543, Validation Loss Current: 9.8181, Validation Loss AVG: 9.8181, lr: 0.001
Epoch [8/100], Training Loss: 6.3654, Validation Loss Current: 10.5717, Validation Loss AVG: 10.5717, lr: 0.001
Epoch [9/100], Training Loss: 6.4864, Validation Loss Current: 12.6693, Validation Loss AVG: 12.6693, lr: 0.001
Epoch [10/100], Training Loss: 4.7080, Validation Loss Current: 11.1398, Validation Loss AVG: 11.1398, lr: 0.001
Epoch [11/100], Training Loss: 5.7164, Validation Loss Current: 11.9595, Validation Loss AVG: 11.9595, lr: 0.001
Epoch [12/100], Training Loss: 6.0998, Validation Loss Current: 10.9623, Validation Loss AVG: 10.9623, lr: 0.001
Epoch [13/100], Training Loss: 5.2552, Validation Loss Current: 11.0658, Validation Loss AVG: 11.0658, lr: 0.001
Epoch [14/100], Training Loss: 3.9923, Validation Loss Current: 10.7932, Validation Loss AVG: 10.7932, lr: 0.001
Epoch [15/100], Training Loss: 4.7114, Validation Loss Current: 9.8299, Validation Loss AVG: 9.8299, lr: 0.001
Epoch [16/100], Training Loss: 3.2343, Validation Loss Current: 11.3718, Validation Loss AVG: 11.3718, lr: 0.001
Epoch [17/100], Training Loss: 2.5659, Validation Loss Current: 10.2794, Validation Loss AVG: 10.2794, lr: 0.001
Epoch [18/100], Training Loss: 3.4238, Validation Loss Current: 11.7839, Validation Loss AVG: 11.7839, lr: 0.001
Epoch [19/100], Training Loss: 4.6007, Validation Loss Current: 11.4988, Validation Loss AVG: 11.4988, lr: 0.001
Epoch [20/100], Training Loss: 4.6461, Validation Loss Current: 11.3702, Validation Loss AVG: 11.3702, lr: 0.001
Epoch [21/100], Training Loss: 3.2014, Validation Loss Current: 14.0400, Validation Loss AVG: 14.0400, lr: 0.001
Epoch [22/100], Training Loss: 2.4047, Validation Loss Current: 11.3599, Validation Loss AVG: 11.3599, lr: 0.001
Epoch [23/100], Training Loss: 5.1961, Validation Loss Current: 13.1153, Validation Loss AVG: 13.1153, lr: 0.001
Epoch [24/100], Training Loss: 5.8499, Validation Loss Current: 13.2925, Validation Loss AVG: 13.2925, lr: 0.001
Epoch [25/100], Training Loss: 3.2285, Validation Loss Current: 11.3677, Validation Loss AVG: 11.3677, lr: 0.001
Epoch [26/100], Training Loss: 2.5945, Validation Loss Current: 14.0087, Validation Loss AVG: 14.0087, lr: 0.001
Epoch [27/100], Training Loss: 2.1093, Validation Loss Current: 13.3191, Validation Loss AVG: 13.3191, lr: 0.001
Epoch [28/100], Training Loss: 3.4312, Validation Loss Current: 12.7655, Validation Loss AVG: 12.7655, lr: 0.001
Epoch [29/100], Training Loss: 5.7404, Validation Loss Current: 11.1323, Validation Loss AVG: 11.1323, lr: 0.001
Epoch [30/100], Training Loss: 2.8561, Validation Loss Current: 13.3696, Validation Loss AVG: 13.3696, lr: 0.001
Epoch [31/100], Training Loss: 3.1524, Validation Loss Current: 11.4910, Validation Loss AVG: 11.4910, lr: 0.001
Epoch [32/100], Training Loss: 4.0174, Validation Loss Current: 15.4974, Validation Loss AVG: 15.4974, lr: 0.001
Epoch [33/100], Training Loss: 6.4589, Validation Loss Current: 13.7020, Validation Loss AVG: 13.7020, lr: 0.001
Epoch [34/100], Training Loss: 8.5336, Validation Loss Current: 11.9405, Validation Loss AVG: 11.9405, lr: 0.001
Epoch [35/100], Training Loss: 8.3674, Validation Loss Current: 11.7468, Validation Loss AVG: 11.7468, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 5 Best val accuracy: [0.44605263157894737, 0.3694078947368421, 0.3884868421052632, 0.39276315789473687, 0.44769736842105257, 0.4203947368421053, 0.4532894736842105, 0.42894736842105263, 0.37532894736842104, 0.4286184210526316, 0.4072368421052632, 0.4631578947368422, 0.4473684210526316, 0.43980263157894733, 0.46677631578947365, 0.46875, 0.45263157894736833, 0.45559210526315785, 0.44342105263157894, 0.4565789473684211, 0.43519736842105267, 0.4355263157894737, 0.43289473684210533, 0.4236842105263158, 0.43881578947368427, 0.4342105263157895, 0.4434210526315788, 0.44671052631578945, 0.4421052631578948, 0.4411184210526316, 0.44703947368421054, 0.4125, 0.4184210526315789, 0.42894736842105263, 0.41940789473684204] Best val loss: 9.50214912891388


Current group: 0.6
Epoch [1/100], Training Loss: 30.3615, Validation Loss Current: 10.6307, Validation Loss AVG: 10.6307, lr: 0.001
Epoch [2/100], Training Loss: 21.6907, Validation Loss Current: 9.8678, Validation Loss AVG: 9.8678, lr: 0.001
Epoch [3/100], Training Loss: 15.9072, Validation Loss Current: 9.3771, Validation Loss AVG: 9.3771, lr: 0.001
Epoch [4/100], Training Loss: 11.1393, Validation Loss Current: 11.1475, Validation Loss AVG: 11.1475, lr: 0.001
Epoch [5/100], Training Loss: 11.2523, Validation Loss Current: 10.0038, Validation Loss AVG: 10.0038, lr: 0.001
Epoch [6/100], Training Loss: 8.3437, Validation Loss Current: 8.6195, Validation Loss AVG: 8.6195, lr: 0.001
Epoch [7/100], Training Loss: 6.8725, Validation Loss Current: 9.0511, Validation Loss AVG: 9.0511, lr: 0.001
Epoch [8/100], Training Loss: 5.2284, Validation Loss Current: 12.3345, Validation Loss AVG: 12.3345, lr: 0.001
Epoch [9/100], Training Loss: 6.8748, Validation Loss Current: 9.5698, Validation Loss AVG: 9.5698, lr: 0.001
Epoch [10/100], Training Loss: 8.0290, Validation Loss Current: 11.0699, Validation Loss AVG: 11.0699, lr: 0.001
Epoch [11/100], Training Loss: 8.6403, Validation Loss Current: 12.3646, Validation Loss AVG: 12.3646, lr: 0.001
Epoch [12/100], Training Loss: 5.0810, Validation Loss Current: 15.0655, Validation Loss AVG: 15.0655, lr: 0.001
Epoch [13/100], Training Loss: 4.3673, Validation Loss Current: 10.8922, Validation Loss AVG: 10.8922, lr: 0.001
Epoch [14/100], Training Loss: 5.4780, Validation Loss Current: 11.2188, Validation Loss AVG: 11.2188, lr: 0.001
Epoch [15/100], Training Loss: 8.8392, Validation Loss Current: 33.3179, Validation Loss AVG: 33.3179, lr: 0.001
Epoch [16/100], Training Loss: 5.5511, Validation Loss Current: 10.1990, Validation Loss AVG: 10.1990, lr: 0.001
Epoch [17/100], Training Loss: 4.1902, Validation Loss Current: 10.9897, Validation Loss AVG: 10.9897, lr: 0.001
Epoch [18/100], Training Loss: 4.0641, Validation Loss Current: 10.1540, Validation Loss AVG: 10.1540, lr: 0.001
Epoch [19/100], Training Loss: 2.8305, Validation Loss Current: 10.4210, Validation Loss AVG: 10.4210, lr: 0.001
Epoch [20/100], Training Loss: 3.8310, Validation Loss Current: 11.0751, Validation Loss AVG: 11.0751, lr: 0.001
Epoch [21/100], Training Loss: 3.0891, Validation Loss Current: 9.7253, Validation Loss AVG: 9.7253, lr: 0.001
Epoch [22/100], Training Loss: 2.4953, Validation Loss Current: 10.1315, Validation Loss AVG: 10.1315, lr: 0.001
Epoch [23/100], Training Loss: 3.5330, Validation Loss Current: 13.7287, Validation Loss AVG: 13.7287, lr: 0.001
Epoch [24/100], Training Loss: 6.3375, Validation Loss Current: 12.6166, Validation Loss AVG: 12.6166, lr: 0.001
Epoch [25/100], Training Loss: 6.6869, Validation Loss Current: 12.9867, Validation Loss AVG: 12.9867, lr: 0.001
Epoch [26/100], Training Loss: 5.1553, Validation Loss Current: 12.0239, Validation Loss AVG: 12.0239, lr: 0.001
Epoch [27/100], Training Loss: 3.6219, Validation Loss Current: 12.0582, Validation Loss AVG: 12.0582, lr: 0.001
Epoch [28/100], Training Loss: 2.7493, Validation Loss Current: 11.0874, Validation Loss AVG: 11.0874, lr: 0.001
Epoch [29/100], Training Loss: 2.3377, Validation Loss Current: 11.3509, Validation Loss AVG: 11.3509, lr: 0.001
Epoch [30/100], Training Loss: 2.5216, Validation Loss Current: 10.2731, Validation Loss AVG: 10.2731, lr: 0.001
Epoch [31/100], Training Loss: 4.6965, Validation Loss Current: 10.9362, Validation Loss AVG: 10.9362, lr: 0.001
Epoch [32/100], Training Loss: 5.9477, Validation Loss Current: 13.0857, Validation Loss AVG: 13.0857, lr: 0.001
Epoch [33/100], Training Loss: 6.3164, Validation Loss Current: 14.2983, Validation Loss AVG: 14.2983, lr: 0.001
Epoch [34/100], Training Loss: 4.1242, Validation Loss Current: 14.6729, Validation Loss AVG: 14.6729, lr: 0.001
Epoch [35/100], Training Loss: 1.9874, Validation Loss Current: 11.7698, Validation Loss AVG: 11.7698, lr: 0.001
Epoch [36/100], Training Loss: 1.9448, Validation Loss Current: 11.8608, Validation Loss AVG: 11.8608, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 6 Best val accuracy: [0.44868421052631574, 0.4769736842105264, 0.4473684210526316, 0.43782894736842104, 0.47335526315789467, 0.5, 0.4792763157894737, 0.4358552631578948, 0.46677631578947365, 0.43552631578947365, 0.4618421052631579, 0.3671052631578947, 0.4809210526315789, 0.4648026315789474, 0.21282894736842106, 0.4598684210526316, 0.4776315789473685, 0.49703947368421053, 0.49605263157894736, 0.4927631578947368, 0.5082236842105263, 0.5042763157894736, 0.4276315789473684, 0.47631578947368425, 0.4532894736842105, 0.4473684210526316, 0.4845394736842105, 0.4838815789473684, 0.48157894736842105, 0.5220394736842106, 0.4891447368421053, 0.45394736842105277, 0.42072368421052636, 0.4365131578947368, 0.47894736842105257, 0.4671052631578948] Best val loss: 8.619548010826112


Current group: 0.4
Epoch [1/100], Training Loss: 33.9335, Validation Loss Current: 13.7377, Validation Loss AVG: 13.7377, lr: 0.001
Epoch [2/100], Training Loss: 19.3020, Validation Loss Current: 13.1252, Validation Loss AVG: 13.1252, lr: 0.001
Epoch [3/100], Training Loss: 14.2355, Validation Loss Current: 13.4698, Validation Loss AVG: 13.4698, lr: 0.001
Epoch [4/100], Training Loss: 13.2354, Validation Loss Current: 11.7123, Validation Loss AVG: 11.7123, lr: 0.001
Epoch [5/100], Training Loss: 14.2596, Validation Loss Current: 17.3161, Validation Loss AVG: 17.3161, lr: 0.001
Epoch [6/100], Training Loss: 8.1698, Validation Loss Current: 10.8087, Validation Loss AVG: 10.8087, lr: 0.001
Epoch [7/100], Training Loss: 4.7480, Validation Loss Current: 10.0258, Validation Loss AVG: 10.0258, lr: 0.001
Epoch [8/100], Training Loss: 5.5270, Validation Loss Current: 10.8228, Validation Loss AVG: 10.8228, lr: 0.001
Epoch [9/100], Training Loss: 6.0664, Validation Loss Current: 11.8147, Validation Loss AVG: 11.8147, lr: 0.001
Epoch [10/100], Training Loss: 9.0216, Validation Loss Current: 12.4108, Validation Loss AVG: 12.4108, lr: 0.001
Epoch [11/100], Training Loss: 4.6182, Validation Loss Current: 11.8358, Validation Loss AVG: 11.8358, lr: 0.001
Epoch [12/100], Training Loss: 4.3263, Validation Loss Current: 10.9862, Validation Loss AVG: 10.9862, lr: 0.001
Epoch [13/100], Training Loss: 3.0584, Validation Loss Current: 11.8352, Validation Loss AVG: 11.8352, lr: 0.001
Epoch [14/100], Training Loss: 4.2299, Validation Loss Current: 13.8678, Validation Loss AVG: 13.8678, lr: 0.001
Epoch [15/100], Training Loss: 5.2722, Validation Loss Current: 15.7468, Validation Loss AVG: 15.7468, lr: 0.001
Epoch [16/100], Training Loss: 7.0374, Validation Loss Current: 14.8636, Validation Loss AVG: 14.8636, lr: 0.001
Epoch [17/100], Training Loss: 6.4584, Validation Loss Current: 11.9069, Validation Loss AVG: 11.9069, lr: 0.001
Epoch [18/100], Training Loss: 7.1966, Validation Loss Current: 10.9065, Validation Loss AVG: 10.9065, lr: 0.001
Epoch [19/100], Training Loss: 3.7947, Validation Loss Current: 11.4528, Validation Loss AVG: 11.4528, lr: 0.001
Epoch [20/100], Training Loss: 7.2462, Validation Loss Current: 11.0400, Validation Loss AVG: 11.0400, lr: 0.001
Epoch [21/100], Training Loss: 4.0833, Validation Loss Current: 11.8886, Validation Loss AVG: 11.8886, lr: 0.001
Epoch [22/100], Training Loss: 2.7197, Validation Loss Current: 12.3866, Validation Loss AVG: 12.3866, lr: 0.001
Epoch [23/100], Training Loss: 4.4918, Validation Loss Current: 14.1015, Validation Loss AVG: 14.1015, lr: 0.001
Epoch [24/100], Training Loss: 10.4563, Validation Loss Current: 14.8071, Validation Loss AVG: 14.8071, lr: 0.001
Epoch [25/100], Training Loss: 11.1764, Validation Loss Current: 14.7503, Validation Loss AVG: 14.7503, lr: 0.001
Epoch [26/100], Training Loss: 7.3067, Validation Loss Current: 12.1238, Validation Loss AVG: 12.1238, lr: 0.001
Epoch [27/100], Training Loss: 2.9296, Validation Loss Current: 12.8785, Validation Loss AVG: 12.8785, lr: 0.001
Epoch [28/100], Training Loss: 4.6768, Validation Loss Current: 11.6169, Validation Loss AVG: 11.6169, lr: 0.001
Epoch [29/100], Training Loss: 4.0964, Validation Loss Current: 14.9224, Validation Loss AVG: 14.9224, lr: 0.001
Epoch [30/100], Training Loss: 5.0935, Validation Loss Current: 12.4082, Validation Loss AVG: 12.4082, lr: 0.001
Epoch [31/100], Training Loss: 3.9392, Validation Loss Current: 12.0269, Validation Loss AVG: 12.0269, lr: 0.001
Epoch [32/100], Training Loss: 4.5906, Validation Loss Current: 14.2406, Validation Loss AVG: 14.2406, lr: 0.001
Epoch [33/100], Training Loss: 5.6531, Validation Loss Current: 19.4875, Validation Loss AVG: 19.4875, lr: 0.001
Epoch [34/100], Training Loss: 6.7118, Validation Loss Current: 14.9801, Validation Loss AVG: 14.9801, lr: 0.001
Epoch [35/100], Training Loss: 7.6765, Validation Loss Current: 15.4010, Validation Loss AVG: 15.4010, lr: 0.001
Epoch [36/100], Training Loss: 2.5827, Validation Loss Current: 13.5354, Validation Loss AVG: 13.5354, lr: 0.001
Epoch [37/100], Training Loss: 2.5123, Validation Loss Current: 12.8435, Validation Loss AVG: 12.8435, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 7 Best val accuracy: [0.40559210526315786, 0.45625, 0.4411184210526316, 0.44506578947368414, 0.2957236842105263, 0.46907894736842104, 0.5016447368421052, 0.4881578947368421, 0.4516447368421052, 0.46743421052631573, 0.46842105263157896, 0.5016447368421053, 0.44572368421052627, 0.44506578947368414, 0.47467105263157905, 0.4148026315789474, 0.4723684210526316, 0.5108552631578946, 0.45592105263157895, 0.4930921052631579, 0.47993421052631574, 0.47467105263157905, 0.4552631578947368, 0.40756578947368416, 0.36644736842105263, 0.46907894736842104, 0.45723684210526316, 0.4749999999999999, 0.42434210526315785, 0.46052631578947373, 0.47302631578947374, 0.43782894736842104, 0.3444078947368421, 0.4476973684210527, 0.4490131578947369, 0.43125, 0.46677631578947365] Best val loss: 10.02577621936798


----- Training resnet18 with sequence: [1, 0.8, 0.6, 0.4, 0.2] -----
Current group: 1
Epoch [1/80], Training Loss: 40.4833, Validation Loss Current: 9.8400, Validation Loss AVG: 9.9864, lr: 0.001
Epoch [2/80], Training Loss: 38.8403, Validation Loss Current: 9.4205, Validation Loss AVG: 9.8907, lr: 0.001
Epoch [3/80], Training Loss: 36.7011, Validation Loss Current: 9.0144, Validation Loss AVG: 9.6658, lr: 0.001
Epoch [4/80], Training Loss: 35.8523, Validation Loss Current: 8.7802, Validation Loss AVG: 9.9782, lr: 0.001
Epoch [5/80], Training Loss: 33.5384, Validation Loss Current: 8.2895, Validation Loss AVG: 9.2594, lr: 0.001
Epoch [6/80], Training Loss: 32.4623, Validation Loss Current: 8.0918, Validation Loss AVG: 9.2518, lr: 0.001
Epoch [7/80], Training Loss: 30.3296, Validation Loss Current: 7.7213, Validation Loss AVG: 10.3158, lr: 0.001
Epoch [8/80], Training Loss: 29.3112, Validation Loss Current: 7.3503, Validation Loss AVG: 9.1992, lr: 0.001
Epoch [9/80], Training Loss: 28.8225, Validation Loss Current: 9.1166, Validation Loss AVG: 11.5300, lr: 0.001
Epoch [10/80], Training Loss: 28.9006, Validation Loss Current: 7.0881, Validation Loss AVG: 9.7913, lr: 0.001
Epoch [11/80], Training Loss: 26.5293, Validation Loss Current: 6.9673, Validation Loss AVG: 10.2974, lr: 0.001
Epoch [12/80], Training Loss: 26.3063, Validation Loss Current: 7.2055, Validation Loss AVG: 9.8175, lr: 0.001
Epoch [13/80], Training Loss: 25.7237, Validation Loss Current: 6.7718, Validation Loss AVG: 8.6833, lr: 0.001
Epoch [14/80], Training Loss: 25.4750, Validation Loss Current: 7.2239, Validation Loss AVG: 9.4342, lr: 0.001
Epoch [15/80], Training Loss: 24.6750, Validation Loss Current: 6.5602, Validation Loss AVG: 10.6828, lr: 0.001
Epoch [16/80], Training Loss: 24.7384, Validation Loss Current: 6.5866, Validation Loss AVG: 9.0303, lr: 0.001
Epoch [17/80], Training Loss: 23.1207, Validation Loss Current: 6.6438, Validation Loss AVG: 9.2608, lr: 0.001
Epoch [18/80], Training Loss: 21.2439, Validation Loss Current: 6.4131, Validation Loss AVG: 10.7541, lr: 0.001
Epoch [19/80], Training Loss: 21.5820, Validation Loss Current: 7.3972, Validation Loss AVG: 10.9405, lr: 0.001
Epoch [20/80], Training Loss: 21.2677, Validation Loss Current: 6.9261, Validation Loss AVG: 9.8694, lr: 0.001
Epoch [21/80], Training Loss: 20.9589, Validation Loss Current: 6.3600, Validation Loss AVG: 12.0298, lr: 0.001
Epoch [22/80], Training Loss: 19.3659, Validation Loss Current: 6.5462, Validation Loss AVG: 11.1551, lr: 0.001
Epoch [23/80], Training Loss: 18.4298, Validation Loss Current: 6.4247, Validation Loss AVG: 14.5409, lr: 0.001
Epoch [24/80], Training Loss: 16.6088, Validation Loss Current: 6.0865, Validation Loss AVG: 11.7975, lr: 0.001
Epoch [25/80], Training Loss: 16.4991, Validation Loss Current: 5.6083, Validation Loss AVG: 8.9177, lr: 0.001
Epoch [26/80], Training Loss: 15.3938, Validation Loss Current: 5.7990, Validation Loss AVG: 8.5516, lr: 0.001
Epoch [27/80], Training Loss: 15.2734, Validation Loss Current: 5.8847, Validation Loss AVG: 10.5663, lr: 0.001
Epoch [28/80], Training Loss: 15.1711, Validation Loss Current: 6.3789, Validation Loss AVG: 14.4676, lr: 0.001
Epoch [29/80], Training Loss: 15.2820, Validation Loss Current: 5.9552, Validation Loss AVG: 8.9124, lr: 0.001
Epoch [30/80], Training Loss: 14.0747, Validation Loss Current: 6.4390, Validation Loss AVG: 12.2003, lr: 0.001
Epoch [31/80], Training Loss: 11.7676, Validation Loss Current: 5.6671, Validation Loss AVG: 9.3755, lr: 0.001
Epoch [32/80], Training Loss: 11.1698, Validation Loss Current: 6.0969, Validation Loss AVG: 11.5729, lr: 0.001
Epoch [33/80], Training Loss: 11.4216, Validation Loss Current: 7.3168, Validation Loss AVG: 16.5425, lr: 0.001
Epoch [34/80], Training Loss: 12.2091, Validation Loss Current: 6.4621, Validation Loss AVG: 13.2073, lr: 0.001
Epoch [35/80], Training Loss: 9.4972, Validation Loss Current: 5.8845, Validation Loss AVG: 13.4326, lr: 0.001
Epoch [36/80], Training Loss: 8.8672, Validation Loss Current: 6.1161, Validation Loss AVG: 14.3676, lr: 0.001
Epoch [37/80], Training Loss: 8.9375, Validation Loss Current: 5.9599, Validation Loss AVG: 11.1404, lr: 0.001
Epoch [38/80], Training Loss: 7.5831, Validation Loss Current: 7.0277, Validation Loss AVG: 15.8567, lr: 0.001
Epoch [39/80], Training Loss: 8.4814, Validation Loss Current: 6.4810, Validation Loss AVG: 18.1562, lr: 0.001
Epoch [40/80], Training Loss: 8.8926, Validation Loss Current: 6.0302, Validation Loss AVG: 10.8630, lr: 0.001
Epoch [41/80], Training Loss: 5.9721, Validation Loss Current: 5.9191, Validation Loss AVG: 10.7172, lr: 0.001
Epoch [42/80], Training Loss: 7.3135, Validation Loss Current: 6.2319, Validation Loss AVG: 15.0713, lr: 0.001
Epoch [43/80], Training Loss: 7.8510, Validation Loss Current: 6.3508, Validation Loss AVG: 16.5051, lr: 0.001
Epoch [44/80], Training Loss: 7.3556, Validation Loss Current: 6.4289, Validation Loss AVG: 12.6780, lr: 0.001
Epoch [45/80], Training Loss: 6.3932, Validation Loss Current: 6.8397, Validation Loss AVG: 16.3019, lr: 0.001
Epoch [46/80], Training Loss: 6.6838, Validation Loss Current: 8.6470, Validation Loss AVG: 12.8972, lr: 0.001
Epoch [47/80], Training Loss: 4.7957, Validation Loss Current: 6.2026, Validation Loss AVG: 12.4145, lr: 0.001
Epoch [48/80], Training Loss: 3.9715, Validation Loss Current: 6.3889, Validation Loss AVG: 16.0642, lr: 0.001
Epoch [49/80], Training Loss: 5.1605, Validation Loss Current: 6.5101, Validation Loss AVG: 19.0903, lr: 0.001
Epoch [50/80], Training Loss: 2.9428, Validation Loss Current: 5.8593, Validation Loss AVG: 11.6719, lr: 0.001
Epoch [51/80], Training Loss: 2.8943, Validation Loss Current: 6.4328, Validation Loss AVG: 14.7698, lr: 0.001
Epoch [52/80], Training Loss: 7.4017, Validation Loss Current: 6.5104, Validation Loss AVG: 13.2086, lr: 0.001
Epoch [53/80], Training Loss: 3.8946, Validation Loss Current: 7.7955, Validation Loss AVG: 12.4539, lr: 0.001
Epoch [54/80], Training Loss: 6.8827, Validation Loss Current: 9.7554, Validation Loss AVG: 21.8830, lr: 0.001
Epoch [55/80], Training Loss: 7.4474, Validation Loss Current: 7.2127, Validation Loss AVG: 11.9906, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 25 Best val accuracy: [0.27631578947368424, 0.32894736842105265, 0.34210526315789475, 0.3832236842105263, 0.39144736842105265, 0.41776315789473684, 0.43256578947368424, 0.46875, 0.37335526315789475, 0.4786184210526316, 0.5148026315789473, 0.4769736842105263, 0.53125, 0.48355263157894735, 0.5164473684210527, 0.5411184210526315, 0.524671052631579, 0.5444078947368421, 0.4934210526315789, 0.5032894736842105, 0.569078947368421, 0.5394736842105263, 0.5411184210526315, 0.5740131578947368, 0.6019736842105263, 0.6019736842105263, 0.5986842105263158, 0.5493421052631579, 0.6036184210526315, 0.5855263157894737, 0.6151315789473685, 0.5838815789473685, 0.5230263157894737, 0.5773026315789473, 0.6200657894736842, 0.6019736842105263, 0.6085526315789473, 0.5805921052631579, 0.5592105263157895, 0.6134868421052632, 0.6266447368421053, 0.6036184210526315, 0.6299342105263158, 0.5921052631578947, 0.5674342105263158, 0.5460526315789473, 0.6085526315789473, 0.6200657894736842, 0.5625, 0.6365131578947368, 0.618421052631579, 0.6085526315789473, 0.5789473684210527, 0.5328947368421053, 0.537828947368421] Best val loss: 5.608290314674377


Current group: 0.8
Epoch [1/80], Training Loss: 21.8788, Validation Loss Current: 12.7581, Validation Loss AVG: 12.7581, lr: 0.001
Epoch [2/80], Training Loss: 19.2773, Validation Loss Current: 13.9421, Validation Loss AVG: 13.9421, lr: 0.001
Epoch [3/80], Training Loss: 13.8333, Validation Loss Current: 17.5001, Validation Loss AVG: 17.5001, lr: 0.001
Epoch [4/80], Training Loss: 13.0114, Validation Loss Current: 14.1571, Validation Loss AVG: 14.1571, lr: 0.001
Epoch [5/80], Training Loss: 12.0879, Validation Loss Current: 11.6374, Validation Loss AVG: 11.6374, lr: 0.001
Epoch [6/80], Training Loss: 10.4846, Validation Loss Current: 9.6180, Validation Loss AVG: 9.6180, lr: 0.001
Epoch [7/80], Training Loss: 9.8511, Validation Loss Current: 13.1273, Validation Loss AVG: 13.1273, lr: 0.001
Epoch [8/80], Training Loss: 8.4026, Validation Loss Current: 9.7918, Validation Loss AVG: 9.7918, lr: 0.001
Epoch [9/80], Training Loss: 7.1680, Validation Loss Current: 11.4594, Validation Loss AVG: 11.4594, lr: 0.001
Epoch [10/80], Training Loss: 6.5145, Validation Loss Current: 9.2135, Validation Loss AVG: 9.2135, lr: 0.001
Epoch [11/80], Training Loss: 8.8829, Validation Loss Current: 25.4133, Validation Loss AVG: 25.4133, lr: 0.001
Epoch [12/80], Training Loss: 10.8142, Validation Loss Current: 17.1382, Validation Loss AVG: 17.1382, lr: 0.001
Epoch [13/80], Training Loss: 9.1035, Validation Loss Current: 16.5225, Validation Loss AVG: 16.5225, lr: 0.001
Epoch [14/80], Training Loss: 7.5275, Validation Loss Current: 11.5043, Validation Loss AVG: 11.5043, lr: 0.001
Epoch [15/80], Training Loss: 8.9372, Validation Loss Current: 13.5032, Validation Loss AVG: 13.5032, lr: 0.001
Epoch [16/80], Training Loss: 5.6589, Validation Loss Current: 17.0562, Validation Loss AVG: 17.0562, lr: 0.001
Epoch [17/80], Training Loss: 7.6780, Validation Loss Current: 17.7363, Validation Loss AVG: 17.7363, lr: 0.001
Epoch [18/80], Training Loss: 8.3132, Validation Loss Current: 15.0551, Validation Loss AVG: 15.0551, lr: 0.001
Epoch [19/80], Training Loss: 8.4657, Validation Loss Current: 19.4635, Validation Loss AVG: 19.4635, lr: 0.001
Epoch [20/80], Training Loss: 7.3610, Validation Loss Current: 20.9116, Validation Loss AVG: 20.9116, lr: 0.001
Epoch [21/80], Training Loss: 6.4043, Validation Loss Current: 17.2310, Validation Loss AVG: 17.2310, lr: 0.001
Epoch [22/80], Training Loss: 4.0367, Validation Loss Current: 12.6103, Validation Loss AVG: 12.6103, lr: 0.001
Epoch [23/80], Training Loss: 4.4237, Validation Loss Current: 12.0458, Validation Loss AVG: 12.0458, lr: 0.001
Epoch [24/80], Training Loss: 4.2966, Validation Loss Current: 15.6172, Validation Loss AVG: 15.6172, lr: 0.001
Epoch [25/80], Training Loss: 6.5778, Validation Loss Current: 15.8681, Validation Loss AVG: 15.8681, lr: 0.001
Epoch [26/80], Training Loss: 4.8710, Validation Loss Current: 13.5842, Validation Loss AVG: 13.5842, lr: 0.001
Epoch [27/80], Training Loss: 3.3398, Validation Loss Current: 12.7591, Validation Loss AVG: 12.7591, lr: 0.001
Epoch [28/80], Training Loss: 3.3337, Validation Loss Current: 15.9358, Validation Loss AVG: 15.9358, lr: 0.001
Epoch [29/80], Training Loss: 5.3809, Validation Loss Current: 15.0958, Validation Loss AVG: 15.0958, lr: 0.001
Epoch [30/80], Training Loss: 5.7235, Validation Loss Current: 10.0231, Validation Loss AVG: 10.0231, lr: 0.001
Epoch [31/80], Training Loss: 6.4380, Validation Loss Current: 11.0402, Validation Loss AVG: 11.0402, lr: 0.001
Epoch [32/80], Training Loss: 4.1287, Validation Loss Current: 11.5492, Validation Loss AVG: 11.5492, lr: 0.001
Epoch [33/80], Training Loss: 3.9120, Validation Loss Current: 15.8484, Validation Loss AVG: 15.8484, lr: 0.001
Epoch [34/80], Training Loss: 2.1492, Validation Loss Current: 13.1724, Validation Loss AVG: 13.1724, lr: 0.001
Epoch [35/80], Training Loss: 3.0226, Validation Loss Current: 14.5675, Validation Loss AVG: 14.5675, lr: 0.001
Epoch [36/80], Training Loss: 4.5346, Validation Loss Current: 13.2372, Validation Loss AVG: 13.2372, lr: 0.001
Epoch [37/80], Training Loss: 1.7595, Validation Loss Current: 13.1859, Validation Loss AVG: 13.1859, lr: 0.001
Epoch [38/80], Training Loss: 4.2775, Validation Loss Current: 17.6573, Validation Loss AVG: 17.6573, lr: 0.001
Epoch [39/80], Training Loss: 5.7226, Validation Loss Current: 12.0185, Validation Loss AVG: 12.0185, lr: 0.001
Epoch [40/80], Training Loss: 4.7167, Validation Loss Current: 11.2483, Validation Loss AVG: 11.2483, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 10 Best val accuracy: [0.37236842105263157, 0.4115131578947368, 0.33717105263157887, 0.39671052631578946, 0.4338815789473685, 0.43782894736842104, 0.4269736842105263, 0.3891447368421053, 0.41118421052631576, 0.4355263157894737, 0.31480263157894733, 0.40361842105263157, 0.3917763157894737, 0.43815789473684214, 0.41546052631578945, 0.3680921052631579, 0.3493421052631579, 0.3838815789473684, 0.39210526315789473, 0.3473684210526316, 0.4203947368421052, 0.41184210526315795, 0.44309210526315795, 0.3957236842105264, 0.4197368421052632, 0.4480263157894737, 0.43618421052631573, 0.43322368421052637, 0.39473684210526316, 0.4582236842105264, 0.4585526315789473, 0.43881578947368427, 0.3983552631578947, 0.3694078947368421, 0.4131578947368421, 0.4217105263157895, 0.436842105263158, 0.41052631578947374, 0.43815789473684214, 0.45756578947368426] Best val loss: 9.21347188949585


Current group: 0.6
Epoch [1/80], Training Loss: 29.9423, Validation Loss Current: 12.4696, Validation Loss AVG: 12.4696, lr: 0.001
Epoch [2/80], Training Loss: 24.7264, Validation Loss Current: 10.1872, Validation Loss AVG: 10.1872, lr: 0.001
Epoch [3/80], Training Loss: 17.7666, Validation Loss Current: 13.9734, Validation Loss AVG: 13.9734, lr: 0.001
Epoch [4/80], Training Loss: 14.6496, Validation Loss Current: 9.1574, Validation Loss AVG: 9.1574, lr: 0.001
Epoch [5/80], Training Loss: 10.0756, Validation Loss Current: 10.5127, Validation Loss AVG: 10.5127, lr: 0.001
Epoch [6/80], Training Loss: 8.0659, Validation Loss Current: 10.3152, Validation Loss AVG: 10.3152, lr: 0.001
Epoch [7/80], Training Loss: 8.6037, Validation Loss Current: 11.7748, Validation Loss AVG: 11.7748, lr: 0.001
Epoch [8/80], Training Loss: 9.3897, Validation Loss Current: 10.2035, Validation Loss AVG: 10.2035, lr: 0.001
Epoch [9/80], Training Loss: 5.9320, Validation Loss Current: 11.7042, Validation Loss AVG: 11.7042, lr: 0.001
Epoch [10/80], Training Loss: 5.9236, Validation Loss Current: 10.2780, Validation Loss AVG: 10.2780, lr: 0.001
Epoch [11/80], Training Loss: 5.7874, Validation Loss Current: 12.0603, Validation Loss AVG: 12.0603, lr: 0.001
Epoch [12/80], Training Loss: 9.9428, Validation Loss Current: 10.3276, Validation Loss AVG: 10.3276, lr: 0.001
Epoch [13/80], Training Loss: 6.5309, Validation Loss Current: 12.1023, Validation Loss AVG: 12.1023, lr: 0.001
Epoch [14/80], Training Loss: 5.9681, Validation Loss Current: 14.1433, Validation Loss AVG: 14.1433, lr: 0.001
Epoch [15/80], Training Loss: 11.3112, Validation Loss Current: 13.0976, Validation Loss AVG: 13.0976, lr: 0.001
Epoch [16/80], Training Loss: 5.2112, Validation Loss Current: 11.3442, Validation Loss AVG: 11.3442, lr: 0.001
Epoch [17/80], Training Loss: 4.7864, Validation Loss Current: 11.4664, Validation Loss AVG: 11.4664, lr: 0.001
Epoch [18/80], Training Loss: 5.7355, Validation Loss Current: 10.6138, Validation Loss AVG: 10.6138, lr: 0.001
Epoch [19/80], Training Loss: 7.7796, Validation Loss Current: 14.2497, Validation Loss AVG: 14.2497, lr: 0.001
Epoch [20/80], Training Loss: 4.4852, Validation Loss Current: 10.9424, Validation Loss AVG: 10.9424, lr: 0.001
Epoch [21/80], Training Loss: 3.4842, Validation Loss Current: 10.3988, Validation Loss AVG: 10.3988, lr: 0.001
Epoch [22/80], Training Loss: 5.4079, Validation Loss Current: 11.3939, Validation Loss AVG: 11.3939, lr: 0.001
Epoch [23/80], Training Loss: 5.5798, Validation Loss Current: 11.0093, Validation Loss AVG: 11.0093, lr: 0.001
Epoch [24/80], Training Loss: 5.3956, Validation Loss Current: 12.8758, Validation Loss AVG: 12.8758, lr: 0.001
Epoch [25/80], Training Loss: 3.1189, Validation Loss Current: 11.4939, Validation Loss AVG: 11.4939, lr: 0.001
Epoch [26/80], Training Loss: 2.0650, Validation Loss Current: 11.7437, Validation Loss AVG: 11.7437, lr: 0.001
Epoch [27/80], Training Loss: 3.3792, Validation Loss Current: 11.1569, Validation Loss AVG: 11.1569, lr: 0.001
Epoch [28/80], Training Loss: 6.7126, Validation Loss Current: 11.9086, Validation Loss AVG: 11.9086, lr: 0.001
Epoch [29/80], Training Loss: 4.7752, Validation Loss Current: 11.1859, Validation Loss AVG: 11.1859, lr: 0.001
Epoch [30/80], Training Loss: 2.9129, Validation Loss Current: 11.8858, Validation Loss AVG: 11.8858, lr: 0.001
Epoch [31/80], Training Loss: 3.5486, Validation Loss Current: 13.3562, Validation Loss AVG: 13.3562, lr: 0.001
Epoch [32/80], Training Loss: 2.6206, Validation Loss Current: 12.5097, Validation Loss AVG: 12.5097, lr: 0.001
Epoch [33/80], Training Loss: 3.9945, Validation Loss Current: 12.1637, Validation Loss AVG: 12.1637, lr: 0.001
Epoch [34/80], Training Loss: 4.1195, Validation Loss Current: 12.2428, Validation Loss AVG: 12.2428, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 4 Best val accuracy: [0.40657894736842104, 0.44605263157894737, 0.4197368421052632, 0.45065789473684215, 0.449671052631579, 0.4384868421052632, 0.4671052631578948, 0.42105263157894735, 0.4588815789473684, 0.4723684210526316, 0.4424342105263158, 0.47993421052631574, 0.4391447368421052, 0.4463815789473684, 0.44539473684210523, 0.43519736842105267, 0.4585526315789473, 0.4917763157894736, 0.4217105263157895, 0.46381578947368424, 0.4526315789473684, 0.4697368421052632, 0.4894736842105263, 0.44046052631578936, 0.4671052631578948, 0.45855263157894743, 0.47171052631578936, 0.4526315789473684, 0.47796052631578956, 0.4473684210526316, 0.45921052631578946, 0.47828947368421054, 0.47006578947368427, 0.487828947368421] Best val loss: 9.157441306114197


Current group: 0.4
Epoch [1/80], Training Loss: 34.9638, Validation Loss Current: 12.1149, Validation Loss AVG: 12.1149, lr: 0.001
Epoch [2/80], Training Loss: 22.6518, Validation Loss Current: 12.9776, Validation Loss AVG: 12.9776, lr: 0.001
Epoch [3/80], Training Loss: 18.2927, Validation Loss Current: 11.6213, Validation Loss AVG: 11.6213, lr: 0.001
Epoch [4/80], Training Loss: 13.4836, Validation Loss Current: 10.3391, Validation Loss AVG: 10.3391, lr: 0.001
Epoch [5/80], Training Loss: 9.4043, Validation Loss Current: 9.5747, Validation Loss AVG: 9.5747, lr: 0.001
Epoch [6/80], Training Loss: 7.9208, Validation Loss Current: 13.6146, Validation Loss AVG: 13.6146, lr: 0.001
Epoch [7/80], Training Loss: 6.8291, Validation Loss Current: 11.2135, Validation Loss AVG: 11.2135, lr: 0.001
Epoch [8/80], Training Loss: 6.5583, Validation Loss Current: 13.3492, Validation Loss AVG: 13.3492, lr: 0.001
Epoch [9/80], Training Loss: 5.9880, Validation Loss Current: 12.4290, Validation Loss AVG: 12.4290, lr: 0.001
Epoch [10/80], Training Loss: 6.1998, Validation Loss Current: 11.3605, Validation Loss AVG: 11.3605, lr: 0.001
Epoch [11/80], Training Loss: 5.1108, Validation Loss Current: 11.0219, Validation Loss AVG: 11.0219, lr: 0.001
Epoch [12/80], Training Loss: 3.2982, Validation Loss Current: 11.7378, Validation Loss AVG: 11.7378, lr: 0.001
Epoch [13/80], Training Loss: 4.7406, Validation Loss Current: 10.9169, Validation Loss AVG: 10.9169, lr: 0.001
Epoch [14/80], Training Loss: 5.2512, Validation Loss Current: 13.2682, Validation Loss AVG: 13.2682, lr: 0.001
Epoch [15/80], Training Loss: 10.1403, Validation Loss Current: 12.8771, Validation Loss AVG: 12.8771, lr: 0.001
Epoch [16/80], Training Loss: 9.0679, Validation Loss Current: 14.2683, Validation Loss AVG: 14.2683, lr: 0.001
Epoch [17/80], Training Loss: 4.4947, Validation Loss Current: 12.0122, Validation Loss AVG: 12.0122, lr: 0.001
Epoch [18/80], Training Loss: 5.6086, Validation Loss Current: 11.9664, Validation Loss AVG: 11.9664, lr: 0.001
Epoch [19/80], Training Loss: 4.7483, Validation Loss Current: 11.7884, Validation Loss AVG: 11.7884, lr: 0.001
Epoch [20/80], Training Loss: 4.2526, Validation Loss Current: 11.4871, Validation Loss AVG: 11.4871, lr: 0.001
Epoch [21/80], Training Loss: 3.1657, Validation Loss Current: 12.0375, Validation Loss AVG: 12.0375, lr: 0.001
Epoch [22/80], Training Loss: 3.9195, Validation Loss Current: 10.6800, Validation Loss AVG: 10.6800, lr: 0.001
Epoch [23/80], Training Loss: 3.3830, Validation Loss Current: 13.0610, Validation Loss AVG: 13.0610, lr: 0.001
Epoch [24/80], Training Loss: 3.8993, Validation Loss Current: 10.9464, Validation Loss AVG: 10.9464, lr: 0.001
Epoch [25/80], Training Loss: 6.5078, Validation Loss Current: 13.2896, Validation Loss AVG: 13.2896, lr: 0.001
Epoch [26/80], Training Loss: 2.8072, Validation Loss Current: 11.4750, Validation Loss AVG: 11.4750, lr: 0.001
Epoch [27/80], Training Loss: 3.2783, Validation Loss Current: 13.6478, Validation Loss AVG: 13.6478, lr: 0.001
Epoch [28/80], Training Loss: 4.8371, Validation Loss Current: 17.0233, Validation Loss AVG: 17.0233, lr: 0.001
Epoch [29/80], Training Loss: 6.4017, Validation Loss Current: 16.3918, Validation Loss AVG: 16.3918, lr: 0.001
Epoch [30/80], Training Loss: 2.6357, Validation Loss Current: 11.8069, Validation Loss AVG: 11.8069, lr: 0.001
Epoch [31/80], Training Loss: 6.6141, Validation Loss Current: 13.1857, Validation Loss AVG: 13.1857, lr: 0.001
Epoch [32/80], Training Loss: 5.0857, Validation Loss Current: 12.5928, Validation Loss AVG: 12.5928, lr: 0.001
Epoch [33/80], Training Loss: 2.4061, Validation Loss Current: 12.0563, Validation Loss AVG: 12.0563, lr: 0.001
Epoch [34/80], Training Loss: 1.3670, Validation Loss Current: 11.9535, Validation Loss AVG: 11.9535, lr: 0.001
Epoch [35/80], Training Loss: 1.6354, Validation Loss Current: 11.6856, Validation Loss AVG: 11.6856, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 5 Best val accuracy: [0.45756578947368415, 0.3907894736842105, 0.44572368421052627, 0.456578947368421, 0.4756578947368421, 0.33125, 0.47368421052631576, 0.3740131578947369, 0.4615131578947369, 0.46480263157894736, 0.46743421052631573, 0.4891447368421053, 0.4858552631578947, 0.4529605263157895, 0.4473684210526316, 0.4302631578947369, 0.46743421052631573, 0.47171052631578947, 0.4529605263157895, 0.48717105263157895, 0.43881578947368427, 0.4953947368421052, 0.4207236842105263, 0.4809210526315789, 0.44210526315789467, 0.49177631578947373, 0.4322368421052632, 0.45592105263157895, 0.3582236842105263, 0.4657894736842104, 0.4621710526315789, 0.4302631578947368, 0.4792763157894737, 0.49144736842105263, 0.4802631578947369] Best val loss: 9.57472641468048


Current group: 0.2
Epoch [1/80], Training Loss: 46.0976, Validation Loss Current: 34.3800, Validation Loss AVG: 34.3800, lr: 0.001
Epoch [2/80], Training Loss: 28.2999, Validation Loss Current: 20.9226, Validation Loss AVG: 20.9226, lr: 0.001
Epoch [3/80], Training Loss: 23.0849, Validation Loss Current: 17.9846, Validation Loss AVG: 17.9846, lr: 0.001
Epoch [4/80], Training Loss: 18.2372, Validation Loss Current: 16.4145, Validation Loss AVG: 16.4145, lr: 0.001
Epoch [5/80], Training Loss: 16.1403, Validation Loss Current: 14.1496, Validation Loss AVG: 14.1496, lr: 0.001
Epoch [6/80], Training Loss: 14.3856, Validation Loss Current: 18.1372, Validation Loss AVG: 18.1372, lr: 0.001
Epoch [7/80], Training Loss: 16.6088, Validation Loss Current: 14.7700, Validation Loss AVG: 14.7700, lr: 0.001
Epoch [8/80], Training Loss: 12.7410, Validation Loss Current: 26.4869, Validation Loss AVG: 26.4869, lr: 0.001
Epoch [9/80], Training Loss: 14.5266, Validation Loss Current: 15.1467, Validation Loss AVG: 15.1467, lr: 0.001
Epoch [10/80], Training Loss: 10.2877, Validation Loss Current: 16.0051, Validation Loss AVG: 16.0051, lr: 0.001
Epoch [11/80], Training Loss: 7.6760, Validation Loss Current: 17.1037, Validation Loss AVG: 17.1037, lr: 0.001
Epoch [12/80], Training Loss: 13.8919, Validation Loss Current: 27.1828, Validation Loss AVG: 27.1828, lr: 0.001
Epoch [13/80], Training Loss: 9.1250, Validation Loss Current: 21.8712, Validation Loss AVG: 21.8712, lr: 0.001
Epoch [14/80], Training Loss: 9.3878, Validation Loss Current: 20.0712, Validation Loss AVG: 20.0712, lr: 0.001
Epoch [15/80], Training Loss: 10.9968, Validation Loss Current: 19.4842, Validation Loss AVG: 19.4842, lr: 0.001
Epoch [16/80], Training Loss: 7.5989, Validation Loss Current: 18.2595, Validation Loss AVG: 18.2595, lr: 0.001
Epoch [17/80], Training Loss: 6.0277, Validation Loss Current: 19.2862, Validation Loss AVG: 19.2862, lr: 0.001
Epoch [18/80], Training Loss: 3.2605, Validation Loss Current: 16.1919, Validation Loss AVG: 16.1919, lr: 0.001
Epoch [19/80], Training Loss: 3.2225, Validation Loss Current: 19.1798, Validation Loss AVG: 19.1798, lr: 0.001
Epoch [20/80], Training Loss: 8.1337, Validation Loss Current: 24.2103, Validation Loss AVG: 24.2103, lr: 0.001
Epoch [21/80], Training Loss: 13.9938, Validation Loss Current: 20.0288, Validation Loss AVG: 20.0288, lr: 0.001
Epoch [22/80], Training Loss: 9.4524, Validation Loss Current: 24.2053, Validation Loss AVG: 24.2053, lr: 0.001
Epoch [23/80], Training Loss: 6.2740, Validation Loss Current: 18.7242, Validation Loss AVG: 18.7242, lr: 0.001
Epoch [24/80], Training Loss: 4.4535, Validation Loss Current: 16.7196, Validation Loss AVG: 16.7196, lr: 0.001
Epoch [25/80], Training Loss: 3.3682, Validation Loss Current: 22.1115, Validation Loss AVG: 22.1115, lr: 0.001
Epoch [26/80], Training Loss: 10.5824, Validation Loss Current: 27.0803, Validation Loss AVG: 27.0803, lr: 0.001
Epoch [27/80], Training Loss: 12.6390, Validation Loss Current: 19.9095, Validation Loss AVG: 19.9095, lr: 0.001
Epoch [28/80], Training Loss: 10.5789, Validation Loss Current: 21.7212, Validation Loss AVG: 21.7212, lr: 0.001
Epoch [29/80], Training Loss: 9.0608, Validation Loss Current: 22.3313, Validation Loss AVG: 22.3313, lr: 0.001
Epoch [30/80], Training Loss: 6.7698, Validation Loss Current: 26.2446, Validation Loss AVG: 26.2446, lr: 0.001
Epoch [31/80], Training Loss: 6.1910, Validation Loss Current: 17.1518, Validation Loss AVG: 17.1518, lr: 0.001
Epoch [32/80], Training Loss: 4.0367, Validation Loss Current: 18.4535, Validation Loss AVG: 18.4535, lr: 0.001
Epoch [33/80], Training Loss: 6.5193, Validation Loss Current: 26.1800, Validation Loss AVG: 26.1800, lr: 0.001
Epoch [34/80], Training Loss: 11.0568, Validation Loss Current: 26.1629, Validation Loss AVG: 26.1629, lr: 0.001
Epoch [35/80], Training Loss: 6.8757, Validation Loss Current: 18.7826, Validation Loss AVG: 18.7826, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 5 Best val accuracy: [0.23651315789473687, 0.24572368421052632, 0.31644736842105264, 0.3299342105263158, 0.40657894736842104, 0.28421052631578947, 0.41578947368421054, 0.22598684210526315, 0.4269736842105263, 0.41414473684210523, 0.31282894736842104, 0.25, 0.32171052631578945, 0.36875, 0.3197368421052632, 0.38289473684210523, 0.30986842105263157, 0.41217105263157894, 0.35328947368421054, 0.29769736842105265, 0.3490131578947368, 0.2967105263157895, 0.3368421052631579, 0.41875, 0.3269736842105263, 0.29276315789473684, 0.32730263157894735, 0.30986842105263157, 0.38322368421052627, 0.2256578947368421, 0.38026315789473686, 0.3470394736842105, 0.28552631578947374, 0.2506578947368421, 0.3282894736842105] Best val loss: 14.149646091461182


-------------------- All training done --------------------


 --- Evaluating ---
Fold: 0
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.173414820473644
Test set distance: 0.8 Top 1 Accuracy: 0.5401069518716578
Test set distance: 0.4 Top 1 Accuracy: 0.26737967914438504
Test set distance: 0.6 Top 1 Accuracy: 0.4209320091673033
Test set distance: 1 Top 1 Accuracy: 0.6080977845683728
---- Testing model trained on sequence: [1, 0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.19480519480519481
Test set distance: 0.8 Top 1 Accuracy: 0.5003819709702063
Test set distance: 0.4 Top 1 Accuracy: 0.28953399541634833
Test set distance: 0.6 Top 1 Accuracy: 0.4255156608097785
Test set distance: 1 Top 1 Accuracy: 0.4881588999236058
---- Testing model trained on sequence: [1, 0.8, 0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.24369747899159663
Test set distance: 0.8 Top 1 Accuracy: 0.5385790679908327
Test set distance: 0.4 Top 1 Accuracy: 0.4766997708174179
Test set distance: 0.6 Top 1 Accuracy: 0.5607333842627961
Test set distance: 1 Top 1 Accuracy: 0.48586707410236823
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.25515660809778457
Test set distance: 0.8 Top 1 Accuracy: 0.5530939648586708
Test set distance: 0.4 Top 1 Accuracy: 0.5798319327731093
Test set distance: 0.6 Top 1 Accuracy: 0.5614973262032086
Test set distance: 1 Top 1 Accuracy: 0.5064935064935064
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4, 0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.29640947288006114
Test set distance: 0.8 Top 1 Accuracy: 0.24369747899159663
Test set distance: 0.4 Top 1 Accuracy: 0.28647822765469827
Test set distance: 0.6 Top 1 Accuracy: 0.2887700534759358
Test set distance: 1 Top 1 Accuracy: 0.2215431627196333
Fold: 1
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.09014514896867838
Test set distance: 0.8 Top 1 Accuracy: 0.5179526355996944
Test set distance: 0.4 Top 1 Accuracy: 0.1894576012223071
Test set distance: 0.6 Top 1 Accuracy: 0.3537051184110008
Test set distance: 1 Top 1 Accuracy: 0.6027501909854851
---- Testing model trained on sequence: [1, 0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.23605805958747136
Test set distance: 0.8 Top 1 Accuracy: 0.6134453781512605
Test set distance: 0.4 Top 1 Accuracy: 0.3651642475171887
Test set distance: 0.6 Top 1 Accuracy: 0.5095492742551566
Test set distance: 1 Top 1 Accuracy: 0.5668449197860963
---- Testing model trained on sequence: [1, 0.8, 0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.21695951107715813
Test set distance: 0.8 Top 1 Accuracy: 0.5622612681436211
Test set distance: 0.4 Top 1 Accuracy: 0.4369747899159664
Test set distance: 0.6 Top 1 Accuracy: 0.6035141329258976
Test set distance: 1 Top 1 Accuracy: 0.5370511841100076
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.2620320855614973
Test set distance: 0.8 Top 1 Accuracy: 0.44919786096256686
Test set distance: 0.4 Top 1 Accuracy: 0.48128342245989303
Test set distance: 0.6 Top 1 Accuracy: 0.47058823529411764
Test set distance: 1 Top 1 Accuracy: 0.4110007639419404
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4, 0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.5477463712757831
Test set distance: 0.8 Top 1 Accuracy: 0.3567608861726509
Test set distance: 0.4 Top 1 Accuracy: 0.4163483575248281
Test set distance: 0.6 Top 1 Accuracy: 0.3949579831932773
Test set distance: 1 Top 1 Accuracy: 0.36134453781512604
Fold: 2
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1520244461420932
Test set distance: 0.8 Top 1 Accuracy: 0.5049656226126814
Test set distance: 0.4 Top 1 Accuracy: 0.24980901451489687
Test set distance: 0.6 Top 1 Accuracy: 0.40106951871657753
Test set distance: 1 Top 1 Accuracy: 0.5721925133689839
---- Testing model trained on sequence: [1, 0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1627196333078686
Test set distance: 0.8 Top 1 Accuracy: 0.5836516424751719
Test set distance: 0.4 Top 1 Accuracy: 0.29488158899923606
Test set distance: 0.6 Top 1 Accuracy: 0.479755538579068
Test set distance: 1 Top 1 Accuracy: 0.5454545454545454
---- Testing model trained on sequence: [1, 0.8, 0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.16195569136745608
Test set distance: 0.8 Top 1 Accuracy: 0.5821237585943468
Test set distance: 0.4 Top 1 Accuracy: 0.385790679908327
Test set distance: 0.6 Top 1 Accuracy: 0.573720397249809
Test set distance: 1 Top 1 Accuracy: 0.5278838808250573
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.29640947288006114
Test set distance: 0.8 Top 1 Accuracy: 0.4904507257448434
Test set distance: 0.4 Top 1 Accuracy: 0.5538579067990833
Test set distance: 0.6 Top 1 Accuracy: 0.492742551566081
Test set distance: 1 Top 1 Accuracy: 0.4369747899159664
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4, 0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1497326203208556
Test set distance: 0.8 Top 1 Accuracy: 0.22536287242169595
Test set distance: 0.4 Top 1 Accuracy: 0.18181818181818182
Test set distance: 0.6 Top 1 Accuracy: 0.24904507257448433
Test set distance: 1 Top 1 Accuracy: 0.20168067226890757
Fold: 3
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18334606569900688
Test set distance: 0.8 Top 1 Accuracy: 0.5202444614209321
Test set distance: 0.4 Top 1 Accuracy: 0.23911382734912145
Test set distance: 0.6 Top 1 Accuracy: 0.3949579831932773
Test set distance: 1 Top 1 Accuracy: 0.5974025974025974
---- Testing model trained on sequence: [1, 0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.17723453017570664
Test set distance: 0.8 Top 1 Accuracy: 0.5355233002291826
Test set distance: 0.4 Top 1 Accuracy: 0.3430099312452254
Test set distance: 0.6 Top 1 Accuracy: 0.4820473644003056
Test set distance: 1 Top 1 Accuracy: 0.5133689839572193
---- Testing model trained on sequence: [1, 0.8, 0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.20855614973262032
Test set distance: 0.8 Top 1 Accuracy: 0.5821237585943468
Test set distance: 0.4 Top 1 Accuracy: 0.43391902215431627
Test set distance: 0.6 Top 1 Accuracy: 0.5691367456073338
Test set distance: 1 Top 1 Accuracy: 0.5561497326203209
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.25668449197860965
Test set distance: 0.8 Top 1 Accuracy: 0.5003819709702063
Test set distance: 0.4 Top 1 Accuracy: 0.5454545454545454
Test set distance: 0.6 Top 1 Accuracy: 0.4904507257448434
Test set distance: 1 Top 1 Accuracy: 0.46524064171123
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4, 0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4514896867838044
Test set distance: 0.8 Top 1 Accuracy: 0.25744843391902217
Test set distance: 0.4 Top 1 Accuracy: 0.32161955691367455
Test set distance: 0.6 Top 1 Accuracy: 0.27043544690603516
Test set distance: 1 Top 1 Accuracy: 0.22077922077922077
Fold: 4
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.13139801375095492
Test set distance: 0.8 Top 1 Accuracy: 0.5324675324675324
Test set distance: 0.4 Top 1 Accuracy: 0.2910618792971734
Test set distance: 0.6 Top 1 Accuracy: 0.440794499618029
Test set distance: 1 Top 1 Accuracy: 0.5981665393430099
---- Testing model trained on sequence: [1, 0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.05653170359052712
Test set distance: 0.8 Top 1 Accuracy: 0.5569136745607334
Test set distance: 0.4 Top 1 Accuracy: 0.23147440794499619
Test set distance: 0.6 Top 1 Accuracy: 0.46524064171123
Test set distance: 1 Top 1 Accuracy: 0.5676088617265088
---- Testing model trained on sequence: [1, 0.8, 0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.19862490450725745
Test set distance: 0.8 Top 1 Accuracy: 0.5882352941176471
Test set distance: 0.4 Top 1 Accuracy: 0.5026737967914439
Test set distance: 0.6 Top 1 Accuracy: 0.6210847975553858
Test set distance: 1 Top 1 Accuracy: 0.5370511841100076
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.2826585179526356
Test set distance: 0.8 Top 1 Accuracy: 0.4721161191749427
Test set distance: 0.4 Top 1 Accuracy: 0.5576776165011459
Test set distance: 0.6 Top 1 Accuracy: 0.5034377387318564
Test set distance: 1 Top 1 Accuracy: 0.4255156608097785
---- Testing model trained on sequence: [1, 0.8, 0.6, 0.4, 0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4369747899159664
Test set distance: 0.8 Top 1 Accuracy: 0.2765469824293354
Test set distance: 0.4 Top 1 Accuracy: 0.31932773109243695
Test set distance: 0.6 Top 1 Accuracy: 0.32238349885408707
Test set distance: 1 Top 1 Accuracy: 0.28418640183346067
------------------------------ End ------------------------------


 # ------------------ Running pipeline on stb_endsame color run_0 -------------------- #
cuda:0
 ------ Pipeline with following parameters ------
training_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/train
val_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/val
test_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/test
dataset_name :  VOC
target_distances :  [0.2, 0.8, 0.4, 0.6, 1]
training_mode :  stb_endsame
n_distances :  None
training_size :  None
background :  color
size :  (150, 150)
cls_to_use :  ['aeroplane', 'bicycle', 'bird', 'boat', 'car', 'cat', 'train', 'tvmonitor']
batch_size :  128
val_size :  1
epochs :  400
resize_method :  long
n_folds :  5
num_workers :  16
model_name :  resnet18
device :  cuda:0
random_seed :  40
result_dirpath :  /u/erdos/students/xcui32/cnslab/results/VOC8R18BlackCUR
save_checkpoints :  False
save_progress_checkpoints :  False
verbose :  0
 ---  Loading datasets ---
 ---  Running  ---
Parameters: --------------------
{'scheduler_kwargs': {'mode': 'min', 'factor': 0.1, 'patience': 5}, 'optim_kwargs': {'lr': 0.001, 'momentum': 0.9}, 'max_norm': None, 'val_target': 'current', 'patience': 30, 'early_stopping': True, 'scheduler_object': None, 'optimizer_object': <class 'torch.optim.sgd.SGD'>, 'criterion_object': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'self': <pipelineCV2.RunModel object at 0x2aac786ee438>}
--------------------
Fold: 0
----- Training resnet18 with sequence: [0.2, 0.4, 0.6, 0.8, 1] -----
Current group: 0.2
Epoch [1/80], Training Loss: 39.9173, Validation Loss Current: 10.0708, Validation Loss AVG: 10.0708, lr: 0.001
Epoch [2/80], Training Loss: 39.7213, Validation Loss Current: 10.7321, Validation Loss AVG: 10.7321, lr: 0.001
Epoch [3/80], Training Loss: 39.0700, Validation Loss Current: 11.8445, Validation Loss AVG: 11.8445, lr: 0.001
Epoch [4/80], Training Loss: 38.1524, Validation Loss Current: 11.7073, Validation Loss AVG: 11.7073, lr: 0.001
Epoch [5/80], Training Loss: 36.3984, Validation Loss Current: 11.3986, Validation Loss AVG: 11.3986, lr: 0.001
Epoch [6/80], Training Loss: 35.0187, Validation Loss Current: 10.4143, Validation Loss AVG: 10.4143, lr: 0.001
Epoch [7/80], Training Loss: 35.0233, Validation Loss Current: 11.6288, Validation Loss AVG: 11.6288, lr: 0.001
Epoch [8/80], Training Loss: 33.2824, Validation Loss Current: 11.2578, Validation Loss AVG: 11.2578, lr: 0.001
Epoch [9/80], Training Loss: 32.9182, Validation Loss Current: 11.5036, Validation Loss AVG: 11.5036, lr: 0.001
Epoch [10/80], Training Loss: 32.5038, Validation Loss Current: 10.7821, Validation Loss AVG: 10.7821, lr: 0.001
Epoch [11/80], Training Loss: 31.6923, Validation Loss Current: 10.8551, Validation Loss AVG: 10.8551, lr: 0.001
Epoch [12/80], Training Loss: 30.8825, Validation Loss Current: 11.2224, Validation Loss AVG: 11.2224, lr: 0.001
Epoch [13/80], Training Loss: 31.0254, Validation Loss Current: 11.5444, Validation Loss AVG: 11.5444, lr: 0.001
Epoch [14/80], Training Loss: 29.4797, Validation Loss Current: 11.1127, Validation Loss AVG: 11.1127, lr: 0.001
Epoch [15/80], Training Loss: 27.7072, Validation Loss Current: 12.2267, Validation Loss AVG: 12.2267, lr: 0.001
Epoch [16/80], Training Loss: 27.5819, Validation Loss Current: 11.8722, Validation Loss AVG: 11.8722, lr: 0.001
Epoch [17/80], Training Loss: 26.5671, Validation Loss Current: 11.7790, Validation Loss AVG: 11.7790, lr: 0.001
Epoch [18/80], Training Loss: 27.5588, Validation Loss Current: 11.3284, Validation Loss AVG: 11.3284, lr: 0.001
Epoch [19/80], Training Loss: 25.7769, Validation Loss Current: 11.1092, Validation Loss AVG: 11.1092, lr: 0.001
Epoch [20/80], Training Loss: 24.0455, Validation Loss Current: 11.9482, Validation Loss AVG: 11.9482, lr: 0.001
Epoch [21/80], Training Loss: 23.4556, Validation Loss Current: 11.7015, Validation Loss AVG: 11.7015, lr: 0.001
Epoch [22/80], Training Loss: 21.3872, Validation Loss Current: 12.4119, Validation Loss AVG: 12.4119, lr: 0.001
Epoch [23/80], Training Loss: 21.1318, Validation Loss Current: 11.0520, Validation Loss AVG: 11.0520, lr: 0.001
Epoch [24/80], Training Loss: 19.2894, Validation Loss Current: 12.7466, Validation Loss AVG: 12.7466, lr: 0.001
Epoch [25/80], Training Loss: 19.2290, Validation Loss Current: 11.7344, Validation Loss AVG: 11.7344, lr: 0.001
Epoch [26/80], Training Loss: 19.4972, Validation Loss Current: 13.7392, Validation Loss AVG: 13.7392, lr: 0.001
Epoch [27/80], Training Loss: 19.8152, Validation Loss Current: 12.3150, Validation Loss AVG: 12.3150, lr: 0.001
Epoch [28/80], Training Loss: 16.9943, Validation Loss Current: 14.6897, Validation Loss AVG: 14.6897, lr: 0.001
Epoch [29/80], Training Loss: 15.0277, Validation Loss Current: 13.7675, Validation Loss AVG: 13.7675, lr: 0.001
Epoch [30/80], Training Loss: 15.5166, Validation Loss Current: 15.5823, Validation Loss AVG: 15.5823, lr: 0.001
Epoch [31/80], Training Loss: 14.2528, Validation Loss Current: 13.8605, Validation Loss AVG: 13.8605, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 1 Best val accuracy: [0.22269736842105262, 0.16578947368421054, 0.14835526315789474, 0.17960526315789474, 0.23092105263157894, 0.24046052631578946, 0.20098684210526319, 0.2348684210526316, 0.23651315789473687, 0.2713815789473684, 0.2509868421052631, 0.2723684210526316, 0.27039473684210524, 0.23322368421052633, 0.29967105263157895, 0.2878289473684211, 0.3263157894736842, 0.3082236842105263, 0.3391447368421053, 0.2960526315789474, 0.32203947368421054, 0.32171052631578945, 0.36151315789473687, 0.31414473684210525, 0.34967105263157894, 0.3059210526315789, 0.3631578947368421, 0.27664473684210533, 0.31447368421052635, 0.28519736842105264, 0.34210526315789475] Best val loss: 10.070799899101257


Current group: 0.4
Epoch [1/80], Training Loss: 32.7493, Validation Loss Current: 13.4010, Validation Loss AVG: 13.4010, lr: 0.001
Epoch [2/80], Training Loss: 29.9377, Validation Loss Current: 12.7928, Validation Loss AVG: 12.7928, lr: 0.001
Epoch [3/80], Training Loss: 27.7278, Validation Loss Current: 10.3376, Validation Loss AVG: 10.3376, lr: 0.001
Epoch [4/80], Training Loss: 25.2058, Validation Loss Current: 8.7850, Validation Loss AVG: 8.7850, lr: 0.001
Epoch [5/80], Training Loss: 23.8840, Validation Loss Current: 10.6224, Validation Loss AVG: 10.6224, lr: 0.001
Epoch [6/80], Training Loss: 23.5114, Validation Loss Current: 8.7705, Validation Loss AVG: 8.7705, lr: 0.001
Epoch [7/80], Training Loss: 21.7624, Validation Loss Current: 9.6889, Validation Loss AVG: 9.6889, lr: 0.001
Epoch [8/80], Training Loss: 21.4901, Validation Loss Current: 9.6724, Validation Loss AVG: 9.6724, lr: 0.001
Epoch [9/80], Training Loss: 17.3004, Validation Loss Current: 8.7239, Validation Loss AVG: 8.7239, lr: 0.001
Epoch [10/80], Training Loss: 16.1535, Validation Loss Current: 8.8055, Validation Loss AVG: 8.8055, lr: 0.001
Epoch [11/80], Training Loss: 15.5655, Validation Loss Current: 9.9017, Validation Loss AVG: 9.9017, lr: 0.001
Epoch [12/80], Training Loss: 14.4807, Validation Loss Current: 9.1300, Validation Loss AVG: 9.1300, lr: 0.001
Epoch [13/80], Training Loss: 13.4479, Validation Loss Current: 9.1458, Validation Loss AVG: 9.1458, lr: 0.001
Epoch [14/80], Training Loss: 10.8085, Validation Loss Current: 9.2278, Validation Loss AVG: 9.2278, lr: 0.001
Epoch [15/80], Training Loss: 11.1589, Validation Loss Current: 9.5842, Validation Loss AVG: 9.5842, lr: 0.001
Epoch [16/80], Training Loss: 11.6416, Validation Loss Current: 9.3611, Validation Loss AVG: 9.3611, lr: 0.001
Epoch [17/80], Training Loss: 10.3312, Validation Loss Current: 11.0224, Validation Loss AVG: 11.0224, lr: 0.001
Epoch [18/80], Training Loss: 9.0060, Validation Loss Current: 9.0603, Validation Loss AVG: 9.0603, lr: 0.001
Epoch [19/80], Training Loss: 7.3538, Validation Loss Current: 10.1070, Validation Loss AVG: 10.1070, lr: 0.001
Epoch [20/80], Training Loss: 10.1309, Validation Loss Current: 10.3195, Validation Loss AVG: 10.3195, lr: 0.001
Epoch [21/80], Training Loss: 8.8133, Validation Loss Current: 10.8958, Validation Loss AVG: 10.8958, lr: 0.001
Epoch [22/80], Training Loss: 6.0268, Validation Loss Current: 10.9790, Validation Loss AVG: 10.9790, lr: 0.001
Epoch [23/80], Training Loss: 6.8266, Validation Loss Current: 14.2155, Validation Loss AVG: 14.2155, lr: 0.001
Epoch [24/80], Training Loss: 11.3223, Validation Loss Current: 13.5055, Validation Loss AVG: 13.5055, lr: 0.001
Epoch [25/80], Training Loss: 13.2359, Validation Loss Current: 10.5876, Validation Loss AVG: 10.5876, lr: 0.001
Epoch [26/80], Training Loss: 10.5016, Validation Loss Current: 16.0900, Validation Loss AVG: 16.0900, lr: 0.001
Epoch [27/80], Training Loss: 8.0874, Validation Loss Current: 10.7796, Validation Loss AVG: 10.7796, lr: 0.001
Epoch [28/80], Training Loss: 6.9953, Validation Loss Current: 19.1246, Validation Loss AVG: 19.1246, lr: 0.001
Epoch [29/80], Training Loss: 13.5787, Validation Loss Current: 12.9282, Validation Loss AVG: 12.9282, lr: 0.001
Epoch [30/80], Training Loss: 13.1542, Validation Loss Current: 13.0581, Validation Loss AVG: 13.0581, lr: 0.001
Epoch [31/80], Training Loss: 7.9579, Validation Loss Current: 12.4966, Validation Loss AVG: 12.4966, lr: 0.001
Epoch [32/80], Training Loss: 8.7809, Validation Loss Current: 12.1529, Validation Loss AVG: 12.1529, lr: 0.001
Epoch [33/80], Training Loss: 14.5024, Validation Loss Current: 16.6135, Validation Loss AVG: 16.6135, lr: 0.001
Epoch [34/80], Training Loss: 12.5893, Validation Loss Current: 12.5188, Validation Loss AVG: 12.5188, lr: 0.001
Epoch [35/80], Training Loss: 6.8423, Validation Loss Current: 11.7565, Validation Loss AVG: 11.7565, lr: 0.001
Epoch [36/80], Training Loss: 4.8090, Validation Loss Current: 11.4125, Validation Loss AVG: 11.4125, lr: 0.001
Epoch [37/80], Training Loss: 5.3906, Validation Loss Current: 11.9128, Validation Loss AVG: 11.9128, lr: 0.001
Epoch [38/80], Training Loss: 8.6203, Validation Loss Current: 15.0397, Validation Loss AVG: 15.0397, lr: 0.001
Epoch [39/80], Training Loss: 6.2353, Validation Loss Current: 11.9130, Validation Loss AVG: 11.9130, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 9 Best val accuracy: [0.32960526315789473, 0.3171052631578948, 0.33980263157894736, 0.38125, 0.3796052631578947, 0.4072368421052632, 0.3953947368421053, 0.38125000000000003, 0.4414473684210526, 0.4203947368421052, 0.39934210526315794, 0.42894736842105263, 0.42434210526315796, 0.4180921052631579, 0.41118421052631576, 0.4141447368421053, 0.35625, 0.4319078947368421, 0.43157894736842106, 0.39999999999999997, 0.4128289473684211, 0.38618421052631574, 0.35000000000000003, 0.3269736842105263, 0.3914473684210526, 0.3608552631578947, 0.41940789473684215, 0.3299342105263158, 0.3003289473684211, 0.3855263157894736, 0.3447368421052631, 0.38256578947368425, 0.34440789473684214, 0.3697368421052632, 0.4072368421052631, 0.40065789473684205, 0.36184210526315785, 0.3585526315789474, 0.4036184210526315] Best val loss: 8.723854875564575


Current group: 0.6
Epoch [1/80], Training Loss: 34.4735, Validation Loss Current: 10.2006, Validation Loss AVG: 10.2006, lr: 0.001
Epoch [2/80], Training Loss: 21.9094, Validation Loss Current: 10.0165, Validation Loss AVG: 10.0165, lr: 0.001
Epoch [3/80], Training Loss: 18.0529, Validation Loss Current: 10.2016, Validation Loss AVG: 10.2016, lr: 0.001
Epoch [4/80], Training Loss: 15.7600, Validation Loss Current: 10.1922, Validation Loss AVG: 10.1922, lr: 0.001
Epoch [5/80], Training Loss: 14.9265, Validation Loss Current: 10.7248, Validation Loss AVG: 10.7248, lr: 0.001
Epoch [6/80], Training Loss: 13.0689, Validation Loss Current: 9.8752, Validation Loss AVG: 9.8752, lr: 0.001
Epoch [7/80], Training Loss: 12.2429, Validation Loss Current: 10.7258, Validation Loss AVG: 10.7258, lr: 0.001
Epoch [8/80], Training Loss: 11.2481, Validation Loss Current: 9.7111, Validation Loss AVG: 9.7111, lr: 0.001
Epoch [9/80], Training Loss: 10.2219, Validation Loss Current: 9.6599, Validation Loss AVG: 9.6599, lr: 0.001
Epoch [10/80], Training Loss: 8.3142, Validation Loss Current: 9.8943, Validation Loss AVG: 9.8943, lr: 0.001
Epoch [11/80], Training Loss: 7.3785, Validation Loss Current: 9.7023, Validation Loss AVG: 9.7023, lr: 0.001
Epoch [12/80], Training Loss: 8.4280, Validation Loss Current: 11.5313, Validation Loss AVG: 11.5313, lr: 0.001
Epoch [13/80], Training Loss: 6.5224, Validation Loss Current: 11.0316, Validation Loss AVG: 11.0316, lr: 0.001
Epoch [14/80], Training Loss: 5.2683, Validation Loss Current: 11.3760, Validation Loss AVG: 11.3760, lr: 0.001
Epoch [15/80], Training Loss: 4.9826, Validation Loss Current: 11.1109, Validation Loss AVG: 11.1109, lr: 0.001
Epoch [16/80], Training Loss: 4.5026, Validation Loss Current: 9.9813, Validation Loss AVG: 9.9813, lr: 0.001
Epoch [17/80], Training Loss: 8.6460, Validation Loss Current: 11.1287, Validation Loss AVG: 11.1287, lr: 0.001
Epoch [18/80], Training Loss: 14.3957, Validation Loss Current: 12.8185, Validation Loss AVG: 12.8185, lr: 0.001
Epoch [19/80], Training Loss: 10.7480, Validation Loss Current: 11.8862, Validation Loss AVG: 11.8862, lr: 0.001
Epoch [20/80], Training Loss: 7.5122, Validation Loss Current: 12.9981, Validation Loss AVG: 12.9981, lr: 0.001
Epoch [21/80], Training Loss: 9.9872, Validation Loss Current: 11.2420, Validation Loss AVG: 11.2420, lr: 0.001
Epoch [22/80], Training Loss: 10.0787, Validation Loss Current: 10.8772, Validation Loss AVG: 10.8772, lr: 0.001
Epoch [23/80], Training Loss: 9.2788, Validation Loss Current: 10.5710, Validation Loss AVG: 10.5710, lr: 0.001
Epoch [24/80], Training Loss: 5.1942, Validation Loss Current: 11.0417, Validation Loss AVG: 11.0417, lr: 0.001
Epoch [25/80], Training Loss: 5.8242, Validation Loss Current: 11.4594, Validation Loss AVG: 11.4594, lr: 0.001
Epoch [26/80], Training Loss: 5.0306, Validation Loss Current: 11.2236, Validation Loss AVG: 11.2236, lr: 0.001
Epoch [27/80], Training Loss: 2.6491, Validation Loss Current: 11.1244, Validation Loss AVG: 11.1244, lr: 0.001
Epoch [28/80], Training Loss: 2.0914, Validation Loss Current: 11.3815, Validation Loss AVG: 11.3815, lr: 0.001
Epoch [29/80], Training Loss: 1.6451, Validation Loss Current: 10.8620, Validation Loss AVG: 10.8620, lr: 0.001
Epoch [30/80], Training Loss: 1.3786, Validation Loss Current: 11.3529, Validation Loss AVG: 11.3529, lr: 0.001
Epoch [31/80], Training Loss: 1.9034, Validation Loss Current: 11.5419, Validation Loss AVG: 11.5419, lr: 0.001
Epoch [32/80], Training Loss: 2.8048, Validation Loss Current: 13.4853, Validation Loss AVG: 13.4853, lr: 0.001
Epoch [33/80], Training Loss: 1.7976, Validation Loss Current: 11.6203, Validation Loss AVG: 11.6203, lr: 0.001
Epoch [34/80], Training Loss: 1.7043, Validation Loss Current: 11.7513, Validation Loss AVG: 11.7513, lr: 0.001
Epoch [35/80], Training Loss: 1.8051, Validation Loss Current: 11.3842, Validation Loss AVG: 11.3842, lr: 0.001
Epoch [36/80], Training Loss: 2.5729, Validation Loss Current: 11.6391, Validation Loss AVG: 11.6391, lr: 0.001
Epoch [37/80], Training Loss: 3.0625, Validation Loss Current: 12.8295, Validation Loss AVG: 12.8295, lr: 0.001
Epoch [38/80], Training Loss: 3.6737, Validation Loss Current: 13.3024, Validation Loss AVG: 13.3024, lr: 0.001
Epoch [39/80], Training Loss: 3.7336, Validation Loss Current: 13.2716, Validation Loss AVG: 13.2716, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 9 Best val accuracy: [0.4269736842105263, 0.4213815789473684, 0.40361842105263157, 0.41414473684210523, 0.41875, 0.4161184210526316, 0.39868421052631575, 0.44868421052631574, 0.4407894736842105, 0.44605263157894737, 0.44703947368421054, 0.40888157894736843, 0.44177631578947374, 0.3921052631578948, 0.43782894736842104, 0.44901315789473684, 0.4375, 0.3983552631578947, 0.41940789473684215, 0.37664473684210525, 0.4203947368421053, 0.43947368421052635, 0.4207236842105263, 0.43947368421052635, 0.4328947368421052, 0.4358552631578948, 0.4427631578947368, 0.45, 0.45723684210526316, 0.46118421052631575, 0.44506578947368425, 0.40394736842105267, 0.4460526315789474, 0.44375, 0.4394736842105263, 0.43618421052631584, 0.4322368421052632, 0.41578947368421043, 0.4207236842105263] Best val loss: 9.659910106658936


Current group: 0.8
Epoch [1/80], Training Loss: 31.8483, Validation Loss Current: 11.7115, Validation Loss AVG: 11.7115, lr: 0.001
Epoch [2/80], Training Loss: 21.5058, Validation Loss Current: 10.6172, Validation Loss AVG: 10.6172, lr: 0.001
Epoch [3/80], Training Loss: 12.2041, Validation Loss Current: 10.0454, Validation Loss AVG: 10.0454, lr: 0.001
Epoch [4/80], Training Loss: 8.5328, Validation Loss Current: 10.2716, Validation Loss AVG: 10.2716, lr: 0.001
Epoch [5/80], Training Loss: 8.9632, Validation Loss Current: 12.7429, Validation Loss AVG: 12.7429, lr: 0.001
Epoch [6/80], Training Loss: 4.8701, Validation Loss Current: 10.2104, Validation Loss AVG: 10.2104, lr: 0.001
Epoch [7/80], Training Loss: 4.3429, Validation Loss Current: 11.0786, Validation Loss AVG: 11.0786, lr: 0.001
Epoch [8/80], Training Loss: 5.1560, Validation Loss Current: 11.1947, Validation Loss AVG: 11.1947, lr: 0.001
Epoch [9/80], Training Loss: 6.5661, Validation Loss Current: 11.5958, Validation Loss AVG: 11.5958, lr: 0.001
Epoch [10/80], Training Loss: 7.8651, Validation Loss Current: 11.1939, Validation Loss AVG: 11.1939, lr: 0.001
Epoch [11/80], Training Loss: 4.9867, Validation Loss Current: 12.0080, Validation Loss AVG: 12.0080, lr: 0.001
Epoch [12/80], Training Loss: 2.6313, Validation Loss Current: 11.6607, Validation Loss AVG: 11.6607, lr: 0.001
Epoch [13/80], Training Loss: 2.6852, Validation Loss Current: 11.2097, Validation Loss AVG: 11.2097, lr: 0.001
Epoch [14/80], Training Loss: 4.9423, Validation Loss Current: 13.5055, Validation Loss AVG: 13.5055, lr: 0.001
Epoch [15/80], Training Loss: 13.2654, Validation Loss Current: 16.4077, Validation Loss AVG: 16.4077, lr: 0.001
Epoch [16/80], Training Loss: 5.5764, Validation Loss Current: 11.1326, Validation Loss AVG: 11.1326, lr: 0.001
Epoch [17/80], Training Loss: 3.6789, Validation Loss Current: 12.2600, Validation Loss AVG: 12.2600, lr: 0.001
Epoch [18/80], Training Loss: 2.6956, Validation Loss Current: 11.2949, Validation Loss AVG: 11.2949, lr: 0.001
Epoch [19/80], Training Loss: 3.2981, Validation Loss Current: 11.3395, Validation Loss AVG: 11.3395, lr: 0.001
Epoch [20/80], Training Loss: 7.3088, Validation Loss Current: 14.5882, Validation Loss AVG: 14.5882, lr: 0.001
Epoch [21/80], Training Loss: 6.9315, Validation Loss Current: 13.5753, Validation Loss AVG: 13.5753, lr: 0.001
Epoch [22/80], Training Loss: 5.4356, Validation Loss Current: 13.3557, Validation Loss AVG: 13.3557, lr: 0.001
Epoch [23/80], Training Loss: 4.7735, Validation Loss Current: 11.7827, Validation Loss AVG: 11.7827, lr: 0.001
Epoch [24/80], Training Loss: 3.9344, Validation Loss Current: 12.3556, Validation Loss AVG: 12.3556, lr: 0.001
Epoch [25/80], Training Loss: 5.1616, Validation Loss Current: 13.8967, Validation Loss AVG: 13.8967, lr: 0.001
Epoch [26/80], Training Loss: 4.7468, Validation Loss Current: 12.4821, Validation Loss AVG: 12.4821, lr: 0.001
Epoch [27/80], Training Loss: 5.5045, Validation Loss Current: 12.0777, Validation Loss AVG: 12.0777, lr: 0.001
Epoch [28/80], Training Loss: 4.9996, Validation Loss Current: 11.9871, Validation Loss AVG: 11.9871, lr: 0.001
Epoch [29/80], Training Loss: 4.8881, Validation Loss Current: 13.6497, Validation Loss AVG: 13.6497, lr: 0.001
Epoch [30/80], Training Loss: 4.7100, Validation Loss Current: 13.1297, Validation Loss AVG: 13.1297, lr: 0.001
Epoch [31/80], Training Loss: 5.6566, Validation Loss Current: 15.5595, Validation Loss AVG: 15.5595, lr: 0.001
Epoch [32/80], Training Loss: 7.0370, Validation Loss Current: 12.9436, Validation Loss AVG: 12.9436, lr: 0.001
Epoch [33/80], Training Loss: 6.2539, Validation Loss Current: 12.3370, Validation Loss AVG: 12.3370, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 3 Best val accuracy: [0.4253289473684211, 0.45921052631578946, 0.47730263157894737, 0.45230263157894746, 0.43618421052631573, 0.46875, 0.47368421052631576, 0.45756578947368426, 0.44901315789473684, 0.4631578947368421, 0.44342105263157894, 0.4546052631578947, 0.4773026315789474, 0.40559210526315786, 0.39703947368421055, 0.43684210526315786, 0.4391447368421053, 0.456578947368421, 0.45230263157894746, 0.4338815789473685, 0.4391447368421052, 0.4220394736842105, 0.4565789473684211, 0.4480263157894736, 0.43322368421052626, 0.4463815789473684, 0.4259868421052631, 0.45756578947368426, 0.39473684210526316, 0.44769736842105257, 0.36875, 0.44046052631578947, 0.42993421052631575] Best val loss: 10.045430016517638


Current group: 1
Epoch [1/80], Training Loss: 26.2763, Validation Loss Current: 8.7541, Validation Loss AVG: 12.3507, lr: 0.001
Epoch [2/80], Training Loss: 17.1357, Validation Loss Current: 9.9299, Validation Loss AVG: 13.2431, lr: 0.001
Epoch [3/80], Training Loss: 9.5108, Validation Loss Current: 7.5812, Validation Loss AVG: 10.2726, lr: 0.001
Epoch [4/80], Training Loss: 5.0446, Validation Loss Current: 7.5771, Validation Loss AVG: 11.5413, lr: 0.001
Epoch [5/80], Training Loss: 5.2272, Validation Loss Current: 7.9574, Validation Loss AVG: 11.1180, lr: 0.001
Epoch [6/80], Training Loss: 9.3485, Validation Loss Current: 8.0831, Validation Loss AVG: 13.2897, lr: 0.001
Epoch [7/80], Training Loss: 8.7354, Validation Loss Current: 10.6445, Validation Loss AVG: 15.0393, lr: 0.001
Epoch [8/80], Training Loss: 8.4352, Validation Loss Current: 8.9799, Validation Loss AVG: 12.0050, lr: 0.001
Epoch [9/80], Training Loss: 7.8833, Validation Loss Current: 8.1216, Validation Loss AVG: 12.6110, lr: 0.001
Epoch [10/80], Training Loss: 5.2427, Validation Loss Current: 7.9376, Validation Loss AVG: 12.8510, lr: 0.001
Epoch [11/80], Training Loss: 2.8981, Validation Loss Current: 8.3339, Validation Loss AVG: 12.8913, lr: 0.001
Epoch [12/80], Training Loss: 4.8250, Validation Loss Current: 7.4758, Validation Loss AVG: 12.3211, lr: 0.001
Epoch [13/80], Training Loss: 3.1881, Validation Loss Current: 8.2623, Validation Loss AVG: 14.1221, lr: 0.001
Epoch [14/80], Training Loss: 5.4179, Validation Loss Current: 9.5404, Validation Loss AVG: 12.8754, lr: 0.001
Epoch [15/80], Training Loss: 11.2980, Validation Loss Current: 10.3672, Validation Loss AVG: 12.9836, lr: 0.001
Epoch [16/80], Training Loss: 7.5104, Validation Loss Current: 11.3246, Validation Loss AVG: 15.7647, lr: 0.001
Epoch [17/80], Training Loss: 6.9603, Validation Loss Current: 8.8223, Validation Loss AVG: 12.4865, lr: 0.001
Epoch [18/80], Training Loss: 3.8412, Validation Loss Current: 8.1142, Validation Loss AVG: 15.1910, lr: 0.001
Epoch [19/80], Training Loss: 2.9000, Validation Loss Current: 8.6245, Validation Loss AVG: 12.5495, lr: 0.001
Epoch [20/80], Training Loss: 1.4451, Validation Loss Current: 7.6230, Validation Loss AVG: 13.3007, lr: 0.001
Epoch [21/80], Training Loss: 0.8609, Validation Loss Current: 7.7606, Validation Loss AVG: 13.0329, lr: 0.001
Epoch [22/80], Training Loss: 2.0380, Validation Loss Current: 8.0042, Validation Loss AVG: 12.2846, lr: 0.001
Epoch [23/80], Training Loss: 4.6241, Validation Loss Current: 8.0345, Validation Loss AVG: 13.7237, lr: 0.001
Epoch [24/80], Training Loss: 1.7209, Validation Loss Current: 8.2904, Validation Loss AVG: 14.1262, lr: 0.001
Epoch [25/80], Training Loss: 2.0157, Validation Loss Current: 8.2590, Validation Loss AVG: 13.0063, lr: 0.001
Epoch [26/80], Training Loss: 1.9918, Validation Loss Current: 9.2312, Validation Loss AVG: 14.9950, lr: 0.001
Epoch [27/80], Training Loss: 1.5834, Validation Loss Current: 8.8517, Validation Loss AVG: 13.4407, lr: 0.001
Epoch [28/80], Training Loss: 4.5283, Validation Loss Current: 9.0886, Validation Loss AVG: 14.1199, lr: 0.001
Epoch [29/80], Training Loss: 7.6434, Validation Loss Current: 9.4318, Validation Loss AVG: 13.8112, lr: 0.001
Epoch [30/80], Training Loss: 5.1071, Validation Loss Current: 9.8037, Validation Loss AVG: 14.8611, lr: 0.001
Epoch [31/80], Training Loss: 2.2593, Validation Loss Current: 8.0952, Validation Loss AVG: 13.1411, lr: 0.001
Epoch [32/80], Training Loss: 1.6033, Validation Loss Current: 8.2879, Validation Loss AVG: 13.5750, lr: 0.001
Epoch [33/80], Training Loss: 0.6988, Validation Loss Current: 7.8077, Validation Loss AVG: 13.5971, lr: 0.001
Epoch [34/80], Training Loss: 1.5326, Validation Loss Current: 8.5949, Validation Loss AVG: 14.9763, lr: 0.001
Epoch [35/80], Training Loss: 3.2331, Validation Loss Current: 8.7428, Validation Loss AVG: 13.7037, lr: 0.001
Epoch [36/80], Training Loss: 5.1494, Validation Loss Current: 9.2071, Validation Loss AVG: 14.0995, lr: 0.001
Epoch [37/80], Training Loss: 4.3536, Validation Loss Current: 9.6915, Validation Loss AVG: 14.3680, lr: 0.001
Epoch [38/80], Training Loss: 2.8246, Validation Loss Current: 9.3355, Validation Loss AVG: 16.0125, lr: 0.001
Epoch [39/80], Training Loss: 2.1086, Validation Loss Current: 8.6967, Validation Loss AVG: 15.1021, lr: 0.001
Epoch [40/80], Training Loss: 3.6073, Validation Loss Current: 10.5007, Validation Loss AVG: 18.4077, lr: 0.001
Epoch [41/80], Training Loss: 7.4471, Validation Loss Current: 9.8822, Validation Loss AVG: 15.7780, lr: 0.001
Epoch [42/80], Training Loss: 6.4154, Validation Loss Current: 10.7346, Validation Loss AVG: 16.0723, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 12 Best val accuracy: [0.53125, 0.5674342105263158, 0.5723684210526315, 0.5756578947368421, 0.5723684210526315, 0.5641447368421053, 0.5674342105263158, 0.537828947368421, 0.555921052631579, 0.59375, 0.5789473684210527, 0.6101973684210527, 0.5641447368421053, 0.5542763157894737, 0.5148026315789473, 0.5115131578947368, 0.5526315789473685, 0.5888157894736842, 0.5773026315789473, 0.5970394736842105, 0.59375, 0.6069078947368421, 0.5970394736842105, 0.5904605263157895, 0.6134868421052632, 0.5707236842105263, 0.6019736842105263, 0.5888157894736842, 0.5641447368421053, 0.5444078947368421, 0.59375, 0.5789473684210527, 0.5921052631578947, 0.5921052631578947, 0.59375, 0.5756578947368421, 0.53125, 0.5460526315789473, 0.5921052631578947, 0.555921052631579, 0.555921052631579, 0.5345394736842105] Best val loss: 7.475806713104248


----- Training resnet18 with sequence: [0.4, 0.6, 0.8, 1] -----
Current group: 0.4
Epoch [1/100], Training Loss: 41.4229, Validation Loss Current: 10.1096, Validation Loss AVG: 10.1096, lr: 0.001
Epoch [2/100], Training Loss: 39.7348, Validation Loss Current: 10.0047, Validation Loss AVG: 10.0047, lr: 0.001
Epoch [3/100], Training Loss: 39.3169, Validation Loss Current: 9.9658, Validation Loss AVG: 9.9658, lr: 0.001
Epoch [4/100], Training Loss: 38.2430, Validation Loss Current: 9.6232, Validation Loss AVG: 9.6232, lr: 0.001
Epoch [5/100], Training Loss: 37.1519, Validation Loss Current: 9.6648, Validation Loss AVG: 9.6648, lr: 0.001
Epoch [6/100], Training Loss: 35.6582, Validation Loss Current: 9.5863, Validation Loss AVG: 9.5863, lr: 0.001
Epoch [7/100], Training Loss: 34.8671, Validation Loss Current: 9.2376, Validation Loss AVG: 9.2376, lr: 0.001
Epoch [8/100], Training Loss: 34.1760, Validation Loss Current: 9.1918, Validation Loss AVG: 9.1918, lr: 0.001
Epoch [9/100], Training Loss: 32.8710, Validation Loss Current: 8.9070, Validation Loss AVG: 8.9070, lr: 0.001
Epoch [10/100], Training Loss: 32.4354, Validation Loss Current: 9.9054, Validation Loss AVG: 9.9054, lr: 0.001
Epoch [11/100], Training Loss: 30.9443, Validation Loss Current: 9.1009, Validation Loss AVG: 9.1009, lr: 0.001
Epoch [12/100], Training Loss: 30.1975, Validation Loss Current: 10.0203, Validation Loss AVG: 10.0203, lr: 0.001
Epoch [13/100], Training Loss: 29.4805, Validation Loss Current: 8.4691, Validation Loss AVG: 8.4691, lr: 0.001
Epoch [14/100], Training Loss: 27.9159, Validation Loss Current: 8.5745, Validation Loss AVG: 8.5745, lr: 0.001
Epoch [15/100], Training Loss: 27.9259, Validation Loss Current: 8.8503, Validation Loss AVG: 8.8503, lr: 0.001
Epoch [16/100], Training Loss: 26.9462, Validation Loss Current: 8.8233, Validation Loss AVG: 8.8233, lr: 0.001
Epoch [17/100], Training Loss: 25.8780, Validation Loss Current: 8.1675, Validation Loss AVG: 8.1675, lr: 0.001
Epoch [18/100], Training Loss: 27.3265, Validation Loss Current: 8.9558, Validation Loss AVG: 8.9558, lr: 0.001
Epoch [19/100], Training Loss: 26.2103, Validation Loss Current: 9.4093, Validation Loss AVG: 9.4093, lr: 0.001
Epoch [20/100], Training Loss: 24.7445, Validation Loss Current: 8.1445, Validation Loss AVG: 8.1445, lr: 0.001
Epoch [21/100], Training Loss: 24.5690, Validation Loss Current: 8.4072, Validation Loss AVG: 8.4072, lr: 0.001
Epoch [22/100], Training Loss: 22.6680, Validation Loss Current: 8.2373, Validation Loss AVG: 8.2373, lr: 0.001
Epoch [23/100], Training Loss: 21.5298, Validation Loss Current: 8.5621, Validation Loss AVG: 8.5621, lr: 0.001
Epoch [24/100], Training Loss: 22.2288, Validation Loss Current: 9.5504, Validation Loss AVG: 9.5504, lr: 0.001
Epoch [25/100], Training Loss: 21.5883, Validation Loss Current: 8.7566, Validation Loss AVG: 8.7566, lr: 0.001
Epoch [26/100], Training Loss: 20.8848, Validation Loss Current: 9.0617, Validation Loss AVG: 9.0617, lr: 0.001
Epoch [27/100], Training Loss: 20.4367, Validation Loss Current: 10.0107, Validation Loss AVG: 10.0107, lr: 0.001
Epoch [28/100], Training Loss: 21.4869, Validation Loss Current: 8.8348, Validation Loss AVG: 8.8348, lr: 0.001
Epoch [29/100], Training Loss: 17.8967, Validation Loss Current: 9.4177, Validation Loss AVG: 9.4177, lr: 0.001
Epoch [30/100], Training Loss: 15.7905, Validation Loss Current: 8.6084, Validation Loss AVG: 8.6084, lr: 0.001
Epoch [31/100], Training Loss: 14.2078, Validation Loss Current: 8.7746, Validation Loss AVG: 8.7746, lr: 0.001
Epoch [32/100], Training Loss: 13.2350, Validation Loss Current: 8.6331, Validation Loss AVG: 8.6331, lr: 0.001
Epoch [33/100], Training Loss: 12.5544, Validation Loss Current: 8.3000, Validation Loss AVG: 8.3000, lr: 0.001
Epoch [34/100], Training Loss: 11.5488, Validation Loss Current: 8.9322, Validation Loss AVG: 8.9322, lr: 0.001
Epoch [35/100], Training Loss: 11.2456, Validation Loss Current: 9.4032, Validation Loss AVG: 9.4032, lr: 0.001
Epoch [36/100], Training Loss: 10.7452, Validation Loss Current: 8.8415, Validation Loss AVG: 8.8415, lr: 0.001
Epoch [37/100], Training Loss: 10.7123, Validation Loss Current: 11.6007, Validation Loss AVG: 11.6007, lr: 0.001
Epoch [38/100], Training Loss: 11.6324, Validation Loss Current: 11.4166, Validation Loss AVG: 11.4166, lr: 0.001
Epoch [39/100], Training Loss: 10.9596, Validation Loss Current: 11.2597, Validation Loss AVG: 11.2597, lr: 0.001
Epoch [40/100], Training Loss: 9.8914, Validation Loss Current: 14.3276, Validation Loss AVG: 14.3276, lr: 0.001
Epoch [41/100], Training Loss: 9.3907, Validation Loss Current: 11.0104, Validation Loss AVG: 11.0104, lr: 0.001
Epoch [42/100], Training Loss: 9.9619, Validation Loss Current: 9.6426, Validation Loss AVG: 9.6426, lr: 0.001
Epoch [43/100], Training Loss: 8.8092, Validation Loss Current: 9.9380, Validation Loss AVG: 9.9380, lr: 0.001
Epoch [44/100], Training Loss: 7.5254, Validation Loss Current: 10.8974, Validation Loss AVG: 10.8974, lr: 0.001
Epoch [45/100], Training Loss: 10.0701, Validation Loss Current: 10.1417, Validation Loss AVG: 10.1417, lr: 0.001
Epoch [46/100], Training Loss: 10.1001, Validation Loss Current: 11.1341, Validation Loss AVG: 11.1341, lr: 0.001
Epoch [47/100], Training Loss: 8.5812, Validation Loss Current: 22.9652, Validation Loss AVG: 22.9652, lr: 0.001
Epoch [48/100], Training Loss: 10.3359, Validation Loss Current: 14.5022, Validation Loss AVG: 14.5022, lr: 0.001
Epoch [49/100], Training Loss: 7.3277, Validation Loss Current: 10.2135, Validation Loss AVG: 10.2135, lr: 0.001
Epoch [50/100], Training Loss: 7.9552, Validation Loss Current: 9.9349, Validation Loss AVG: 9.9349, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 20 Best val accuracy: [0.2013157894736842, 0.22796052631578947, 0.2473684210526316, 0.2983552631578947, 0.2980263157894737, 0.2976973684210526, 0.3493421052631579, 0.3401315789473684, 0.3513157894736842, 0.3325657894736842, 0.34539473684210525, 0.3319078947368421, 0.38914473684210527, 0.40493421052631573, 0.3631578947368421, 0.3986842105263158, 0.4253289473684211, 0.36348684210526316, 0.37335526315789475, 0.43881578947368427, 0.4088815789473685, 0.40690789473684214, 0.41940789473684215, 0.34342105263157896, 0.4276315789473684, 0.3453947368421052, 0.36907894736842106, 0.4009868421052632, 0.40592105263157896, 0.44342105263157894, 0.4161184210526316, 0.44046052631578947, 0.4430921052631579, 0.4164473684210527, 0.4009868421052632, 0.4233552631578948, 0.35230263157894737, 0.3335526315789473, 0.3138157894736842, 0.31842105263157894, 0.4029605263157895, 0.40657894736842104, 0.4236842105263158, 0.3657894736842105, 0.40493421052631573, 0.3694078947368421, 0.2674342105263158, 0.28092105263157896, 0.4134868421052632, 0.40230263157894736] Best val loss: 8.144515776634217


Current group: 0.6
Epoch [1/100], Training Loss: 29.4996, Validation Loss Current: 13.2807, Validation Loss AVG: 13.2807, lr: 0.001
Epoch [2/100], Training Loss: 22.7894, Validation Loss Current: 8.6625, Validation Loss AVG: 8.6625, lr: 0.001
Epoch [3/100], Training Loss: 20.7881, Validation Loss Current: 9.2054, Validation Loss AVG: 9.2054, lr: 0.001
Epoch [4/100], Training Loss: 17.9508, Validation Loss Current: 9.3218, Validation Loss AVG: 9.3218, lr: 0.001
Epoch [5/100], Training Loss: 16.0293, Validation Loss Current: 11.6331, Validation Loss AVG: 11.6331, lr: 0.001
Epoch [6/100], Training Loss: 15.0189, Validation Loss Current: 10.7013, Validation Loss AVG: 10.7013, lr: 0.001
Epoch [7/100], Training Loss: 14.1470, Validation Loss Current: 8.5971, Validation Loss AVG: 8.5971, lr: 0.001
Epoch [8/100], Training Loss: 12.0774, Validation Loss Current: 9.4040, Validation Loss AVG: 9.4040, lr: 0.001
Epoch [9/100], Training Loss: 10.4624, Validation Loss Current: 8.6590, Validation Loss AVG: 8.6590, lr: 0.001
Epoch [10/100], Training Loss: 7.8797, Validation Loss Current: 9.1405, Validation Loss AVG: 9.1405, lr: 0.001
Epoch [11/100], Training Loss: 7.1627, Validation Loss Current: 9.6835, Validation Loss AVG: 9.6835, lr: 0.001
Epoch [12/100], Training Loss: 6.1437, Validation Loss Current: 9.5403, Validation Loss AVG: 9.5403, lr: 0.001
Epoch [13/100], Training Loss: 5.5942, Validation Loss Current: 10.2299, Validation Loss AVG: 10.2299, lr: 0.001
Epoch [14/100], Training Loss: 9.1470, Validation Loss Current: 9.9829, Validation Loss AVG: 9.9829, lr: 0.001
Epoch [15/100], Training Loss: 9.2300, Validation Loss Current: 11.8642, Validation Loss AVG: 11.8642, lr: 0.001
Epoch [16/100], Training Loss: 17.8897, Validation Loss Current: 14.4796, Validation Loss AVG: 14.4796, lr: 0.001
Epoch [17/100], Training Loss: 14.0627, Validation Loss Current: 10.2692, Validation Loss AVG: 10.2692, lr: 0.001
Epoch [18/100], Training Loss: 14.5108, Validation Loss Current: 9.6654, Validation Loss AVG: 9.6654, lr: 0.001
Epoch [19/100], Training Loss: 9.6715, Validation Loss Current: 9.7713, Validation Loss AVG: 9.7713, lr: 0.001
Epoch [20/100], Training Loss: 7.4492, Validation Loss Current: 10.0057, Validation Loss AVG: 10.0057, lr: 0.001
Epoch [21/100], Training Loss: 6.9735, Validation Loss Current: 11.0079, Validation Loss AVG: 11.0079, lr: 0.001
Epoch [22/100], Training Loss: 5.4893, Validation Loss Current: 11.1233, Validation Loss AVG: 11.1233, lr: 0.001
Epoch [23/100], Training Loss: 4.1938, Validation Loss Current: 11.2824, Validation Loss AVG: 11.2824, lr: 0.001
Epoch [24/100], Training Loss: 6.6517, Validation Loss Current: 12.6381, Validation Loss AVG: 12.6381, lr: 0.001
Epoch [25/100], Training Loss: 5.7832, Validation Loss Current: 12.8743, Validation Loss AVG: 12.8743, lr: 0.001
Epoch [26/100], Training Loss: 4.1225, Validation Loss Current: 10.9209, Validation Loss AVG: 10.9209, lr: 0.001
Epoch [27/100], Training Loss: 5.0597, Validation Loss Current: 11.3314, Validation Loss AVG: 11.3314, lr: 0.001
Epoch [28/100], Training Loss: 4.6091, Validation Loss Current: 12.0671, Validation Loss AVG: 12.0671, lr: 0.001
Epoch [29/100], Training Loss: 4.9300, Validation Loss Current: 11.0932, Validation Loss AVG: 11.0932, lr: 0.001
Epoch [30/100], Training Loss: 3.5606, Validation Loss Current: 12.3153, Validation Loss AVG: 12.3153, lr: 0.001
Epoch [31/100], Training Loss: 2.2545, Validation Loss Current: 10.3540, Validation Loss AVG: 10.3540, lr: 0.001
Epoch [32/100], Training Loss: 2.5743, Validation Loss Current: 11.4293, Validation Loss AVG: 11.4293, lr: 0.001
Epoch [33/100], Training Loss: 6.2249, Validation Loss Current: 11.5961, Validation Loss AVG: 11.5961, lr: 0.001
Epoch [34/100], Training Loss: 3.0796, Validation Loss Current: 10.7889, Validation Loss AVG: 10.7889, lr: 0.001
Epoch [35/100], Training Loss: 1.6806, Validation Loss Current: 10.9286, Validation Loss AVG: 10.9286, lr: 0.001
Epoch [36/100], Training Loss: 1.6445, Validation Loss Current: 11.0901, Validation Loss AVG: 11.0901, lr: 0.001
Epoch [37/100], Training Loss: 4.1945, Validation Loss Current: 12.6325, Validation Loss AVG: 12.6325, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 7 Best val accuracy: [0.34375, 0.4526315789473684, 0.43684210526315786, 0.4141447368421053, 0.36973684210526314, 0.35328947368421054, 0.46447368421052637, 0.4549342105263158, 0.4532894736842105, 0.48026315789473684, 0.44572368421052627, 0.45921052631578957, 0.4407894736842105, 0.4342105263157895, 0.3907894736842105, 0.36348684210526316, 0.40065789473684205, 0.4473684210526316, 0.46578947368421053, 0.4447368421052632, 0.4092105263157896, 0.43519736842105267, 0.45394736842105265, 0.43453947368421053, 0.37434210526315786, 0.44210526315789467, 0.43519736842105267, 0.43782894736842104, 0.4164473684210527, 0.43782894736842104, 0.4720394736842105, 0.4516447368421053, 0.4319078947368421, 0.4634868421052632, 0.4720394736842105, 0.45592105263157895, 0.40888157894736843] Best val loss: 8.597056531906128


Current group: 0.8
Epoch [1/100], Training Loss: 25.9267, Validation Loss Current: 15.9970, Validation Loss AVG: 15.9970, lr: 0.001
Epoch [2/100], Training Loss: 19.2185, Validation Loss Current: 11.6314, Validation Loss AVG: 11.6314, lr: 0.001
Epoch [3/100], Training Loss: 12.6584, Validation Loss Current: 9.9998, Validation Loss AVG: 9.9998, lr: 0.001
Epoch [4/100], Training Loss: 13.2759, Validation Loss Current: 10.8931, Validation Loss AVG: 10.8931, lr: 0.001
Epoch [5/100], Training Loss: 12.1507, Validation Loss Current: 10.7189, Validation Loss AVG: 10.7189, lr: 0.001
Epoch [6/100], Training Loss: 10.6538, Validation Loss Current: 11.8752, Validation Loss AVG: 11.8752, lr: 0.001
Epoch [7/100], Training Loss: 11.6260, Validation Loss Current: 9.9950, Validation Loss AVG: 9.9950, lr: 0.001
Epoch [8/100], Training Loss: 9.1499, Validation Loss Current: 11.1662, Validation Loss AVG: 11.1662, lr: 0.001
Epoch [9/100], Training Loss: 6.3212, Validation Loss Current: 10.8558, Validation Loss AVG: 10.8558, lr: 0.001
Epoch [10/100], Training Loss: 4.3925, Validation Loss Current: 9.8841, Validation Loss AVG: 9.8841, lr: 0.001
Epoch [11/100], Training Loss: 4.5264, Validation Loss Current: 9.8923, Validation Loss AVG: 9.8923, lr: 0.001
Epoch [12/100], Training Loss: 3.8567, Validation Loss Current: 10.7475, Validation Loss AVG: 10.7475, lr: 0.001
Epoch [13/100], Training Loss: 3.8101, Validation Loss Current: 10.8704, Validation Loss AVG: 10.8704, lr: 0.001
Epoch [14/100], Training Loss: 6.8396, Validation Loss Current: 10.7750, Validation Loss AVG: 10.7750, lr: 0.001
Epoch [15/100], Training Loss: 6.1584, Validation Loss Current: 10.5700, Validation Loss AVG: 10.5700, lr: 0.001
Epoch [16/100], Training Loss: 6.0229, Validation Loss Current: 12.0867, Validation Loss AVG: 12.0867, lr: 0.001
Epoch [17/100], Training Loss: 6.5354, Validation Loss Current: 11.8559, Validation Loss AVG: 11.8559, lr: 0.001
Epoch [18/100], Training Loss: 4.3704, Validation Loss Current: 11.4894, Validation Loss AVG: 11.4894, lr: 0.001
Epoch [19/100], Training Loss: 2.1329, Validation Loss Current: 10.3326, Validation Loss AVG: 10.3326, lr: 0.001
Epoch [20/100], Training Loss: 3.7631, Validation Loss Current: 11.9121, Validation Loss AVG: 11.9121, lr: 0.001
Epoch [21/100], Training Loss: 8.0305, Validation Loss Current: 12.0344, Validation Loss AVG: 12.0344, lr: 0.001
Epoch [22/100], Training Loss: 7.6405, Validation Loss Current: 12.6559, Validation Loss AVG: 12.6559, lr: 0.001
Epoch [23/100], Training Loss: 5.1733, Validation Loss Current: 11.5714, Validation Loss AVG: 11.5714, lr: 0.001
Epoch [24/100], Training Loss: 3.3292, Validation Loss Current: 11.0544, Validation Loss AVG: 11.0544, lr: 0.001
Epoch [25/100], Training Loss: 3.0620, Validation Loss Current: 11.5195, Validation Loss AVG: 11.5195, lr: 0.001
Epoch [26/100], Training Loss: 3.0055, Validation Loss Current: 10.5695, Validation Loss AVG: 10.5695, lr: 0.001
Epoch [27/100], Training Loss: 5.0324, Validation Loss Current: 12.8424, Validation Loss AVG: 12.8424, lr: 0.001
Epoch [28/100], Training Loss: 6.7825, Validation Loss Current: 11.5551, Validation Loss AVG: 11.5551, lr: 0.001
Epoch [29/100], Training Loss: 3.0270, Validation Loss Current: 10.6445, Validation Loss AVG: 10.6445, lr: 0.001
Epoch [30/100], Training Loss: 2.9336, Validation Loss Current: 11.6923, Validation Loss AVG: 11.6923, lr: 0.001
Epoch [31/100], Training Loss: 1.8572, Validation Loss Current: 14.6489, Validation Loss AVG: 14.6489, lr: 0.001
Epoch [32/100], Training Loss: 0.9701, Validation Loss Current: 11.2312, Validation Loss AVG: 11.2312, lr: 0.001
Epoch [33/100], Training Loss: 2.3179, Validation Loss Current: 11.2291, Validation Loss AVG: 11.2291, lr: 0.001
Epoch [34/100], Training Loss: 2.6712, Validation Loss Current: 11.8228, Validation Loss AVG: 11.8228, lr: 0.001
Epoch [35/100], Training Loss: 2.3298, Validation Loss Current: 12.1041, Validation Loss AVG: 12.1041, lr: 0.001
Epoch [36/100], Training Loss: 4.1978, Validation Loss Current: 13.9632, Validation Loss AVG: 13.9632, lr: 0.001
Epoch [37/100], Training Loss: 2.3603, Validation Loss Current: 11.9002, Validation Loss AVG: 11.9002, lr: 0.001
Epoch [38/100], Training Loss: 2.7290, Validation Loss Current: 13.2594, Validation Loss AVG: 13.2594, lr: 0.001
Epoch [39/100], Training Loss: 3.6856, Validation Loss Current: 12.1941, Validation Loss AVG: 12.1941, lr: 0.001
Epoch [40/100], Training Loss: 9.3054, Validation Loss Current: 14.7532, Validation Loss AVG: 14.7532, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 10 Best val accuracy: [0.31447368421052635, 0.4171052631578947, 0.4509868421052632, 0.4608552631578947, 0.43256578947368424, 0.45559210526315785, 0.4720394736842105, 0.3907894736842105, 0.4411184210526316, 0.4358552631578947, 0.4549342105263158, 0.4493421052631579, 0.4207236842105263, 0.4796052631578947, 0.4496710526315789, 0.4473684210526315, 0.4480263157894737, 0.4407894736842105, 0.46085526315789477, 0.45855263157894743, 0.4148026315789474, 0.4273026315789473, 0.4213815789473684, 0.4365131578947368, 0.4493421052631579, 0.46644736842105267, 0.42796052631578946, 0.4618421052631579, 0.46578947368421053, 0.42993421052631575, 0.41085526315789467, 0.4598684210526315, 0.4631578947368421, 0.48190789473684215, 0.45559210526315785, 0.4164473684210527, 0.45427631578947364, 0.42631578947368415, 0.43881578947368427, 0.43355263157894736] Best val loss: 9.884105682373047


Current group: 1
Epoch [1/100], Training Loss: 24.8085, Validation Loss Current: 11.0062, Validation Loss AVG: 13.8826, lr: 0.001
Epoch [2/100], Training Loss: 14.6992, Validation Loss Current: 8.5818, Validation Loss AVG: 13.3808, lr: 0.001
Epoch [3/100], Training Loss: 8.8291, Validation Loss Current: 7.6464, Validation Loss AVG: 11.8792, lr: 0.001
Epoch [4/100], Training Loss: 6.0175, Validation Loss Current: 7.5551, Validation Loss AVG: 10.9684, lr: 0.001
Epoch [5/100], Training Loss: 4.6056, Validation Loss Current: 7.5774, Validation Loss AVG: 10.8187, lr: 0.001
Epoch [6/100], Training Loss: 2.9763, Validation Loss Current: 7.6644, Validation Loss AVG: 11.0775, lr: 0.001
Epoch [7/100], Training Loss: 4.8882, Validation Loss Current: 7.8383, Validation Loss AVG: 10.9891, lr: 0.001
Epoch [8/100], Training Loss: 2.4444, Validation Loss Current: 8.1018, Validation Loss AVG: 10.7060, lr: 0.001
Epoch [9/100], Training Loss: 3.6827, Validation Loss Current: 8.4434, Validation Loss AVG: 11.7311, lr: 0.001
Epoch [10/100], Training Loss: 4.9308, Validation Loss Current: 8.2663, Validation Loss AVG: 11.3053, lr: 0.001
Epoch [11/100], Training Loss: 5.4524, Validation Loss Current: 9.0382, Validation Loss AVG: 12.2327, lr: 0.001
Epoch [12/100], Training Loss: 10.6358, Validation Loss Current: 10.8610, Validation Loss AVG: 16.7383, lr: 0.001
Epoch [13/100], Training Loss: 11.1311, Validation Loss Current: 11.5353, Validation Loss AVG: 15.5906, lr: 0.001
Epoch [14/100], Training Loss: 7.7618, Validation Loss Current: 8.4091, Validation Loss AVG: 10.3229, lr: 0.001
Epoch [15/100], Training Loss: 4.4969, Validation Loss Current: 7.5521, Validation Loss AVG: 12.0702, lr: 0.001
Epoch [16/100], Training Loss: 7.0220, Validation Loss Current: 8.1751, Validation Loss AVG: 12.1931, lr: 0.001
Epoch [17/100], Training Loss: 4.2937, Validation Loss Current: 9.0740, Validation Loss AVG: 12.9054, lr: 0.001
Epoch [18/100], Training Loss: 3.0787, Validation Loss Current: 9.0085, Validation Loss AVG: 11.2588, lr: 0.001
Epoch [19/100], Training Loss: 2.2641, Validation Loss Current: 9.3328, Validation Loss AVG: 12.8168, lr: 0.001
Epoch [20/100], Training Loss: 1.3262, Validation Loss Current: 7.7032, Validation Loss AVG: 11.4031, lr: 0.001
Epoch [21/100], Training Loss: 3.1077, Validation Loss Current: 8.3630, Validation Loss AVG: 13.1845, lr: 0.001
Epoch [22/100], Training Loss: 3.0845, Validation Loss Current: 8.9438, Validation Loss AVG: 12.4125, lr: 0.001
Epoch [23/100], Training Loss: 7.6839, Validation Loss Current: 9.3022, Validation Loss AVG: 14.1237, lr: 0.001
Epoch [24/100], Training Loss: 7.1497, Validation Loss Current: 9.5911, Validation Loss AVG: 13.0284, lr: 0.001
Epoch [25/100], Training Loss: 7.5599, Validation Loss Current: 9.1453, Validation Loss AVG: 12.6839, lr: 0.001
Epoch [26/100], Training Loss: 3.5965, Validation Loss Current: 8.8264, Validation Loss AVG: 11.7784, lr: 0.001
Epoch [27/100], Training Loss: 3.0130, Validation Loss Current: 7.9608, Validation Loss AVG: 10.8243, lr: 0.001
Epoch [28/100], Training Loss: 3.6658, Validation Loss Current: 9.4667, Validation Loss AVG: 13.1259, lr: 0.001
Epoch [29/100], Training Loss: 5.2834, Validation Loss Current: 9.6410, Validation Loss AVG: 13.2550, lr: 0.001
Epoch [30/100], Training Loss: 3.8625, Validation Loss Current: 9.7007, Validation Loss AVG: 12.7983, lr: 0.001
Epoch [31/100], Training Loss: 2.8800, Validation Loss Current: 8.9333, Validation Loss AVG: 12.2775, lr: 0.001
Epoch [32/100], Training Loss: 2.6304, Validation Loss Current: 9.1099, Validation Loss AVG: 11.8585, lr: 0.001
Epoch [33/100], Training Loss: 1.2799, Validation Loss Current: 7.8934, Validation Loss AVG: 11.5756, lr: 0.001
Epoch [34/100], Training Loss: 2.9071, Validation Loss Current: 9.4766, Validation Loss AVG: 16.2193, lr: 0.001
Epoch [35/100], Training Loss: 5.8890, Validation Loss Current: 10.1865, Validation Loss AVG: 13.4626, lr: 0.001
Epoch [36/100], Training Loss: 7.3667, Validation Loss Current: 9.4114, Validation Loss AVG: 13.3801, lr: 0.001
Epoch [37/100], Training Loss: 3.0275, Validation Loss Current: 9.1475, Validation Loss AVG: 14.3419, lr: 0.001
Epoch [38/100], Training Loss: 3.2558, Validation Loss Current: 10.0678, Validation Loss AVG: 13.7137, lr: 0.001
Epoch [39/100], Training Loss: 3.8321, Validation Loss Current: 10.1365, Validation Loss AVG: 15.5631, lr: 0.001
Epoch [40/100], Training Loss: 3.0139, Validation Loss Current: 9.3876, Validation Loss AVG: 12.7873, lr: 0.001
Epoch [41/100], Training Loss: 4.2808, Validation Loss Current: 9.2360, Validation Loss AVG: 13.8545, lr: 0.001
Epoch [42/100], Training Loss: 1.7822, Validation Loss Current: 8.7839, Validation Loss AVG: 14.4966, lr: 0.001
Epoch [43/100], Training Loss: 2.2185, Validation Loss Current: 8.6318, Validation Loss AVG: 13.7635, lr: 0.001
Epoch [44/100], Training Loss: 4.0391, Validation Loss Current: 9.3928, Validation Loss AVG: 14.4633, lr: 0.001
Epoch [45/100], Training Loss: 2.3935, Validation Loss Current: 10.8925, Validation Loss AVG: 13.9065, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 15 Best val accuracy: [0.4819078947368421, 0.569078947368421, 0.587171052631579, 0.6069078947368421, 0.5855263157894737, 0.59375, 0.5805921052631579, 0.6167763157894737, 0.5953947368421053, 0.555921052631579, 0.59375, 0.4605263157894737, 0.4934210526315789, 0.5805921052631579, 0.6085526315789473, 0.5855263157894737, 0.5509868421052632, 0.555921052631579, 0.5789473684210527, 0.6134868421052632, 0.5904605263157895, 0.5608552631578947, 0.5526315789473685, 0.5657894736842105, 0.5427631578947368, 0.5921052631578947, 0.6036184210526315, 0.5542763157894737, 0.5789473684210527, 0.600328947368421, 0.5970394736842105, 0.6019736842105263, 0.6414473684210527, 0.6052631578947368, 0.5493421052631579, 0.6085526315789473, 0.5789473684210527, 0.5608552631578947, 0.5542763157894737, 0.5986842105263158, 0.5953947368421053, 0.5888157894736842, 0.59375, 0.5921052631578947, 0.5888157894736842] Best val loss: 7.552061557769775


----- Training resnet18 with sequence: [0.6, 0.8, 1] -----
Current group: 0.6
Epoch [1/134], Training Loss: 41.1045, Validation Loss Current: 10.0345, Validation Loss AVG: 10.0345, lr: 0.001
Epoch [2/134], Training Loss: 39.5908, Validation Loss Current: 9.8392, Validation Loss AVG: 9.8392, lr: 0.001
Epoch [3/134], Training Loss: 38.3605, Validation Loss Current: 9.6843, Validation Loss AVG: 9.6843, lr: 0.001
Epoch [4/134], Training Loss: 38.2254, Validation Loss Current: 9.4572, Validation Loss AVG: 9.4572, lr: 0.001
Epoch [5/134], Training Loss: 36.6694, Validation Loss Current: 9.3260, Validation Loss AVG: 9.3260, lr: 0.001
Epoch [6/134], Training Loss: 35.5876, Validation Loss Current: 9.0638, Validation Loss AVG: 9.0638, lr: 0.001
Epoch [7/134], Training Loss: 34.0104, Validation Loss Current: 9.1877, Validation Loss AVG: 9.1877, lr: 0.001
Epoch [8/134], Training Loss: 32.7394, Validation Loss Current: 8.8807, Validation Loss AVG: 8.8807, lr: 0.001
Epoch [9/134], Training Loss: 31.6265, Validation Loss Current: 8.4689, Validation Loss AVG: 8.4689, lr: 0.001
Epoch [10/134], Training Loss: 29.2660, Validation Loss Current: 8.4876, Validation Loss AVG: 8.4876, lr: 0.001
Epoch [11/134], Training Loss: 29.0884, Validation Loss Current: 8.2907, Validation Loss AVG: 8.2907, lr: 0.001
Epoch [12/134], Training Loss: 28.6676, Validation Loss Current: 8.6008, Validation Loss AVG: 8.6008, lr: 0.001
Epoch [13/134], Training Loss: 28.4194, Validation Loss Current: 8.1428, Validation Loss AVG: 8.1428, lr: 0.001
Epoch [14/134], Training Loss: 25.5566, Validation Loss Current: 8.0765, Validation Loss AVG: 8.0765, lr: 0.001
Epoch [15/134], Training Loss: 24.8243, Validation Loss Current: 8.1567, Validation Loss AVG: 8.1567, lr: 0.001
Epoch [16/134], Training Loss: 24.6250, Validation Loss Current: 7.9711, Validation Loss AVG: 7.9711, lr: 0.001
Epoch [17/134], Training Loss: 25.3571, Validation Loss Current: 8.0130, Validation Loss AVG: 8.0130, lr: 0.001
Epoch [18/134], Training Loss: 23.8423, Validation Loss Current: 8.4217, Validation Loss AVG: 8.4217, lr: 0.001
Epoch [19/134], Training Loss: 24.2132, Validation Loss Current: 8.1660, Validation Loss AVG: 8.1660, lr: 0.001
Epoch [20/134], Training Loss: 22.1762, Validation Loss Current: 8.1339, Validation Loss AVG: 8.1339, lr: 0.001
Epoch [21/134], Training Loss: 21.7261, Validation Loss Current: 7.9620, Validation Loss AVG: 7.9620, lr: 0.001
Epoch [22/134], Training Loss: 21.4658, Validation Loss Current: 8.6234, Validation Loss AVG: 8.6234, lr: 0.001
Epoch [23/134], Training Loss: 21.1340, Validation Loss Current: 8.8840, Validation Loss AVG: 8.8840, lr: 0.001
Epoch [24/134], Training Loss: 20.5664, Validation Loss Current: 7.9467, Validation Loss AVG: 7.9467, lr: 0.001
Epoch [25/134], Training Loss: 19.9479, Validation Loss Current: 7.4216, Validation Loss AVG: 7.4216, lr: 0.001
Epoch [26/134], Training Loss: 18.0454, Validation Loss Current: 8.0160, Validation Loss AVG: 8.0160, lr: 0.001
Epoch [27/134], Training Loss: 18.0747, Validation Loss Current: 8.3735, Validation Loss AVG: 8.3735, lr: 0.001
Epoch [28/134], Training Loss: 16.0744, Validation Loss Current: 8.6727, Validation Loss AVG: 8.6727, lr: 0.001
Epoch [29/134], Training Loss: 14.9518, Validation Loss Current: 8.6421, Validation Loss AVG: 8.6421, lr: 0.001
Epoch [30/134], Training Loss: 14.2085, Validation Loss Current: 11.7449, Validation Loss AVG: 11.7449, lr: 0.001
Epoch [31/134], Training Loss: 17.3528, Validation Loss Current: 10.5174, Validation Loss AVG: 10.5174, lr: 0.001
Epoch [32/134], Training Loss: 17.2887, Validation Loss Current: 9.1176, Validation Loss AVG: 9.1176, lr: 0.001
Epoch [33/134], Training Loss: 17.2831, Validation Loss Current: 12.5250, Validation Loss AVG: 12.5250, lr: 0.001
Epoch [34/134], Training Loss: 15.9845, Validation Loss Current: 8.0768, Validation Loss AVG: 8.0768, lr: 0.001
Epoch [35/134], Training Loss: 13.8325, Validation Loss Current: 9.2975, Validation Loss AVG: 9.2975, lr: 0.001
Epoch [36/134], Training Loss: 13.5512, Validation Loss Current: 8.9661, Validation Loss AVG: 8.9661, lr: 0.001
Epoch [37/134], Training Loss: 11.6566, Validation Loss Current: 8.0665, Validation Loss AVG: 8.0665, lr: 0.001
Epoch [38/134], Training Loss: 10.1424, Validation Loss Current: 8.9900, Validation Loss AVG: 8.9900, lr: 0.001
Epoch [39/134], Training Loss: 9.8316, Validation Loss Current: 9.0482, Validation Loss AVG: 9.0482, lr: 0.001
Epoch [40/134], Training Loss: 9.3785, Validation Loss Current: 8.3643, Validation Loss AVG: 8.3643, lr: 0.001
Epoch [41/134], Training Loss: 8.7881, Validation Loss Current: 8.0425, Validation Loss AVG: 8.0425, lr: 0.001
Epoch [42/134], Training Loss: 10.0119, Validation Loss Current: 8.8951, Validation Loss AVG: 8.8951, lr: 0.001
Epoch [43/134], Training Loss: 10.4139, Validation Loss Current: 8.8984, Validation Loss AVG: 8.8984, lr: 0.001
Epoch [44/134], Training Loss: 8.7693, Validation Loss Current: 9.3955, Validation Loss AVG: 9.3955, lr: 0.001
Epoch [45/134], Training Loss: 7.9271, Validation Loss Current: 9.5008, Validation Loss AVG: 9.5008, lr: 0.001
Epoch [46/134], Training Loss: 8.7013, Validation Loss Current: 9.1739, Validation Loss AVG: 9.1739, lr: 0.001
Epoch [47/134], Training Loss: 5.7718, Validation Loss Current: 9.7252, Validation Loss AVG: 9.7252, lr: 0.001
Epoch [48/134], Training Loss: 5.1726, Validation Loss Current: 9.7029, Validation Loss AVG: 9.7029, lr: 0.001
Epoch [49/134], Training Loss: 9.4121, Validation Loss Current: 9.5538, Validation Loss AVG: 9.5538, lr: 0.001
Epoch [50/134], Training Loss: 8.1681, Validation Loss Current: 11.1913, Validation Loss AVG: 11.1913, lr: 0.001
Epoch [51/134], Training Loss: 9.3570, Validation Loss Current: 9.9872, Validation Loss AVG: 9.9872, lr: 0.001
Epoch [52/134], Training Loss: 7.3416, Validation Loss Current: 10.2001, Validation Loss AVG: 10.2001, lr: 0.001
Epoch [53/134], Training Loss: 4.9282, Validation Loss Current: 9.3468, Validation Loss AVG: 9.3468, lr: 0.001
Epoch [54/134], Training Loss: 6.0221, Validation Loss Current: 9.8559, Validation Loss AVG: 9.8559, lr: 0.001
Epoch [55/134], Training Loss: 6.4853, Validation Loss Current: 11.2709, Validation Loss AVG: 11.2709, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 25 Best val accuracy: [0.22730263157894734, 0.2536184210526316, 0.26249999999999996, 0.29769736842105265, 0.31644736842105264, 0.3289473684210526, 0.32072368421052627, 0.3375, 0.40197368421052626, 0.38453947368421054, 0.3967105263157894, 0.35657894736842105, 0.4184210526315789, 0.4095394736842105, 0.41875, 0.4483552631578947, 0.4338815789473684, 0.39703947368421055, 0.4286184210526316, 0.4411184210526316, 0.44309210526315795, 0.3907894736842105, 0.4009868421052631, 0.4447368421052632, 0.47631578947368425, 0.4483552631578947, 0.44144736842105264, 0.4394736842105263, 0.43552631578947365, 0.37302631578947365, 0.4009868421052632, 0.40888157894736843, 0.3421052631578947, 0.42894736842105263, 0.42927631578947373, 0.4365131578947368, 0.4546052631578947, 0.43519736842105267, 0.42927631578947373, 0.4638157894736842, 0.45032894736842105, 0.4375, 0.4516447368421052, 0.4273026315789473, 0.44605263157894737, 0.4342105263157895, 0.4230263157894737, 0.4407894736842105, 0.41546052631578945, 0.40855263157894744, 0.40230263157894736, 0.4273026315789473, 0.45131578947368417, 0.4444078947368421, 0.3671052631578947] Best val loss: 7.421591973304748


Current group: 0.8
Epoch [1/134], Training Loss: 23.6416, Validation Loss Current: 9.9909, Validation Loss AVG: 9.9909, lr: 0.001
Epoch [2/134], Training Loss: 17.4279, Validation Loss Current: 10.4889, Validation Loss AVG: 10.4889, lr: 0.001
Epoch [3/134], Training Loss: 13.8146, Validation Loss Current: 9.6305, Validation Loss AVG: 9.6305, lr: 0.001
Epoch [4/134], Training Loss: 12.6108, Validation Loss Current: 12.2489, Validation Loss AVG: 12.2489, lr: 0.001
Epoch [5/134], Training Loss: 15.7013, Validation Loss Current: 11.8908, Validation Loss AVG: 11.8908, lr: 0.001
Epoch [6/134], Training Loss: 10.8095, Validation Loss Current: 8.8120, Validation Loss AVG: 8.8120, lr: 0.001
Epoch [7/134], Training Loss: 8.6119, Validation Loss Current: 10.7256, Validation Loss AVG: 10.7256, lr: 0.001
Epoch [8/134], Training Loss: 6.7325, Validation Loss Current: 8.6030, Validation Loss AVG: 8.6030, lr: 0.001
Epoch [9/134], Training Loss: 4.9971, Validation Loss Current: 9.4605, Validation Loss AVG: 9.4605, lr: 0.001
Epoch [10/134], Training Loss: 6.4100, Validation Loss Current: 10.3225, Validation Loss AVG: 10.3225, lr: 0.001
Epoch [11/134], Training Loss: 12.9875, Validation Loss Current: 17.0486, Validation Loss AVG: 17.0486, lr: 0.001
Epoch [12/134], Training Loss: 11.7728, Validation Loss Current: 11.2724, Validation Loss AVG: 11.2724, lr: 0.001
Epoch [13/134], Training Loss: 8.7817, Validation Loss Current: 10.6694, Validation Loss AVG: 10.6694, lr: 0.001
Epoch [14/134], Training Loss: 8.5089, Validation Loss Current: 10.3600, Validation Loss AVG: 10.3600, lr: 0.001
Epoch [15/134], Training Loss: 7.9597, Validation Loss Current: 11.7561, Validation Loss AVG: 11.7561, lr: 0.001
Epoch [16/134], Training Loss: 5.4800, Validation Loss Current: 10.9203, Validation Loss AVG: 10.9203, lr: 0.001
Epoch [17/134], Training Loss: 5.4471, Validation Loss Current: 9.2865, Validation Loss AVG: 9.2865, lr: 0.001
Epoch [18/134], Training Loss: 7.0879, Validation Loss Current: 13.5194, Validation Loss AVG: 13.5194, lr: 0.001
Epoch [19/134], Training Loss: 10.0614, Validation Loss Current: 12.3322, Validation Loss AVG: 12.3322, lr: 0.001
Epoch [20/134], Training Loss: 6.5543, Validation Loss Current: 10.2246, Validation Loss AVG: 10.2246, lr: 0.001
Epoch [21/134], Training Loss: 5.5435, Validation Loss Current: 11.4138, Validation Loss AVG: 11.4138, lr: 0.001
Epoch [22/134], Training Loss: 4.9034, Validation Loss Current: 12.8122, Validation Loss AVG: 12.8122, lr: 0.001
Epoch [23/134], Training Loss: 4.4938, Validation Loss Current: 9.8426, Validation Loss AVG: 9.8426, lr: 0.001
Epoch [24/134], Training Loss: 4.3129, Validation Loss Current: 12.6462, Validation Loss AVG: 12.6462, lr: 0.001
Epoch [25/134], Training Loss: 6.1582, Validation Loss Current: 11.2213, Validation Loss AVG: 11.2213, lr: 0.001
Epoch [26/134], Training Loss: 5.2033, Validation Loss Current: 9.7567, Validation Loss AVG: 9.7567, lr: 0.001
Epoch [27/134], Training Loss: 4.1588, Validation Loss Current: 10.6380, Validation Loss AVG: 10.6380, lr: 0.001
Epoch [28/134], Training Loss: 4.6956, Validation Loss Current: 10.7651, Validation Loss AVG: 10.7651, lr: 0.001
Epoch [29/134], Training Loss: 3.9555, Validation Loss Current: 12.8173, Validation Loss AVG: 12.8173, lr: 0.001
Epoch [30/134], Training Loss: 6.6603, Validation Loss Current: 12.0232, Validation Loss AVG: 12.0232, lr: 0.001
Epoch [31/134], Training Loss: 5.0169, Validation Loss Current: 11.5940, Validation Loss AVG: 11.5940, lr: 0.001
Epoch [32/134], Training Loss: 3.7211, Validation Loss Current: 11.1089, Validation Loss AVG: 11.1089, lr: 0.001
Epoch [33/134], Training Loss: 3.1682, Validation Loss Current: 10.5096, Validation Loss AVG: 10.5096, lr: 0.001
Epoch [34/134], Training Loss: 5.0450, Validation Loss Current: 11.9396, Validation Loss AVG: 11.9396, lr: 0.001
Epoch [35/134], Training Loss: 12.0964, Validation Loss Current: 12.1268, Validation Loss AVG: 12.1268, lr: 0.001
Epoch [36/134], Training Loss: 9.5850, Validation Loss Current: 11.8579, Validation Loss AVG: 11.8579, lr: 0.001
Epoch [37/134], Training Loss: 5.7261, Validation Loss Current: 11.1773, Validation Loss AVG: 11.1773, lr: 0.001
Epoch [38/134], Training Loss: 5.9277, Validation Loss Current: 12.0671, Validation Loss AVG: 12.0671, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 8 Best val accuracy: [0.4463815789473684, 0.3894736842105263, 0.4148026315789474, 0.4164473684210527, 0.4266447368421053, 0.4536184210526316, 0.4266447368421053, 0.4457236842105264, 0.4634868421052632, 0.43355263157894736, 0.3605263157894737, 0.41743421052631585, 0.43519736842105267, 0.42302631578947364, 0.40888157894736843, 0.4407894736842105, 0.4766447368421053, 0.37236842105263157, 0.42269736842105254, 0.4421052631578948, 0.4184210526315789, 0.4256578947368421, 0.4118421052631579, 0.4384868421052632, 0.4144736842105264, 0.43486842105263157, 0.4319078947368421, 0.4430921052631579, 0.4220394736842105, 0.3963815789473684, 0.4029605263157895, 0.46875, 0.45723684210526316, 0.44671052631578945, 0.3924342105263158, 0.3993421052631579, 0.4309210526315789, 0.4026315789473684] Best val loss: 8.60304274559021


Current group: 1
Epoch [1/134], Training Loss: 21.5831, Validation Loss Current: 8.8640, Validation Loss AVG: 10.9364, lr: 0.001
Epoch [2/134], Training Loss: 12.1432, Validation Loss Current: 7.3529, Validation Loss AVG: 11.0228, lr: 0.001
Epoch [3/134], Training Loss: 9.0973, Validation Loss Current: 7.3962, Validation Loss AVG: 12.9875, lr: 0.001
Epoch [4/134], Training Loss: 9.9924, Validation Loss Current: 7.6762, Validation Loss AVG: 11.3924, lr: 0.001
Epoch [5/134], Training Loss: 7.3682, Validation Loss Current: 8.1675, Validation Loss AVG: 13.2103, lr: 0.001
Epoch [6/134], Training Loss: 7.3798, Validation Loss Current: 9.9680, Validation Loss AVG: 13.3892, lr: 0.001
Epoch [7/134], Training Loss: 6.4569, Validation Loss Current: 8.4825, Validation Loss AVG: 11.0006, lr: 0.001
Epoch [8/134], Training Loss: 7.4315, Validation Loss Current: 9.0907, Validation Loss AVG: 15.1296, lr: 0.001
Epoch [9/134], Training Loss: 4.2254, Validation Loss Current: 8.3460, Validation Loss AVG: 11.6573, lr: 0.001
Epoch [10/134], Training Loss: 3.4888, Validation Loss Current: 7.5109, Validation Loss AVG: 11.1975, lr: 0.001
Epoch [11/134], Training Loss: 5.7961, Validation Loss Current: 8.6892, Validation Loss AVG: 10.7664, lr: 0.001
Epoch [12/134], Training Loss: 5.9511, Validation Loss Current: 8.3487, Validation Loss AVG: 11.5524, lr: 0.001
Epoch [13/134], Training Loss: 4.6632, Validation Loss Current: 7.5798, Validation Loss AVG: 13.1229, lr: 0.001
Epoch [14/134], Training Loss: 4.6392, Validation Loss Current: 8.8505, Validation Loss AVG: 12.8677, lr: 0.001
Epoch [15/134], Training Loss: 3.4342, Validation Loss Current: 7.9746, Validation Loss AVG: 13.2373, lr: 0.001
Epoch [16/134], Training Loss: 6.1226, Validation Loss Current: 8.5029, Validation Loss AVG: 13.0304, lr: 0.001
Epoch [17/134], Training Loss: 5.7335, Validation Loss Current: 13.0955, Validation Loss AVG: 15.6726, lr: 0.001
Epoch [18/134], Training Loss: 9.7960, Validation Loss Current: 9.1321, Validation Loss AVG: 12.1473, lr: 0.001
Epoch [19/134], Training Loss: 7.7193, Validation Loss Current: 9.1732, Validation Loss AVG: 13.2497, lr: 0.001
Epoch [20/134], Training Loss: 4.1680, Validation Loss Current: 8.1418, Validation Loss AVG: 12.3260, lr: 0.001
Epoch [21/134], Training Loss: 2.0179, Validation Loss Current: 7.9833, Validation Loss AVG: 11.4952, lr: 0.001
Epoch [22/134], Training Loss: 1.8631, Validation Loss Current: 7.7134, Validation Loss AVG: 12.1666, lr: 0.001
Epoch [23/134], Training Loss: 4.6123, Validation Loss Current: 8.7699, Validation Loss AVG: 12.3305, lr: 0.001
Epoch [24/134], Training Loss: 3.4358, Validation Loss Current: 8.9990, Validation Loss AVG: 12.9017, lr: 0.001
Epoch [25/134], Training Loss: 4.6461, Validation Loss Current: 8.5492, Validation Loss AVG: 11.6027, lr: 0.001
Epoch [26/134], Training Loss: 4.6997, Validation Loss Current: 9.9980, Validation Loss AVG: 13.7493, lr: 0.001
Epoch [27/134], Training Loss: 6.6586, Validation Loss Current: 9.1562, Validation Loss AVG: 12.6493, lr: 0.001
Epoch [28/134], Training Loss: 4.9380, Validation Loss Current: 9.5509, Validation Loss AVG: 12.6395, lr: 0.001
Epoch [29/134], Training Loss: 2.7462, Validation Loss Current: 8.6834, Validation Loss AVG: 13.6492, lr: 0.001
Epoch [30/134], Training Loss: 2.7754, Validation Loss Current: 9.2874, Validation Loss AVG: 16.7965, lr: 0.001
Epoch [31/134], Training Loss: 1.5440, Validation Loss Current: 8.2347, Validation Loss AVG: 13.4881, lr: 0.001
Epoch [32/134], Training Loss: 3.5325, Validation Loss Current: 8.7490, Validation Loss AVG: 13.8774, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 2 Best val accuracy: [0.5197368421052632, 0.5542763157894737, 0.5625, 0.5805921052631579, 0.5756578947368421, 0.5509868421052632, 0.5296052631578947, 0.5427631578947368, 0.5723684210526315, 0.5970394736842105, 0.5394736842105263, 0.555921052631579, 0.5707236842105263, 0.5509868421052632, 0.5657894736842105, 0.5542763157894737, 0.5098684210526315, 0.5476973684210527, 0.6101973684210527, 0.5921052631578947, 0.6019736842105263, 0.6052631578947368, 0.5756578947368421, 0.5674342105263158, 0.5575657894736842, 0.5230263157894737, 0.5460526315789473, 0.5361842105263158, 0.5904605263157895, 0.5575657894736842, 0.6217105263157895, 0.5904605263157895] Best val loss: 7.352864503860474


----- Training resnet18 with sequence: [0.8, 1] -----
Current group: 0.8
Epoch [1/200], Training Loss: 40.0545, Validation Loss Current: 10.0592, Validation Loss AVG: 10.0592, lr: 0.001
Epoch [2/200], Training Loss: 38.8003, Validation Loss Current: 9.9180, Validation Loss AVG: 9.9180, lr: 0.001
Epoch [3/200], Training Loss: 38.7653, Validation Loss Current: 10.1043, Validation Loss AVG: 10.1043, lr: 0.001
Epoch [4/200], Training Loss: 37.4390, Validation Loss Current: 9.7067, Validation Loss AVG: 9.7067, lr: 0.001
Epoch [5/200], Training Loss: 36.3137, Validation Loss Current: 10.1646, Validation Loss AVG: 10.1646, lr: 0.001
Epoch [6/200], Training Loss: 35.6392, Validation Loss Current: 9.3063, Validation Loss AVG: 9.3063, lr: 0.001
Epoch [7/200], Training Loss: 33.9223, Validation Loss Current: 9.1690, Validation Loss AVG: 9.1690, lr: 0.001
Epoch [8/200], Training Loss: 32.5652, Validation Loss Current: 9.1906, Validation Loss AVG: 9.1906, lr: 0.001
Epoch [9/200], Training Loss: 30.6818, Validation Loss Current: 9.0713, Validation Loss AVG: 9.0713, lr: 0.001
Epoch [10/200], Training Loss: 30.2097, Validation Loss Current: 8.9865, Validation Loss AVG: 8.9865, lr: 0.001
Epoch [11/200], Training Loss: 29.9382, Validation Loss Current: 8.6535, Validation Loss AVG: 8.6535, lr: 0.001
Epoch [12/200], Training Loss: 27.9450, Validation Loss Current: 8.7217, Validation Loss AVG: 8.7217, lr: 0.001
Epoch [13/200], Training Loss: 26.8967, Validation Loss Current: 8.5978, Validation Loss AVG: 8.5978, lr: 0.001
Epoch [14/200], Training Loss: 26.1121, Validation Loss Current: 10.5443, Validation Loss AVG: 10.5443, lr: 0.001
Epoch [15/200], Training Loss: 26.6865, Validation Loss Current: 8.7061, Validation Loss AVG: 8.7061, lr: 0.001
Epoch [16/200], Training Loss: 26.0111, Validation Loss Current: 8.6890, Validation Loss AVG: 8.6890, lr: 0.001
Epoch [17/200], Training Loss: 24.2036, Validation Loss Current: 8.6412, Validation Loss AVG: 8.6412, lr: 0.001
Epoch [18/200], Training Loss: 23.8425, Validation Loss Current: 9.5714, Validation Loss AVG: 9.5714, lr: 0.001
Epoch [19/200], Training Loss: 22.1641, Validation Loss Current: 8.3555, Validation Loss AVG: 8.3555, lr: 0.001
Epoch [20/200], Training Loss: 22.5536, Validation Loss Current: 9.5353, Validation Loss AVG: 9.5353, lr: 0.001
Epoch [21/200], Training Loss: 21.2107, Validation Loss Current: 9.0326, Validation Loss AVG: 9.0326, lr: 0.001
Epoch [22/200], Training Loss: 20.6504, Validation Loss Current: 8.5696, Validation Loss AVG: 8.5696, lr: 0.001
Epoch [23/200], Training Loss: 19.3618, Validation Loss Current: 7.8090, Validation Loss AVG: 7.8090, lr: 0.001
Epoch [24/200], Training Loss: 18.8604, Validation Loss Current: 8.6649, Validation Loss AVG: 8.6649, lr: 0.001
Epoch [25/200], Training Loss: 17.1487, Validation Loss Current: 10.5808, Validation Loss AVG: 10.5808, lr: 0.001
Epoch [26/200], Training Loss: 18.0825, Validation Loss Current: 8.9743, Validation Loss AVG: 8.9743, lr: 0.001
Epoch [27/200], Training Loss: 21.4865, Validation Loss Current: 11.5258, Validation Loss AVG: 11.5258, lr: 0.001
Epoch [28/200], Training Loss: 20.7528, Validation Loss Current: 9.7740, Validation Loss AVG: 9.7740, lr: 0.001
Epoch [29/200], Training Loss: 17.6406, Validation Loss Current: 10.7123, Validation Loss AVG: 10.7123, lr: 0.001
Epoch [30/200], Training Loss: 16.5237, Validation Loss Current: 9.1031, Validation Loss AVG: 9.1031, lr: 0.001
Epoch [31/200], Training Loss: 17.5887, Validation Loss Current: 8.6521, Validation Loss AVG: 8.6521, lr: 0.001
Epoch [32/200], Training Loss: 15.7490, Validation Loss Current: 8.7103, Validation Loss AVG: 8.7103, lr: 0.001
Epoch [33/200], Training Loss: 15.0516, Validation Loss Current: 10.8448, Validation Loss AVG: 10.8448, lr: 0.001
Epoch [34/200], Training Loss: 14.0940, Validation Loss Current: 9.3786, Validation Loss AVG: 9.3786, lr: 0.001
Epoch [35/200], Training Loss: 14.4568, Validation Loss Current: 8.4500, Validation Loss AVG: 8.4500, lr: 0.001
Epoch [36/200], Training Loss: 13.5503, Validation Loss Current: 8.9659, Validation Loss AVG: 8.9659, lr: 0.001
Epoch [37/200], Training Loss: 13.7076, Validation Loss Current: 8.3168, Validation Loss AVG: 8.3168, lr: 0.001
Epoch [38/200], Training Loss: 11.0123, Validation Loss Current: 10.0998, Validation Loss AVG: 10.0998, lr: 0.001
Epoch [39/200], Training Loss: 9.9174, Validation Loss Current: 9.9195, Validation Loss AVG: 9.9195, lr: 0.001
Epoch [40/200], Training Loss: 9.6054, Validation Loss Current: 8.8486, Validation Loss AVG: 8.8486, lr: 0.001
Epoch [41/200], Training Loss: 10.7365, Validation Loss Current: 11.4948, Validation Loss AVG: 11.4948, lr: 0.001
Epoch [42/200], Training Loss: 9.1908, Validation Loss Current: 9.0643, Validation Loss AVG: 9.0643, lr: 0.001
Epoch [43/200], Training Loss: 9.1851, Validation Loss Current: 10.3807, Validation Loss AVG: 10.3807, lr: 0.001
Epoch [44/200], Training Loss: 10.6737, Validation Loss Current: 9.7629, Validation Loss AVG: 9.7629, lr: 0.001
Epoch [45/200], Training Loss: 7.5102, Validation Loss Current: 9.0633, Validation Loss AVG: 9.0633, lr: 0.001
Epoch [46/200], Training Loss: 6.0546, Validation Loss Current: 8.6366, Validation Loss AVG: 8.6366, lr: 0.001
Epoch [47/200], Training Loss: 7.8049, Validation Loss Current: 10.8015, Validation Loss AVG: 10.8015, lr: 0.001
Epoch [48/200], Training Loss: 8.0905, Validation Loss Current: 11.8389, Validation Loss AVG: 11.8389, lr: 0.001
Epoch [49/200], Training Loss: 6.6311, Validation Loss Current: 12.6991, Validation Loss AVG: 12.6991, lr: 0.001
Epoch [50/200], Training Loss: 5.1219, Validation Loss Current: 9.0495, Validation Loss AVG: 9.0495, lr: 0.001
Epoch [51/200], Training Loss: 5.5407, Validation Loss Current: 12.3326, Validation Loss AVG: 12.3326, lr: 0.001
Epoch [52/200], Training Loss: 8.9900, Validation Loss Current: 11.6090, Validation Loss AVG: 11.6090, lr: 0.001
Epoch [53/200], Training Loss: 5.4824, Validation Loss Current: 11.8203, Validation Loss AVG: 11.8203, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 23 Best val accuracy: [0.22532894736842107, 0.22796052631578947, 0.2361842105263158, 0.27861842105263157, 0.24046052631578946, 0.31381578947368427, 0.3381578947368421, 0.3223684210526316, 0.37335526315789475, 0.37105263157894736, 0.3726973684210526, 0.39638157894736836, 0.39144736842105265, 0.33289473684210524, 0.3960526315789473, 0.39703947368421055, 0.3894736842105263, 0.3838815789473684, 0.4292763157894736, 0.3759868421052632, 0.40032894736842106, 0.42993421052631575, 0.4411184210526315, 0.4273026315789473, 0.40131578947368424, 0.44144736842105264, 0.34243421052631573, 0.4046052631578948, 0.38421052631578945, 0.3861842105263158, 0.4440789473684211, 0.43289473684210533, 0.4115131578947368, 0.38651315789473684, 0.4401315789473685, 0.42467105263157895, 0.45592105263157895, 0.4052631578947368, 0.4414473684210526, 0.4217105263157895, 0.3707236842105263, 0.4151315789473684, 0.40493421052631573, 0.4203947368421053, 0.44506578947368425, 0.4585526315789473, 0.43618421052631573, 0.32368421052631585, 0.39309210526315785, 0.43355263157894736, 0.4200657894736842, 0.3605263157894737, 0.39703947368421055] Best val loss: 7.808964204788208


Current group: 1
Epoch [1/200], Training Loss: 21.6166, Validation Loss Current: 8.9546, Validation Loss AVG: 14.2623, lr: 0.001
Epoch [2/200], Training Loss: 20.3699, Validation Loss Current: 8.9607, Validation Loss AVG: 16.1675, lr: 0.001
Epoch [3/200], Training Loss: 16.8658, Validation Loss Current: 8.9335, Validation Loss AVG: 15.6638, lr: 0.001
Epoch [4/200], Training Loss: 15.3781, Validation Loss Current: 7.2684, Validation Loss AVG: 11.8454, lr: 0.001
Epoch [5/200], Training Loss: 15.9964, Validation Loss Current: 6.3826, Validation Loss AVG: 11.0879, lr: 0.001
Epoch [6/200], Training Loss: 19.6325, Validation Loss Current: 6.8502, Validation Loss AVG: 8.8521, lr: 0.001
Epoch [7/200], Training Loss: 13.6270, Validation Loss Current: 6.4047, Validation Loss AVG: 8.9243, lr: 0.001
Epoch [8/200], Training Loss: 11.4420, Validation Loss Current: 7.1652, Validation Loss AVG: 10.3660, lr: 0.001
Epoch [9/200], Training Loss: 12.8749, Validation Loss Current: 6.7916, Validation Loss AVG: 11.1963, lr: 0.001
Epoch [10/200], Training Loss: 12.1690, Validation Loss Current: 6.9291, Validation Loss AVG: 12.5134, lr: 0.001
Epoch [11/200], Training Loss: 8.8981, Validation Loss Current: 6.4324, Validation Loss AVG: 11.5363, lr: 0.001
Epoch [12/200], Training Loss: 7.6387, Validation Loss Current: 7.5208, Validation Loss AVG: 10.9640, lr: 0.001
Epoch [13/200], Training Loss: 7.6638, Validation Loss Current: 6.4561, Validation Loss AVG: 10.4798, lr: 0.001
Epoch [14/200], Training Loss: 6.9039, Validation Loss Current: 6.7031, Validation Loss AVG: 12.2728, lr: 0.001
Epoch [15/200], Training Loss: 8.4392, Validation Loss Current: 6.9605, Validation Loss AVG: 10.3290, lr: 0.001
Epoch [16/200], Training Loss: 7.6337, Validation Loss Current: 9.2669, Validation Loss AVG: 11.8859, lr: 0.001
Epoch [17/200], Training Loss: 8.5681, Validation Loss Current: 7.3412, Validation Loss AVG: 14.5469, lr: 0.001
Epoch [18/200], Training Loss: 4.5325, Validation Loss Current: 6.5806, Validation Loss AVG: 10.0047, lr: 0.001
Epoch [19/200], Training Loss: 4.9905, Validation Loss Current: 6.6157, Validation Loss AVG: 11.2148, lr: 0.001
Epoch [20/200], Training Loss: 6.2601, Validation Loss Current: 8.3431, Validation Loss AVG: 16.0019, lr: 0.001
Epoch [21/200], Training Loss: 6.4913, Validation Loss Current: 6.1230, Validation Loss AVG: 10.8348, lr: 0.001
Epoch [22/200], Training Loss: 3.8812, Validation Loss Current: 7.5042, Validation Loss AVG: 10.5584, lr: 0.001
Epoch [23/200], Training Loss: 4.9946, Validation Loss Current: 6.5113, Validation Loss AVG: 13.5453, lr: 0.001
Epoch [24/200], Training Loss: 6.8465, Validation Loss Current: 8.0480, Validation Loss AVG: 12.0257, lr: 0.001
Epoch [25/200], Training Loss: 2.9624, Validation Loss Current: 6.5730, Validation Loss AVG: 11.6198, lr: 0.001
Epoch [26/200], Training Loss: 2.6121, Validation Loss Current: 6.8057, Validation Loss AVG: 9.6498, lr: 0.001
Epoch [27/200], Training Loss: 2.4325, Validation Loss Current: 6.9042, Validation Loss AVG: 10.1981, lr: 0.001
Epoch [28/200], Training Loss: 3.5345, Validation Loss Current: 6.7931, Validation Loss AVG: 13.1443, lr: 0.001
Epoch [29/200], Training Loss: 3.3821, Validation Loss Current: 7.3647, Validation Loss AVG: 11.2212, lr: 0.001
Epoch [30/200], Training Loss: 6.3183, Validation Loss Current: 8.8755, Validation Loss AVG: 15.0824, lr: 0.001
Epoch [31/200], Training Loss: 3.7563, Validation Loss Current: 6.6903, Validation Loss AVG: 12.1039, lr: 0.001
Epoch [32/200], Training Loss: 2.8219, Validation Loss Current: 7.4298, Validation Loss AVG: 10.4467, lr: 0.001
Epoch [33/200], Training Loss: 3.6245, Validation Loss Current: 7.6345, Validation Loss AVG: 12.0210, lr: 0.001
Epoch [34/200], Training Loss: 4.2763, Validation Loss Current: 7.4701, Validation Loss AVG: 12.1918, lr: 0.001
Epoch [35/200], Training Loss: 6.9160, Validation Loss Current: 8.2069, Validation Loss AVG: 13.0693, lr: 0.001
Epoch [36/200], Training Loss: 4.7211, Validation Loss Current: 7.1579, Validation Loss AVG: 12.2768, lr: 0.001
Epoch [37/200], Training Loss: 4.9393, Validation Loss Current: 7.3084, Validation Loss AVG: 12.4046, lr: 0.001
Epoch [38/200], Training Loss: 5.4004, Validation Loss Current: 7.5476, Validation Loss AVG: 13.0507, lr: 0.001
Epoch [39/200], Training Loss: 3.9848, Validation Loss Current: 8.1437, Validation Loss AVG: 14.5393, lr: 0.001
Epoch [40/200], Training Loss: 2.4880, Validation Loss Current: 7.2428, Validation Loss AVG: 11.3515, lr: 0.001
Epoch [41/200], Training Loss: 3.3070, Validation Loss Current: 7.8876, Validation Loss AVG: 14.9357, lr: 0.001
Epoch [42/200], Training Loss: 2.1647, Validation Loss Current: 8.1130, Validation Loss AVG: 11.8334, lr: 0.001
Epoch [43/200], Training Loss: 1.5978, Validation Loss Current: 7.0840, Validation Loss AVG: 13.9450, lr: 0.001
Epoch [44/200], Training Loss: 1.5348, Validation Loss Current: 7.3573, Validation Loss AVG: 11.6892, lr: 0.001
Epoch [45/200], Training Loss: 1.4174, Validation Loss Current: 7.0394, Validation Loss AVG: 12.7992, lr: 0.001
Epoch [46/200], Training Loss: 5.6772, Validation Loss Current: 7.7677, Validation Loss AVG: 14.4522, lr: 0.001
Epoch [47/200], Training Loss: 4.6646, Validation Loss Current: 8.5276, Validation Loss AVG: 12.6018, lr: 0.001
Epoch [48/200], Training Loss: 2.4535, Validation Loss Current: 7.7878, Validation Loss AVG: 14.8916, lr: 0.001
Epoch [49/200], Training Loss: 3.4567, Validation Loss Current: 8.0282, Validation Loss AVG: 15.8359, lr: 0.001
Epoch [50/200], Training Loss: 4.5811, Validation Loss Current: 8.0490, Validation Loss AVG: 12.2618, lr: 0.001
Epoch [51/200], Training Loss: 2.6797, Validation Loss Current: 7.6908, Validation Loss AVG: 12.7171, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 21 Best val accuracy: [0.46381578947368424, 0.4621710526315789, 0.49506578947368424, 0.555921052631579, 0.587171052631579, 0.5674342105263158, 0.5953947368421053, 0.5328947368421053, 0.5756578947368421, 0.5723684210526315, 0.6019736842105263, 0.5773026315789473, 0.5953947368421053, 0.5740131578947368, 0.5888157894736842, 0.5394736842105263, 0.6052631578947368, 0.6118421052631579, 0.5921052631578947, 0.5394736842105263, 0.6134868421052632, 0.5921052631578947, 0.5986842105263158, 0.5805921052631579, 0.5855263157894737, 0.6036184210526315, 0.6019736842105263, 0.6118421052631579, 0.6085526315789473, 0.5444078947368421, 0.6217105263157895, 0.618421052631579, 0.6052631578947368, 0.6101973684210527, 0.5592105263157895, 0.6332236842105263, 0.6036184210526315, 0.6151315789473685, 0.5592105263157895, 0.6200657894736842, 0.5707236842105263, 0.5953947368421053, 0.625, 0.625, 0.6332236842105263, 0.6036184210526315, 0.59375, 0.6036184210526315, 0.6085526315789473, 0.5953947368421053, 0.5822368421052632] Best val loss: 6.12300717830658


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.6291, Validation Loss Current: 10.0981, Validation Loss AVG: 10.1828, lr: 0.001
Epoch [2/400], Training Loss: 38.7339, Validation Loss Current: 9.4601, Validation Loss AVG: 9.7998, lr: 0.001
Epoch [3/400], Training Loss: 36.7632, Validation Loss Current: 9.1914, Validation Loss AVG: 9.8052, lr: 0.001
Epoch [4/400], Training Loss: 34.9656, Validation Loss Current: 8.7852, Validation Loss AVG: 9.5475, lr: 0.001
Epoch [5/400], Training Loss: 33.4851, Validation Loss Current: 8.5080, Validation Loss AVG: 9.3548, lr: 0.001
Epoch [6/400], Training Loss: 32.2026, Validation Loss Current: 8.1788, Validation Loss AVG: 9.3522, lr: 0.001
Epoch [7/400], Training Loss: 31.0644, Validation Loss Current: 8.5871, Validation Loss AVG: 9.9651, lr: 0.001
Epoch [8/400], Training Loss: 30.6649, Validation Loss Current: 7.8480, Validation Loss AVG: 9.4862, lr: 0.001
Epoch [9/400], Training Loss: 29.2257, Validation Loss Current: 10.4361, Validation Loss AVG: 14.1170, lr: 0.001
Epoch [10/400], Training Loss: 29.3211, Validation Loss Current: 7.7629, Validation Loss AVG: 9.9356, lr: 0.001
Epoch [11/400], Training Loss: 29.2969, Validation Loss Current: 9.0580, Validation Loss AVG: 11.4573, lr: 0.001
Epoch [12/400], Training Loss: 29.5157, Validation Loss Current: 7.3440, Validation Loss AVG: 10.3767, lr: 0.001
Epoch [13/400], Training Loss: 27.2680, Validation Loss Current: 7.0197, Validation Loss AVG: 9.2993, lr: 0.001
Epoch [14/400], Training Loss: 27.0601, Validation Loss Current: 7.6648, Validation Loss AVG: 11.0851, lr: 0.001
Epoch [15/400], Training Loss: 25.8992, Validation Loss Current: 6.9707, Validation Loss AVG: 9.9250, lr: 0.001
Epoch [16/400], Training Loss: 24.9962, Validation Loss Current: 6.9906, Validation Loss AVG: 10.1208, lr: 0.001
Epoch [17/400], Training Loss: 23.5049, Validation Loss Current: 6.6071, Validation Loss AVG: 8.7703, lr: 0.001
Epoch [18/400], Training Loss: 22.1203, Validation Loss Current: 6.7452, Validation Loss AVG: 10.9873, lr: 0.001
Epoch [19/400], Training Loss: 22.6600, Validation Loss Current: 6.1830, Validation Loss AVG: 8.8471, lr: 0.001
Epoch [20/400], Training Loss: 20.5949, Validation Loss Current: 6.3720, Validation Loss AVG: 8.6623, lr: 0.001
Epoch [21/400], Training Loss: 20.4491, Validation Loss Current: 5.7910, Validation Loss AVG: 8.8421, lr: 0.001
Epoch [22/400], Training Loss: 19.2071, Validation Loss Current: 6.2747, Validation Loss AVG: 9.3016, lr: 0.001
Epoch [23/400], Training Loss: 20.0314, Validation Loss Current: 6.4856, Validation Loss AVG: 11.3513, lr: 0.001
Epoch [24/400], Training Loss: 18.7205, Validation Loss Current: 5.8062, Validation Loss AVG: 9.0893, lr: 0.001
Epoch [25/400], Training Loss: 18.2039, Validation Loss Current: 6.1347, Validation Loss AVG: 8.1748, lr: 0.001
Epoch [26/400], Training Loss: 18.0228, Validation Loss Current: 5.8282, Validation Loss AVG: 9.6117, lr: 0.001
Epoch [27/400], Training Loss: 17.8232, Validation Loss Current: 5.7538, Validation Loss AVG: 8.7101, lr: 0.001
Epoch [28/400], Training Loss: 16.3115, Validation Loss Current: 6.5102, Validation Loss AVG: 10.3118, lr: 0.001
Epoch [29/400], Training Loss: 14.0896, Validation Loss Current: 5.5661, Validation Loss AVG: 8.5562, lr: 0.001
Epoch [30/400], Training Loss: 15.3572, Validation Loss Current: 6.1585, Validation Loss AVG: 12.4796, lr: 0.001
Epoch [31/400], Training Loss: 16.3143, Validation Loss Current: 6.1815, Validation Loss AVG: 11.4731, lr: 0.001
Epoch [32/400], Training Loss: 14.3394, Validation Loss Current: 6.7190, Validation Loss AVG: 11.1861, lr: 0.001
Epoch [33/400], Training Loss: 14.0078, Validation Loss Current: 5.6954, Validation Loss AVG: 9.8876, lr: 0.001
Epoch [34/400], Training Loss: 14.0113, Validation Loss Current: 6.8405, Validation Loss AVG: 14.0508, lr: 0.001
Epoch [35/400], Training Loss: 19.4106, Validation Loss Current: 6.7458, Validation Loss AVG: 10.6251, lr: 0.001
Epoch [36/400], Training Loss: 15.9048, Validation Loss Current: 6.2871, Validation Loss AVG: 9.4644, lr: 0.001
Epoch [37/400], Training Loss: 12.9131, Validation Loss Current: 5.6979, Validation Loss AVG: 9.8016, lr: 0.001
Epoch [38/400], Training Loss: 10.5976, Validation Loss Current: 5.4976, Validation Loss AVG: 8.6992, lr: 0.001
Epoch [39/400], Training Loss: 9.3678, Validation Loss Current: 5.5536, Validation Loss AVG: 10.7224, lr: 0.001
Epoch [40/400], Training Loss: 7.8590, Validation Loss Current: 5.6936, Validation Loss AVG: 9.1965, lr: 0.001
Epoch [41/400], Training Loss: 10.2440, Validation Loss Current: 6.1876, Validation Loss AVG: 9.5324, lr: 0.001
Epoch [42/400], Training Loss: 8.8513, Validation Loss Current: 5.4898, Validation Loss AVG: 8.6616, lr: 0.001
Epoch [43/400], Training Loss: 8.2235, Validation Loss Current: 5.9493, Validation Loss AVG: 10.3030, lr: 0.001
Epoch [44/400], Training Loss: 6.7897, Validation Loss Current: 6.2322, Validation Loss AVG: 13.1540, lr: 0.001
Epoch [45/400], Training Loss: 6.2802, Validation Loss Current: 6.2200, Validation Loss AVG: 10.8772, lr: 0.001
Epoch [46/400], Training Loss: 9.7965, Validation Loss Current: 7.5137, Validation Loss AVG: 11.0839, lr: 0.001
Epoch [47/400], Training Loss: 13.2375, Validation Loss Current: 7.1576, Validation Loss AVG: 11.4967, lr: 0.001
Epoch [48/400], Training Loss: 7.5367, Validation Loss Current: 5.8857, Validation Loss AVG: 9.9252, lr: 0.001
Epoch [49/400], Training Loss: 7.7024, Validation Loss Current: 5.5726, Validation Loss AVG: 11.2366, lr: 0.001
Epoch [50/400], Training Loss: 6.6286, Validation Loss Current: 6.1909, Validation Loss AVG: 11.1602, lr: 0.001
Epoch [51/400], Training Loss: 5.8258, Validation Loss Current: 6.0752, Validation Loss AVG: 9.9602, lr: 0.001
Epoch [52/400], Training Loss: 5.6497, Validation Loss Current: 9.2137, Validation Loss AVG: 12.4084, lr: 0.001
Epoch [53/400], Training Loss: 6.5369, Validation Loss Current: 6.0642, Validation Loss AVG: 10.4992, lr: 0.001
Epoch [54/400], Training Loss: 6.7204, Validation Loss Current: 6.2807, Validation Loss AVG: 11.0129, lr: 0.001
Epoch [55/400], Training Loss: 5.7000, Validation Loss Current: 7.6904, Validation Loss AVG: 10.8832, lr: 0.001
Epoch [56/400], Training Loss: 7.3996, Validation Loss Current: 7.2825, Validation Loss AVG: 14.4571, lr: 0.001
Epoch [57/400], Training Loss: 5.1748, Validation Loss Current: 6.7185, Validation Loss AVG: 11.2471, lr: 0.001
Epoch [58/400], Training Loss: 5.6695, Validation Loss Current: 7.4190, Validation Loss AVG: 10.5704, lr: 0.001
Epoch [59/400], Training Loss: 6.1657, Validation Loss Current: 6.8310, Validation Loss AVG: 12.4655, lr: 0.001
Epoch [60/400], Training Loss: 5.0174, Validation Loss Current: 7.6912, Validation Loss AVG: 12.0419, lr: 0.001
Epoch [61/400], Training Loss: 3.2751, Validation Loss Current: 6.5418, Validation Loss AVG: 11.1316, lr: 0.001
Epoch [62/400], Training Loss: 3.7622, Validation Loss Current: 6.9682, Validation Loss AVG: 13.0839, lr: 0.001
Epoch [63/400], Training Loss: 3.3981, Validation Loss Current: 7.8310, Validation Loss AVG: 13.4353, lr: 0.001
Epoch [64/400], Training Loss: 5.1055, Validation Loss Current: 7.0561, Validation Loss AVG: 12.5224, lr: 0.001
Epoch [65/400], Training Loss: 5.5888, Validation Loss Current: 7.3147, Validation Loss AVG: 11.3871, lr: 0.001
Epoch [66/400], Training Loss: 4.6438, Validation Loss Current: 7.6233, Validation Loss AVG: 14.8753, lr: 0.001
Epoch [67/400], Training Loss: 3.9291, Validation Loss Current: 7.2497, Validation Loss AVG: 13.3086, lr: 0.001
Epoch [68/400], Training Loss: 4.7571, Validation Loss Current: 6.9483, Validation Loss AVG: 12.3413, lr: 0.001
Epoch [69/400], Training Loss: 4.1825, Validation Loss Current: 7.6900, Validation Loss AVG: 15.9418, lr: 0.001
Epoch [70/400], Training Loss: 4.0268, Validation Loss Current: 8.8293, Validation Loss AVG: 13.2285, lr: 0.001
Epoch [71/400], Training Loss: 4.0063, Validation Loss Current: 8.4502, Validation Loss AVG: 19.0463, lr: 0.001
Epoch [72/400], Training Loss: 2.3685, Validation Loss Current: 7.7976, Validation Loss AVG: 12.7612, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 42 Best val accuracy: [0.2779605263157895, 0.2911184210526316, 0.34539473684210525, 0.3684210526315789, 0.3832236842105263, 0.4292763157894737, 0.3503289473684211, 0.4194078947368421, 0.3717105263157895, 0.43256578947368424, 0.3503289473684211, 0.4967105263157895, 0.5296052631578947, 0.4720394736842105, 0.47368421052631576, 0.506578947368421, 0.5345394736842105, 0.5394736842105263, 0.5789473684210527, 0.569078947368421, 0.6101973684210527, 0.5476973684210527, 0.5509868421052632, 0.5953947368421053, 0.5542763157894737, 0.5904605263157895, 0.6134868421052632, 0.5575657894736842, 0.6217105263157895, 0.5641447368421053, 0.5707236842105263, 0.5394736842105263, 0.5855263157894737, 0.5411184210526315, 0.5427631578947368, 0.5608552631578947, 0.5921052631578947, 0.6101973684210527, 0.6134868421052632, 0.625, 0.5986842105263158, 0.625, 0.5986842105263158, 0.5888157894736842, 0.5822368421052632, 0.5526315789473685, 0.5542763157894737, 0.6200657894736842, 0.6398026315789473, 0.6052631578947368, 0.625, 0.5263157894736842, 0.625, 0.6019736842105263, 0.5756578947368421, 0.5723684210526315, 0.5921052631578947, 0.5822368421052632, 0.6052631578947368, 0.5608552631578947, 0.6134868421052632, 0.5822368421052632, 0.5608552631578947, 0.5740131578947368, 0.5575657894736842, 0.5970394736842105, 0.5822368421052632, 0.5953947368421053, 0.5625, 0.5756578947368421, 0.5394736842105263, 0.6069078947368421] Best val loss: 5.489812731742859


Fold: 1
----- Training resnet18 with sequence: [0.2, 0.4, 0.6, 0.8, 1] -----
Current group: 0.2
Epoch [1/80], Training Loss: 40.9528, Validation Loss Current: 10.1214, Validation Loss AVG: 10.1214, lr: 0.001
Epoch [2/80], Training Loss: 39.5045, Validation Loss Current: 10.5658, Validation Loss AVG: 10.5658, lr: 0.001
Epoch [3/80], Training Loss: 39.1022, Validation Loss Current: 12.0682, Validation Loss AVG: 12.0682, lr: 0.001
Epoch [4/80], Training Loss: 38.2787, Validation Loss Current: 11.5822, Validation Loss AVG: 11.5822, lr: 0.001
Epoch [5/80], Training Loss: 37.7307, Validation Loss Current: 11.7343, Validation Loss AVG: 11.7343, lr: 0.001
Epoch [6/80], Training Loss: 37.4763, Validation Loss Current: 10.8970, Validation Loss AVG: 10.8970, lr: 0.001
Epoch [7/80], Training Loss: 37.3576, Validation Loss Current: 12.2023, Validation Loss AVG: 12.2023, lr: 0.001
Epoch [8/80], Training Loss: 35.8377, Validation Loss Current: 10.7941, Validation Loss AVG: 10.7941, lr: 0.001
Epoch [9/80], Training Loss: 33.8804, Validation Loss Current: 10.3102, Validation Loss AVG: 10.3102, lr: 0.001
Epoch [10/80], Training Loss: 33.6599, Validation Loss Current: 12.0820, Validation Loss AVG: 12.0820, lr: 0.001
Epoch [11/80], Training Loss: 32.6552, Validation Loss Current: 10.9471, Validation Loss AVG: 10.9471, lr: 0.001
Epoch [12/80], Training Loss: 32.4082, Validation Loss Current: 11.2042, Validation Loss AVG: 11.2042, lr: 0.001
Epoch [13/80], Training Loss: 30.9102, Validation Loss Current: 11.7826, Validation Loss AVG: 11.7826, lr: 0.001
Epoch [14/80], Training Loss: 30.2764, Validation Loss Current: 12.0955, Validation Loss AVG: 12.0955, lr: 0.001
Epoch [15/80], Training Loss: 29.3554, Validation Loss Current: 11.0558, Validation Loss AVG: 11.0558, lr: 0.001
Epoch [16/80], Training Loss: 28.5111, Validation Loss Current: 11.0348, Validation Loss AVG: 11.0348, lr: 0.001
Epoch [17/80], Training Loss: 28.2158, Validation Loss Current: 11.4786, Validation Loss AVG: 11.4786, lr: 0.001
Epoch [18/80], Training Loss: 26.3910, Validation Loss Current: 11.3673, Validation Loss AVG: 11.3673, lr: 0.001
Epoch [19/80], Training Loss: 25.9521, Validation Loss Current: 10.9188, Validation Loss AVG: 10.9188, lr: 0.001
Epoch [20/80], Training Loss: 25.6125, Validation Loss Current: 11.0733, Validation Loss AVG: 11.0733, lr: 0.001
Epoch [21/80], Training Loss: 23.3883, Validation Loss Current: 10.9661, Validation Loss AVG: 10.9661, lr: 0.001
Epoch [22/80], Training Loss: 25.4151, Validation Loss Current: 11.9961, Validation Loss AVG: 11.9961, lr: 0.001
Epoch [23/80], Training Loss: 23.9834, Validation Loss Current: 10.3728, Validation Loss AVG: 10.3728, lr: 0.001
Epoch [24/80], Training Loss: 22.9872, Validation Loss Current: 12.6683, Validation Loss AVG: 12.6683, lr: 0.001
Epoch [25/80], Training Loss: 21.0561, Validation Loss Current: 11.1308, Validation Loss AVG: 11.1308, lr: 0.001
Epoch [26/80], Training Loss: 19.3865, Validation Loss Current: 12.0876, Validation Loss AVG: 12.0876, lr: 0.001
Epoch [27/80], Training Loss: 20.0396, Validation Loss Current: 15.8865, Validation Loss AVG: 15.8865, lr: 0.001
Epoch [28/80], Training Loss: 18.0368, Validation Loss Current: 11.5977, Validation Loss AVG: 11.5977, lr: 0.001
Epoch [29/80], Training Loss: 17.0944, Validation Loss Current: 15.4776, Validation Loss AVG: 15.4776, lr: 0.001
Epoch [30/80], Training Loss: 19.2743, Validation Loss Current: 12.8469, Validation Loss AVG: 12.8469, lr: 0.001
Epoch [31/80], Training Loss: 16.3020, Validation Loss Current: 19.3548, Validation Loss AVG: 19.3548, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 1 Best val accuracy: [0.2335526315789474, 0.18881578947368421, 0.15526315789473685, 0.14802631578947367, 0.13355263157894737, 0.19374999999999998, 0.15921052631578947, 0.23388157894736844, 0.25625, 0.20822368421052634, 0.24407894736842106, 0.24539473684210528, 0.2325657894736842, 0.2230263157894737, 0.27697368421052626, 0.25921052631578945, 0.25526315789473686, 0.2674342105263158, 0.2967105263157895, 0.30164473684210524, 0.31414473684210525, 0.29046052631578945, 0.35657894736842105, 0.3118421052631579, 0.3539473684210526, 0.33782894736842106, 0.29078947368421054, 0.3470394736842105, 0.31414473684210525, 0.27861842105263157, 0.30328947368421055] Best val loss: 10.121402072906495


Current group: 0.4
Epoch [1/80], Training Loss: 33.2366, Validation Loss Current: 10.7622, Validation Loss AVG: 10.7622, lr: 0.001
Epoch [2/80], Training Loss: 29.9470, Validation Loss Current: 8.9103, Validation Loss AVG: 8.9103, lr: 0.001
Epoch [3/80], Training Loss: 27.4177, Validation Loss Current: 9.5563, Validation Loss AVG: 9.5563, lr: 0.001
Epoch [4/80], Training Loss: 25.1461, Validation Loss Current: 8.5453, Validation Loss AVG: 8.5453, lr: 0.001
Epoch [5/80], Training Loss: 24.6345, Validation Loss Current: 8.7623, Validation Loss AVG: 8.7623, lr: 0.001
Epoch [6/80], Training Loss: 21.5552, Validation Loss Current: 8.6377, Validation Loss AVG: 8.6377, lr: 0.001
Epoch [7/80], Training Loss: 20.4030, Validation Loss Current: 8.3457, Validation Loss AVG: 8.3457, lr: 0.001
Epoch [8/80], Training Loss: 19.4169, Validation Loss Current: 10.6988, Validation Loss AVG: 10.6988, lr: 0.001
Epoch [9/80], Training Loss: 19.1818, Validation Loss Current: 8.8519, Validation Loss AVG: 8.8519, lr: 0.001
Epoch [10/80], Training Loss: 18.6203, Validation Loss Current: 8.1657, Validation Loss AVG: 8.1657, lr: 0.001
Epoch [11/80], Training Loss: 15.6681, Validation Loss Current: 9.3709, Validation Loss AVG: 9.3709, lr: 0.001
Epoch [12/80], Training Loss: 18.1278, Validation Loss Current: 8.4944, Validation Loss AVG: 8.4944, lr: 0.001
Epoch [13/80], Training Loss: 14.0512, Validation Loss Current: 8.8461, Validation Loss AVG: 8.8461, lr: 0.001
Epoch [14/80], Training Loss: 12.3095, Validation Loss Current: 8.2427, Validation Loss AVG: 8.2427, lr: 0.001
Epoch [15/80], Training Loss: 12.7293, Validation Loss Current: 8.6771, Validation Loss AVG: 8.6771, lr: 0.001
Epoch [16/80], Training Loss: 11.7237, Validation Loss Current: 13.5322, Validation Loss AVG: 13.5322, lr: 0.001
Epoch [17/80], Training Loss: 17.2461, Validation Loss Current: 10.9841, Validation Loss AVG: 10.9841, lr: 0.001
Epoch [18/80], Training Loss: 15.3176, Validation Loss Current: 9.2624, Validation Loss AVG: 9.2624, lr: 0.001
Epoch [19/80], Training Loss: 10.4561, Validation Loss Current: 12.4475, Validation Loss AVG: 12.4475, lr: 0.001
Epoch [20/80], Training Loss: 10.9809, Validation Loss Current: 11.5937, Validation Loss AVG: 11.5937, lr: 0.001
Epoch [21/80], Training Loss: 10.5882, Validation Loss Current: 10.2457, Validation Loss AVG: 10.2457, lr: 0.001
Epoch [22/80], Training Loss: 8.1445, Validation Loss Current: 10.2406, Validation Loss AVG: 10.2406, lr: 0.001
Epoch [23/80], Training Loss: 7.7529, Validation Loss Current: 12.2259, Validation Loss AVG: 12.2259, lr: 0.001
Epoch [24/80], Training Loss: 15.4825, Validation Loss Current: 16.4001, Validation Loss AVG: 16.4001, lr: 0.001
Epoch [25/80], Training Loss: 10.4516, Validation Loss Current: 10.8211, Validation Loss AVG: 10.8211, lr: 0.001
Epoch [26/80], Training Loss: 7.5046, Validation Loss Current: 9.2897, Validation Loss AVG: 9.2897, lr: 0.001
Epoch [27/80], Training Loss: 6.7425, Validation Loss Current: 9.7068, Validation Loss AVG: 9.7068, lr: 0.001
Epoch [28/80], Training Loss: 5.1028, Validation Loss Current: 9.3180, Validation Loss AVG: 9.3180, lr: 0.001
Epoch [29/80], Training Loss: 5.9753, Validation Loss Current: 11.3073, Validation Loss AVG: 11.3073, lr: 0.001
Epoch [30/80], Training Loss: 5.1237, Validation Loss Current: 9.7136, Validation Loss AVG: 9.7136, lr: 0.001
Epoch [31/80], Training Loss: 3.7803, Validation Loss Current: 9.9942, Validation Loss AVG: 9.9942, lr: 0.001
Epoch [32/80], Training Loss: 3.4077, Validation Loss Current: 10.3181, Validation Loss AVG: 10.3181, lr: 0.001
Epoch [33/80], Training Loss: 7.8302, Validation Loss Current: 13.9476, Validation Loss AVG: 13.9476, lr: 0.001
Epoch [34/80], Training Loss: 20.9144, Validation Loss Current: 14.3414, Validation Loss AVG: 14.3414, lr: 0.001
Epoch [35/80], Training Loss: 15.5806, Validation Loss Current: 13.5981, Validation Loss AVG: 13.5981, lr: 0.001
Epoch [36/80], Training Loss: 12.1747, Validation Loss Current: 11.1922, Validation Loss AVG: 11.1922, lr: 0.001
Epoch [37/80], Training Loss: 8.2904, Validation Loss Current: 10.5502, Validation Loss AVG: 10.5502, lr: 0.001
Epoch [38/80], Training Loss: 7.7174, Validation Loss Current: 11.6190, Validation Loss AVG: 11.6190, lr: 0.001
Epoch [39/80], Training Loss: 5.6114, Validation Loss Current: 12.0092, Validation Loss AVG: 12.0092, lr: 0.001
Epoch [40/80], Training Loss: 6.4800, Validation Loss Current: 12.2974, Validation Loss AVG: 12.2974, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 10 Best val accuracy: [0.2825657894736842, 0.41875, 0.3335526315789474, 0.44243421052631576, 0.40888157894736843, 0.44177631578947374, 0.4302631578947368, 0.3904605263157895, 0.40164473684210533, 0.45065789473684215, 0.35427631578947366, 0.4480263157894737, 0.42927631578947373, 0.4384868421052631, 0.4276315789473684, 0.31513157894736843, 0.39309210526315785, 0.4322368421052632, 0.40230263157894736, 0.3335526315789473, 0.4213815789473684, 0.3842105263157895, 0.35328947368421054, 0.3213815789473684, 0.4131578947368421, 0.4588815789473684, 0.45953947368421055, 0.4483552631578947, 0.4213815789473684, 0.43684210526315786, 0.4230263157894737, 0.43322368421052626, 0.3486842105263158, 0.26842105263157895, 0.30756578947368424, 0.36381578947368415, 0.4213815789473684, 0.43453947368421053, 0.350328947368421, 0.40855263157894733] Best val loss: 8.165675187110901


Current group: 0.6
Epoch [1/80], Training Loss: 29.9276, Validation Loss Current: 10.6565, Validation Loss AVG: 10.6565, lr: 0.001
Epoch [2/80], Training Loss: 20.9979, Validation Loss Current: 9.3607, Validation Loss AVG: 9.3607, lr: 0.001
Epoch [3/80], Training Loss: 15.0793, Validation Loss Current: 10.0707, Validation Loss AVG: 10.0707, lr: 0.001
Epoch [4/80], Training Loss: 11.7701, Validation Loss Current: 8.8976, Validation Loss AVG: 8.8976, lr: 0.001
Epoch [5/80], Training Loss: 9.6300, Validation Loss Current: 10.4820, Validation Loss AVG: 10.4820, lr: 0.001
Epoch [6/80], Training Loss: 8.5015, Validation Loss Current: 9.0837, Validation Loss AVG: 9.0837, lr: 0.001
Epoch [7/80], Training Loss: 11.7961, Validation Loss Current: 10.0882, Validation Loss AVG: 10.0882, lr: 0.001
Epoch [8/80], Training Loss: 11.1129, Validation Loss Current: 10.3729, Validation Loss AVG: 10.3729, lr: 0.001
Epoch [9/80], Training Loss: 9.2081, Validation Loss Current: 13.6062, Validation Loss AVG: 13.6062, lr: 0.001
Epoch [10/80], Training Loss: 10.1648, Validation Loss Current: 10.7415, Validation Loss AVG: 10.7415, lr: 0.001
Epoch [11/80], Training Loss: 5.4565, Validation Loss Current: 10.8558, Validation Loss AVG: 10.8558, lr: 0.001
Epoch [12/80], Training Loss: 6.2576, Validation Loss Current: 10.3242, Validation Loss AVG: 10.3242, lr: 0.001
Epoch [13/80], Training Loss: 7.0339, Validation Loss Current: 12.2171, Validation Loss AVG: 12.2171, lr: 0.001
Epoch [14/80], Training Loss: 11.3310, Validation Loss Current: 11.8613, Validation Loss AVG: 11.8613, lr: 0.001
Epoch [15/80], Training Loss: 7.5581, Validation Loss Current: 10.0470, Validation Loss AVG: 10.0470, lr: 0.001
Epoch [16/80], Training Loss: 6.1861, Validation Loss Current: 11.1850, Validation Loss AVG: 11.1850, lr: 0.001
Epoch [17/80], Training Loss: 9.1871, Validation Loss Current: 12.0172, Validation Loss AVG: 12.0172, lr: 0.001
Epoch [18/80], Training Loss: 4.8029, Validation Loss Current: 10.7053, Validation Loss AVG: 10.7053, lr: 0.001
Epoch [19/80], Training Loss: 3.3154, Validation Loss Current: 10.4565, Validation Loss AVG: 10.4565, lr: 0.001
Epoch [20/80], Training Loss: 3.8388, Validation Loss Current: 10.9353, Validation Loss AVG: 10.9353, lr: 0.001
Epoch [21/80], Training Loss: 4.1074, Validation Loss Current: 11.4228, Validation Loss AVG: 11.4228, lr: 0.001
Epoch [22/80], Training Loss: 3.5527, Validation Loss Current: 12.6218, Validation Loss AVG: 12.6218, lr: 0.001
Epoch [23/80], Training Loss: 4.1451, Validation Loss Current: 11.4100, Validation Loss AVG: 11.4100, lr: 0.001
Epoch [24/80], Training Loss: 4.1398, Validation Loss Current: 12.3641, Validation Loss AVG: 12.3641, lr: 0.001
Epoch [25/80], Training Loss: 2.1718, Validation Loss Current: 11.6029, Validation Loss AVG: 11.6029, lr: 0.001
Epoch [26/80], Training Loss: 1.9432, Validation Loss Current: 11.9532, Validation Loss AVG: 11.9532, lr: 0.001
Epoch [27/80], Training Loss: 4.7812, Validation Loss Current: 12.4452, Validation Loss AVG: 12.4452, lr: 0.001
Epoch [28/80], Training Loss: 5.6376, Validation Loss Current: 12.1415, Validation Loss AVG: 12.1415, lr: 0.001
Epoch [29/80], Training Loss: 7.8521, Validation Loss Current: 16.3719, Validation Loss AVG: 16.3719, lr: 0.001
Epoch [30/80], Training Loss: 5.5918, Validation Loss Current: 12.9229, Validation Loss AVG: 12.9229, lr: 0.001
Epoch [31/80], Training Loss: 8.2788, Validation Loss Current: 11.8206, Validation Loss AVG: 11.8206, lr: 0.001
Epoch [32/80], Training Loss: 4.2493, Validation Loss Current: 12.1901, Validation Loss AVG: 12.1901, lr: 0.001
Epoch [33/80], Training Loss: 7.2919, Validation Loss Current: 12.1286, Validation Loss AVG: 12.1286, lr: 0.001
Epoch [34/80], Training Loss: 4.0289, Validation Loss Current: 11.9839, Validation Loss AVG: 11.9839, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 4 Best val accuracy: [0.4164473684210527, 0.45, 0.42631578947368426, 0.4641447368421052, 0.42993421052631586, 0.4276315789473685, 0.46052631578947373, 0.3917763157894737, 0.45000000000000007, 0.41776315789473684, 0.4384868421052632, 0.44407894736842096, 0.4046052631578947, 0.41447368421052627, 0.4253289473684211, 0.4042763157894737, 0.41019736842105264, 0.4115131578947368, 0.45131578947368417, 0.4453947368421053, 0.40921052631578947, 0.4394736842105263, 0.42796052631578946, 0.3894736842105263, 0.4296052631578947, 0.41217105263157894, 0.4358552631578947, 0.39769736842105263, 0.3944078947368421, 0.39671052631578946, 0.4319078947368421, 0.4180921052631579, 0.4240131578947368, 0.40559210526315786] Best val loss: 8.897584414482116


Current group: 0.8
Epoch [1/80], Training Loss: 28.3223, Validation Loss Current: 10.6874, Validation Loss AVG: 10.6874, lr: 0.001
Epoch [2/80], Training Loss: 16.2855, Validation Loss Current: 12.4950, Validation Loss AVG: 12.4950, lr: 0.001
Epoch [3/80], Training Loss: 13.3507, Validation Loss Current: 11.3689, Validation Loss AVG: 11.3689, lr: 0.001
Epoch [4/80], Training Loss: 7.7107, Validation Loss Current: 11.4962, Validation Loss AVG: 11.4962, lr: 0.001
Epoch [5/80], Training Loss: 5.5058, Validation Loss Current: 11.1206, Validation Loss AVG: 11.1206, lr: 0.001
Epoch [6/80], Training Loss: 5.3980, Validation Loss Current: 11.4261, Validation Loss AVG: 11.4261, lr: 0.001
Epoch [7/80], Training Loss: 7.0420, Validation Loss Current: 15.1304, Validation Loss AVG: 15.1304, lr: 0.001
Epoch [8/80], Training Loss: 3.9036, Validation Loss Current: 12.2874, Validation Loss AVG: 12.2874, lr: 0.001
Epoch [9/80], Training Loss: 4.1156, Validation Loss Current: 13.2758, Validation Loss AVG: 13.2758, lr: 0.001
Epoch [10/80], Training Loss: 5.1218, Validation Loss Current: 13.0984, Validation Loss AVG: 13.0984, lr: 0.001
Epoch [11/80], Training Loss: 5.3201, Validation Loss Current: 13.8750, Validation Loss AVG: 13.8750, lr: 0.001
Epoch [12/80], Training Loss: 3.8010, Validation Loss Current: 14.7686, Validation Loss AVG: 14.7686, lr: 0.001
Epoch [13/80], Training Loss: 9.7561, Validation Loss Current: 13.7741, Validation Loss AVG: 13.7741, lr: 0.001
Epoch [14/80], Training Loss: 7.7224, Validation Loss Current: 12.7668, Validation Loss AVG: 12.7668, lr: 0.001
Epoch [15/80], Training Loss: 8.5510, Validation Loss Current: 13.4713, Validation Loss AVG: 13.4713, lr: 0.001
Epoch [16/80], Training Loss: 6.5521, Validation Loss Current: 11.2041, Validation Loss AVG: 11.2041, lr: 0.001
Epoch [17/80], Training Loss: 5.8914, Validation Loss Current: 12.3035, Validation Loss AVG: 12.3035, lr: 0.001
Epoch [18/80], Training Loss: 3.7838, Validation Loss Current: 10.8386, Validation Loss AVG: 10.8386, lr: 0.001
Epoch [19/80], Training Loss: 4.0540, Validation Loss Current: 11.9448, Validation Loss AVG: 11.9448, lr: 0.001
Epoch [20/80], Training Loss: 8.9751, Validation Loss Current: 15.7643, Validation Loss AVG: 15.7643, lr: 0.001
Epoch [21/80], Training Loss: 6.1295, Validation Loss Current: 11.5378, Validation Loss AVG: 11.5378, lr: 0.001
Epoch [22/80], Training Loss: 4.4659, Validation Loss Current: 11.3892, Validation Loss AVG: 11.3892, lr: 0.001
Epoch [23/80], Training Loss: 3.3296, Validation Loss Current: 11.3743, Validation Loss AVG: 11.3743, lr: 0.001
Epoch [24/80], Training Loss: 3.8874, Validation Loss Current: 12.3221, Validation Loss AVG: 12.3221, lr: 0.001
Epoch [25/80], Training Loss: 4.9513, Validation Loss Current: 12.2663, Validation Loss AVG: 12.2663, lr: 0.001
Epoch [26/80], Training Loss: 3.2179, Validation Loss Current: 12.3729, Validation Loss AVG: 12.3729, lr: 0.001
Epoch [27/80], Training Loss: 2.7554, Validation Loss Current: 12.1347, Validation Loss AVG: 12.1347, lr: 0.001
Epoch [28/80], Training Loss: 3.9892, Validation Loss Current: 16.6567, Validation Loss AVG: 16.6567, lr: 0.001
Epoch [29/80], Training Loss: 11.3658, Validation Loss Current: 15.8528, Validation Loss AVG: 15.8528, lr: 0.001
Epoch [30/80], Training Loss: 7.1195, Validation Loss Current: 13.0700, Validation Loss AVG: 13.0700, lr: 0.001
Epoch [31/80], Training Loss: 3.1685, Validation Loss Current: 12.1208, Validation Loss AVG: 12.1208, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 1 Best val accuracy: [0.43355263157894736, 0.4213815789473684, 0.4203947368421053, 0.4286184210526317, 0.4582236842105263, 0.3940789473684211, 0.40230263157894736, 0.44901315789473684, 0.4276315789473684, 0.41776315789473684, 0.4151315789473684, 0.3519736842105263, 0.46480263157894736, 0.4513157894736842, 0.41776315789473684, 0.4391447368421052, 0.44375, 0.4542763157894737, 0.42434210526315785, 0.40164473684210533, 0.4457236842105264, 0.4342105263157895, 0.43684210526315786, 0.42598684210526316, 0.43717105263157896, 0.44868421052631574, 0.4365131578947368, 0.3740131578947368, 0.4026315789473684, 0.4236842105263158, 0.43157894736842106] Best val loss: 10.687445020675659


Current group: 1
Epoch [1/80], Training Loss: 27.8849, Validation Loss Current: 8.8997, Validation Loss AVG: 11.8487, lr: 0.001
Epoch [2/80], Training Loss: 20.0591, Validation Loss Current: 8.9628, Validation Loss AVG: 11.0367, lr: 0.001
Epoch [3/80], Training Loss: 13.9022, Validation Loss Current: 8.0493, Validation Loss AVG: 11.0871, lr: 0.001
Epoch [4/80], Training Loss: 11.7745, Validation Loss Current: 8.0521, Validation Loss AVG: 12.2483, lr: 0.001
Epoch [5/80], Training Loss: 7.3723, Validation Loss Current: 8.6485, Validation Loss AVG: 11.7926, lr: 0.001
Epoch [6/80], Training Loss: 4.0255, Validation Loss Current: 6.9251, Validation Loss AVG: 10.8829, lr: 0.001
Epoch [7/80], Training Loss: 6.2053, Validation Loss Current: 7.3909, Validation Loss AVG: 10.8212, lr: 0.001
Epoch [8/80], Training Loss: 4.6569, Validation Loss Current: 7.3061, Validation Loss AVG: 11.5843, lr: 0.001
Epoch [9/80], Training Loss: 3.8437, Validation Loss Current: 7.8997, Validation Loss AVG: 11.6608, lr: 0.001
Epoch [10/80], Training Loss: 5.2724, Validation Loss Current: 8.2683, Validation Loss AVG: 13.6706, lr: 0.001
Epoch [11/80], Training Loss: 5.6555, Validation Loss Current: 8.3332, Validation Loss AVG: 12.2710, lr: 0.001
Epoch [12/80], Training Loss: 4.7812, Validation Loss Current: 8.3318, Validation Loss AVG: 13.4588, lr: 0.001
Epoch [13/80], Training Loss: 8.3344, Validation Loss Current: 8.2549, Validation Loss AVG: 11.8646, lr: 0.001
Epoch [14/80], Training Loss: 4.4553, Validation Loss Current: 8.3271, Validation Loss AVG: 13.4356, lr: 0.001
Epoch [15/80], Training Loss: 3.1295, Validation Loss Current: 7.3712, Validation Loss AVG: 12.1718, lr: 0.001
Epoch [16/80], Training Loss: 3.4264, Validation Loss Current: 9.5559, Validation Loss AVG: 16.5759, lr: 0.001
Epoch [17/80], Training Loss: 2.4261, Validation Loss Current: 7.5561, Validation Loss AVG: 12.5847, lr: 0.001
Epoch [18/80], Training Loss: 5.1874, Validation Loss Current: 7.3900, Validation Loss AVG: 13.5761, lr: 0.001
Epoch [19/80], Training Loss: 3.1024, Validation Loss Current: 9.0454, Validation Loss AVG: 14.9549, lr: 0.001
Epoch [20/80], Training Loss: 2.2050, Validation Loss Current: 7.2434, Validation Loss AVG: 14.2073, lr: 0.001
Epoch [21/80], Training Loss: 1.7309, Validation Loss Current: 7.6904, Validation Loss AVG: 12.1119, lr: 0.001
Epoch [22/80], Training Loss: 2.8630, Validation Loss Current: 7.7953, Validation Loss AVG: 13.0533, lr: 0.001
Epoch [23/80], Training Loss: 5.0964, Validation Loss Current: 8.3275, Validation Loss AVG: 12.3694, lr: 0.001
Epoch [24/80], Training Loss: 2.7634, Validation Loss Current: 8.6748, Validation Loss AVG: 13.6910, lr: 0.001
Epoch [25/80], Training Loss: 1.6527, Validation Loss Current: 7.5981, Validation Loss AVG: 12.8113, lr: 0.001
Epoch [26/80], Training Loss: 2.6742, Validation Loss Current: 8.6036, Validation Loss AVG: 16.6061, lr: 0.001
Epoch [27/80], Training Loss: 6.7564, Validation Loss Current: 8.5499, Validation Loss AVG: 14.3087, lr: 0.001
Epoch [28/80], Training Loss: 2.5393, Validation Loss Current: 9.4837, Validation Loss AVG: 15.4266, lr: 0.001
Epoch [29/80], Training Loss: 1.2687, Validation Loss Current: 8.3106, Validation Loss AVG: 15.2119, lr: 0.001
Epoch [30/80], Training Loss: 4.7703, Validation Loss Current: 8.6383, Validation Loss AVG: 13.7249, lr: 0.001
Epoch [31/80], Training Loss: 2.2591, Validation Loss Current: 8.5425, Validation Loss AVG: 16.0965, lr: 0.001
Epoch [32/80], Training Loss: 4.8571, Validation Loss Current: 8.8627, Validation Loss AVG: 13.4592, lr: 0.001
Epoch [33/80], Training Loss: 6.1195, Validation Loss Current: 8.9858, Validation Loss AVG: 14.3963, lr: 0.001
Epoch [34/80], Training Loss: 3.7090, Validation Loss Current: 8.6423, Validation Loss AVG: 14.8749, lr: 0.001
Epoch [35/80], Training Loss: 4.7986, Validation Loss Current: 8.8885, Validation Loss AVG: 15.4061, lr: 0.001
Epoch [36/80], Training Loss: 5.8199, Validation Loss Current: 9.9167, Validation Loss AVG: 15.5833, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 6 Best val accuracy: [0.5723684210526315, 0.537828947368421, 0.5657894736842105, 0.5740131578947368, 0.5427631578947368, 0.6118421052631579, 0.569078947368421, 0.5789473684210527, 0.5723684210526315, 0.5904605263157895, 0.5526315789473685, 0.5526315789473685, 0.5707236842105263, 0.5855263157894737, 0.6036184210526315, 0.5674342105263158, 0.6085526315789473, 0.587171052631579, 0.5542763157894737, 0.6069078947368421, 0.5970394736842105, 0.5904605263157895, 0.5822368421052632, 0.5838815789473685, 0.6052631578947368, 0.6134868421052632, 0.5888157894736842, 0.5723684210526315, 0.59375, 0.587171052631579, 0.5756578947368421, 0.5740131578947368, 0.5904605263157895, 0.5921052631578947, 0.5838815789473685, 0.5394736842105263] Best val loss: 6.925129771232605


----- Training resnet18 with sequence: [0.4, 0.6, 0.8, 1] -----
Current group: 0.4
Epoch [1/100], Training Loss: 41.3101, Validation Loss Current: 9.9454, Validation Loss AVG: 9.9454, lr: 0.001
Epoch [2/100], Training Loss: 40.0456, Validation Loss Current: 9.9153, Validation Loss AVG: 9.9153, lr: 0.001
Epoch [3/100], Training Loss: 38.9727, Validation Loss Current: 9.7963, Validation Loss AVG: 9.7963, lr: 0.001
Epoch [4/100], Training Loss: 38.3755, Validation Loss Current: 9.5758, Validation Loss AVG: 9.5758, lr: 0.001
Epoch [5/100], Training Loss: 36.9233, Validation Loss Current: 9.4408, Validation Loss AVG: 9.4408, lr: 0.001
Epoch [6/100], Training Loss: 36.1403, Validation Loss Current: 9.4663, Validation Loss AVG: 9.4663, lr: 0.001
Epoch [7/100], Training Loss: 34.5683, Validation Loss Current: 9.4124, Validation Loss AVG: 9.4124, lr: 0.001
Epoch [8/100], Training Loss: 33.5594, Validation Loss Current: 9.2972, Validation Loss AVG: 9.2972, lr: 0.001
Epoch [9/100], Training Loss: 33.3028, Validation Loss Current: 9.2440, Validation Loss AVG: 9.2440, lr: 0.001
Epoch [10/100], Training Loss: 32.6065, Validation Loss Current: 9.1391, Validation Loss AVG: 9.1391, lr: 0.001
Epoch [11/100], Training Loss: 31.2850, Validation Loss Current: 8.9791, Validation Loss AVG: 8.9791, lr: 0.001
Epoch [12/100], Training Loss: 30.4168, Validation Loss Current: 9.1133, Validation Loss AVG: 9.1133, lr: 0.001
Epoch [13/100], Training Loss: 31.5553, Validation Loss Current: 9.0377, Validation Loss AVG: 9.0377, lr: 0.001
Epoch [14/100], Training Loss: 30.4022, Validation Loss Current: 9.3434, Validation Loss AVG: 9.3434, lr: 0.001
Epoch [15/100], Training Loss: 30.1664, Validation Loss Current: 9.2852, Validation Loss AVG: 9.2852, lr: 0.001
Epoch [16/100], Training Loss: 29.6724, Validation Loss Current: 9.0727, Validation Loss AVG: 9.0727, lr: 0.001
Epoch [17/100], Training Loss: 28.4376, Validation Loss Current: 9.5297, Validation Loss AVG: 9.5297, lr: 0.001
Epoch [18/100], Training Loss: 26.9899, Validation Loss Current: 8.6846, Validation Loss AVG: 8.6846, lr: 0.001
Epoch [19/100], Training Loss: 25.6739, Validation Loss Current: 8.4362, Validation Loss AVG: 8.4362, lr: 0.001
Epoch [20/100], Training Loss: 26.2825, Validation Loss Current: 8.8963, Validation Loss AVG: 8.8963, lr: 0.001
Epoch [21/100], Training Loss: 25.3315, Validation Loss Current: 8.8608, Validation Loss AVG: 8.8608, lr: 0.001
Epoch [22/100], Training Loss: 23.6240, Validation Loss Current: 8.0315, Validation Loss AVG: 8.0315, lr: 0.001
Epoch [23/100], Training Loss: 23.4339, Validation Loss Current: 8.2973, Validation Loss AVG: 8.2973, lr: 0.001
Epoch [24/100], Training Loss: 23.4717, Validation Loss Current: 8.2827, Validation Loss AVG: 8.2827, lr: 0.001
Epoch [25/100], Training Loss: 21.6666, Validation Loss Current: 7.8893, Validation Loss AVG: 7.8893, lr: 0.001
Epoch [26/100], Training Loss: 21.3650, Validation Loss Current: 8.1767, Validation Loss AVG: 8.1767, lr: 0.001
Epoch [27/100], Training Loss: 19.1307, Validation Loss Current: 7.8379, Validation Loss AVG: 7.8379, lr: 0.001
Epoch [28/100], Training Loss: 19.7315, Validation Loss Current: 8.8961, Validation Loss AVG: 8.8961, lr: 0.001
Epoch [29/100], Training Loss: 19.0200, Validation Loss Current: 8.6086, Validation Loss AVG: 8.6086, lr: 0.001
Epoch [30/100], Training Loss: 18.9635, Validation Loss Current: 8.3795, Validation Loss AVG: 8.3795, lr: 0.001
Epoch [31/100], Training Loss: 16.9911, Validation Loss Current: 8.7387, Validation Loss AVG: 8.7387, lr: 0.001
Epoch [32/100], Training Loss: 16.5081, Validation Loss Current: 9.1433, Validation Loss AVG: 9.1433, lr: 0.001
Epoch [33/100], Training Loss: 14.5076, Validation Loss Current: 8.6164, Validation Loss AVG: 8.6164, lr: 0.001
Epoch [34/100], Training Loss: 13.7816, Validation Loss Current: 8.2688, Validation Loss AVG: 8.2688, lr: 0.001
Epoch [35/100], Training Loss: 13.8320, Validation Loss Current: 8.3870, Validation Loss AVG: 8.3870, lr: 0.001
Epoch [36/100], Training Loss: 13.3978, Validation Loss Current: 9.1843, Validation Loss AVG: 9.1843, lr: 0.001
Epoch [37/100], Training Loss: 14.8127, Validation Loss Current: 9.4118, Validation Loss AVG: 9.4118, lr: 0.001
Epoch [38/100], Training Loss: 13.2125, Validation Loss Current: 9.3417, Validation Loss AVG: 9.3417, lr: 0.001
Epoch [39/100], Training Loss: 13.0247, Validation Loss Current: 9.4799, Validation Loss AVG: 9.4799, lr: 0.001
Epoch [40/100], Training Loss: 13.1382, Validation Loss Current: 9.3472, Validation Loss AVG: 9.3472, lr: 0.001
Epoch [41/100], Training Loss: 11.4986, Validation Loss Current: 10.3761, Validation Loss AVG: 10.3761, lr: 0.001
Epoch [42/100], Training Loss: 9.7562, Validation Loss Current: 9.4516, Validation Loss AVG: 9.4516, lr: 0.001
Epoch [43/100], Training Loss: 7.8263, Validation Loss Current: 10.1916, Validation Loss AVG: 10.1916, lr: 0.001
Epoch [44/100], Training Loss: 10.9316, Validation Loss Current: 10.4612, Validation Loss AVG: 10.4612, lr: 0.001
Epoch [45/100], Training Loss: 11.2342, Validation Loss Current: 10.0002, Validation Loss AVG: 10.0002, lr: 0.001
Epoch [46/100], Training Loss: 12.6459, Validation Loss Current: 11.0629, Validation Loss AVG: 11.0629, lr: 0.001
Epoch [47/100], Training Loss: 11.4648, Validation Loss Current: 11.4406, Validation Loss AVG: 11.4406, lr: 0.001
Epoch [48/100], Training Loss: 8.9824, Validation Loss Current: 11.3155, Validation Loss AVG: 11.3155, lr: 0.001
Epoch [49/100], Training Loss: 8.9967, Validation Loss Current: 11.1923, Validation Loss AVG: 11.1923, lr: 0.001
Epoch [50/100], Training Loss: 5.7933, Validation Loss Current: 10.0273, Validation Loss AVG: 10.0273, lr: 0.001
Epoch [51/100], Training Loss: 4.8160, Validation Loss Current: 10.1005, Validation Loss AVG: 10.1005, lr: 0.001
Epoch [52/100], Training Loss: 6.4646, Validation Loss Current: 10.9566, Validation Loss AVG: 10.9566, lr: 0.001
Epoch [53/100], Training Loss: 5.4161, Validation Loss Current: 11.7629, Validation Loss AVG: 11.7629, lr: 0.001
Epoch [54/100], Training Loss: 10.0088, Validation Loss Current: 20.4023, Validation Loss AVG: 20.4023, lr: 0.001
Epoch [55/100], Training Loss: 9.2326, Validation Loss Current: 13.8492, Validation Loss AVG: 13.8492, lr: 0.001
Epoch [56/100], Training Loss: 6.8833, Validation Loss Current: 11.2500, Validation Loss AVG: 11.2500, lr: 0.001
Epoch [57/100], Training Loss: 5.5951, Validation Loss Current: 12.1601, Validation Loss AVG: 12.1601, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 27 Best val accuracy: [0.24539473684210528, 0.2473684210526316, 0.2641447368421053, 0.29375, 0.2986842105263158, 0.3023026315789473, 0.32105263157894737, 0.3115131578947369, 0.2963815789473684, 0.305921052631579, 0.3549342105263158, 0.34901315789473686, 0.31414473684210525, 0.33684210526315794, 0.3174342105263158, 0.3279605263157895, 0.36743421052631586, 0.39868421052631575, 0.4046052631578948, 0.38190789473684206, 0.3927631578947369, 0.42598684210526316, 0.4016447368421052, 0.4236842105263158, 0.43717105263157896, 0.41546052631578945, 0.45, 0.3815789473684211, 0.40625, 0.4203947368421052, 0.43519736842105267, 0.3865131578947369, 0.4171052631578947, 0.4483552631578947, 0.43717105263157896, 0.43486842105263157, 0.3924342105263158, 0.43717105263157896, 0.36907894736842106, 0.41940789473684215, 0.33223684210526316, 0.4131578947368421, 0.40361842105263157, 0.37368421052631573, 0.40855263157894733, 0.3898026315789474, 0.3858552631578947, 0.38848684210526313, 0.3338815789473684, 0.40888157894736843, 0.4269736842105264, 0.42631578947368426, 0.34638157894736843, 0.3177631578947368, 0.3513157894736842, 0.4365131578947368, 0.3815789473684211] Best val loss: 7.837883639335632


Current group: 0.6
Epoch [1/100], Training Loss: 30.5075, Validation Loss Current: 12.7757, Validation Loss AVG: 12.7757, lr: 0.001
Epoch [2/100], Training Loss: 21.9716, Validation Loss Current: 9.8098, Validation Loss AVG: 9.8098, lr: 0.001
Epoch [3/100], Training Loss: 18.3242, Validation Loss Current: 10.8117, Validation Loss AVG: 10.8117, lr: 0.001
Epoch [4/100], Training Loss: 13.2037, Validation Loss Current: 9.1553, Validation Loss AVG: 9.1553, lr: 0.001
Epoch [5/100], Training Loss: 12.9036, Validation Loss Current: 9.3267, Validation Loss AVG: 9.3267, lr: 0.001
Epoch [6/100], Training Loss: 11.6004, Validation Loss Current: 15.0212, Validation Loss AVG: 15.0212, lr: 0.001
Epoch [7/100], Training Loss: 17.2685, Validation Loss Current: 9.6941, Validation Loss AVG: 9.6941, lr: 0.001
Epoch [8/100], Training Loss: 12.7699, Validation Loss Current: 9.6120, Validation Loss AVG: 9.6120, lr: 0.001
Epoch [9/100], Training Loss: 9.0430, Validation Loss Current: 9.7424, Validation Loss AVG: 9.7424, lr: 0.001
Epoch [10/100], Training Loss: 5.9453, Validation Loss Current: 9.5886, Validation Loss AVG: 9.5886, lr: 0.001
Epoch [11/100], Training Loss: 6.8172, Validation Loss Current: 10.7396, Validation Loss AVG: 10.7396, lr: 0.001
Epoch [12/100], Training Loss: 6.6526, Validation Loss Current: 10.4239, Validation Loss AVG: 10.4239, lr: 0.001
Epoch [13/100], Training Loss: 5.9621, Validation Loss Current: 9.9161, Validation Loss AVG: 9.9161, lr: 0.001
Epoch [14/100], Training Loss: 6.0120, Validation Loss Current: 11.2665, Validation Loss AVG: 11.2665, lr: 0.001
Epoch [15/100], Training Loss: 12.4290, Validation Loss Current: 12.9065, Validation Loss AVG: 12.9065, lr: 0.001
Epoch [16/100], Training Loss: 9.5992, Validation Loss Current: 10.8155, Validation Loss AVG: 10.8155, lr: 0.001
Epoch [17/100], Training Loss: 7.1880, Validation Loss Current: 11.4433, Validation Loss AVG: 11.4433, lr: 0.001
Epoch [18/100], Training Loss: 13.1146, Validation Loss Current: 13.3595, Validation Loss AVG: 13.3595, lr: 0.001
Epoch [19/100], Training Loss: 14.2550, Validation Loss Current: 11.0691, Validation Loss AVG: 11.0691, lr: 0.001
Epoch [20/100], Training Loss: 6.9328, Validation Loss Current: 10.1048, Validation Loss AVG: 10.1048, lr: 0.001
Epoch [21/100], Training Loss: 3.7188, Validation Loss Current: 10.1085, Validation Loss AVG: 10.1085, lr: 0.001
Epoch [22/100], Training Loss: 7.2616, Validation Loss Current: 10.7389, Validation Loss AVG: 10.7389, lr: 0.001
Epoch [23/100], Training Loss: 5.3795, Validation Loss Current: 11.9478, Validation Loss AVG: 11.9478, lr: 0.001
Epoch [24/100], Training Loss: 5.6510, Validation Loss Current: 12.8893, Validation Loss AVG: 12.8893, lr: 0.001
Epoch [25/100], Training Loss: 6.5144, Validation Loss Current: 12.4813, Validation Loss AVG: 12.4813, lr: 0.001
Epoch [26/100], Training Loss: 5.5142, Validation Loss Current: 13.4490, Validation Loss AVG: 13.4490, lr: 0.001
Epoch [27/100], Training Loss: 9.4829, Validation Loss Current: 12.7145, Validation Loss AVG: 12.7145, lr: 0.001
Epoch [28/100], Training Loss: 7.0516, Validation Loss Current: 11.9111, Validation Loss AVG: 11.9111, lr: 0.001
Epoch [29/100], Training Loss: 4.0750, Validation Loss Current: 11.5963, Validation Loss AVG: 11.5963, lr: 0.001
Epoch [30/100], Training Loss: 4.1982, Validation Loss Current: 11.8625, Validation Loss AVG: 11.8625, lr: 0.001
Epoch [31/100], Training Loss: 3.2040, Validation Loss Current: 11.0191, Validation Loss AVG: 11.0191, lr: 0.001
Epoch [32/100], Training Loss: 2.2119, Validation Loss Current: 10.8720, Validation Loss AVG: 10.8720, lr: 0.001
Epoch [33/100], Training Loss: 4.5922, Validation Loss Current: 21.6104, Validation Loss AVG: 21.6104, lr: 0.001
Epoch [34/100], Training Loss: 7.3049, Validation Loss Current: 13.1740, Validation Loss AVG: 13.1740, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 4 Best val accuracy: [0.3539473684210527, 0.41052631578947363, 0.39671052631578946, 0.43190789473684205, 0.42993421052631575, 0.32532894736842105, 0.4098684210526316, 0.44375, 0.44243421052631576, 0.44671052631578945, 0.4026315789473684, 0.425, 0.4322368421052632, 0.4, 0.3927631578947368, 0.40657894736842104, 0.3950657894736842, 0.34539473684210525, 0.41381578947368414, 0.40328947368421053, 0.45953947368421055, 0.43881578947368416, 0.37203947368421053, 0.3960526315789473, 0.35098684210526315, 0.40921052631578947, 0.42796052631578946, 0.3983552631578947, 0.4463815789473684, 0.425, 0.42598684210526316, 0.4569078947368421, 0.3003289473684211, 0.40394736842105267] Best val loss: 9.155299830436707


Current group: 0.8
Epoch [1/100], Training Loss: 28.9408, Validation Loss Current: 11.8708, Validation Loss AVG: 11.8708, lr: 0.001
Epoch [2/100], Training Loss: 20.7869, Validation Loss Current: 10.9117, Validation Loss AVG: 10.9117, lr: 0.001
Epoch [3/100], Training Loss: 17.8425, Validation Loss Current: 10.6041, Validation Loss AVG: 10.6041, lr: 0.001
Epoch [4/100], Training Loss: 11.3925, Validation Loss Current: 11.0287, Validation Loss AVG: 11.0287, lr: 0.001
Epoch [5/100], Training Loss: 9.2641, Validation Loss Current: 12.3651, Validation Loss AVG: 12.3651, lr: 0.001
Epoch [6/100], Training Loss: 7.0964, Validation Loss Current: 10.6373, Validation Loss AVG: 10.6373, lr: 0.001
Epoch [7/100], Training Loss: 4.8943, Validation Loss Current: 11.6262, Validation Loss AVG: 11.6262, lr: 0.001
Epoch [8/100], Training Loss: 3.9231, Validation Loss Current: 10.4650, Validation Loss AVG: 10.4650, lr: 0.001
Epoch [9/100], Training Loss: 2.7225, Validation Loss Current: 10.2946, Validation Loss AVG: 10.2946, lr: 0.001
Epoch [10/100], Training Loss: 1.9422, Validation Loss Current: 10.4749, Validation Loss AVG: 10.4749, lr: 0.001
Epoch [11/100], Training Loss: 2.1637, Validation Loss Current: 10.0566, Validation Loss AVG: 10.0566, lr: 0.001
Epoch [12/100], Training Loss: 2.1254, Validation Loss Current: 11.5744, Validation Loss AVG: 11.5744, lr: 0.001
Epoch [13/100], Training Loss: 1.9677, Validation Loss Current: 12.1004, Validation Loss AVG: 12.1004, lr: 0.001
Epoch [14/100], Training Loss: 6.3215, Validation Loss Current: 11.7106, Validation Loss AVG: 11.7106, lr: 0.001
Epoch [15/100], Training Loss: 5.0776, Validation Loss Current: 13.9060, Validation Loss AVG: 13.9060, lr: 0.001
Epoch [16/100], Training Loss: 3.3761, Validation Loss Current: 12.3225, Validation Loss AVG: 12.3225, lr: 0.001
Epoch [17/100], Training Loss: 4.8889, Validation Loss Current: 12.9055, Validation Loss AVG: 12.9055, lr: 0.001
Epoch [18/100], Training Loss: 2.3380, Validation Loss Current: 10.7480, Validation Loss AVG: 10.7480, lr: 0.001
Epoch [19/100], Training Loss: 1.0188, Validation Loss Current: 9.9158, Validation Loss AVG: 9.9158, lr: 0.001
Epoch [20/100], Training Loss: 1.6017, Validation Loss Current: 11.3783, Validation Loss AVG: 11.3783, lr: 0.001
Epoch [21/100], Training Loss: 3.4660, Validation Loss Current: 13.7947, Validation Loss AVG: 13.7947, lr: 0.001
Epoch [22/100], Training Loss: 9.2082, Validation Loss Current: 13.1676, Validation Loss AVG: 13.1676, lr: 0.001
Epoch [23/100], Training Loss: 4.1943, Validation Loss Current: 13.0184, Validation Loss AVG: 13.0184, lr: 0.001
Epoch [24/100], Training Loss: 2.5563, Validation Loss Current: 12.0937, Validation Loss AVG: 12.0937, lr: 0.001
Epoch [25/100], Training Loss: 2.2476, Validation Loss Current: 11.5868, Validation Loss AVG: 11.5868, lr: 0.001
Epoch [26/100], Training Loss: 3.2514, Validation Loss Current: 12.7733, Validation Loss AVG: 12.7733, lr: 0.001
Epoch [27/100], Training Loss: 4.7165, Validation Loss Current: 15.5401, Validation Loss AVG: 15.5401, lr: 0.001
Epoch [28/100], Training Loss: 10.3647, Validation Loss Current: 18.1022, Validation Loss AVG: 18.1022, lr: 0.001
Epoch [29/100], Training Loss: 8.5529, Validation Loss Current: 12.5182, Validation Loss AVG: 12.5182, lr: 0.001
Epoch [30/100], Training Loss: 5.3673, Validation Loss Current: 13.6211, Validation Loss AVG: 13.6211, lr: 0.001
Epoch [31/100], Training Loss: 6.0493, Validation Loss Current: 13.4981, Validation Loss AVG: 13.4981, lr: 0.001
Epoch [32/100], Training Loss: 4.8934, Validation Loss Current: 11.7854, Validation Loss AVG: 11.7854, lr: 0.001
Epoch [33/100], Training Loss: 4.2129, Validation Loss Current: 12.6811, Validation Loss AVG: 12.6811, lr: 0.001
Epoch [34/100], Training Loss: 3.0053, Validation Loss Current: 13.2020, Validation Loss AVG: 13.2020, lr: 0.001
Epoch [35/100], Training Loss: 4.5136, Validation Loss Current: 14.6905, Validation Loss AVG: 14.6905, lr: 0.001
Epoch [36/100], Training Loss: 4.2320, Validation Loss Current: 14.5964, Validation Loss AVG: 14.5964, lr: 0.001
Epoch [37/100], Training Loss: 2.8592, Validation Loss Current: 12.4062, Validation Loss AVG: 12.4062, lr: 0.001
Epoch [38/100], Training Loss: 6.6281, Validation Loss Current: 15.5577, Validation Loss AVG: 15.5577, lr: 0.001
Epoch [39/100], Training Loss: 12.6758, Validation Loss Current: 13.5599, Validation Loss AVG: 13.5599, lr: 0.001
Epoch [40/100], Training Loss: 4.9783, Validation Loss Current: 11.2978, Validation Loss AVG: 11.2978, lr: 0.001
Epoch [41/100], Training Loss: 3.6015, Validation Loss Current: 11.0310, Validation Loss AVG: 11.0310, lr: 0.001
Epoch [42/100], Training Loss: 2.3306, Validation Loss Current: 12.3112, Validation Loss AVG: 12.3112, lr: 0.001
Epoch [43/100], Training Loss: 1.2619, Validation Loss Current: 11.2661, Validation Loss AVG: 11.2661, lr: 0.001
Epoch [44/100], Training Loss: 1.0123, Validation Loss Current: 11.2164, Validation Loss AVG: 11.2164, lr: 0.001
Epoch [45/100], Training Loss: 1.9976, Validation Loss Current: 12.0449, Validation Loss AVG: 12.0449, lr: 0.001
Epoch [46/100], Training Loss: 4.0174, Validation Loss Current: 12.2908, Validation Loss AVG: 12.2908, lr: 0.001
Epoch [47/100], Training Loss: 4.6698, Validation Loss Current: 13.3847, Validation Loss AVG: 13.3847, lr: 0.001
Epoch [48/100], Training Loss: 4.8285, Validation Loss Current: 11.4825, Validation Loss AVG: 11.4825, lr: 0.001
Epoch [49/100], Training Loss: 3.4808, Validation Loss Current: 11.5986, Validation Loss AVG: 11.5986, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 19 Best val accuracy: [0.40756578947368427, 0.39473684210526316, 0.40131578947368424, 0.39802631578947373, 0.3940789473684211, 0.4016447368421052, 0.4233552631578947, 0.4302631578947368, 0.4447368421052632, 0.4348684210526315, 0.4509868421052632, 0.3990131578947369, 0.4230263157894737, 0.4256578947368421, 0.42105263157894735, 0.3917763157894737, 0.4134868421052632, 0.4414473684210526, 0.44309210526315795, 0.4151315789473684, 0.38355263157894737, 0.3924342105263158, 0.3924342105263158, 0.41743421052631574, 0.4266447368421053, 0.39144736842105265, 0.40164473684210533, 0.3726973684210526, 0.4167763157894737, 0.38618421052631574, 0.3815789473684211, 0.4319078947368421, 0.4411184210526315, 0.40394736842105267, 0.3960526315789473, 0.3901315789473684, 0.4309210526315789, 0.3519736842105263, 0.4200657894736842, 0.44210526315789467, 0.44605263157894737, 0.41184210526315795, 0.44539473684210523, 0.4365131578947368, 0.42269736842105265, 0.41875, 0.40559210526315786, 0.4286184210526316, 0.4302631578947368] Best val loss: 9.91582019329071


Current group: 1
Epoch [1/100], Training Loss: 29.3155, Validation Loss Current: 9.3070, Validation Loss AVG: 11.9075, lr: 0.001
Epoch [2/100], Training Loss: 18.3841, Validation Loss Current: 8.3970, Validation Loss AVG: 11.7606, lr: 0.001
Epoch [3/100], Training Loss: 12.2141, Validation Loss Current: 8.7281, Validation Loss AVG: 13.5393, lr: 0.001
Epoch [4/100], Training Loss: 10.3560, Validation Loss Current: 7.9356, Validation Loss AVG: 10.9911, lr: 0.001
Epoch [5/100], Training Loss: 6.4982, Validation Loss Current: 8.0118, Validation Loss AVG: 10.6883, lr: 0.001
Epoch [6/100], Training Loss: 3.7520, Validation Loss Current: 8.4073, Validation Loss AVG: 11.9836, lr: 0.001
Epoch [7/100], Training Loss: 3.0772, Validation Loss Current: 8.1919, Validation Loss AVG: 14.5502, lr: 0.001
Epoch [8/100], Training Loss: 2.9090, Validation Loss Current: 9.0150, Validation Loss AVG: 11.6929, lr: 0.001
Epoch [9/100], Training Loss: 6.1427, Validation Loss Current: 10.5006, Validation Loss AVG: 12.8455, lr: 0.001
Epoch [10/100], Training Loss: 6.4287, Validation Loss Current: 9.5116, Validation Loss AVG: 17.0596, lr: 0.001
Epoch [11/100], Training Loss: 4.6310, Validation Loss Current: 8.8893, Validation Loss AVG: 11.2369, lr: 0.001
Epoch [12/100], Training Loss: 2.5097, Validation Loss Current: 8.9460, Validation Loss AVG: 12.6290, lr: 0.001
Epoch [13/100], Training Loss: 3.6040, Validation Loss Current: 9.0219, Validation Loss AVG: 11.6564, lr: 0.001
Epoch [14/100], Training Loss: 3.0574, Validation Loss Current: 8.9921, Validation Loss AVG: 11.7907, lr: 0.001
Epoch [15/100], Training Loss: 3.6237, Validation Loss Current: 7.9926, Validation Loss AVG: 11.7049, lr: 0.001
Epoch [16/100], Training Loss: 2.9827, Validation Loss Current: 8.7270, Validation Loss AVG: 11.9616, lr: 0.001
Epoch [17/100], Training Loss: 3.3345, Validation Loss Current: 8.4285, Validation Loss AVG: 12.5132, lr: 0.001
Epoch [18/100], Training Loss: 4.6172, Validation Loss Current: 9.3876, Validation Loss AVG: 15.7124, lr: 0.001
Epoch [19/100], Training Loss: 6.6645, Validation Loss Current: 10.1095, Validation Loss AVG: 15.4680, lr: 0.001
Epoch [20/100], Training Loss: 5.3761, Validation Loss Current: 10.4672, Validation Loss AVG: 12.5353, lr: 0.001
Epoch [21/100], Training Loss: 1.7864, Validation Loss Current: 8.8930, Validation Loss AVG: 13.8388, lr: 0.001
Epoch [22/100], Training Loss: 2.6391, Validation Loss Current: 8.5030, Validation Loss AVG: 12.8255, lr: 0.001
Epoch [23/100], Training Loss: 4.0954, Validation Loss Current: 9.0265, Validation Loss AVG: 13.0366, lr: 0.001
Epoch [24/100], Training Loss: 5.1180, Validation Loss Current: 9.7481, Validation Loss AVG: 12.5659, lr: 0.001
Epoch [25/100], Training Loss: 4.0852, Validation Loss Current: 9.5645, Validation Loss AVG: 15.2097, lr: 0.001
Epoch [26/100], Training Loss: 3.9974, Validation Loss Current: 9.3570, Validation Loss AVG: 12.9114, lr: 0.001
Epoch [27/100], Training Loss: 2.3843, Validation Loss Current: 8.7994, Validation Loss AVG: 13.2828, lr: 0.001
Epoch [28/100], Training Loss: 3.4785, Validation Loss Current: 9.0774, Validation Loss AVG: 13.9360, lr: 0.001
Epoch [29/100], Training Loss: 3.0645, Validation Loss Current: 9.2602, Validation Loss AVG: 12.0312, lr: 0.001
Epoch [30/100], Training Loss: 2.8205, Validation Loss Current: 9.7986, Validation Loss AVG: 13.3430, lr: 0.001
Epoch [31/100], Training Loss: 5.6250, Validation Loss Current: 12.0750, Validation Loss AVG: 17.8642, lr: 0.001
Epoch [32/100], Training Loss: 7.6381, Validation Loss Current: 10.0470, Validation Loss AVG: 12.8429, lr: 0.001
Epoch [33/100], Training Loss: 3.7288, Validation Loss Current: 9.3245, Validation Loss AVG: 12.8340, lr: 0.001
Epoch [34/100], Training Loss: 4.0612, Validation Loss Current: 9.3631, Validation Loss AVG: 13.0135, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 4 Best val accuracy: [0.53125, 0.5526315789473685, 0.5657894736842105, 0.5493421052631579, 0.5707236842105263, 0.5526315789473685, 0.5789473684210527, 0.5707236842105263, 0.5723684210526315, 0.5345394736842105, 0.5608552631578947, 0.5888157894736842, 0.5822368421052632, 0.587171052631579, 0.5805921052631579, 0.5789473684210527, 0.5723684210526315, 0.5526315789473685, 0.5131578947368421, 0.5394736842105263, 0.5822368421052632, 0.5970394736842105, 0.5526315789473685, 0.5427631578947368, 0.5460526315789473, 0.5723684210526315, 0.5608552631578947, 0.569078947368421, 0.5575657894736842, 0.5608552631578947, 0.5180921052631579, 0.569078947368421, 0.5608552631578947, 0.5657894736842105] Best val loss: 7.935583114624023


----- Training resnet18 with sequence: [0.6, 0.8, 1] -----
Current group: 0.6
Epoch [1/134], Training Loss: 41.7413, Validation Loss Current: 10.0705, Validation Loss AVG: 10.0705, lr: 0.001
Epoch [2/134], Training Loss: 39.5752, Validation Loss Current: 9.8560, Validation Loss AVG: 9.8560, lr: 0.001
Epoch [3/134], Training Loss: 38.8440, Validation Loss Current: 9.7325, Validation Loss AVG: 9.7325, lr: 0.001
Epoch [4/134], Training Loss: 36.9931, Validation Loss Current: 9.4559, Validation Loss AVG: 9.4559, lr: 0.001
Epoch [5/134], Training Loss: 36.7217, Validation Loss Current: 9.4443, Validation Loss AVG: 9.4443, lr: 0.001
Epoch [6/134], Training Loss: 35.3858, Validation Loss Current: 9.3392, Validation Loss AVG: 9.3392, lr: 0.001
Epoch [7/134], Training Loss: 34.9654, Validation Loss Current: 9.0706, Validation Loss AVG: 9.0706, lr: 0.001
Epoch [8/134], Training Loss: 32.9788, Validation Loss Current: 8.9436, Validation Loss AVG: 8.9436, lr: 0.001
Epoch [9/134], Training Loss: 32.1820, Validation Loss Current: 8.7732, Validation Loss AVG: 8.7732, lr: 0.001
Epoch [10/134], Training Loss: 30.5794, Validation Loss Current: 8.7226, Validation Loss AVG: 8.7226, lr: 0.001
Epoch [11/134], Training Loss: 29.1960, Validation Loss Current: 8.9318, Validation Loss AVG: 8.9318, lr: 0.001
Epoch [12/134], Training Loss: 28.6876, Validation Loss Current: 8.6855, Validation Loss AVG: 8.6855, lr: 0.001
Epoch [13/134], Training Loss: 27.6092, Validation Loss Current: 8.2325, Validation Loss AVG: 8.2325, lr: 0.001
Epoch [14/134], Training Loss: 27.2474, Validation Loss Current: 9.2567, Validation Loss AVG: 9.2567, lr: 0.001
Epoch [15/134], Training Loss: 29.1960, Validation Loss Current: 8.2989, Validation Loss AVG: 8.2989, lr: 0.001
Epoch [16/134], Training Loss: 28.9427, Validation Loss Current: 8.8148, Validation Loss AVG: 8.8148, lr: 0.001
Epoch [17/134], Training Loss: 28.2738, Validation Loss Current: 8.5949, Validation Loss AVG: 8.5949, lr: 0.001
Epoch [18/134], Training Loss: 25.8804, Validation Loss Current: 8.1057, Validation Loss AVG: 8.1057, lr: 0.001
Epoch [19/134], Training Loss: 25.0293, Validation Loss Current: 7.9658, Validation Loss AVG: 7.9658, lr: 0.001
Epoch [20/134], Training Loss: 23.5063, Validation Loss Current: 7.9405, Validation Loss AVG: 7.9405, lr: 0.001
Epoch [21/134], Training Loss: 22.1687, Validation Loss Current: 7.9702, Validation Loss AVG: 7.9702, lr: 0.001
Epoch [22/134], Training Loss: 22.8617, Validation Loss Current: 8.0737, Validation Loss AVG: 8.0737, lr: 0.001
Epoch [23/134], Training Loss: 22.9331, Validation Loss Current: 8.8956, Validation Loss AVG: 8.8956, lr: 0.001
Epoch [24/134], Training Loss: 22.2119, Validation Loss Current: 8.2022, Validation Loss AVG: 8.2022, lr: 0.001
Epoch [25/134], Training Loss: 20.3281, Validation Loss Current: 7.8805, Validation Loss AVG: 7.8805, lr: 0.001
Epoch [26/134], Training Loss: 18.1179, Validation Loss Current: 7.7250, Validation Loss AVG: 7.7250, lr: 0.001
Epoch [27/134], Training Loss: 17.8333, Validation Loss Current: 8.6936, Validation Loss AVG: 8.6936, lr: 0.001
Epoch [28/134], Training Loss: 17.8407, Validation Loss Current: 8.7918, Validation Loss AVG: 8.7918, lr: 0.001
Epoch [29/134], Training Loss: 16.2022, Validation Loss Current: 8.0465, Validation Loss AVG: 8.0465, lr: 0.001
Epoch [30/134], Training Loss: 15.4047, Validation Loss Current: 7.9516, Validation Loss AVG: 7.9516, lr: 0.001
Epoch [31/134], Training Loss: 14.6039, Validation Loss Current: 8.1941, Validation Loss AVG: 8.1941, lr: 0.001
Epoch [32/134], Training Loss: 13.7471, Validation Loss Current: 8.2171, Validation Loss AVG: 8.2171, lr: 0.001
Epoch [33/134], Training Loss: 13.2858, Validation Loss Current: 8.0585, Validation Loss AVG: 8.0585, lr: 0.001
Epoch [34/134], Training Loss: 11.6000, Validation Loss Current: 9.0571, Validation Loss AVG: 9.0571, lr: 0.001
Epoch [35/134], Training Loss: 11.4256, Validation Loss Current: 9.1881, Validation Loss AVG: 9.1881, lr: 0.001
Epoch [36/134], Training Loss: 11.0022, Validation Loss Current: 8.5540, Validation Loss AVG: 8.5540, lr: 0.001
Epoch [37/134], Training Loss: 9.3177, Validation Loss Current: 9.6817, Validation Loss AVG: 9.6817, lr: 0.001
Epoch [38/134], Training Loss: 10.9862, Validation Loss Current: 10.4517, Validation Loss AVG: 10.4517, lr: 0.001
Epoch [39/134], Training Loss: 9.1303, Validation Loss Current: 8.4182, Validation Loss AVG: 8.4182, lr: 0.001
Epoch [40/134], Training Loss: 8.4414, Validation Loss Current: 8.8991, Validation Loss AVG: 8.8991, lr: 0.001
Epoch [41/134], Training Loss: 8.0614, Validation Loss Current: 10.0292, Validation Loss AVG: 10.0292, lr: 0.001
Epoch [42/134], Training Loss: 8.6581, Validation Loss Current: 9.7622, Validation Loss AVG: 9.7622, lr: 0.001
Epoch [43/134], Training Loss: 7.0022, Validation Loss Current: 10.3578, Validation Loss AVG: 10.3578, lr: 0.001
Epoch [44/134], Training Loss: 7.0049, Validation Loss Current: 9.1517, Validation Loss AVG: 9.1517, lr: 0.001
Epoch [45/134], Training Loss: 5.8814, Validation Loss Current: 9.3498, Validation Loss AVG: 9.3498, lr: 0.001
Epoch [46/134], Training Loss: 6.3174, Validation Loss Current: 10.0130, Validation Loss AVG: 10.0130, lr: 0.001
Epoch [47/134], Training Loss: 6.2708, Validation Loss Current: 10.4888, Validation Loss AVG: 10.4888, lr: 0.001
Epoch [48/134], Training Loss: 7.7352, Validation Loss Current: 12.5363, Validation Loss AVG: 12.5363, lr: 0.001
Epoch [49/134], Training Loss: 7.0926, Validation Loss Current: 9.5101, Validation Loss AVG: 9.5101, lr: 0.001
Epoch [50/134], Training Loss: 8.5037, Validation Loss Current: 14.1582, Validation Loss AVG: 14.1582, lr: 0.001
Epoch [51/134], Training Loss: 10.1186, Validation Loss Current: 10.8591, Validation Loss AVG: 10.8591, lr: 0.001
Epoch [52/134], Training Loss: 11.3062, Validation Loss Current: 12.5829, Validation Loss AVG: 12.5829, lr: 0.001
Epoch [53/134], Training Loss: 7.4292, Validation Loss Current: 13.6214, Validation Loss AVG: 13.6214, lr: 0.001
Epoch [54/134], Training Loss: 8.9060, Validation Loss Current: 10.3744, Validation Loss AVG: 10.3744, lr: 0.001
Epoch [55/134], Training Loss: 7.8539, Validation Loss Current: 13.3327, Validation Loss AVG: 13.3327, lr: 0.001
Epoch [56/134], Training Loss: 7.6226, Validation Loss Current: 12.2750, Validation Loss AVG: 12.2750, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 26 Best val accuracy: [0.24309210526315791, 0.2542763157894737, 0.26809210526315785, 0.3052631578947368, 0.3111842105263158, 0.30296052631578946, 0.3480263157894737, 0.3424342105263158, 0.37072368421052626, 0.38782894736842105, 0.3539473684210526, 0.3924342105263158, 0.42467105263157895, 0.3638157894736842, 0.40328947368421053, 0.38092105263157894, 0.3911184210526316, 0.4365131578947368, 0.44769736842105257, 0.4496710526315789, 0.4394736842105263, 0.4319078947368421, 0.4131578947368421, 0.43717105263157896, 0.44769736842105257, 0.45855263157894743, 0.43684210526315786, 0.4171052631578947, 0.44703947368421054, 0.4549342105263158, 0.4532894736842105, 0.4440789473684211, 0.4519736842105263, 0.4447368421052631, 0.419078947368421, 0.48157894736842105, 0.40328947368421053, 0.40197368421052626, 0.4588815789473684, 0.4427631578947369, 0.42894736842105263, 0.4072368421052632, 0.3983552631578947, 0.4526315789473684, 0.43782894736842104, 0.4447368421052632, 0.42960526315789477, 0.34572368421052635, 0.4391447368421053, 0.3697368421052632, 0.40657894736842104, 0.34342105263157896, 0.3875, 0.4, 0.39210526315789473, 0.3940789473684211] Best val loss: 7.725037384033203


Current group: 0.8
Epoch [1/134], Training Loss: 25.5925, Validation Loss Current: 10.5801, Validation Loss AVG: 10.5801, lr: 0.001
Epoch [2/134], Training Loss: 22.3893, Validation Loss Current: 10.4600, Validation Loss AVG: 10.4600, lr: 0.001
Epoch [3/134], Training Loss: 17.1226, Validation Loss Current: 11.6023, Validation Loss AVG: 11.6023, lr: 0.001
Epoch [4/134], Training Loss: 14.7558, Validation Loss Current: 8.8196, Validation Loss AVG: 8.8196, lr: 0.001
Epoch [5/134], Training Loss: 13.1032, Validation Loss Current: 8.3805, Validation Loss AVG: 8.3805, lr: 0.001
Epoch [6/134], Training Loss: 11.1213, Validation Loss Current: 9.4725, Validation Loss AVG: 9.4725, lr: 0.001
Epoch [7/134], Training Loss: 8.5441, Validation Loss Current: 9.1527, Validation Loss AVG: 9.1527, lr: 0.001
Epoch [8/134], Training Loss: 8.1600, Validation Loss Current: 9.7219, Validation Loss AVG: 9.7219, lr: 0.001
Epoch [9/134], Training Loss: 8.8849, Validation Loss Current: 12.9618, Validation Loss AVG: 12.9618, lr: 0.001
Epoch [10/134], Training Loss: 6.8805, Validation Loss Current: 10.5708, Validation Loss AVG: 10.5708, lr: 0.001
Epoch [11/134], Training Loss: 5.7230, Validation Loss Current: 10.5972, Validation Loss AVG: 10.5972, lr: 0.001
Epoch [12/134], Training Loss: 8.1933, Validation Loss Current: 9.5894, Validation Loss AVG: 9.5894, lr: 0.001
Epoch [13/134], Training Loss: 6.3632, Validation Loss Current: 10.7281, Validation Loss AVG: 10.7281, lr: 0.001
Epoch [14/134], Training Loss: 12.5651, Validation Loss Current: 10.8606, Validation Loss AVG: 10.8606, lr: 0.001
Epoch [15/134], Training Loss: 13.2825, Validation Loss Current: 13.0381, Validation Loss AVG: 13.0381, lr: 0.001
Epoch [16/134], Training Loss: 8.8582, Validation Loss Current: 10.0586, Validation Loss AVG: 10.0586, lr: 0.001
Epoch [17/134], Training Loss: 6.8464, Validation Loss Current: 10.7387, Validation Loss AVG: 10.7387, lr: 0.001
Epoch [18/134], Training Loss: 8.0385, Validation Loss Current: 11.5625, Validation Loss AVG: 11.5625, lr: 0.001
Epoch [19/134], Training Loss: 5.5711, Validation Loss Current: 10.2877, Validation Loss AVG: 10.2877, lr: 0.001
Epoch [20/134], Training Loss: 7.6459, Validation Loss Current: 11.7604, Validation Loss AVG: 11.7604, lr: 0.001
Epoch [21/134], Training Loss: 4.4046, Validation Loss Current: 11.3950, Validation Loss AVG: 11.3950, lr: 0.001
Epoch [22/134], Training Loss: 4.7818, Validation Loss Current: 10.3302, Validation Loss AVG: 10.3302, lr: 0.001
Epoch [23/134], Training Loss: 6.1250, Validation Loss Current: 11.4137, Validation Loss AVG: 11.4137, lr: 0.001
Epoch [24/134], Training Loss: 7.9020, Validation Loss Current: 10.6503, Validation Loss AVG: 10.6503, lr: 0.001
Epoch [25/134], Training Loss: 7.3376, Validation Loss Current: 9.9252, Validation Loss AVG: 9.9252, lr: 0.001
Epoch [26/134], Training Loss: 5.1613, Validation Loss Current: 11.2235, Validation Loss AVG: 11.2235, lr: 0.001
Epoch [27/134], Training Loss: 3.4242, Validation Loss Current: 10.7901, Validation Loss AVG: 10.7901, lr: 0.001
Epoch [28/134], Training Loss: 4.4960, Validation Loss Current: 12.1587, Validation Loss AVG: 12.1587, lr: 0.001
Epoch [29/134], Training Loss: 5.5683, Validation Loss Current: 11.4972, Validation Loss AVG: 11.4972, lr: 0.001
Epoch [30/134], Training Loss: 9.3811, Validation Loss Current: 11.7489, Validation Loss AVG: 11.7489, lr: 0.001
Epoch [31/134], Training Loss: 3.9794, Validation Loss Current: 11.3384, Validation Loss AVG: 11.3384, lr: 0.001
Epoch [32/134], Training Loss: 2.7502, Validation Loss Current: 10.4015, Validation Loss AVG: 10.4015, lr: 0.001
Epoch [33/134], Training Loss: 1.4688, Validation Loss Current: 9.9542, Validation Loss AVG: 9.9542, lr: 0.001
Epoch [34/134], Training Loss: 1.9794, Validation Loss Current: 10.3772, Validation Loss AVG: 10.3772, lr: 0.001
Epoch [35/134], Training Loss: 3.7783, Validation Loss Current: 12.1825, Validation Loss AVG: 12.1825, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 5 Best val accuracy: [0.3996710526315789, 0.43717105263157896, 0.3924342105263158, 0.4740131578947368, 0.44868421052631574, 0.44703947368421054, 0.47006578947368427, 0.42631578947368426, 0.42105263157894746, 0.4358552631578948, 0.4273026315789473, 0.44703947368421054, 0.43289473684210533, 0.41052631578947374, 0.38190789473684206, 0.42302631578947364, 0.4516447368421052, 0.42269736842105265, 0.4286184210526316, 0.4220394736842105, 0.4213815789473684, 0.47796052631578945, 0.39835526315789477, 0.4542763157894737, 0.44572368421052627, 0.4618421052631579, 0.4529605263157895, 0.43486842105263157, 0.4319078947368421, 0.39769736842105263, 0.46480263157894736, 0.43125, 0.4838815789473684, 0.4565789473684211, 0.425] Best val loss: 8.38053662776947


Current group: 1
Epoch [1/134], Training Loss: 21.8037, Validation Loss Current: 8.0394, Validation Loss AVG: 9.5306, lr: 0.001
Epoch [2/134], Training Loss: 17.3165, Validation Loss Current: 7.9995, Validation Loss AVG: 12.4835, lr: 0.001
Epoch [3/134], Training Loss: 12.2588, Validation Loss Current: 7.1844, Validation Loss AVG: 10.0231, lr: 0.001
Epoch [4/134], Training Loss: 8.0146, Validation Loss Current: 6.8218, Validation Loss AVG: 11.0189, lr: 0.001
Epoch [5/134], Training Loss: 5.8227, Validation Loss Current: 7.2295, Validation Loss AVG: 12.9529, lr: 0.001
Epoch [6/134], Training Loss: 5.4802, Validation Loss Current: 7.2413, Validation Loss AVG: 11.9219, lr: 0.001
Epoch [7/134], Training Loss: 7.5698, Validation Loss Current: 7.2994, Validation Loss AVG: 11.8790, lr: 0.001
Epoch [8/134], Training Loss: 8.7975, Validation Loss Current: 7.0991, Validation Loss AVG: 11.8920, lr: 0.001
Epoch [9/134], Training Loss: 10.3642, Validation Loss Current: 8.7445, Validation Loss AVG: 12.1635, lr: 0.001
Epoch [10/134], Training Loss: 6.0471, Validation Loss Current: 7.3773, Validation Loss AVG: 14.9065, lr: 0.001
Epoch [11/134], Training Loss: 5.2771, Validation Loss Current: 8.4169, Validation Loss AVG: 11.9229, lr: 0.001
Epoch [12/134], Training Loss: 5.9364, Validation Loss Current: 8.1035, Validation Loss AVG: 12.4634, lr: 0.001
Epoch [13/134], Training Loss: 4.4570, Validation Loss Current: 7.7233, Validation Loss AVG: 13.4622, lr: 0.001
Epoch [14/134], Training Loss: 4.4855, Validation Loss Current: 9.9313, Validation Loss AVG: 12.3550, lr: 0.001
Epoch [15/134], Training Loss: 6.7790, Validation Loss Current: 8.6872, Validation Loss AVG: 15.9215, lr: 0.001
Epoch [16/134], Training Loss: 4.8945, Validation Loss Current: 7.8508, Validation Loss AVG: 13.0423, lr: 0.001
Epoch [17/134], Training Loss: 5.7040, Validation Loss Current: 8.6945, Validation Loss AVG: 12.6535, lr: 0.001
Epoch [18/134], Training Loss: 3.7323, Validation Loss Current: 8.6757, Validation Loss AVG: 12.9185, lr: 0.001
Epoch [19/134], Training Loss: 4.2245, Validation Loss Current: 8.2735, Validation Loss AVG: 12.5031, lr: 0.001
Epoch [20/134], Training Loss: 7.1356, Validation Loss Current: 9.1224, Validation Loss AVG: 12.8217, lr: 0.001
Epoch [21/134], Training Loss: 6.6476, Validation Loss Current: 8.9463, Validation Loss AVG: 15.7225, lr: 0.001
Epoch [22/134], Training Loss: 2.4011, Validation Loss Current: 7.7208, Validation Loss AVG: 11.8663, lr: 0.001
Epoch [23/134], Training Loss: 1.5525, Validation Loss Current: 7.8354, Validation Loss AVG: 12.6019, lr: 0.001
Epoch [24/134], Training Loss: 1.9670, Validation Loss Current: 7.6573, Validation Loss AVG: 12.2576, lr: 0.001
Epoch [25/134], Training Loss: 2.7772, Validation Loss Current: 7.8325, Validation Loss AVG: 14.7419, lr: 0.001
Epoch [26/134], Training Loss: 3.7828, Validation Loss Current: 8.2230, Validation Loss AVG: 12.5143, lr: 0.001
Epoch [27/134], Training Loss: 4.3719, Validation Loss Current: 8.2324, Validation Loss AVG: 13.4478, lr: 0.001
Epoch [28/134], Training Loss: 3.6225, Validation Loss Current: 8.6825, Validation Loss AVG: 13.9645, lr: 0.001
Epoch [29/134], Training Loss: 3.3652, Validation Loss Current: 9.5183, Validation Loss AVG: 17.4836, lr: 0.001
Epoch [30/134], Training Loss: 3.2719, Validation Loss Current: 7.8811, Validation Loss AVG: 16.3316, lr: 0.001
Epoch [31/134], Training Loss: 2.5627, Validation Loss Current: 7.3168, Validation Loss AVG: 13.7561, lr: 0.001
Epoch [32/134], Training Loss: 1.7807, Validation Loss Current: 7.6803, Validation Loss AVG: 13.4534, lr: 0.001
Epoch [33/134], Training Loss: 3.4147, Validation Loss Current: 11.9731, Validation Loss AVG: 15.2424, lr: 0.001
Epoch [34/134], Training Loss: 11.4161, Validation Loss Current: 13.4176, Validation Loss AVG: 25.1075, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 4 Best val accuracy: [0.5115131578947368, 0.5542763157894737, 0.5575657894736842, 0.5953947368421053, 0.5756578947368421, 0.5773026315789473, 0.5904605263157895, 0.5838815789473685, 0.53125, 0.59375, 0.5674342105263158, 0.5805921052631579, 0.5542763157894737, 0.5526315789473685, 0.53125, 0.5707236842105263, 0.5789473684210527, 0.5855263157894737, 0.5542763157894737, 0.5328947368421053, 0.555921052631579, 0.5773026315789473, 0.5789473684210527, 0.587171052631579, 0.5888157894736842, 0.5526315789473685, 0.5904605263157895, 0.5625, 0.5789473684210527, 0.5904605263157895, 0.6036184210526315, 0.6200657894736842, 0.5180921052631579, 0.4506578947368421] Best val loss: 6.821823716163635


----- Training resnet18 with sequence: [0.8, 1] -----
Current group: 0.8
Epoch [1/200], Training Loss: 40.2086, Validation Loss Current: 9.9489, Validation Loss AVG: 9.9489, lr: 0.001
Epoch [2/200], Training Loss: 38.7936, Validation Loss Current: 9.9615, Validation Loss AVG: 9.9615, lr: 0.001
Epoch [3/200], Training Loss: 37.7050, Validation Loss Current: 9.6122, Validation Loss AVG: 9.6122, lr: 0.001
Epoch [4/200], Training Loss: 36.5934, Validation Loss Current: 9.5154, Validation Loss AVG: 9.5154, lr: 0.001
Epoch [5/200], Training Loss: 34.9694, Validation Loss Current: 9.7211, Validation Loss AVG: 9.7211, lr: 0.001
Epoch [6/200], Training Loss: 34.7774, Validation Loss Current: 9.3429, Validation Loss AVG: 9.3429, lr: 0.001
Epoch [7/200], Training Loss: 33.6470, Validation Loss Current: 8.9333, Validation Loss AVG: 8.9333, lr: 0.001
Epoch [8/200], Training Loss: 31.6625, Validation Loss Current: 9.3799, Validation Loss AVG: 9.3799, lr: 0.001
Epoch [9/200], Training Loss: 31.0650, Validation Loss Current: 8.6081, Validation Loss AVG: 8.6081, lr: 0.001
Epoch [10/200], Training Loss: 29.9334, Validation Loss Current: 10.1212, Validation Loss AVG: 10.1212, lr: 0.001
Epoch [11/200], Training Loss: 29.1664, Validation Loss Current: 8.6412, Validation Loss AVG: 8.6412, lr: 0.001
Epoch [12/200], Training Loss: 29.3643, Validation Loss Current: 8.9030, Validation Loss AVG: 8.9030, lr: 0.001
Epoch [13/200], Training Loss: 27.9970, Validation Loss Current: 8.8035, Validation Loss AVG: 8.8035, lr: 0.001
Epoch [14/200], Training Loss: 26.6066, Validation Loss Current: 8.7372, Validation Loss AVG: 8.7372, lr: 0.001
Epoch [15/200], Training Loss: 28.0479, Validation Loss Current: 8.5519, Validation Loss AVG: 8.5519, lr: 0.001
Epoch [16/200], Training Loss: 27.9447, Validation Loss Current: 8.6257, Validation Loss AVG: 8.6257, lr: 0.001
Epoch [17/200], Training Loss: 26.3244, Validation Loss Current: 8.2351, Validation Loss AVG: 8.2351, lr: 0.001
Epoch [18/200], Training Loss: 24.8738, Validation Loss Current: 8.4432, Validation Loss AVG: 8.4432, lr: 0.001
Epoch [19/200], Training Loss: 24.0721, Validation Loss Current: 8.4187, Validation Loss AVG: 8.4187, lr: 0.001
Epoch [20/200], Training Loss: 23.7992, Validation Loss Current: 9.3179, Validation Loss AVG: 9.3179, lr: 0.001
Epoch [21/200], Training Loss: 21.4942, Validation Loss Current: 8.0450, Validation Loss AVG: 8.0450, lr: 0.001
Epoch [22/200], Training Loss: 21.1889, Validation Loss Current: 8.6800, Validation Loss AVG: 8.6800, lr: 0.001
Epoch [23/200], Training Loss: 20.4860, Validation Loss Current: 7.8181, Validation Loss AVG: 7.8181, lr: 0.001
Epoch [24/200], Training Loss: 20.3997, Validation Loss Current: 9.1739, Validation Loss AVG: 9.1739, lr: 0.001
Epoch [25/200], Training Loss: 18.8279, Validation Loss Current: 8.5024, Validation Loss AVG: 8.5024, lr: 0.001
Epoch [26/200], Training Loss: 18.4901, Validation Loss Current: 8.6141, Validation Loss AVG: 8.6141, lr: 0.001
Epoch [27/200], Training Loss: 17.9607, Validation Loss Current: 9.5546, Validation Loss AVG: 9.5546, lr: 0.001
Epoch [28/200], Training Loss: 16.6661, Validation Loss Current: 8.4618, Validation Loss AVG: 8.4618, lr: 0.001
Epoch [29/200], Training Loss: 16.2595, Validation Loss Current: 8.2180, Validation Loss AVG: 8.2180, lr: 0.001
Epoch [30/200], Training Loss: 15.4691, Validation Loss Current: 8.3160, Validation Loss AVG: 8.3160, lr: 0.001
Epoch [31/200], Training Loss: 17.7302, Validation Loss Current: 8.7629, Validation Loss AVG: 8.7629, lr: 0.001
Epoch [32/200], Training Loss: 16.8628, Validation Loss Current: 8.5983, Validation Loss AVG: 8.5983, lr: 0.001
Epoch [33/200], Training Loss: 15.5595, Validation Loss Current: 10.2067, Validation Loss AVG: 10.2067, lr: 0.001
Epoch [34/200], Training Loss: 14.8702, Validation Loss Current: 10.2780, Validation Loss AVG: 10.2780, lr: 0.001
Epoch [35/200], Training Loss: 13.8294, Validation Loss Current: 8.3727, Validation Loss AVG: 8.3727, lr: 0.001
Epoch [36/200], Training Loss: 11.4944, Validation Loss Current: 8.5650, Validation Loss AVG: 8.5650, lr: 0.001
Epoch [37/200], Training Loss: 12.0119, Validation Loss Current: 9.2244, Validation Loss AVG: 9.2244, lr: 0.001
Epoch [38/200], Training Loss: 10.5509, Validation Loss Current: 10.1342, Validation Loss AVG: 10.1342, lr: 0.001
Epoch [39/200], Training Loss: 12.8397, Validation Loss Current: 8.9623, Validation Loss AVG: 8.9623, lr: 0.001
Epoch [40/200], Training Loss: 10.2553, Validation Loss Current: 9.3400, Validation Loss AVG: 9.3400, lr: 0.001
Epoch [41/200], Training Loss: 8.1022, Validation Loss Current: 9.9140, Validation Loss AVG: 9.9140, lr: 0.001
Epoch [42/200], Training Loss: 9.2974, Validation Loss Current: 8.1620, Validation Loss AVG: 8.1620, lr: 0.001
Epoch [43/200], Training Loss: 7.8474, Validation Loss Current: 9.0554, Validation Loss AVG: 9.0554, lr: 0.001
Epoch [44/200], Training Loss: 7.1414, Validation Loss Current: 9.1691, Validation Loss AVG: 9.1691, lr: 0.001
Epoch [45/200], Training Loss: 7.0451, Validation Loss Current: 11.6945, Validation Loss AVG: 11.6945, lr: 0.001
Epoch [46/200], Training Loss: 5.9456, Validation Loss Current: 9.6434, Validation Loss AVG: 9.6434, lr: 0.001
Epoch [47/200], Training Loss: 4.9723, Validation Loss Current: 9.0417, Validation Loss AVG: 9.0417, lr: 0.001
Epoch [48/200], Training Loss: 4.5956, Validation Loss Current: 9.8270, Validation Loss AVG: 9.8270, lr: 0.001
Epoch [49/200], Training Loss: 5.8787, Validation Loss Current: 14.1408, Validation Loss AVG: 14.1408, lr: 0.001
Epoch [50/200], Training Loss: 5.0650, Validation Loss Current: 13.5429, Validation Loss AVG: 13.5429, lr: 0.001
Epoch [51/200], Training Loss: 10.4993, Validation Loss Current: 13.5410, Validation Loss AVG: 13.5410, lr: 0.001
Epoch [52/200], Training Loss: 9.2014, Validation Loss Current: 10.7490, Validation Loss AVG: 10.7490, lr: 0.001
Epoch [53/200], Training Loss: 6.6793, Validation Loss Current: 11.8537, Validation Loss AVG: 11.8537, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 23 Best val accuracy: [0.2539473684210526, 0.25427631578947374, 0.2934210526315789, 0.31513157894736843, 0.31381578947368427, 0.3490131578947368, 0.3615131578947368, 0.34572368421052635, 0.40657894736842104, 0.3503289473684211, 0.39868421052631586, 0.3582236842105263, 0.40328947368421053, 0.3694078947368421, 0.39539473684210524, 0.4269736842105264, 0.41743421052631574, 0.4266447368421053, 0.45427631578947364, 0.40657894736842104, 0.4440789473684211, 0.4391447368421052, 0.4526315789473684, 0.42927631578947373, 0.46907894736842104, 0.45263157894736833, 0.4476973684210527, 0.4865131578947368, 0.4638157894736842, 0.4598684210526316, 0.43256578947368424, 0.47105263157894733, 0.4046052631578947, 0.4585526315789473, 0.48256578947368417, 0.44506578947368425, 0.45756578947368426, 0.46447368421052626, 0.39703947368421055, 0.45756578947368426, 0.4473684210526316, 0.46940789473684214, 0.45394736842105265, 0.4842105263157895, 0.4029605263157895, 0.43815789473684214, 0.44605263157894737, 0.45065789473684215, 0.4006578947368421, 0.33026315789473687, 0.3509868421052632, 0.4184210526315789, 0.39703947368421055] Best val loss: 7.818147325515747


Current group: 1
Epoch [1/200], Training Loss: 20.3829, Validation Loss Current: 7.4894, Validation Loss AVG: 10.7425, lr: 0.001
Epoch [2/200], Training Loss: 18.7508, Validation Loss Current: 8.4361, Validation Loss AVG: 16.4085, lr: 0.001
Epoch [3/200], Training Loss: 16.8814, Validation Loss Current: 7.3478, Validation Loss AVG: 16.7099, lr: 0.001
Epoch [4/200], Training Loss: 15.8151, Validation Loss Current: 7.1929, Validation Loss AVG: 11.9213, lr: 0.001
Epoch [5/200], Training Loss: 12.7656, Validation Loss Current: 6.9008, Validation Loss AVG: 11.5250, lr: 0.001
Epoch [6/200], Training Loss: 11.8653, Validation Loss Current: 6.7767, Validation Loss AVG: 14.1924, lr: 0.001
Epoch [7/200], Training Loss: 8.8983, Validation Loss Current: 6.5070, Validation Loss AVG: 10.7990, lr: 0.001
Epoch [8/200], Training Loss: 8.3789, Validation Loss Current: 7.2115, Validation Loss AVG: 10.7481, lr: 0.001
Epoch [9/200], Training Loss: 8.6492, Validation Loss Current: 7.0763, Validation Loss AVG: 14.5217, lr: 0.001
Epoch [10/200], Training Loss: 6.4598, Validation Loss Current: 6.5174, Validation Loss AVG: 11.3634, lr: 0.001
Epoch [11/200], Training Loss: 10.3318, Validation Loss Current: 6.6823, Validation Loss AVG: 9.7329, lr: 0.001
Epoch [12/200], Training Loss: 5.8949, Validation Loss Current: 6.9719, Validation Loss AVG: 11.7948, lr: 0.001
Epoch [13/200], Training Loss: 5.2529, Validation Loss Current: 6.1891, Validation Loss AVG: 10.3746, lr: 0.001
Epoch [14/200], Training Loss: 5.6068, Validation Loss Current: 6.5472, Validation Loss AVG: 11.1987, lr: 0.001
Epoch [15/200], Training Loss: 5.7395, Validation Loss Current: 7.2159, Validation Loss AVG: 11.4915, lr: 0.001
Epoch [16/200], Training Loss: 9.5391, Validation Loss Current: 9.9395, Validation Loss AVG: 16.7490, lr: 0.001
Epoch [17/200], Training Loss: 11.8683, Validation Loss Current: 8.0188, Validation Loss AVG: 14.9382, lr: 0.001
Epoch [18/200], Training Loss: 8.9483, Validation Loss Current: 7.1687, Validation Loss AVG: 10.5677, lr: 0.001
Epoch [19/200], Training Loss: 7.6949, Validation Loss Current: 7.0197, Validation Loss AVG: 12.9796, lr: 0.001
Epoch [20/200], Training Loss: 7.7476, Validation Loss Current: 7.2100, Validation Loss AVG: 11.3454, lr: 0.001
Epoch [21/200], Training Loss: 4.3698, Validation Loss Current: 6.6754, Validation Loss AVG: 10.7227, lr: 0.001
Epoch [22/200], Training Loss: 5.2701, Validation Loss Current: 6.6085, Validation Loss AVG: 10.1454, lr: 0.001
Epoch [23/200], Training Loss: 3.7181, Validation Loss Current: 6.5796, Validation Loss AVG: 11.7951, lr: 0.001
Epoch [24/200], Training Loss: 6.4732, Validation Loss Current: 7.0690, Validation Loss AVG: 12.7244, lr: 0.001
Epoch [25/200], Training Loss: 5.6401, Validation Loss Current: 6.8020, Validation Loss AVG: 15.7647, lr: 0.001
Epoch [26/200], Training Loss: 5.4750, Validation Loss Current: 7.4999, Validation Loss AVG: 11.0679, lr: 0.001
Epoch [27/200], Training Loss: 5.3363, Validation Loss Current: 7.1341, Validation Loss AVG: 11.8333, lr: 0.001
Epoch [28/200], Training Loss: 4.5270, Validation Loss Current: 7.5916, Validation Loss AVG: 15.0307, lr: 0.001
Epoch [29/200], Training Loss: 4.5727, Validation Loss Current: 8.0397, Validation Loss AVG: 11.4668, lr: 0.001
Epoch [30/200], Training Loss: 5.1370, Validation Loss Current: 7.3297, Validation Loss AVG: 13.4601, lr: 0.001
Epoch [31/200], Training Loss: 4.6558, Validation Loss Current: 7.5705, Validation Loss AVG: 13.5049, lr: 0.001
Epoch [32/200], Training Loss: 3.7982, Validation Loss Current: 7.5776, Validation Loss AVG: 12.7673, lr: 0.001
Epoch [33/200], Training Loss: 2.7618, Validation Loss Current: 7.3386, Validation Loss AVG: 11.6577, lr: 0.001
Epoch [34/200], Training Loss: 2.5338, Validation Loss Current: 7.0753, Validation Loss AVG: 11.9484, lr: 0.001
Epoch [35/200], Training Loss: 2.1064, Validation Loss Current: 8.3743, Validation Loss AVG: 13.8839, lr: 0.001
Epoch [36/200], Training Loss: 1.0643, Validation Loss Current: 6.9270, Validation Loss AVG: 13.6679, lr: 0.001
Epoch [37/200], Training Loss: 0.7664, Validation Loss Current: 7.2047, Validation Loss AVG: 13.1179, lr: 0.001
Epoch [38/200], Training Loss: 2.1569, Validation Loss Current: 8.0613, Validation Loss AVG: 15.3838, lr: 0.001
Epoch [39/200], Training Loss: 4.8480, Validation Loss Current: 7.9043, Validation Loss AVG: 14.1065, lr: 0.001
Epoch [40/200], Training Loss: 3.4460, Validation Loss Current: 7.2436, Validation Loss AVG: 14.6340, lr: 0.001
Epoch [41/200], Training Loss: 2.6870, Validation Loss Current: 7.8413, Validation Loss AVG: 17.9486, lr: 0.001
Epoch [42/200], Training Loss: 3.4801, Validation Loss Current: 8.1485, Validation Loss AVG: 12.0752, lr: 0.001
Epoch [43/200], Training Loss: 4.3350, Validation Loss Current: 7.8414, Validation Loss AVG: 14.5185, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 13 Best val accuracy: [0.5723684210526315, 0.53125, 0.5296052631578947, 0.5493421052631579, 0.5328947368421053, 0.5855263157894737, 0.5904605263157895, 0.5740131578947368, 0.59375, 0.5904605263157895, 0.59375, 0.6085526315789473, 0.6036184210526315, 0.6233552631578947, 0.5805921052631579, 0.4868421052631579, 0.5476973684210527, 0.5707236842105263, 0.6085526315789473, 0.5575657894736842, 0.6167763157894737, 0.6217105263157895, 0.6151315789473685, 0.600328947368421, 0.6200657894736842, 0.600328947368421, 0.6118421052631579, 0.5838815789473685, 0.5904605263157895, 0.5888157894736842, 0.6036184210526315, 0.6101973684210527, 0.6217105263157895, 0.5822368421052632, 0.569078947368421, 0.6381578947368421, 0.631578947368421, 0.5756578947368421, 0.6085526315789473, 0.5904605263157895, 0.6036184210526315, 0.5822368421052632, 0.5888157894736842] Best val loss: 6.189092218875885


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 41.2344, Validation Loss Current: 9.9125, Validation Loss AVG: 9.9767, lr: 0.001
Epoch [2/400], Training Loss: 38.3874, Validation Loss Current: 9.5310, Validation Loss AVG: 9.8867, lr: 0.001
Epoch [3/400], Training Loss: 38.3974, Validation Loss Current: 9.2570, Validation Loss AVG: 10.1623, lr: 0.001
Epoch [4/400], Training Loss: 35.9772, Validation Loss Current: 8.9661, Validation Loss AVG: 9.7543, lr: 0.001
Epoch [5/400], Training Loss: 34.7339, Validation Loss Current: 8.4915, Validation Loss AVG: 9.2360, lr: 0.001
Epoch [6/400], Training Loss: 32.4370, Validation Loss Current: 8.3347, Validation Loss AVG: 9.2549, lr: 0.001
Epoch [7/400], Training Loss: 33.4482, Validation Loss Current: 8.3098, Validation Loss AVG: 9.9113, lr: 0.001
Epoch [8/400], Training Loss: 31.4499, Validation Loss Current: 8.1957, Validation Loss AVG: 9.3621, lr: 0.001
Epoch [9/400], Training Loss: 30.0700, Validation Loss Current: 7.4900, Validation Loss AVG: 8.9571, lr: 0.001
Epoch [10/400], Training Loss: 29.4033, Validation Loss Current: 7.4901, Validation Loss AVG: 10.1977, lr: 0.001
Epoch [11/400], Training Loss: 27.0454, Validation Loss Current: 7.1951, Validation Loss AVG: 8.9592, lr: 0.001
Epoch [12/400], Training Loss: 25.7091, Validation Loss Current: 7.2313, Validation Loss AVG: 11.3583, lr: 0.001
Epoch [13/400], Training Loss: 25.8928, Validation Loss Current: 7.3832, Validation Loss AVG: 9.9918, lr: 0.001
Epoch [14/400], Training Loss: 25.7597, Validation Loss Current: 6.8086, Validation Loss AVG: 9.6620, lr: 0.001
Epoch [15/400], Training Loss: 23.6681, Validation Loss Current: 6.7204, Validation Loss AVG: 9.0017, lr: 0.001
Epoch [16/400], Training Loss: 23.4696, Validation Loss Current: 6.8508, Validation Loss AVG: 8.6834, lr: 0.001
Epoch [17/400], Training Loss: 23.3427, Validation Loss Current: 7.0606, Validation Loss AVG: 11.4662, lr: 0.001
Epoch [18/400], Training Loss: 21.9799, Validation Loss Current: 6.5380, Validation Loss AVG: 9.5863, lr: 0.001
Epoch [19/400], Training Loss: 21.3185, Validation Loss Current: 6.4840, Validation Loss AVG: 9.7352, lr: 0.001
Epoch [20/400], Training Loss: 21.1021, Validation Loss Current: 6.6489, Validation Loss AVG: 8.7459, lr: 0.001
Epoch [21/400], Training Loss: 20.0060, Validation Loss Current: 6.2127, Validation Loss AVG: 8.4959, lr: 0.001
Epoch [22/400], Training Loss: 18.8179, Validation Loss Current: 6.3042, Validation Loss AVG: 8.9722, lr: 0.001
Epoch [23/400], Training Loss: 18.3885, Validation Loss Current: 6.0829, Validation Loss AVG: 9.3003, lr: 0.001
Epoch [24/400], Training Loss: 17.9267, Validation Loss Current: 6.5585, Validation Loss AVG: 9.8222, lr: 0.001
Epoch [25/400], Training Loss: 17.9998, Validation Loss Current: 5.9713, Validation Loss AVG: 9.2895, lr: 0.001
Epoch [26/400], Training Loss: 17.3709, Validation Loss Current: 6.1678, Validation Loss AVG: 9.7566, lr: 0.001
Epoch [27/400], Training Loss: 16.4721, Validation Loss Current: 6.3882, Validation Loss AVG: 10.1010, lr: 0.001
Epoch [28/400], Training Loss: 19.3782, Validation Loss Current: 6.2031, Validation Loss AVG: 12.2905, lr: 0.001
Epoch [29/400], Training Loss: 17.4382, Validation Loss Current: 5.9375, Validation Loss AVG: 10.8814, lr: 0.001
Epoch [30/400], Training Loss: 15.0307, Validation Loss Current: 5.8205, Validation Loss AVG: 7.9764, lr: 0.001
Epoch [31/400], Training Loss: 13.9954, Validation Loss Current: 5.7102, Validation Loss AVG: 8.3823, lr: 0.001
Epoch [32/400], Training Loss: 13.8913, Validation Loss Current: 6.4744, Validation Loss AVG: 13.7365, lr: 0.001
Epoch [33/400], Training Loss: 12.6200, Validation Loss Current: 5.7851, Validation Loss AVG: 8.4693, lr: 0.001
Epoch [34/400], Training Loss: 12.5483, Validation Loss Current: 6.2065, Validation Loss AVG: 10.4007, lr: 0.001
Epoch [35/400], Training Loss: 10.1796, Validation Loss Current: 6.3381, Validation Loss AVG: 10.4002, lr: 0.001
Epoch [36/400], Training Loss: 10.4091, Validation Loss Current: 7.5832, Validation Loss AVG: 11.1148, lr: 0.001
Epoch [37/400], Training Loss: 12.1311, Validation Loss Current: 6.0942, Validation Loss AVG: 9.5504, lr: 0.001
Epoch [38/400], Training Loss: 11.0748, Validation Loss Current: 6.0418, Validation Loss AVG: 10.7336, lr: 0.001
Epoch [39/400], Training Loss: 9.2883, Validation Loss Current: 6.1023, Validation Loss AVG: 9.2441, lr: 0.001
Epoch [40/400], Training Loss: 8.0088, Validation Loss Current: 6.5078, Validation Loss AVG: 10.6466, lr: 0.001
Epoch [41/400], Training Loss: 9.5072, Validation Loss Current: 6.4664, Validation Loss AVG: 10.0475, lr: 0.001
Epoch [42/400], Training Loss: 8.5745, Validation Loss Current: 6.5482, Validation Loss AVG: 11.2000, lr: 0.001
Epoch [43/400], Training Loss: 6.9331, Validation Loss Current: 6.3197, Validation Loss AVG: 10.2344, lr: 0.001
Epoch [44/400], Training Loss: 5.7050, Validation Loss Current: 6.1047, Validation Loss AVG: 9.7185, lr: 0.001
Epoch [45/400], Training Loss: 6.5773, Validation Loss Current: 6.4054, Validation Loss AVG: 11.5639, lr: 0.001
Epoch [46/400], Training Loss: 6.3488, Validation Loss Current: 6.7754, Validation Loss AVG: 9.8173, lr: 0.001
Epoch [47/400], Training Loss: 7.1450, Validation Loss Current: 6.2463, Validation Loss AVG: 10.1500, lr: 0.001
Epoch [48/400], Training Loss: 6.7852, Validation Loss Current: 6.3670, Validation Loss AVG: 10.4968, lr: 0.001
Epoch [49/400], Training Loss: 7.3601, Validation Loss Current: 7.0347, Validation Loss AVG: 12.6471, lr: 0.001
Epoch [50/400], Training Loss: 5.8849, Validation Loss Current: 6.3324, Validation Loss AVG: 10.0701, lr: 0.001
Epoch [51/400], Training Loss: 4.9739, Validation Loss Current: 7.1933, Validation Loss AVG: 14.7102, lr: 0.001
Epoch [52/400], Training Loss: 4.2514, Validation Loss Current: 6.3725, Validation Loss AVG: 11.2900, lr: 0.001
Epoch [53/400], Training Loss: 3.7063, Validation Loss Current: 6.6671, Validation Loss AVG: 10.9370, lr: 0.001
Epoch [54/400], Training Loss: 3.4513, Validation Loss Current: 7.1074, Validation Loss AVG: 12.2828, lr: 0.001
Epoch [55/400], Training Loss: 3.2422, Validation Loss Current: 6.5438, Validation Loss AVG: 10.4563, lr: 0.001
Epoch [56/400], Training Loss: 6.0855, Validation Loss Current: 7.3217, Validation Loss AVG: 12.2953, lr: 0.001
Epoch [57/400], Training Loss: 3.5090, Validation Loss Current: 7.1913, Validation Loss AVG: 12.3664, lr: 0.001
Epoch [58/400], Training Loss: 4.8848, Validation Loss Current: 6.7935, Validation Loss AVG: 10.9590, lr: 0.001
Epoch [59/400], Training Loss: 4.3314, Validation Loss Current: 7.4359, Validation Loss AVG: 11.8101, lr: 0.001
Epoch [60/400], Training Loss: 5.4885, Validation Loss Current: 8.6562, Validation Loss AVG: 18.4425, lr: 0.001
Epoch [61/400], Training Loss: 5.2281, Validation Loss Current: 8.9134, Validation Loss AVG: 12.3048, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 31 Best val accuracy: [0.24013157894736842, 0.28289473684210525, 0.34210526315789475, 0.3519736842105263, 0.3848684210526316, 0.40460526315789475, 0.42598684210526316, 0.41776315789473684, 0.5016447368421053, 0.4868421052631579, 0.49506578947368424, 0.5082236842105263, 0.48355263157894735, 0.5394736842105263, 0.5509868421052632, 0.5148026315789473, 0.5411184210526315, 0.5657894736842105, 0.5723684210526315, 0.5460526315789473, 0.5707236842105263, 0.5509868421052632, 0.5904605263157895, 0.5592105263157895, 0.5904605263157895, 0.5822368421052632, 0.5707236842105263, 0.5641447368421053, 0.6134868421052632, 0.6069078947368421, 0.6019736842105263, 0.5921052631578947, 0.6282894736842105, 0.59375, 0.587171052631579, 0.5279605263157895, 0.5888157894736842, 0.6134868421052632, 0.6167763157894737, 0.6069078947368421, 0.5953947368421053, 0.5707236842105263, 0.5822368421052632, 0.6085526315789473, 0.587171052631579, 0.5953947368421053, 0.6282894736842105, 0.6019736842105263, 0.569078947368421, 0.5773026315789473, 0.5773026315789473, 0.625, 0.6019736842105263, 0.6134868421052632, 0.618421052631579, 0.5822368421052632, 0.5953947368421053, 0.5953947368421053, 0.5773026315789473, 0.5674342105263158, 0.5213815789473685] Best val loss: 5.710241138935089


Fold: 2
----- Training resnet18 with sequence: [0.2, 0.4, 0.6, 0.8, 1] -----
Current group: 0.2
Epoch [1/80], Training Loss: 40.6093, Validation Loss Current: 10.1737, Validation Loss AVG: 10.1737, lr: 0.001
Epoch [2/80], Training Loss: 39.1227, Validation Loss Current: 10.4342, Validation Loss AVG: 10.4342, lr: 0.001
Epoch [3/80], Training Loss: 39.3549, Validation Loss Current: 11.5492, Validation Loss AVG: 11.5492, lr: 0.001
Epoch [4/80], Training Loss: 37.6253, Validation Loss Current: 10.2217, Validation Loss AVG: 10.2217, lr: 0.001
Epoch [5/80], Training Loss: 36.9954, Validation Loss Current: 11.2723, Validation Loss AVG: 11.2723, lr: 0.001
Epoch [6/80], Training Loss: 35.3383, Validation Loss Current: 10.4512, Validation Loss AVG: 10.4512, lr: 0.001
Epoch [7/80], Training Loss: 34.1221, Validation Loss Current: 10.8372, Validation Loss AVG: 10.8372, lr: 0.001
Epoch [8/80], Training Loss: 33.9190, Validation Loss Current: 11.8964, Validation Loss AVG: 11.8964, lr: 0.001
Epoch [9/80], Training Loss: 33.4255, Validation Loss Current: 11.1905, Validation Loss AVG: 11.1905, lr: 0.001
Epoch [10/80], Training Loss: 31.8262, Validation Loss Current: 12.3980, Validation Loss AVG: 12.3980, lr: 0.001
Epoch [11/80], Training Loss: 30.9307, Validation Loss Current: 10.5552, Validation Loss AVG: 10.5552, lr: 0.001
Epoch [12/80], Training Loss: 31.0334, Validation Loss Current: 13.3736, Validation Loss AVG: 13.3736, lr: 0.001
Epoch [13/80], Training Loss: 30.2020, Validation Loss Current: 10.9005, Validation Loss AVG: 10.9005, lr: 0.001
Epoch [14/80], Training Loss: 29.5543, Validation Loss Current: 11.3342, Validation Loss AVG: 11.3342, lr: 0.001
Epoch [15/80], Training Loss: 28.3480, Validation Loss Current: 12.6993, Validation Loss AVG: 12.6993, lr: 0.001
Epoch [16/80], Training Loss: 27.4473, Validation Loss Current: 11.8094, Validation Loss AVG: 11.8094, lr: 0.001
Epoch [17/80], Training Loss: 27.0032, Validation Loss Current: 13.9968, Validation Loss AVG: 13.9968, lr: 0.001
Epoch [18/80], Training Loss: 26.9433, Validation Loss Current: 11.4277, Validation Loss AVG: 11.4277, lr: 0.001
Epoch [19/80], Training Loss: 25.5661, Validation Loss Current: 12.1014, Validation Loss AVG: 12.1014, lr: 0.001
Epoch [20/80], Training Loss: 25.6822, Validation Loss Current: 11.4173, Validation Loss AVG: 11.4173, lr: 0.001
Epoch [21/80], Training Loss: 23.7267, Validation Loss Current: 13.0826, Validation Loss AVG: 13.0826, lr: 0.001
Epoch [22/80], Training Loss: 24.3075, Validation Loss Current: 12.4986, Validation Loss AVG: 12.4986, lr: 0.001
Epoch [23/80], Training Loss: 23.4245, Validation Loss Current: 11.4770, Validation Loss AVG: 11.4770, lr: 0.001
Epoch [24/80], Training Loss: 23.4438, Validation Loss Current: 11.3911, Validation Loss AVG: 11.3911, lr: 0.001
Epoch [25/80], Training Loss: 22.0354, Validation Loss Current: 12.4589, Validation Loss AVG: 12.4589, lr: 0.001
Epoch [26/80], Training Loss: 20.0267, Validation Loss Current: 13.0569, Validation Loss AVG: 13.0569, lr: 0.001
Epoch [27/80], Training Loss: 20.2633, Validation Loss Current: 12.0148, Validation Loss AVG: 12.0148, lr: 0.001
Epoch [28/80], Training Loss: 18.9383, Validation Loss Current: 13.4512, Validation Loss AVG: 13.4512, lr: 0.001
Epoch [29/80], Training Loss: 18.4670, Validation Loss Current: 12.2239, Validation Loss AVG: 12.2239, lr: 0.001
Epoch [30/80], Training Loss: 16.4871, Validation Loss Current: 12.3444, Validation Loss AVG: 12.3444, lr: 0.001
Epoch [31/80], Training Loss: 16.5121, Validation Loss Current: 13.1433, Validation Loss AVG: 13.1433, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 1 Best val accuracy: [0.2006578947368421, 0.1825657894736842, 0.1453947368421053, 0.21973684210526315, 0.1990131578947368, 0.2411184210526316, 0.225, 0.20723684210526314, 0.2335526315789474, 0.1868421052631579, 0.249671052631579, 0.15921052631578947, 0.24868421052631579, 0.24473684210526314, 0.22138157894736846, 0.24342105263157893, 0.20723684210526314, 0.24999999999999994, 0.28388157894736843, 0.31217105263157896, 0.24967105263157893, 0.22763157894736846, 0.2911184210526316, 0.31381578947368427, 0.2881578947368421, 0.25592105263157894, 0.34078947368421053, 0.24309210526315791, 0.33782894736842106, 0.3036184210526316, 0.3111842105263158] Best val loss: 10.173726844787598


Current group: 0.4
Epoch [1/80], Training Loss: 31.8584, Validation Loss Current: 11.1044, Validation Loss AVG: 11.1044, lr: 0.001
Epoch [2/80], Training Loss: 28.5983, Validation Loss Current: 9.3090, Validation Loss AVG: 9.3090, lr: 0.001
Epoch [3/80], Training Loss: 27.0068, Validation Loss Current: 9.4765, Validation Loss AVG: 9.4765, lr: 0.001
Epoch [4/80], Training Loss: 26.2642, Validation Loss Current: 9.2638, Validation Loss AVG: 9.2638, lr: 0.001
Epoch [5/80], Training Loss: 25.4209, Validation Loss Current: 11.3755, Validation Loss AVG: 11.3755, lr: 0.001
Epoch [6/80], Training Loss: 25.5864, Validation Loss Current: 11.3585, Validation Loss AVG: 11.3585, lr: 0.001
Epoch [7/80], Training Loss: 24.3041, Validation Loss Current: 8.8345, Validation Loss AVG: 8.8345, lr: 0.001
Epoch [8/80], Training Loss: 23.4138, Validation Loss Current: 9.6919, Validation Loss AVG: 9.6919, lr: 0.001
Epoch [9/80], Training Loss: 21.6619, Validation Loss Current: 10.0833, Validation Loss AVG: 10.0833, lr: 0.001
Epoch [10/80], Training Loss: 20.5305, Validation Loss Current: 9.2454, Validation Loss AVG: 9.2454, lr: 0.001
Epoch [11/80], Training Loss: 18.9845, Validation Loss Current: 9.4543, Validation Loss AVG: 9.4543, lr: 0.001
Epoch [12/80], Training Loss: 17.1040, Validation Loss Current: 9.5452, Validation Loss AVG: 9.5452, lr: 0.001
Epoch [13/80], Training Loss: 17.5709, Validation Loss Current: 10.2566, Validation Loss AVG: 10.2566, lr: 0.001
Epoch [14/80], Training Loss: 16.5449, Validation Loss Current: 10.4529, Validation Loss AVG: 10.4529, lr: 0.001
Epoch [15/80], Training Loss: 16.4072, Validation Loss Current: 9.8355, Validation Loss AVG: 9.8355, lr: 0.001
Epoch [16/80], Training Loss: 13.3298, Validation Loss Current: 9.0506, Validation Loss AVG: 9.0506, lr: 0.001
Epoch [17/80], Training Loss: 14.2315, Validation Loss Current: 10.2956, Validation Loss AVG: 10.2956, lr: 0.001
Epoch [18/80], Training Loss: 11.8379, Validation Loss Current: 13.0759, Validation Loss AVG: 13.0759, lr: 0.001
Epoch [19/80], Training Loss: 13.9540, Validation Loss Current: 9.1764, Validation Loss AVG: 9.1764, lr: 0.001
Epoch [20/80], Training Loss: 11.0524, Validation Loss Current: 9.6843, Validation Loss AVG: 9.6843, lr: 0.001
Epoch [21/80], Training Loss: 11.1884, Validation Loss Current: 11.8508, Validation Loss AVG: 11.8508, lr: 0.001
Epoch [22/80], Training Loss: 18.1557, Validation Loss Current: 12.0802, Validation Loss AVG: 12.0802, lr: 0.001
Epoch [23/80], Training Loss: 15.2640, Validation Loss Current: 10.8503, Validation Loss AVG: 10.8503, lr: 0.001
Epoch [24/80], Training Loss: 12.8527, Validation Loss Current: 10.1369, Validation Loss AVG: 10.1369, lr: 0.001
Epoch [25/80], Training Loss: 11.6304, Validation Loss Current: 12.1119, Validation Loss AVG: 12.1119, lr: 0.001
Epoch [26/80], Training Loss: 10.7767, Validation Loss Current: 10.4633, Validation Loss AVG: 10.4633, lr: 0.001
Epoch [27/80], Training Loss: 13.0584, Validation Loss Current: 11.9508, Validation Loss AVG: 11.9508, lr: 0.001
Epoch [28/80], Training Loss: 12.8298, Validation Loss Current: 10.5493, Validation Loss AVG: 10.5493, lr: 0.001
Epoch [29/80], Training Loss: 11.7109, Validation Loss Current: 10.8719, Validation Loss AVG: 10.8719, lr: 0.001
Epoch [30/80], Training Loss: 13.1094, Validation Loss Current: 11.5420, Validation Loss AVG: 11.5420, lr: 0.001
Epoch [31/80], Training Loss: 9.6409, Validation Loss Current: 11.0041, Validation Loss AVG: 11.0041, lr: 0.001
Epoch [32/80], Training Loss: 7.8862, Validation Loss Current: 12.2858, Validation Loss AVG: 12.2858, lr: 0.001
Epoch [33/80], Training Loss: 5.0378, Validation Loss Current: 9.5813, Validation Loss AVG: 9.5813, lr: 0.001
Epoch [34/80], Training Loss: 4.4215, Validation Loss Current: 9.9248, Validation Loss AVG: 9.9248, lr: 0.001
Epoch [35/80], Training Loss: 5.6532, Validation Loss Current: 11.2978, Validation Loss AVG: 11.2978, lr: 0.001
Epoch [36/80], Training Loss: 7.0026, Validation Loss Current: 10.7499, Validation Loss AVG: 10.7499, lr: 0.001
Epoch [37/80], Training Loss: 7.6052, Validation Loss Current: 11.4115, Validation Loss AVG: 11.4115, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 7 Best val accuracy: [0.2578947368421053, 0.3493421052631579, 0.3611842105263158, 0.37434210526315786, 0.29013157894736846, 0.36875, 0.3907894736842105, 0.4078947368421053, 0.3983552631578947, 0.3953947368421053, 0.41052631578947374, 0.3927631578947368, 0.4006578947368421, 0.3851973684210527, 0.3779605263157895, 0.4496710526315789, 0.39473684210526316, 0.38355263157894737, 0.4161184210526316, 0.42927631578947373, 0.3825657894736842, 0.2835526315789474, 0.3388157894736842, 0.45394736842105265, 0.3707236842105263, 0.45, 0.34407894736842104, 0.40657894736842104, 0.3736842105263158, 0.40592105263157896, 0.4006578947368421, 0.38585526315789476, 0.43717105263157896, 0.4496710526315789, 0.3796052631578947, 0.4223684210526315, 0.4128289473684211] Best val loss: 8.834492015838624


Current group: 0.6
Epoch [1/80], Training Loss: 30.6744, Validation Loss Current: 9.3043, Validation Loss AVG: 9.3043, lr: 0.001
Epoch [2/80], Training Loss: 23.7283, Validation Loss Current: 10.1823, Validation Loss AVG: 10.1823, lr: 0.001
Epoch [3/80], Training Loss: 19.6552, Validation Loss Current: 9.4017, Validation Loss AVG: 9.4017, lr: 0.001
Epoch [4/80], Training Loss: 15.7196, Validation Loss Current: 11.2259, Validation Loss AVG: 11.2259, lr: 0.001
Epoch [5/80], Training Loss: 12.3509, Validation Loss Current: 10.0784, Validation Loss AVG: 10.0784, lr: 0.001
Epoch [6/80], Training Loss: 12.0008, Validation Loss Current: 11.2600, Validation Loss AVG: 11.2600, lr: 0.001
Epoch [7/80], Training Loss: 13.8750, Validation Loss Current: 10.4923, Validation Loss AVG: 10.4923, lr: 0.001
Epoch [8/80], Training Loss: 11.1248, Validation Loss Current: 8.7669, Validation Loss AVG: 8.7669, lr: 0.001
Epoch [9/80], Training Loss: 8.4125, Validation Loss Current: 9.3780, Validation Loss AVG: 9.3780, lr: 0.001
Epoch [10/80], Training Loss: 6.4979, Validation Loss Current: 9.3861, Validation Loss AVG: 9.3861, lr: 0.001
Epoch [11/80], Training Loss: 7.5245, Validation Loss Current: 10.4307, Validation Loss AVG: 10.4307, lr: 0.001
Epoch [12/80], Training Loss: 5.7562, Validation Loss Current: 10.3455, Validation Loss AVG: 10.3455, lr: 0.001
Epoch [13/80], Training Loss: 4.2335, Validation Loss Current: 10.1950, Validation Loss AVG: 10.1950, lr: 0.001
Epoch [14/80], Training Loss: 4.0114, Validation Loss Current: 10.4470, Validation Loss AVG: 10.4470, lr: 0.001
Epoch [15/80], Training Loss: 8.6859, Validation Loss Current: 11.6485, Validation Loss AVG: 11.6485, lr: 0.001
Epoch [16/80], Training Loss: 10.4232, Validation Loss Current: 12.1207, Validation Loss AVG: 12.1207, lr: 0.001
Epoch [17/80], Training Loss: 7.5805, Validation Loss Current: 12.2895, Validation Loss AVG: 12.2895, lr: 0.001
Epoch [18/80], Training Loss: 6.7829, Validation Loss Current: 9.9846, Validation Loss AVG: 9.9846, lr: 0.001
Epoch [19/80], Training Loss: 5.8623, Validation Loss Current: 10.5539, Validation Loss AVG: 10.5539, lr: 0.001
Epoch [20/80], Training Loss: 7.0933, Validation Loss Current: 11.5341, Validation Loss AVG: 11.5341, lr: 0.001
Epoch [21/80], Training Loss: 8.7848, Validation Loss Current: 12.1754, Validation Loss AVG: 12.1754, lr: 0.001
Epoch [22/80], Training Loss: 6.4159, Validation Loss Current: 11.1729, Validation Loss AVG: 11.1729, lr: 0.001
Epoch [23/80], Training Loss: 4.4964, Validation Loss Current: 10.8896, Validation Loss AVG: 10.8896, lr: 0.001
Epoch [24/80], Training Loss: 5.0680, Validation Loss Current: 10.6670, Validation Loss AVG: 10.6670, lr: 0.001
Epoch [25/80], Training Loss: 3.6632, Validation Loss Current: 11.6698, Validation Loss AVG: 11.6698, lr: 0.001
Epoch [26/80], Training Loss: 3.8816, Validation Loss Current: 11.7022, Validation Loss AVG: 11.7022, lr: 0.001
Epoch [27/80], Training Loss: 4.9514, Validation Loss Current: 12.4913, Validation Loss AVG: 12.4913, lr: 0.001
Epoch [28/80], Training Loss: 5.7970, Validation Loss Current: 13.1771, Validation Loss AVG: 13.1771, lr: 0.001
Epoch [29/80], Training Loss: 5.9187, Validation Loss Current: 12.5903, Validation Loss AVG: 12.5903, lr: 0.001
Epoch [30/80], Training Loss: 6.3589, Validation Loss Current: 13.5451, Validation Loss AVG: 13.5451, lr: 0.001
Epoch [31/80], Training Loss: 8.6468, Validation Loss Current: 15.7395, Validation Loss AVG: 15.7395, lr: 0.001
Epoch [32/80], Training Loss: 12.1566, Validation Loss Current: 12.3887, Validation Loss AVG: 12.3887, lr: 0.001
Epoch [33/80], Training Loss: 7.7530, Validation Loss Current: 12.3387, Validation Loss AVG: 12.3387, lr: 0.001
Epoch [34/80], Training Loss: 4.6284, Validation Loss Current: 10.7242, Validation Loss AVG: 10.7242, lr: 0.001
Epoch [35/80], Training Loss: 3.7647, Validation Loss Current: 10.8299, Validation Loss AVG: 10.8299, lr: 0.001
Epoch [36/80], Training Loss: 6.4286, Validation Loss Current: 12.8169, Validation Loss AVG: 12.8169, lr: 0.001
Epoch [37/80], Training Loss: 8.0467, Validation Loss Current: 11.8673, Validation Loss AVG: 11.8673, lr: 0.001
Epoch [38/80], Training Loss: 4.9787, Validation Loss Current: 12.5411, Validation Loss AVG: 12.5411, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 8 Best val accuracy: [0.4582236842105263, 0.3888157894736842, 0.43717105263157896, 0.37434210526315786, 0.41546052631578945, 0.4167763157894736, 0.4151315789473684, 0.4703947368421052, 0.45953947368421055, 0.4358552631578948, 0.43782894736842104, 0.4391447368421053, 0.45625, 0.4223684210526316, 0.425657894736842, 0.40756578947368416, 0.43355263157894736, 0.44342105263157894, 0.4496710526315789, 0.4430921052631579, 0.39309210526315785, 0.42796052631578946, 0.4276315789473685, 0.4437500000000001, 0.4476973684210527, 0.45197368421052636, 0.3759868421052631, 0.42631578947368426, 0.45855263157894743, 0.40690789473684214, 0.4115131578947368, 0.37993421052631576, 0.44144736842105264, 0.4661184210526315, 0.46611842105263157, 0.41447368421052627, 0.42631578947368415, 0.4319078947368421] Best val loss: 8.766876840591431


Current group: 0.8
Epoch [1/80], Training Loss: 27.3790, Validation Loss Current: 11.2369, Validation Loss AVG: 11.2369, lr: 0.001
Epoch [2/80], Training Loss: 19.7288, Validation Loss Current: 10.5352, Validation Loss AVG: 10.5352, lr: 0.001
Epoch [3/80], Training Loss: 15.8680, Validation Loss Current: 12.8404, Validation Loss AVG: 12.8404, lr: 0.001
Epoch [4/80], Training Loss: 15.1485, Validation Loss Current: 9.0823, Validation Loss AVG: 9.0823, lr: 0.001
Epoch [5/80], Training Loss: 11.7780, Validation Loss Current: 10.4958, Validation Loss AVG: 10.4958, lr: 0.001
Epoch [6/80], Training Loss: 9.3151, Validation Loss Current: 11.5759, Validation Loss AVG: 11.5759, lr: 0.001
Epoch [7/80], Training Loss: 7.7409, Validation Loss Current: 9.7763, Validation Loss AVG: 9.7763, lr: 0.001
Epoch [8/80], Training Loss: 5.9131, Validation Loss Current: 13.7267, Validation Loss AVG: 13.7267, lr: 0.001
Epoch [9/80], Training Loss: 5.5035, Validation Loss Current: 10.2260, Validation Loss AVG: 10.2260, lr: 0.001
Epoch [10/80], Training Loss: 4.2924, Validation Loss Current: 10.6348, Validation Loss AVG: 10.6348, lr: 0.001
Epoch [11/80], Training Loss: 6.5252, Validation Loss Current: 11.9462, Validation Loss AVG: 11.9462, lr: 0.001
Epoch [12/80], Training Loss: 4.6145, Validation Loss Current: 12.8042, Validation Loss AVG: 12.8042, lr: 0.001
Epoch [13/80], Training Loss: 6.7412, Validation Loss Current: 11.5816, Validation Loss AVG: 11.5816, lr: 0.001
Epoch [14/80], Training Loss: 6.5708, Validation Loss Current: 15.1533, Validation Loss AVG: 15.1533, lr: 0.001
Epoch [15/80], Training Loss: 7.2593, Validation Loss Current: 12.0864, Validation Loss AVG: 12.0864, lr: 0.001
Epoch [16/80], Training Loss: 4.2917, Validation Loss Current: 12.8416, Validation Loss AVG: 12.8416, lr: 0.001
Epoch [17/80], Training Loss: 2.4689, Validation Loss Current: 11.3187, Validation Loss AVG: 11.3187, lr: 0.001
Epoch [18/80], Training Loss: 1.6018, Validation Loss Current: 12.0306, Validation Loss AVG: 12.0306, lr: 0.001
Epoch [19/80], Training Loss: 3.5570, Validation Loss Current: 10.5560, Validation Loss AVG: 10.5560, lr: 0.001
Epoch [20/80], Training Loss: 3.7220, Validation Loss Current: 10.3554, Validation Loss AVG: 10.3554, lr: 0.001
Epoch [21/80], Training Loss: 6.8494, Validation Loss Current: 12.4168, Validation Loss AVG: 12.4168, lr: 0.001
Epoch [22/80], Training Loss: 2.9557, Validation Loss Current: 12.2026, Validation Loss AVG: 12.2026, lr: 0.001
Epoch [23/80], Training Loss: 3.9797, Validation Loss Current: 14.3752, Validation Loss AVG: 14.3752, lr: 0.001
Epoch [24/80], Training Loss: 4.3124, Validation Loss Current: 12.6534, Validation Loss AVG: 12.6534, lr: 0.001
Epoch [25/80], Training Loss: 6.1177, Validation Loss Current: 12.5668, Validation Loss AVG: 12.5668, lr: 0.001
Epoch [26/80], Training Loss: 5.0107, Validation Loss Current: 14.6163, Validation Loss AVG: 14.6163, lr: 0.001
Epoch [27/80], Training Loss: 4.2139, Validation Loss Current: 14.1656, Validation Loss AVG: 14.1656, lr: 0.001
Epoch [28/80], Training Loss: 5.0911, Validation Loss Current: 11.0169, Validation Loss AVG: 11.0169, lr: 0.001
Epoch [29/80], Training Loss: 5.4068, Validation Loss Current: 12.7365, Validation Loss AVG: 12.7365, lr: 0.001
Epoch [30/80], Training Loss: 4.3079, Validation Loss Current: 12.2825, Validation Loss AVG: 12.2825, lr: 0.001
Epoch [31/80], Training Loss: 2.2646, Validation Loss Current: 14.7344, Validation Loss AVG: 14.7344, lr: 0.001
Epoch [32/80], Training Loss: 4.4068, Validation Loss Current: 13.7631, Validation Loss AVG: 13.7631, lr: 0.001
Epoch [33/80], Training Loss: 4.2785, Validation Loss Current: 13.3370, Validation Loss AVG: 13.3370, lr: 0.001
Epoch [34/80], Training Loss: 7.1821, Validation Loss Current: 14.7123, Validation Loss AVG: 14.7123, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.4526315789473684, 0.43322368421052626, 0.3684210526315789, 0.49046052631578946, 0.4598684210526316, 0.44013157894736843, 0.4703947368421053, 0.4319078947368421, 0.45625, 0.4740131578947368, 0.43552631578947365, 0.4493421052631579, 0.4526315789473685, 0.36447368421052634, 0.44539473684210523, 0.44144736842105264, 0.44342105263157894, 0.46611842105263157, 0.46019736842105263, 0.48322368421052636, 0.4552631578947368, 0.43815789473684214, 0.43618421052631584, 0.4276315789473684, 0.43519736842105267, 0.40230263157894736, 0.41743421052631574, 0.46644736842105267, 0.40032894736842106, 0.44605263157894737, 0.4338815789473684, 0.4473684210526316, 0.4269736842105263, 0.4046052631578948] Best val loss: 9.082300329208374


Current group: 1
Epoch [1/80], Training Loss: 27.8661, Validation Loss Current: 9.3774, Validation Loss AVG: 12.7067, lr: 0.001
Epoch [2/80], Training Loss: 16.0422, Validation Loss Current: 8.0361, Validation Loss AVG: 11.0291, lr: 0.001
Epoch [3/80], Training Loss: 9.6285, Validation Loss Current: 7.2405, Validation Loss AVG: 13.2317, lr: 0.001
Epoch [4/80], Training Loss: 7.0809, Validation Loss Current: 8.4529, Validation Loss AVG: 14.1552, lr: 0.001
Epoch [5/80], Training Loss: 8.4310, Validation Loss Current: 7.3510, Validation Loss AVG: 13.6061, lr: 0.001
Epoch [6/80], Training Loss: 8.6370, Validation Loss Current: 7.6523, Validation Loss AVG: 11.5465, lr: 0.001
Epoch [7/80], Training Loss: 8.7400, Validation Loss Current: 7.8353, Validation Loss AVG: 15.4849, lr: 0.001
Epoch [8/80], Training Loss: 6.8143, Validation Loss Current: 7.3641, Validation Loss AVG: 12.7997, lr: 0.001
Epoch [9/80], Training Loss: 4.6872, Validation Loss Current: 7.1177, Validation Loss AVG: 11.2933, lr: 0.001
Epoch [10/80], Training Loss: 5.5186, Validation Loss Current: 6.9931, Validation Loss AVG: 12.0659, lr: 0.001
Epoch [11/80], Training Loss: 3.9665, Validation Loss Current: 7.3781, Validation Loss AVG: 12.4664, lr: 0.001
Epoch [12/80], Training Loss: 4.6177, Validation Loss Current: 7.2737, Validation Loss AVG: 14.2419, lr: 0.001
Epoch [13/80], Training Loss: 6.9300, Validation Loss Current: 7.5086, Validation Loss AVG: 13.4628, lr: 0.001
Epoch [14/80], Training Loss: 6.8375, Validation Loss Current: 8.5670, Validation Loss AVG: 11.6133, lr: 0.001
Epoch [15/80], Training Loss: 6.2363, Validation Loss Current: 8.5055, Validation Loss AVG: 14.4719, lr: 0.001
Epoch [16/80], Training Loss: 6.8224, Validation Loss Current: 8.7289, Validation Loss AVG: 14.1624, lr: 0.001
Epoch [17/80], Training Loss: 8.3697, Validation Loss Current: 9.6422, Validation Loss AVG: 14.0198, lr: 0.001
Epoch [18/80], Training Loss: 5.7613, Validation Loss Current: 7.4962, Validation Loss AVG: 13.8392, lr: 0.001
Epoch [19/80], Training Loss: 4.1796, Validation Loss Current: 8.0391, Validation Loss AVG: 12.6849, lr: 0.001
Epoch [20/80], Training Loss: 2.4799, Validation Loss Current: 8.0064, Validation Loss AVG: 12.9190, lr: 0.001
Epoch [21/80], Training Loss: 3.6032, Validation Loss Current: 9.1126, Validation Loss AVG: 14.1561, lr: 0.001
Epoch [22/80], Training Loss: 5.4235, Validation Loss Current: 8.4667, Validation Loss AVG: 17.6615, lr: 0.001
Epoch [23/80], Training Loss: 5.4555, Validation Loss Current: 8.8909, Validation Loss AVG: 12.0916, lr: 0.001
Epoch [24/80], Training Loss: 4.5181, Validation Loss Current: 7.1752, Validation Loss AVG: 12.7439, lr: 0.001
Epoch [25/80], Training Loss: 5.6898, Validation Loss Current: 8.3896, Validation Loss AVG: 12.7638, lr: 0.001
Epoch [26/80], Training Loss: 4.3341, Validation Loss Current: 9.3975, Validation Loss AVG: 13.3393, lr: 0.001
Epoch [27/80], Training Loss: 4.9590, Validation Loss Current: 9.7156, Validation Loss AVG: 13.8116, lr: 0.001
Epoch [28/80], Training Loss: 2.5171, Validation Loss Current: 7.1237, Validation Loss AVG: 13.2217, lr: 0.001
Epoch [29/80], Training Loss: 2.8209, Validation Loss Current: 8.1101, Validation Loss AVG: 13.2812, lr: 0.001
Epoch [30/80], Training Loss: 4.2465, Validation Loss Current: 8.2812, Validation Loss AVG: 12.2830, lr: 0.001
Epoch [31/80], Training Loss: 3.0015, Validation Loss Current: 7.7021, Validation Loss AVG: 13.2549, lr: 0.001
Epoch [32/80], Training Loss: 4.0833, Validation Loss Current: 7.5252, Validation Loss AVG: 12.6273, lr: 0.001
Epoch [33/80], Training Loss: 4.2703, Validation Loss Current: 8.4595, Validation Loss AVG: 14.1776, lr: 0.001
Epoch [34/80], Training Loss: 4.8450, Validation Loss Current: 7.3853, Validation Loss AVG: 12.6997, lr: 0.001
Epoch [35/80], Training Loss: 2.5820, Validation Loss Current: 8.0896, Validation Loss AVG: 12.3744, lr: 0.001
Epoch [36/80], Training Loss: 2.5278, Validation Loss Current: 7.8067, Validation Loss AVG: 13.3071, lr: 0.001
Epoch [37/80], Training Loss: 5.3979, Validation Loss Current: 10.6479, Validation Loss AVG: 16.5841, lr: 0.001
Epoch [38/80], Training Loss: 6.6928, Validation Loss Current: 9.2431, Validation Loss AVG: 13.1344, lr: 0.001
Epoch [39/80], Training Loss: 6.3705, Validation Loss Current: 8.0998, Validation Loss AVG: 11.7577, lr: 0.001
Epoch [40/80], Training Loss: 3.7905, Validation Loss Current: 7.8586, Validation Loss AVG: 14.0470, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 10 Best val accuracy: [0.5411184210526315, 0.5641447368421053, 0.5921052631578947, 0.5723684210526315, 0.5723684210526315, 0.5657894736842105, 0.6036184210526315, 0.5970394736842105, 0.6266447368421053, 0.6332236842105263, 0.5953947368421053, 0.6266447368421053, 0.5986842105263158, 0.5888157894736842, 0.5641447368421053, 0.5723684210526315, 0.5756578947368421, 0.6069078947368421, 0.587171052631579, 0.6036184210526315, 0.569078947368421, 0.5805921052631579, 0.5707236842105263, 0.6151315789473685, 0.618421052631579, 0.5740131578947368, 0.5361842105263158, 0.631578947368421, 0.5986842105263158, 0.600328947368421, 0.6217105263157895, 0.6134868421052632, 0.6085526315789473, 0.6167763157894737, 0.6200657894736842, 0.6036184210526315, 0.5805921052631579, 0.5674342105263158, 0.6398026315789473, 0.6069078947368421] Best val loss: 6.993078827857971


----- Training resnet18 with sequence: [0.4, 0.6, 0.8, 1] -----
Current group: 0.4
Epoch [1/100], Training Loss: 40.0400, Validation Loss Current: 10.1332, Validation Loss AVG: 10.1332, lr: 0.001
Epoch [2/100], Training Loss: 39.2970, Validation Loss Current: 10.0378, Validation Loss AVG: 10.0378, lr: 0.001
Epoch [3/100], Training Loss: 38.8979, Validation Loss Current: 10.0516, Validation Loss AVG: 10.0516, lr: 0.001
Epoch [4/100], Training Loss: 38.5847, Validation Loss Current: 9.8696, Validation Loss AVG: 9.8696, lr: 0.001
Epoch [5/100], Training Loss: 37.2796, Validation Loss Current: 10.0065, Validation Loss AVG: 10.0065, lr: 0.001
Epoch [6/100], Training Loss: 36.8405, Validation Loss Current: 9.5549, Validation Loss AVG: 9.5549, lr: 0.001
Epoch [7/100], Training Loss: 36.5780, Validation Loss Current: 9.5074, Validation Loss AVG: 9.5074, lr: 0.001
Epoch [8/100], Training Loss: 35.1499, Validation Loss Current: 9.4520, Validation Loss AVG: 9.4520, lr: 0.001
Epoch [9/100], Training Loss: 34.0159, Validation Loss Current: 9.4036, Validation Loss AVG: 9.4036, lr: 0.001
Epoch [10/100], Training Loss: 33.3261, Validation Loss Current: 9.0900, Validation Loss AVG: 9.0900, lr: 0.001
Epoch [11/100], Training Loss: 32.4036, Validation Loss Current: 9.0081, Validation Loss AVG: 9.0081, lr: 0.001
Epoch [12/100], Training Loss: 31.1397, Validation Loss Current: 9.3749, Validation Loss AVG: 9.3749, lr: 0.001
Epoch [13/100], Training Loss: 30.8102, Validation Loss Current: 8.8808, Validation Loss AVG: 8.8808, lr: 0.001
Epoch [14/100], Training Loss: 30.2636, Validation Loss Current: 9.0279, Validation Loss AVG: 9.0279, lr: 0.001
Epoch [15/100], Training Loss: 31.3242, Validation Loss Current: 8.5251, Validation Loss AVG: 8.5251, lr: 0.001
Epoch [16/100], Training Loss: 28.4738, Validation Loss Current: 10.1969, Validation Loss AVG: 10.1969, lr: 0.001
Epoch [17/100], Training Loss: 27.7268, Validation Loss Current: 12.0123, Validation Loss AVG: 12.0123, lr: 0.001
Epoch [18/100], Training Loss: 28.9392, Validation Loss Current: 10.1157, Validation Loss AVG: 10.1157, lr: 0.001
Epoch [19/100], Training Loss: 26.3583, Validation Loss Current: 10.3289, Validation Loss AVG: 10.3289, lr: 0.001
Epoch [20/100], Training Loss: 27.3124, Validation Loss Current: 8.0384, Validation Loss AVG: 8.0384, lr: 0.001
Epoch [21/100], Training Loss: 25.4586, Validation Loss Current: 8.5230, Validation Loss AVG: 8.5230, lr: 0.001
Epoch [22/100], Training Loss: 25.7346, Validation Loss Current: 9.7969, Validation Loss AVG: 9.7969, lr: 0.001
Epoch [23/100], Training Loss: 23.2510, Validation Loss Current: 8.1330, Validation Loss AVG: 8.1330, lr: 0.001
Epoch [24/100], Training Loss: 23.0603, Validation Loss Current: 8.0269, Validation Loss AVG: 8.0269, lr: 0.001
Epoch [25/100], Training Loss: 21.6979, Validation Loss Current: 10.0519, Validation Loss AVG: 10.0519, lr: 0.001
Epoch [26/100], Training Loss: 21.7384, Validation Loss Current: 8.2032, Validation Loss AVG: 8.2032, lr: 0.001
Epoch [27/100], Training Loss: 19.8987, Validation Loss Current: 10.1637, Validation Loss AVG: 10.1637, lr: 0.001
Epoch [28/100], Training Loss: 21.0502, Validation Loss Current: 8.6433, Validation Loss AVG: 8.6433, lr: 0.001
Epoch [29/100], Training Loss: 20.2241, Validation Loss Current: 8.6240, Validation Loss AVG: 8.6240, lr: 0.001
Epoch [30/100], Training Loss: 20.1340, Validation Loss Current: 9.1724, Validation Loss AVG: 9.1724, lr: 0.001
Epoch [31/100], Training Loss: 17.9151, Validation Loss Current: 8.0808, Validation Loss AVG: 8.0808, lr: 0.001
Epoch [32/100], Training Loss: 16.3340, Validation Loss Current: 10.0704, Validation Loss AVG: 10.0704, lr: 0.001
Epoch [33/100], Training Loss: 19.5472, Validation Loss Current: 8.9791, Validation Loss AVG: 8.9791, lr: 0.001
Epoch [34/100], Training Loss: 17.6710, Validation Loss Current: 10.8557, Validation Loss AVG: 10.8557, lr: 0.001
Epoch [35/100], Training Loss: 17.0638, Validation Loss Current: 10.0554, Validation Loss AVG: 10.0554, lr: 0.001
Epoch [36/100], Training Loss: 14.6936, Validation Loss Current: 8.5343, Validation Loss AVG: 8.5343, lr: 0.001
Epoch [37/100], Training Loss: 13.3305, Validation Loss Current: 8.5977, Validation Loss AVG: 8.5977, lr: 0.001
Epoch [38/100], Training Loss: 13.7343, Validation Loss Current: 9.0111, Validation Loss AVG: 9.0111, lr: 0.001
Epoch [39/100], Training Loss: 15.0876, Validation Loss Current: 10.6220, Validation Loss AVG: 10.6220, lr: 0.001
Epoch [40/100], Training Loss: 12.4619, Validation Loss Current: 8.9983, Validation Loss AVG: 8.9983, lr: 0.001
Epoch [41/100], Training Loss: 11.8200, Validation Loss Current: 9.3374, Validation Loss AVG: 9.3374, lr: 0.001
Epoch [42/100], Training Loss: 11.9230, Validation Loss Current: 9.0383, Validation Loss AVG: 9.0383, lr: 0.001
Epoch [43/100], Training Loss: 11.6562, Validation Loss Current: 8.9977, Validation Loss AVG: 8.9977, lr: 0.001
Epoch [44/100], Training Loss: 9.5440, Validation Loss Current: 8.7726, Validation Loss AVG: 8.7726, lr: 0.001
Epoch [45/100], Training Loss: 8.1866, Validation Loss Current: 9.5770, Validation Loss AVG: 9.5770, lr: 0.001
Epoch [46/100], Training Loss: 12.1806, Validation Loss Current: 18.3942, Validation Loss AVG: 18.3942, lr: 0.001
Epoch [47/100], Training Loss: 9.2891, Validation Loss Current: 9.5794, Validation Loss AVG: 9.5794, lr: 0.001
Epoch [48/100], Training Loss: 7.2764, Validation Loss Current: 9.6149, Validation Loss AVG: 9.6149, lr: 0.001
Epoch [49/100], Training Loss: 7.9687, Validation Loss Current: 9.5917, Validation Loss AVG: 9.5917, lr: 0.001
Epoch [50/100], Training Loss: 8.3631, Validation Loss Current: 12.4723, Validation Loss AVG: 12.4723, lr: 0.001
Epoch [51/100], Training Loss: 6.8875, Validation Loss Current: 10.8815, Validation Loss AVG: 10.8815, lr: 0.001
Epoch [52/100], Training Loss: 4.8790, Validation Loss Current: 10.6240, Validation Loss AVG: 10.6240, lr: 0.001
Epoch [53/100], Training Loss: 5.8998, Validation Loss Current: 10.2148, Validation Loss AVG: 10.2148, lr: 0.001
Epoch [54/100], Training Loss: 7.5873, Validation Loss Current: 12.1620, Validation Loss AVG: 12.1620, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 24 Best val accuracy: [0.23092105263157894, 0.22401315789473686, 0.23585526315789473, 0.24177631578947373, 0.19703947368421051, 0.2855263157894737, 0.27960526315789475, 0.2776315789473684, 0.26842105263157895, 0.3092105263157895, 0.32532894736842105, 0.30164473684210524, 0.3411184210526316, 0.3023026315789473, 0.3717105263157895, 0.31085526315789475, 0.3203947368421053, 0.28717105263157894, 0.3226973684210526, 0.3963815789473685, 0.38092105263157894, 0.35723684210526313, 0.4200657894736842, 0.4365131578947368, 0.3779605263157894, 0.4118421052631579, 0.3875, 0.3786184210526316, 0.40756578947368416, 0.35427631578947366, 0.43519736842105267, 0.39769736842105263, 0.41118421052631576, 0.32302631578947366, 0.3519736842105264, 0.4430921052631579, 0.42828947368421055, 0.3960526315789473, 0.37105263157894736, 0.4532894736842105, 0.44013157894736843, 0.42072368421052636, 0.4273026315789473, 0.43717105263157896, 0.41052631578947374, 0.27532894736842106, 0.40855263157894733, 0.4342105263157895, 0.4220394736842105, 0.35822368421052636, 0.3990131578947369, 0.4144736842105264, 0.4125, 0.4131578947368421] Best val loss: 8.026945948600769


Current group: 0.6
Epoch [1/100], Training Loss: 30.9696, Validation Loss Current: 10.8782, Validation Loss AVG: 10.8782, lr: 0.001
Epoch [2/100], Training Loss: 22.6360, Validation Loss Current: 11.0663, Validation Loss AVG: 11.0663, lr: 0.001
Epoch [3/100], Training Loss: 17.9942, Validation Loss Current: 9.6902, Validation Loss AVG: 9.6902, lr: 0.001
Epoch [4/100], Training Loss: 17.2521, Validation Loss Current: 9.1224, Validation Loss AVG: 9.1224, lr: 0.001
Epoch [5/100], Training Loss: 20.0047, Validation Loss Current: 10.7777, Validation Loss AVG: 10.7777, lr: 0.001
Epoch [6/100], Training Loss: 17.3799, Validation Loss Current: 8.8256, Validation Loss AVG: 8.8256, lr: 0.001
Epoch [7/100], Training Loss: 12.2088, Validation Loss Current: 9.6614, Validation Loss AVG: 9.6614, lr: 0.001
Epoch [8/100], Training Loss: 9.0305, Validation Loss Current: 9.2853, Validation Loss AVG: 9.2853, lr: 0.001
Epoch [9/100], Training Loss: 7.7730, Validation Loss Current: 9.8287, Validation Loss AVG: 9.8287, lr: 0.001
Epoch [10/100], Training Loss: 13.2811, Validation Loss Current: 10.4899, Validation Loss AVG: 10.4899, lr: 0.001
Epoch [11/100], Training Loss: 12.4700, Validation Loss Current: 9.8993, Validation Loss AVG: 9.8993, lr: 0.001
Epoch [12/100], Training Loss: 9.9005, Validation Loss Current: 9.2176, Validation Loss AVG: 9.2176, lr: 0.001
Epoch [13/100], Training Loss: 7.8780, Validation Loss Current: 9.1778, Validation Loss AVG: 9.1778, lr: 0.001
Epoch [14/100], Training Loss: 9.4816, Validation Loss Current: 10.2342, Validation Loss AVG: 10.2342, lr: 0.001
Epoch [15/100], Training Loss: 8.1546, Validation Loss Current: 10.0036, Validation Loss AVG: 10.0036, lr: 0.001
Epoch [16/100], Training Loss: 5.2913, Validation Loss Current: 9.2198, Validation Loss AVG: 9.2198, lr: 0.001
Epoch [17/100], Training Loss: 5.3540, Validation Loss Current: 9.0706, Validation Loss AVG: 9.0706, lr: 0.001
Epoch [18/100], Training Loss: 7.6922, Validation Loss Current: 10.8472, Validation Loss AVG: 10.8472, lr: 0.001
Epoch [19/100], Training Loss: 5.9525, Validation Loss Current: 10.0883, Validation Loss AVG: 10.0883, lr: 0.001
Epoch [20/100], Training Loss: 5.8579, Validation Loss Current: 13.3435, Validation Loss AVG: 13.3435, lr: 0.001
Epoch [21/100], Training Loss: 9.7881, Validation Loss Current: 11.1352, Validation Loss AVG: 11.1352, lr: 0.001
Epoch [22/100], Training Loss: 7.1346, Validation Loss Current: 10.9960, Validation Loss AVG: 10.9960, lr: 0.001
Epoch [23/100], Training Loss: 4.9272, Validation Loss Current: 10.3546, Validation Loss AVG: 10.3546, lr: 0.001
Epoch [24/100], Training Loss: 4.9767, Validation Loss Current: 10.8214, Validation Loss AVG: 10.8214, lr: 0.001
Epoch [25/100], Training Loss: 4.4359, Validation Loss Current: 12.3541, Validation Loss AVG: 12.3541, lr: 0.001
Epoch [26/100], Training Loss: 4.8842, Validation Loss Current: 10.9383, Validation Loss AVG: 10.9383, lr: 0.001
Epoch [27/100], Training Loss: 4.4586, Validation Loss Current: 10.4280, Validation Loss AVG: 10.4280, lr: 0.001
Epoch [28/100], Training Loss: 5.3174, Validation Loss Current: 10.3582, Validation Loss AVG: 10.3582, lr: 0.001
Epoch [29/100], Training Loss: 7.0339, Validation Loss Current: 10.8144, Validation Loss AVG: 10.8144, lr: 0.001
Epoch [30/100], Training Loss: 10.8956, Validation Loss Current: 15.0523, Validation Loss AVG: 15.0523, lr: 0.001
Epoch [31/100], Training Loss: 11.6055, Validation Loss Current: 11.1591, Validation Loss AVG: 11.1591, lr: 0.001
Epoch [32/100], Training Loss: 8.7912, Validation Loss Current: 12.7466, Validation Loss AVG: 12.7466, lr: 0.001
Epoch [33/100], Training Loss: 6.0800, Validation Loss Current: 11.2298, Validation Loss AVG: 11.2298, lr: 0.001
Epoch [34/100], Training Loss: 3.7460, Validation Loss Current: 12.6238, Validation Loss AVG: 12.6238, lr: 0.001
Epoch [35/100], Training Loss: 7.6050, Validation Loss Current: 12.0355, Validation Loss AVG: 12.0355, lr: 0.001
Epoch [36/100], Training Loss: 4.3798, Validation Loss Current: 10.7334, Validation Loss AVG: 10.7334, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 6 Best val accuracy: [0.3907894736842105, 0.4276315789473684, 0.41052631578947363, 0.4230263157894737, 0.3674342105263158, 0.44210526315789467, 0.44703947368421054, 0.46118421052631586, 0.42664473684210524, 0.4302631578947368, 0.43782894736842104, 0.4585526315789473, 0.4858552631578948, 0.4203947368421053, 0.43618421052631573, 0.43684210526315786, 0.46907894736842104, 0.4213815789473684, 0.44013157894736843, 0.3832236842105263, 0.42828947368421055, 0.44671052631578945, 0.4618421052631579, 0.42993421052631586, 0.4095394736842105, 0.4536184210526316, 0.45921052631578946, 0.4513157894736842, 0.46052631578947373, 0.39703947368421055, 0.4276315789473685, 0.4072368421052632, 0.45559210526315785, 0.45065789473684204, 0.37894736842105264, 0.46743421052631584] Best val loss: 8.825570249557495


Current group: 0.8
Epoch [1/100], Training Loss: 29.5955, Validation Loss Current: 11.4579, Validation Loss AVG: 11.4579, lr: 0.001
Epoch [2/100], Training Loss: 29.3648, Validation Loss Current: 14.3076, Validation Loss AVG: 14.3076, lr: 0.001
Epoch [3/100], Training Loss: 20.0362, Validation Loss Current: 9.9734, Validation Loss AVG: 9.9734, lr: 0.001
Epoch [4/100], Training Loss: 15.5952, Validation Loss Current: 10.3522, Validation Loss AVG: 10.3522, lr: 0.001
Epoch [5/100], Training Loss: 11.4832, Validation Loss Current: 9.7013, Validation Loss AVG: 9.7013, lr: 0.001
Epoch [6/100], Training Loss: 9.4866, Validation Loss Current: 10.4206, Validation Loss AVG: 10.4206, lr: 0.001
Epoch [7/100], Training Loss: 10.3237, Validation Loss Current: 10.3287, Validation Loss AVG: 10.3287, lr: 0.001
Epoch [8/100], Training Loss: 8.9146, Validation Loss Current: 9.8215, Validation Loss AVG: 9.8215, lr: 0.001
Epoch [9/100], Training Loss: 7.8958, Validation Loss Current: 10.3619, Validation Loss AVG: 10.3619, lr: 0.001
Epoch [10/100], Training Loss: 9.7926, Validation Loss Current: 14.6544, Validation Loss AVG: 14.6544, lr: 0.001
Epoch [11/100], Training Loss: 8.5988, Validation Loss Current: 10.5925, Validation Loss AVG: 10.5925, lr: 0.001
Epoch [12/100], Training Loss: 6.9217, Validation Loss Current: 9.9058, Validation Loss AVG: 9.9058, lr: 0.001
Epoch [13/100], Training Loss: 5.1114, Validation Loss Current: 11.6042, Validation Loss AVG: 11.6042, lr: 0.001
Epoch [14/100], Training Loss: 3.9186, Validation Loss Current: 10.4519, Validation Loss AVG: 10.4519, lr: 0.001
Epoch [15/100], Training Loss: 4.8554, Validation Loss Current: 10.0204, Validation Loss AVG: 10.0204, lr: 0.001
Epoch [16/100], Training Loss: 7.2907, Validation Loss Current: 14.0270, Validation Loss AVG: 14.0270, lr: 0.001
Epoch [17/100], Training Loss: 7.0433, Validation Loss Current: 11.2998, Validation Loss AVG: 11.2998, lr: 0.001
Epoch [18/100], Training Loss: 9.7272, Validation Loss Current: 13.8599, Validation Loss AVG: 13.8599, lr: 0.001
Epoch [19/100], Training Loss: 4.6303, Validation Loss Current: 11.7697, Validation Loss AVG: 11.7697, lr: 0.001
Epoch [20/100], Training Loss: 3.8278, Validation Loss Current: 14.2163, Validation Loss AVG: 14.2163, lr: 0.001
Epoch [21/100], Training Loss: 4.4753, Validation Loss Current: 12.8963, Validation Loss AVG: 12.8963, lr: 0.001
Epoch [22/100], Training Loss: 8.2833, Validation Loss Current: 11.6673, Validation Loss AVG: 11.6673, lr: 0.001
Epoch [23/100], Training Loss: 9.7304, Validation Loss Current: 17.0878, Validation Loss AVG: 17.0878, lr: 0.001
Epoch [24/100], Training Loss: 5.0224, Validation Loss Current: 12.7807, Validation Loss AVG: 12.7807, lr: 0.001
Epoch [25/100], Training Loss: 2.4559, Validation Loss Current: 12.1407, Validation Loss AVG: 12.1407, lr: 0.001
Epoch [26/100], Training Loss: 1.6744, Validation Loss Current: 12.6448, Validation Loss AVG: 12.6448, lr: 0.001
Epoch [27/100], Training Loss: 2.1510, Validation Loss Current: 13.5538, Validation Loss AVG: 13.5538, lr: 0.001
Epoch [28/100], Training Loss: 4.2294, Validation Loss Current: 12.6569, Validation Loss AVG: 12.6569, lr: 0.001
Epoch [29/100], Training Loss: 2.5842, Validation Loss Current: 12.9150, Validation Loss AVG: 12.9150, lr: 0.001
Epoch [30/100], Training Loss: 1.3561, Validation Loss Current: 11.4054, Validation Loss AVG: 11.4054, lr: 0.001
Epoch [31/100], Training Loss: 0.6476, Validation Loss Current: 11.2903, Validation Loss AVG: 11.2903, lr: 0.001
Epoch [32/100], Training Loss: 1.4373, Validation Loss Current: 13.1444, Validation Loss AVG: 13.1444, lr: 0.001
Epoch [33/100], Training Loss: 5.6381, Validation Loss Current: 11.5500, Validation Loss AVG: 11.5500, lr: 0.001
Epoch [34/100], Training Loss: 6.4917, Validation Loss Current: 13.2056, Validation Loss AVG: 13.2056, lr: 0.001
Epoch [35/100], Training Loss: 4.2736, Validation Loss Current: 12.6096, Validation Loss AVG: 12.6096, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 5 Best val accuracy: [0.3417763157894737, 0.3819078947368421, 0.4546052631578948, 0.43782894736842104, 0.4598684210526315, 0.4375, 0.48190789473684215, 0.4585526315789473, 0.4582236842105264, 0.3973684210526316, 0.44342105263157894, 0.4526315789473684, 0.4565789473684211, 0.48026315789473684, 0.46809210526315786, 0.4526315789473684, 0.45559210526315785, 0.4217105263157895, 0.4671052631578947, 0.40855263157894733, 0.44539473684210523, 0.44506578947368425, 0.38026315789473686, 0.46118421052631575, 0.4427631578947368, 0.4588815789473684, 0.4582236842105264, 0.46743421052631584, 0.42434210526315785, 0.47171052631578947, 0.4740131578947369, 0.4233552631578947, 0.43125, 0.4236842105263158, 0.4338815789473684] Best val loss: 9.70131275653839


Current group: 1
Epoch [1/100], Training Loss: 22.9416, Validation Loss Current: 8.8620, Validation Loss AVG: 12.2261, lr: 0.001
Epoch [2/100], Training Loss: 15.9002, Validation Loss Current: 8.9786, Validation Loss AVG: 13.5874, lr: 0.001
Epoch [3/100], Training Loss: 13.1238, Validation Loss Current: 7.8500, Validation Loss AVG: 12.6387, lr: 0.001
Epoch [4/100], Training Loss: 10.2449, Validation Loss Current: 7.6994, Validation Loss AVG: 11.7825, lr: 0.001
Epoch [5/100], Training Loss: 7.4467, Validation Loss Current: 7.2559, Validation Loss AVG: 13.7777, lr: 0.001
Epoch [6/100], Training Loss: 5.5063, Validation Loss Current: 7.1101, Validation Loss AVG: 11.9826, lr: 0.001
Epoch [7/100], Training Loss: 5.0122, Validation Loss Current: 6.9873, Validation Loss AVG: 11.9838, lr: 0.001
Epoch [8/100], Training Loss: 4.0426, Validation Loss Current: 7.0901, Validation Loss AVG: 13.1862, lr: 0.001
Epoch [9/100], Training Loss: 7.1278, Validation Loss Current: 8.0812, Validation Loss AVG: 14.6145, lr: 0.001
Epoch [10/100], Training Loss: 7.4138, Validation Loss Current: 7.7722, Validation Loss AVG: 14.5769, lr: 0.001
Epoch [11/100], Training Loss: 3.2921, Validation Loss Current: 6.9245, Validation Loss AVG: 12.4439, lr: 0.001
Epoch [12/100], Training Loss: 2.1655, Validation Loss Current: 6.8430, Validation Loss AVG: 13.0292, lr: 0.001
Epoch [13/100], Training Loss: 5.4891, Validation Loss Current: 6.8247, Validation Loss AVG: 14.0563, lr: 0.001
Epoch [14/100], Training Loss: 5.6398, Validation Loss Current: 7.5520, Validation Loss AVG: 13.5568, lr: 0.001
Epoch [15/100], Training Loss: 9.3610, Validation Loss Current: 7.5907, Validation Loss AVG: 14.3168, lr: 0.001
Epoch [16/100], Training Loss: 7.7118, Validation Loss Current: 8.2484, Validation Loss AVG: 13.6783, lr: 0.001
Epoch [17/100], Training Loss: 4.3807, Validation Loss Current: 7.0400, Validation Loss AVG: 12.0657, lr: 0.001
Epoch [18/100], Training Loss: 3.5131, Validation Loss Current: 7.0716, Validation Loss AVG: 13.7643, lr: 0.001
Epoch [19/100], Training Loss: 2.1040, Validation Loss Current: 7.0506, Validation Loss AVG: 12.2759, lr: 0.001
Epoch [20/100], Training Loss: 1.6216, Validation Loss Current: 6.7645, Validation Loss AVG: 13.3689, lr: 0.001
Epoch [21/100], Training Loss: 1.5182, Validation Loss Current: 7.2513, Validation Loss AVG: 11.9751, lr: 0.001
Epoch [22/100], Training Loss: 3.3939, Validation Loss Current: 7.8430, Validation Loss AVG: 13.0909, lr: 0.001
Epoch [23/100], Training Loss: 6.4853, Validation Loss Current: 7.6369, Validation Loss AVG: 13.3494, lr: 0.001
Epoch [24/100], Training Loss: 4.4043, Validation Loss Current: 6.9574, Validation Loss AVG: 15.2293, lr: 0.001
Epoch [25/100], Training Loss: 2.5104, Validation Loss Current: 7.5393, Validation Loss AVG: 15.3521, lr: 0.001
Epoch [26/100], Training Loss: 1.2650, Validation Loss Current: 7.2704, Validation Loss AVG: 13.9341, lr: 0.001
Epoch [27/100], Training Loss: 1.4715, Validation Loss Current: 6.7484, Validation Loss AVG: 13.2732, lr: 0.001
Epoch [28/100], Training Loss: 3.4029, Validation Loss Current: 7.8718, Validation Loss AVG: 14.6945, lr: 0.001
Epoch [29/100], Training Loss: 4.5877, Validation Loss Current: 7.8426, Validation Loss AVG: 16.9101, lr: 0.001
Epoch [30/100], Training Loss: 2.8674, Validation Loss Current: 7.9141, Validation Loss AVG: 13.8323, lr: 0.001
Epoch [31/100], Training Loss: 7.1944, Validation Loss Current: 7.7365, Validation Loss AVG: 16.3258, lr: 0.001
Epoch [32/100], Training Loss: 2.8782, Validation Loss Current: 7.6870, Validation Loss AVG: 15.8553, lr: 0.001
Epoch [33/100], Training Loss: 2.9131, Validation Loss Current: 7.8377, Validation Loss AVG: 18.5909, lr: 0.001
Epoch [34/100], Training Loss: 1.9598, Validation Loss Current: 7.0471, Validation Loss AVG: 15.6317, lr: 0.001
Epoch [35/100], Training Loss: 3.5584, Validation Loss Current: 7.5230, Validation Loss AVG: 16.2604, lr: 0.001
Epoch [36/100], Training Loss: 2.7752, Validation Loss Current: 7.8419, Validation Loss AVG: 15.6744, lr: 0.001
Epoch [37/100], Training Loss: 2.1973, Validation Loss Current: 7.0483, Validation Loss AVG: 14.2569, lr: 0.001
Epoch [38/100], Training Loss: 2.7278, Validation Loss Current: 8.0759, Validation Loss AVG: 20.1057, lr: 0.001
Epoch [39/100], Training Loss: 4.3149, Validation Loss Current: 7.5017, Validation Loss AVG: 15.5429, lr: 0.001
Epoch [40/100], Training Loss: 3.3396, Validation Loss Current: 8.4623, Validation Loss AVG: 17.6999, lr: 0.001
Epoch [41/100], Training Loss: 1.4113, Validation Loss Current: 7.1088, Validation Loss AVG: 13.8577, lr: 0.001
Epoch [42/100], Training Loss: 2.0370, Validation Loss Current: 8.0731, Validation Loss AVG: 14.4786, lr: 0.001
Epoch [43/100], Training Loss: 2.7670, Validation Loss Current: 8.4900, Validation Loss AVG: 15.6566, lr: 0.001
Epoch [44/100], Training Loss: 3.8249, Validation Loss Current: 7.9344, Validation Loss AVG: 14.2400, lr: 0.001
Epoch [45/100], Training Loss: 4.0910, Validation Loss Current: 8.0523, Validation Loss AVG: 14.9528, lr: 0.001
Epoch [46/100], Training Loss: 1.4225, Validation Loss Current: 7.9545, Validation Loss AVG: 13.4258, lr: 0.001
Epoch [47/100], Training Loss: 2.8505, Validation Loss Current: 7.7573, Validation Loss AVG: 12.6488, lr: 0.001
Epoch [48/100], Training Loss: 4.5595, Validation Loss Current: 10.5262, Validation Loss AVG: 18.7303, lr: 0.001
Epoch [49/100], Training Loss: 4.1843, Validation Loss Current: 9.7111, Validation Loss AVG: 15.3748, lr: 0.001
Epoch [50/100], Training Loss: 2.0339, Validation Loss Current: 9.2827, Validation Loss AVG: 14.7400, lr: 0.001
Epoch [51/100], Training Loss: 0.8359, Validation Loss Current: 7.4276, Validation Loss AVG: 14.9198, lr: 0.001
Epoch [52/100], Training Loss: 1.6011, Validation Loss Current: 7.9242, Validation Loss AVG: 15.9924, lr: 0.001
Epoch [53/100], Training Loss: 2.9257, Validation Loss Current: 8.9478, Validation Loss AVG: 16.7038, lr: 0.001
Epoch [54/100], Training Loss: 2.1093, Validation Loss Current: 7.7045, Validation Loss AVG: 16.4074, lr: 0.001
Epoch [55/100], Training Loss: 1.9676, Validation Loss Current: 8.0648, Validation Loss AVG: 15.8148, lr: 0.001
Epoch [56/100], Training Loss: 3.4777, Validation Loss Current: 8.3411, Validation Loss AVG: 14.2313, lr: 0.001
Epoch [57/100], Training Loss: 8.0326, Validation Loss Current: 9.8295, Validation Loss AVG: 17.6834, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 27 Best val accuracy: [0.5493421052631579, 0.5838815789473685, 0.5789473684210527, 0.5394736842105263, 0.6069078947368421, 0.6036184210526315, 0.6200657894736842, 0.6282894736842105, 0.5526315789473685, 0.5756578947368421, 0.5888157894736842, 0.6282894736842105, 0.6299342105263158, 0.587171052631579, 0.5970394736842105, 0.587171052631579, 0.6134868421052632, 0.6381578947368421, 0.6348684210526315, 0.649671052631579, 0.6414473684210527, 0.6069078947368421, 0.587171052631579, 0.6282894736842105, 0.6299342105263158, 0.625, 0.6414473684210527, 0.5970394736842105, 0.6118421052631579, 0.625, 0.625, 0.6118421052631579, 0.6217105263157895, 0.6398026315789473, 0.6217105263157895, 0.6167763157894737, 0.6398026315789473, 0.6398026315789473, 0.6217105263157895, 0.5805921052631579, 0.6398026315789473, 0.6233552631578947, 0.6233552631578947, 0.6430921052631579, 0.6134868421052632, 0.6085526315789473, 0.618421052631579, 0.5509868421052632, 0.5740131578947368, 0.5986842105263158, 0.6101973684210527, 0.6019736842105263, 0.6118421052631579, 0.6101973684210527, 0.6447368421052632, 0.6233552631578947, 0.600328947368421] Best val loss: 6.748383641242981


----- Training resnet18 with sequence: [0.6, 0.8, 1] -----
Current group: 0.6
Epoch [1/134], Training Loss: 40.3832, Validation Loss Current: 10.0400, Validation Loss AVG: 10.0400, lr: 0.001
Epoch [2/134], Training Loss: 39.3532, Validation Loss Current: 9.9476, Validation Loss AVG: 9.9476, lr: 0.001
Epoch [3/134], Training Loss: 38.2561, Validation Loss Current: 9.8827, Validation Loss AVG: 9.8827, lr: 0.001
Epoch [4/134], Training Loss: 37.5952, Validation Loss Current: 9.6843, Validation Loss AVG: 9.6843, lr: 0.001
Epoch [5/134], Training Loss: 36.5887, Validation Loss Current: 9.4360, Validation Loss AVG: 9.4360, lr: 0.001
Epoch [6/134], Training Loss: 35.7334, Validation Loss Current: 9.2839, Validation Loss AVG: 9.2839, lr: 0.001
Epoch [7/134], Training Loss: 34.1937, Validation Loss Current: 9.1725, Validation Loss AVG: 9.1725, lr: 0.001
Epoch [8/134], Training Loss: 32.7792, Validation Loss Current: 9.2623, Validation Loss AVG: 9.2623, lr: 0.001
Epoch [9/134], Training Loss: 31.9100, Validation Loss Current: 9.4071, Validation Loss AVG: 9.4071, lr: 0.001
Epoch [10/134], Training Loss: 30.9014, Validation Loss Current: 8.7806, Validation Loss AVG: 8.7806, lr: 0.001
Epoch [11/134], Training Loss: 30.0742, Validation Loss Current: 8.6299, Validation Loss AVG: 8.6299, lr: 0.001
Epoch [12/134], Training Loss: 29.5134, Validation Loss Current: 8.7704, Validation Loss AVG: 8.7704, lr: 0.001
Epoch [13/134], Training Loss: 29.2346, Validation Loss Current: 9.3202, Validation Loss AVG: 9.3202, lr: 0.001
Epoch [14/134], Training Loss: 29.3697, Validation Loss Current: 8.6520, Validation Loss AVG: 8.6520, lr: 0.001
Epoch [15/134], Training Loss: 28.5154, Validation Loss Current: 8.7673, Validation Loss AVG: 8.7673, lr: 0.001
Epoch [16/134], Training Loss: 26.7285, Validation Loss Current: 8.2622, Validation Loss AVG: 8.2622, lr: 0.001
Epoch [17/134], Training Loss: 26.7186, Validation Loss Current: 8.3187, Validation Loss AVG: 8.3187, lr: 0.001
Epoch [18/134], Training Loss: 24.5023, Validation Loss Current: 9.4097, Validation Loss AVG: 9.4097, lr: 0.001
Epoch [19/134], Training Loss: 24.3286, Validation Loss Current: 8.5766, Validation Loss AVG: 8.5766, lr: 0.001
Epoch [20/134], Training Loss: 22.2473, Validation Loss Current: 8.3755, Validation Loss AVG: 8.3755, lr: 0.001
Epoch [21/134], Training Loss: 22.5809, Validation Loss Current: 9.7711, Validation Loss AVG: 9.7711, lr: 0.001
Epoch [22/134], Training Loss: 23.5408, Validation Loss Current: 9.5918, Validation Loss AVG: 9.5918, lr: 0.001
Epoch [23/134], Training Loss: 24.7878, Validation Loss Current: 9.0226, Validation Loss AVG: 9.0226, lr: 0.001
Epoch [24/134], Training Loss: 22.3065, Validation Loss Current: 8.6561, Validation Loss AVG: 8.6561, lr: 0.001
Epoch [25/134], Training Loss: 22.3747, Validation Loss Current: 8.1052, Validation Loss AVG: 8.1052, lr: 0.001
Epoch [26/134], Training Loss: 21.0205, Validation Loss Current: 9.4615, Validation Loss AVG: 9.4615, lr: 0.001
Epoch [27/134], Training Loss: 19.0481, Validation Loss Current: 8.4745, Validation Loss AVG: 8.4745, lr: 0.001
Epoch [28/134], Training Loss: 18.2153, Validation Loss Current: 7.5319, Validation Loss AVG: 7.5319, lr: 0.001
Epoch [29/134], Training Loss: 18.3999, Validation Loss Current: 7.9446, Validation Loss AVG: 7.9446, lr: 0.001
Epoch [30/134], Training Loss: 16.8557, Validation Loss Current: 8.1158, Validation Loss AVG: 8.1158, lr: 0.001
Epoch [31/134], Training Loss: 16.7871, Validation Loss Current: 8.9023, Validation Loss AVG: 8.9023, lr: 0.001
Epoch [32/134], Training Loss: 15.7707, Validation Loss Current: 9.0688, Validation Loss AVG: 9.0688, lr: 0.001
Epoch [33/134], Training Loss: 16.8101, Validation Loss Current: 7.8977, Validation Loss AVG: 7.8977, lr: 0.001
Epoch [34/134], Training Loss: 14.7263, Validation Loss Current: 8.1633, Validation Loss AVG: 8.1633, lr: 0.001
Epoch [35/134], Training Loss: 15.2288, Validation Loss Current: 10.6724, Validation Loss AVG: 10.6724, lr: 0.001
Epoch [36/134], Training Loss: 14.8365, Validation Loss Current: 8.2157, Validation Loss AVG: 8.2157, lr: 0.001
Epoch [37/134], Training Loss: 13.4900, Validation Loss Current: 8.9059, Validation Loss AVG: 8.9059, lr: 0.001
Epoch [38/134], Training Loss: 12.2909, Validation Loss Current: 8.9067, Validation Loss AVG: 8.9067, lr: 0.001
Epoch [39/134], Training Loss: 12.2453, Validation Loss Current: 10.6207, Validation Loss AVG: 10.6207, lr: 0.001
Epoch [40/134], Training Loss: 13.9148, Validation Loss Current: 9.5754, Validation Loss AVG: 9.5754, lr: 0.001
Epoch [41/134], Training Loss: 10.9917, Validation Loss Current: 9.9290, Validation Loss AVG: 9.9290, lr: 0.001
Epoch [42/134], Training Loss: 8.9860, Validation Loss Current: 8.4481, Validation Loss AVG: 8.4481, lr: 0.001
Epoch [43/134], Training Loss: 7.8327, Validation Loss Current: 11.3325, Validation Loss AVG: 11.3325, lr: 0.001
Epoch [44/134], Training Loss: 8.4868, Validation Loss Current: 8.9275, Validation Loss AVG: 8.9275, lr: 0.001
Epoch [45/134], Training Loss: 8.3649, Validation Loss Current: 9.6851, Validation Loss AVG: 9.6851, lr: 0.001
Epoch [46/134], Training Loss: 8.9812, Validation Loss Current: 9.3131, Validation Loss AVG: 9.3131, lr: 0.001
Epoch [47/134], Training Loss: 8.1294, Validation Loss Current: 15.6127, Validation Loss AVG: 15.6127, lr: 0.001
Epoch [48/134], Training Loss: 8.5224, Validation Loss Current: 12.6542, Validation Loss AVG: 12.6542, lr: 0.001
Epoch [49/134], Training Loss: 7.4705, Validation Loss Current: 10.9026, Validation Loss AVG: 10.9026, lr: 0.001
Epoch [50/134], Training Loss: 13.1900, Validation Loss Current: 12.2801, Validation Loss AVG: 12.2801, lr: 0.001
Epoch [51/134], Training Loss: 9.3944, Validation Loss Current: 11.6847, Validation Loss AVG: 11.6847, lr: 0.001
Epoch [52/134], Training Loss: 11.0823, Validation Loss Current: 12.1138, Validation Loss AVG: 12.1138, lr: 0.001
Epoch [53/134], Training Loss: 10.0154, Validation Loss Current: 10.8650, Validation Loss AVG: 10.8650, lr: 0.001
Epoch [54/134], Training Loss: 8.4809, Validation Loss Current: 9.9233, Validation Loss AVG: 9.9233, lr: 0.001
Epoch [55/134], Training Loss: 7.6749, Validation Loss Current: 10.6055, Validation Loss AVG: 10.6055, lr: 0.001
Epoch [56/134], Training Loss: 6.3241, Validation Loss Current: 10.2637, Validation Loss AVG: 10.2637, lr: 0.001
Epoch [57/134], Training Loss: 5.5555, Validation Loss Current: 11.1276, Validation Loss AVG: 11.1276, lr: 0.001
Epoch [58/134], Training Loss: 6.2427, Validation Loss Current: 11.7186, Validation Loss AVG: 11.7186, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 28 Best val accuracy: [0.2302631578947368, 0.2375, 0.2523026315789474, 0.2552631578947368, 0.3075657894736842, 0.31611842105263155, 0.33421052631578946, 0.3279605263157895, 0.29078947368421054, 0.37072368421052637, 0.375, 0.36315789473684207, 0.3493421052631579, 0.3871710526315789, 0.3805921052631579, 0.43519736842105267, 0.4046052631578948, 0.375, 0.41578947368421054, 0.41052631578947374, 0.3924342105263158, 0.3549342105263158, 0.38980263157894735, 0.3990131578947369, 0.41414473684210523, 0.4134868421052632, 0.4335526315789474, 0.4546052631578948, 0.4526315789473684, 0.45592105263157895, 0.41480263157894737, 0.4342105263157895, 0.45559210526315785, 0.45789473684210524, 0.40625, 0.4453947368421053, 0.4203947368421052, 0.44243421052631576, 0.3993421052631579, 0.4286184210526316, 0.4131578947368421, 0.4578947368421053, 0.43717105263157896, 0.4180921052631579, 0.43717105263157896, 0.44342105263157894, 0.37664473684210525, 0.4141447368421053, 0.42927631578947373, 0.3911184210526316, 0.44013157894736843, 0.42993421052631586, 0.40394736842105267, 0.42894736842105263, 0.41578947368421054, 0.43519736842105267, 0.4394736842105263, 0.4220394736842105] Best val loss: 7.531871032714844


Current group: 0.8
Epoch [1/134], Training Loss: 24.1329, Validation Loss Current: 9.0496, Validation Loss AVG: 9.0496, lr: 0.001
Epoch [2/134], Training Loss: 17.7127, Validation Loss Current: 9.7181, Validation Loss AVG: 9.7181, lr: 0.001
Epoch [3/134], Training Loss: 14.0072, Validation Loss Current: 8.8353, Validation Loss AVG: 8.8353, lr: 0.001
Epoch [4/134], Training Loss: 11.1619, Validation Loss Current: 13.3912, Validation Loss AVG: 13.3912, lr: 0.001
Epoch [5/134], Training Loss: 10.8656, Validation Loss Current: 10.3994, Validation Loss AVG: 10.3994, lr: 0.001
Epoch [6/134], Training Loss: 8.5936, Validation Loss Current: 9.5412, Validation Loss AVG: 9.5412, lr: 0.001
Epoch [7/134], Training Loss: 8.8770, Validation Loss Current: 8.6358, Validation Loss AVG: 8.6358, lr: 0.001
Epoch [8/134], Training Loss: 9.9153, Validation Loss Current: 12.6816, Validation Loss AVG: 12.6816, lr: 0.001
Epoch [9/134], Training Loss: 8.5871, Validation Loss Current: 10.3125, Validation Loss AVG: 10.3125, lr: 0.001
Epoch [10/134], Training Loss: 7.0507, Validation Loss Current: 10.5819, Validation Loss AVG: 10.5819, lr: 0.001
Epoch [11/134], Training Loss: 6.6143, Validation Loss Current: 10.6051, Validation Loss AVG: 10.6051, lr: 0.001
Epoch [12/134], Training Loss: 5.0964, Validation Loss Current: 9.8501, Validation Loss AVG: 9.8501, lr: 0.001
Epoch [13/134], Training Loss: 5.2874, Validation Loss Current: 10.1944, Validation Loss AVG: 10.1944, lr: 0.001
Epoch [14/134], Training Loss: 5.8142, Validation Loss Current: 11.8550, Validation Loss AVG: 11.8550, lr: 0.001
Epoch [15/134], Training Loss: 3.7994, Validation Loss Current: 9.8165, Validation Loss AVG: 9.8165, lr: 0.001
Epoch [16/134], Training Loss: 2.6907, Validation Loss Current: 10.1049, Validation Loss AVG: 10.1049, lr: 0.001
Epoch [17/134], Training Loss: 2.8777, Validation Loss Current: 10.7085, Validation Loss AVG: 10.7085, lr: 0.001
Epoch [18/134], Training Loss: 3.4050, Validation Loss Current: 11.8187, Validation Loss AVG: 11.8187, lr: 0.001
Epoch [19/134], Training Loss: 9.1210, Validation Loss Current: 13.8421, Validation Loss AVG: 13.8421, lr: 0.001
Epoch [20/134], Training Loss: 9.3526, Validation Loss Current: 10.0690, Validation Loss AVG: 10.0690, lr: 0.001
Epoch [21/134], Training Loss: 7.0161, Validation Loss Current: 11.6690, Validation Loss AVG: 11.6690, lr: 0.001
Epoch [22/134], Training Loss: 2.8219, Validation Loss Current: 11.6595, Validation Loss AVG: 11.6595, lr: 0.001
Epoch [23/134], Training Loss: 2.4691, Validation Loss Current: 10.2945, Validation Loss AVG: 10.2945, lr: 0.001
Epoch [24/134], Training Loss: 6.1180, Validation Loss Current: 12.0087, Validation Loss AVG: 12.0087, lr: 0.001
Epoch [25/134], Training Loss: 6.0492, Validation Loss Current: 10.7369, Validation Loss AVG: 10.7369, lr: 0.001
Epoch [26/134], Training Loss: 5.1232, Validation Loss Current: 13.1404, Validation Loss AVG: 13.1404, lr: 0.001
Epoch [27/134], Training Loss: 8.6476, Validation Loss Current: 12.2638, Validation Loss AVG: 12.2638, lr: 0.001
Epoch [28/134], Training Loss: 5.7522, Validation Loss Current: 15.0989, Validation Loss AVG: 15.0989, lr: 0.001
Epoch [29/134], Training Loss: 10.2594, Validation Loss Current: 11.5727, Validation Loss AVG: 11.5727, lr: 0.001
Epoch [30/134], Training Loss: 7.7371, Validation Loss Current: 12.7627, Validation Loss AVG: 12.7627, lr: 0.001
Epoch [31/134], Training Loss: 10.9440, Validation Loss Current: 10.0174, Validation Loss AVG: 10.0174, lr: 0.001
Epoch [32/134], Training Loss: 8.9588, Validation Loss Current: 12.0056, Validation Loss AVG: 12.0056, lr: 0.001
Epoch [33/134], Training Loss: 5.9037, Validation Loss Current: 13.4520, Validation Loss AVG: 13.4520, lr: 0.001
Epoch [34/134], Training Loss: 3.7334, Validation Loss Current: 10.8520, Validation Loss AVG: 10.8520, lr: 0.001
Epoch [35/134], Training Loss: 4.1241, Validation Loss Current: 14.0628, Validation Loss AVG: 14.0628, lr: 0.001
Epoch [36/134], Training Loss: 5.2679, Validation Loss Current: 12.8326, Validation Loss AVG: 12.8326, lr: 0.001
Epoch [37/134], Training Loss: 4.8628, Validation Loss Current: 12.0727, Validation Loss AVG: 12.0727, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 7 Best val accuracy: [0.4493421052631579, 0.4253289473684211, 0.46611842105263157, 0.40690789473684214, 0.4440789473684211, 0.46743421052631573, 0.46447368421052626, 0.3595394736842105, 0.4460526315789474, 0.43519736842105267, 0.43782894736842104, 0.4743421052631579, 0.4588815789473684, 0.43947368421052635, 0.44243421052631576, 0.47171052631578947, 0.4569078947368421, 0.44605263157894737, 0.4128289473684211, 0.45592105263157895, 0.4338815789473685, 0.43684210526315786, 0.475, 0.45230263157894735, 0.46743421052631573, 0.4319078947368421, 0.4463815789473685, 0.42105263157894735, 0.4180921052631579, 0.41578947368421054, 0.4536184210526316, 0.4223684210526316, 0.42631578947368426, 0.4605263157894736, 0.4348684210526315, 0.4437500000000001, 0.4220394736842105] Best val loss: 8.635779309272767


Current group: 1
Epoch [1/134], Training Loss: 20.5834, Validation Loss Current: 8.8810, Validation Loss AVG: 15.3447, lr: 0.001
Epoch [2/134], Training Loss: 14.1490, Validation Loss Current: 7.5573, Validation Loss AVG: 11.7159, lr: 0.001
Epoch [3/134], Training Loss: 11.3493, Validation Loss Current: 6.9500, Validation Loss AVG: 11.6522, lr: 0.001
Epoch [4/134], Training Loss: 11.1068, Validation Loss Current: 9.7025, Validation Loss AVG: 14.2274, lr: 0.001
Epoch [5/134], Training Loss: 9.0464, Validation Loss Current: 7.4037, Validation Loss AVG: 13.1337, lr: 0.001
Epoch [6/134], Training Loss: 5.6660, Validation Loss Current: 7.1471, Validation Loss AVG: 12.4014, lr: 0.001
Epoch [7/134], Training Loss: 4.7207, Validation Loss Current: 6.7805, Validation Loss AVG: 12.3509, lr: 0.001
Epoch [8/134], Training Loss: 4.2679, Validation Loss Current: 7.2468, Validation Loss AVG: 12.5022, lr: 0.001
Epoch [9/134], Training Loss: 4.4959, Validation Loss Current: 7.1907, Validation Loss AVG: 11.7150, lr: 0.001
Epoch [10/134], Training Loss: 3.5649, Validation Loss Current: 6.9590, Validation Loss AVG: 14.0455, lr: 0.001
Epoch [11/134], Training Loss: 5.2435, Validation Loss Current: 7.7922, Validation Loss AVG: 12.0050, lr: 0.001
Epoch [12/134], Training Loss: 9.1058, Validation Loss Current: 9.5509, Validation Loss AVG: 17.5313, lr: 0.001
Epoch [13/134], Training Loss: 8.2020, Validation Loss Current: 7.8974, Validation Loss AVG: 11.0271, lr: 0.001
Epoch [14/134], Training Loss: 3.9247, Validation Loss Current: 7.2173, Validation Loss AVG: 12.6501, lr: 0.001
Epoch [15/134], Training Loss: 2.3708, Validation Loss Current: 6.7347, Validation Loss AVG: 13.1657, lr: 0.001
Epoch [16/134], Training Loss: 5.0612, Validation Loss Current: 7.3299, Validation Loss AVG: 15.3897, lr: 0.001
Epoch [17/134], Training Loss: 5.6696, Validation Loss Current: 9.0548, Validation Loss AVG: 15.1854, lr: 0.001
Epoch [18/134], Training Loss: 3.0543, Validation Loss Current: 6.7685, Validation Loss AVG: 11.7874, lr: 0.001
Epoch [19/134], Training Loss: 2.1620, Validation Loss Current: 7.2106, Validation Loss AVG: 12.6375, lr: 0.001
Epoch [20/134], Training Loss: 1.5033, Validation Loss Current: 6.8285, Validation Loss AVG: 12.3180, lr: 0.001
Epoch [21/134], Training Loss: 3.4858, Validation Loss Current: 7.4088, Validation Loss AVG: 16.8575, lr: 0.001
Epoch [22/134], Training Loss: 2.7374, Validation Loss Current: 7.3258, Validation Loss AVG: 11.6339, lr: 0.001
Epoch [23/134], Training Loss: 3.3881, Validation Loss Current: 7.5796, Validation Loss AVG: 13.0749, lr: 0.001
Epoch [24/134], Training Loss: 3.1974, Validation Loss Current: 7.1843, Validation Loss AVG: 16.5492, lr: 0.001
Epoch [25/134], Training Loss: 2.3220, Validation Loss Current: 7.8472, Validation Loss AVG: 13.1411, lr: 0.001
Epoch [26/134], Training Loss: 3.0962, Validation Loss Current: 9.5038, Validation Loss AVG: 15.0255, lr: 0.001
Epoch [27/134], Training Loss: 3.6258, Validation Loss Current: 7.7845, Validation Loss AVG: 16.0524, lr: 0.001
Epoch [28/134], Training Loss: 2.6271, Validation Loss Current: 8.5320, Validation Loss AVG: 12.7439, lr: 0.001
Epoch [29/134], Training Loss: 1.0801, Validation Loss Current: 7.3754, Validation Loss AVG: 15.1496, lr: 0.001
Epoch [30/134], Training Loss: 1.4000, Validation Loss Current: 7.0425, Validation Loss AVG: 14.0302, lr: 0.001
Epoch [31/134], Training Loss: 1.8955, Validation Loss Current: 7.8151, Validation Loss AVG: 15.5355, lr: 0.001
Epoch [32/134], Training Loss: 3.0741, Validation Loss Current: 8.3066, Validation Loss AVG: 14.4353, lr: 0.001
Epoch [33/134], Training Loss: 5.6146, Validation Loss Current: 11.7725, Validation Loss AVG: 20.5534, lr: 0.001
Epoch [34/134], Training Loss: 10.5087, Validation Loss Current: 8.6742, Validation Loss AVG: 14.3416, lr: 0.001
Epoch [35/134], Training Loss: 6.4576, Validation Loss Current: 8.7460, Validation Loss AVG: 14.9860, lr: 0.001
Epoch [36/134], Training Loss: 3.6795, Validation Loss Current: 8.0659, Validation Loss AVG: 14.4561, lr: 0.001
Epoch [37/134], Training Loss: 3.4141, Validation Loss Current: 8.2125, Validation Loss AVG: 15.5146, lr: 0.001
Epoch [38/134], Training Loss: 4.6637, Validation Loss Current: 7.3093, Validation Loss AVG: 14.1210, lr: 0.001
Epoch [39/134], Training Loss: 6.7020, Validation Loss Current: 9.4751, Validation Loss AVG: 16.7957, lr: 0.001
Epoch [40/134], Training Loss: 6.1295, Validation Loss Current: 9.5402, Validation Loss AVG: 13.9326, lr: 0.001
Epoch [41/134], Training Loss: 4.9986, Validation Loss Current: 7.5949, Validation Loss AVG: 13.5861, lr: 0.001
Epoch [42/134], Training Loss: 3.2443, Validation Loss Current: 6.9955, Validation Loss AVG: 13.7525, lr: 0.001
Epoch [43/134], Training Loss: 3.0801, Validation Loss Current: 8.6686, Validation Loss AVG: 16.2927, lr: 0.001
Epoch [44/134], Training Loss: 3.9779, Validation Loss Current: 7.0441, Validation Loss AVG: 12.9742, lr: 0.001
Epoch [45/134], Training Loss: 3.5129, Validation Loss Current: 9.1824, Validation Loss AVG: 13.9762, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 15 Best val accuracy: [0.5098684210526315, 0.569078947368421, 0.5953947368421053, 0.5164473684210527, 0.5970394736842105, 0.6217105263157895, 0.6069078947368421, 0.6233552631578947, 0.6167763157894737, 0.6332236842105263, 0.587171052631579, 0.5197368421052632, 0.587171052631579, 0.6200657894736842, 0.6398026315789473, 0.5921052631578947, 0.5805921052631579, 0.6167763157894737, 0.618421052631579, 0.6447368421052632, 0.6167763157894737, 0.625, 0.6332236842105263, 0.6233552631578947, 0.6233552631578947, 0.5526315789473685, 0.6101973684210527, 0.6118421052631579, 0.6200657894736842, 0.6398026315789473, 0.625, 0.5953947368421053, 0.5608552631578947, 0.5740131578947368, 0.5707236842105263, 0.5855263157894737, 0.6101973684210527, 0.631578947368421, 0.5822368421052632, 0.5625, 0.6167763157894737, 0.6151315789473685, 0.587171052631579, 0.6052631578947368, 0.6101973684210527] Best val loss: 6.73469340801239


----- Training resnet18 with sequence: [0.8, 1] -----
Current group: 0.8
Epoch [1/200], Training Loss: 40.7629, Validation Loss Current: 10.0290, Validation Loss AVG: 10.0290, lr: 0.001
Epoch [2/200], Training Loss: 39.3515, Validation Loss Current: 9.9818, Validation Loss AVG: 9.9818, lr: 0.001
Epoch [3/200], Training Loss: 38.6395, Validation Loss Current: 9.8181, Validation Loss AVG: 9.8181, lr: 0.001
Epoch [4/200], Training Loss: 37.1030, Validation Loss Current: 9.6709, Validation Loss AVG: 9.6709, lr: 0.001
Epoch [5/200], Training Loss: 35.0271, Validation Loss Current: 9.3567, Validation Loss AVG: 9.3567, lr: 0.001
Epoch [6/200], Training Loss: 33.8391, Validation Loss Current: 9.2539, Validation Loss AVG: 9.2539, lr: 0.001
Epoch [7/200], Training Loss: 32.9359, Validation Loss Current: 9.0630, Validation Loss AVG: 9.0630, lr: 0.001
Epoch [8/200], Training Loss: 31.4802, Validation Loss Current: 9.2210, Validation Loss AVG: 9.2210, lr: 0.001
Epoch [9/200], Training Loss: 30.4558, Validation Loss Current: 8.9210, Validation Loss AVG: 8.9210, lr: 0.001
Epoch [10/200], Training Loss: 30.0268, Validation Loss Current: 9.3745, Validation Loss AVG: 9.3745, lr: 0.001
Epoch [11/200], Training Loss: 28.0410, Validation Loss Current: 9.6597, Validation Loss AVG: 9.6597, lr: 0.001
Epoch [12/200], Training Loss: 26.8667, Validation Loss Current: 9.1879, Validation Loss AVG: 9.1879, lr: 0.001
Epoch [13/200], Training Loss: 26.9535, Validation Loss Current: 9.5846, Validation Loss AVG: 9.5846, lr: 0.001
Epoch [14/200], Training Loss: 25.3315, Validation Loss Current: 10.5748, Validation Loss AVG: 10.5748, lr: 0.001
Epoch [15/200], Training Loss: 24.4936, Validation Loss Current: 10.1794, Validation Loss AVG: 10.1794, lr: 0.001
Epoch [16/200], Training Loss: 24.4959, Validation Loss Current: 9.1684, Validation Loss AVG: 9.1684, lr: 0.001
Epoch [17/200], Training Loss: 25.4613, Validation Loss Current: 9.2129, Validation Loss AVG: 9.2129, lr: 0.001
Epoch [18/200], Training Loss: 24.0711, Validation Loss Current: 9.0549, Validation Loss AVG: 9.0549, lr: 0.001
Epoch [19/200], Training Loss: 22.4457, Validation Loss Current: 8.1726, Validation Loss AVG: 8.1726, lr: 0.001
Epoch [20/200], Training Loss: 21.2301, Validation Loss Current: 9.9974, Validation Loss AVG: 9.9974, lr: 0.001
Epoch [21/200], Training Loss: 20.8651, Validation Loss Current: 8.9317, Validation Loss AVG: 8.9317, lr: 0.001
Epoch [22/200], Training Loss: 22.3879, Validation Loss Current: 11.3553, Validation Loss AVG: 11.3553, lr: 0.001
Epoch [23/200], Training Loss: 21.6019, Validation Loss Current: 8.6469, Validation Loss AVG: 8.6469, lr: 0.001
Epoch [24/200], Training Loss: 21.3064, Validation Loss Current: 11.1296, Validation Loss AVG: 11.1296, lr: 0.001
Epoch [25/200], Training Loss: 21.2593, Validation Loss Current: 10.1524, Validation Loss AVG: 10.1524, lr: 0.001
Epoch [26/200], Training Loss: 19.9956, Validation Loss Current: 8.4729, Validation Loss AVG: 8.4729, lr: 0.001
Epoch [27/200], Training Loss: 20.3501, Validation Loss Current: 10.1242, Validation Loss AVG: 10.1242, lr: 0.001
Epoch [28/200], Training Loss: 18.3749, Validation Loss Current: 8.5195, Validation Loss AVG: 8.5195, lr: 0.001
Epoch [29/200], Training Loss: 16.0090, Validation Loss Current: 9.0350, Validation Loss AVG: 9.0350, lr: 0.001
Epoch [30/200], Training Loss: 15.6150, Validation Loss Current: 9.2493, Validation Loss AVG: 9.2493, lr: 0.001
Epoch [31/200], Training Loss: 16.6606, Validation Loss Current: 8.2048, Validation Loss AVG: 8.2048, lr: 0.001
Epoch [32/200], Training Loss: 15.3768, Validation Loss Current: 9.3846, Validation Loss AVG: 9.3846, lr: 0.001
Epoch [33/200], Training Loss: 13.9655, Validation Loss Current: 9.3301, Validation Loss AVG: 9.3301, lr: 0.001
Epoch [34/200], Training Loss: 13.5703, Validation Loss Current: 9.0118, Validation Loss AVG: 9.0118, lr: 0.001
Epoch [35/200], Training Loss: 13.5729, Validation Loss Current: 10.0905, Validation Loss AVG: 10.0905, lr: 0.001
Epoch [36/200], Training Loss: 12.6057, Validation Loss Current: 8.2706, Validation Loss AVG: 8.2706, lr: 0.001
Epoch [37/200], Training Loss: 11.3531, Validation Loss Current: 8.5418, Validation Loss AVG: 8.5418, lr: 0.001
Epoch [38/200], Training Loss: 11.0016, Validation Loss Current: 9.8416, Validation Loss AVG: 9.8416, lr: 0.001
Epoch [39/200], Training Loss: 10.9320, Validation Loss Current: 9.2031, Validation Loss AVG: 9.2031, lr: 0.001
Epoch [40/200], Training Loss: 10.4500, Validation Loss Current: 9.9854, Validation Loss AVG: 9.9854, lr: 0.001
Epoch [41/200], Training Loss: 8.6119, Validation Loss Current: 8.7514, Validation Loss AVG: 8.7514, lr: 0.001
Epoch [42/200], Training Loss: 8.1712, Validation Loss Current: 10.2268, Validation Loss AVG: 10.2268, lr: 0.001
Epoch [43/200], Training Loss: 9.1952, Validation Loss Current: 11.4892, Validation Loss AVG: 11.4892, lr: 0.001
Epoch [44/200], Training Loss: 7.7612, Validation Loss Current: 10.1832, Validation Loss AVG: 10.1832, lr: 0.001
Epoch [45/200], Training Loss: 7.0409, Validation Loss Current: 9.6165, Validation Loss AVG: 9.6165, lr: 0.001
Epoch [46/200], Training Loss: 7.8541, Validation Loss Current: 9.9928, Validation Loss AVG: 9.9928, lr: 0.001
Epoch [47/200], Training Loss: 8.8574, Validation Loss Current: 12.4268, Validation Loss AVG: 12.4268, lr: 0.001
Epoch [48/200], Training Loss: 7.7058, Validation Loss Current: 11.4713, Validation Loss AVG: 11.4713, lr: 0.001
Epoch [49/200], Training Loss: 5.5859, Validation Loss Current: 12.5818, Validation Loss AVG: 12.5818, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 19 Best val accuracy: [0.23059210526315788, 0.2351973684210526, 0.26315789473684215, 0.27499999999999997, 0.31019736842105267, 0.3273026315789474, 0.3286184210526316, 0.3381578947368421, 0.3697368421052632, 0.3592105263157895, 0.34309210526315786, 0.3759868421052631, 0.36644736842105263, 0.3388157894736842, 0.3680921052631579, 0.36578947368421055, 0.3559210526315789, 0.39703947368421055, 0.41381578947368425, 0.3805921052631579, 0.40394736842105256, 0.35296052631578945, 0.3720394736842106, 0.3447368421052632, 0.38651315789473684, 0.39473684210526316, 0.4167763157894737, 0.40230263157894736, 0.4036184210526315, 0.4220394736842105, 0.4213815789473684, 0.4128289473684211, 0.4213815789473684, 0.4302631578947368, 0.39934210526315794, 0.44243421052631576, 0.43453947368421053, 0.45723684210526316, 0.41776315789473684, 0.4407894736842105, 0.46940789473684214, 0.4276315789473684, 0.3944078947368421, 0.4115131578947368, 0.43355263157894736, 0.42828947368421055, 0.3940789473684211, 0.42828947368421055, 0.36151315789473687] Best val loss: 8.172581553459167


Current group: 1
Epoch [1/200], Training Loss: 19.4199, Validation Loss Current: 7.3536, Validation Loss AVG: 13.9209, lr: 0.001
Epoch [2/200], Training Loss: 15.6739, Validation Loss Current: 6.4558, Validation Loss AVG: 9.3328, lr: 0.001
Epoch [3/200], Training Loss: 15.7388, Validation Loss Current: 6.9451, Validation Loss AVG: 11.2248, lr: 0.001
Epoch [4/200], Training Loss: 13.4462, Validation Loss Current: 6.5465, Validation Loss AVG: 10.3998, lr: 0.001
Epoch [5/200], Training Loss: 12.6076, Validation Loss Current: 6.2837, Validation Loss AVG: 10.4253, lr: 0.001
Epoch [6/200], Training Loss: 10.8644, Validation Loss Current: 6.7746, Validation Loss AVG: 12.0506, lr: 0.001
Epoch [7/200], Training Loss: 9.6955, Validation Loss Current: 6.3916, Validation Loss AVG: 10.8697, lr: 0.001
Epoch [8/200], Training Loss: 9.9724, Validation Loss Current: 7.7633, Validation Loss AVG: 16.6164, lr: 0.001
Epoch [9/200], Training Loss: 9.1831, Validation Loss Current: 8.3957, Validation Loss AVG: 12.2114, lr: 0.001
Epoch [10/200], Training Loss: 8.9876, Validation Loss Current: 7.4121, Validation Loss AVG: 11.6925, lr: 0.001
Epoch [11/200], Training Loss: 10.3484, Validation Loss Current: 8.6566, Validation Loss AVG: 12.5441, lr: 0.001
Epoch [12/200], Training Loss: 10.0645, Validation Loss Current: 6.5143, Validation Loss AVG: 9.9901, lr: 0.001
Epoch [13/200], Training Loss: 9.8547, Validation Loss Current: 6.8836, Validation Loss AVG: 11.7690, lr: 0.001
Epoch [14/200], Training Loss: 6.2314, Validation Loss Current: 6.7971, Validation Loss AVG: 12.3626, lr: 0.001
Epoch [15/200], Training Loss: 5.6165, Validation Loss Current: 7.8771, Validation Loss AVG: 12.4661, lr: 0.001
Epoch [16/200], Training Loss: 11.0428, Validation Loss Current: 7.7077, Validation Loss AVG: 11.0877, lr: 0.001
Epoch [17/200], Training Loss: 9.0035, Validation Loss Current: 7.4682, Validation Loss AVG: 10.4990, lr: 0.001
Epoch [18/200], Training Loss: 5.6512, Validation Loss Current: 7.5735, Validation Loss AVG: 11.2299, lr: 0.001
Epoch [19/200], Training Loss: 5.0015, Validation Loss Current: 6.7023, Validation Loss AVG: 11.4511, lr: 0.001
Epoch [20/200], Training Loss: 6.0817, Validation Loss Current: 8.0029, Validation Loss AVG: 16.6095, lr: 0.001
Epoch [21/200], Training Loss: 5.3518, Validation Loss Current: 7.4325, Validation Loss AVG: 12.8492, lr: 0.001
Epoch [22/200], Training Loss: 5.1781, Validation Loss Current: 7.8897, Validation Loss AVG: 12.4777, lr: 0.001
Epoch [23/200], Training Loss: 6.9006, Validation Loss Current: 10.7143, Validation Loss AVG: 17.3056, lr: 0.001
Epoch [24/200], Training Loss: 11.5499, Validation Loss Current: 7.9230, Validation Loss AVG: 11.2681, lr: 0.001
Epoch [25/200], Training Loss: 10.3165, Validation Loss Current: 7.4681, Validation Loss AVG: 11.3396, lr: 0.001
Epoch [26/200], Training Loss: 9.2313, Validation Loss Current: 8.1171, Validation Loss AVG: 15.1951, lr: 0.001
Epoch [27/200], Training Loss: 5.3840, Validation Loss Current: 7.2926, Validation Loss AVG: 11.6174, lr: 0.001
Epoch [28/200], Training Loss: 3.0900, Validation Loss Current: 7.4493, Validation Loss AVG: 12.7073, lr: 0.001
Epoch [29/200], Training Loss: 2.2936, Validation Loss Current: 6.9223, Validation Loss AVG: 12.0632, lr: 0.001
Epoch [30/200], Training Loss: 4.0127, Validation Loss Current: 6.7446, Validation Loss AVG: 11.0434, lr: 0.001
Epoch [31/200], Training Loss: 4.3552, Validation Loss Current: 7.9648, Validation Loss AVG: 12.9528, lr: 0.001
Epoch [32/200], Training Loss: 5.3880, Validation Loss Current: 8.1094, Validation Loss AVG: 12.0356, lr: 0.001
Epoch [33/200], Training Loss: 4.2879, Validation Loss Current: 7.6950, Validation Loss AVG: 16.9391, lr: 0.001
Epoch [34/200], Training Loss: 4.2545, Validation Loss Current: 7.7595, Validation Loss AVG: 11.0828, lr: 0.001
Epoch [35/200], Training Loss: 2.4783, Validation Loss Current: 7.3086, Validation Loss AVG: 13.6491, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 5 Best val accuracy: [0.5608552631578947, 0.5904605263157895, 0.5625, 0.587171052631579, 0.5970394736842105, 0.5756578947368421, 0.6085526315789473, 0.5493421052631579, 0.5328947368421053, 0.569078947368421, 0.524671052631579, 0.5970394736842105, 0.569078947368421, 0.6282894736842105, 0.53125, 0.5460526315789473, 0.5674342105263158, 0.5805921052631579, 0.6036184210526315, 0.5476973684210527, 0.5855263157894737, 0.5855263157894737, 0.5, 0.5855263157894737, 0.569078947368421, 0.5542763157894737, 0.5625, 0.5773026315789473, 0.5986842105263158, 0.6217105263157895, 0.53125, 0.5805921052631579, 0.5921052631578947, 0.5789473684210527, 0.6036184210526315] Best val loss: 6.283735990524292


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 41.2395, Validation Loss Current: 10.1079, Validation Loss AVG: 10.1101, lr: 0.001
Epoch [2/400], Training Loss: 39.0023, Validation Loss Current: 9.7063, Validation Loss AVG: 10.0301, lr: 0.001
Epoch [3/400], Training Loss: 37.4498, Validation Loss Current: 9.5580, Validation Loss AVG: 10.1082, lr: 0.001
Epoch [4/400], Training Loss: 35.9591, Validation Loss Current: 9.2618, Validation Loss AVG: 11.0431, lr: 0.001
Epoch [5/400], Training Loss: 33.7409, Validation Loss Current: 8.9183, Validation Loss AVG: 9.7423, lr: 0.001
Epoch [6/400], Training Loss: 32.6683, Validation Loss Current: 8.8413, Validation Loss AVG: 10.6215, lr: 0.001
Epoch [7/400], Training Loss: 32.4128, Validation Loss Current: 8.5439, Validation Loss AVG: 10.1367, lr: 0.001
Epoch [8/400], Training Loss: 30.5516, Validation Loss Current: 8.0222, Validation Loss AVG: 9.1010, lr: 0.001
Epoch [9/400], Training Loss: 30.2583, Validation Loss Current: 7.7920, Validation Loss AVG: 9.0822, lr: 0.001
Epoch [10/400], Training Loss: 28.9575, Validation Loss Current: 7.6092, Validation Loss AVG: 9.4896, lr: 0.001
Epoch [11/400], Training Loss: 28.7333, Validation Loss Current: 7.3186, Validation Loss AVG: 8.6769, lr: 0.001
Epoch [12/400], Training Loss: 27.1279, Validation Loss Current: 7.8611, Validation Loss AVG: 9.6758, lr: 0.001
Epoch [13/400], Training Loss: 27.0589, Validation Loss Current: 7.4935, Validation Loss AVG: 12.7470, lr: 0.001
Epoch [14/400], Training Loss: 26.2405, Validation Loss Current: 7.1594, Validation Loss AVG: 9.7633, lr: 0.001
Epoch [15/400], Training Loss: 24.8074, Validation Loss Current: 7.0652, Validation Loss AVG: 10.7070, lr: 0.001
Epoch [16/400], Training Loss: 23.9060, Validation Loss Current: 7.0567, Validation Loss AVG: 9.9186, lr: 0.001
Epoch [17/400], Training Loss: 25.1856, Validation Loss Current: 6.5893, Validation Loss AVG: 8.4193, lr: 0.001
Epoch [18/400], Training Loss: 23.4140, Validation Loss Current: 6.8081, Validation Loss AVG: 11.2236, lr: 0.001
Epoch [19/400], Training Loss: 22.2552, Validation Loss Current: 7.4674, Validation Loss AVG: 11.6898, lr: 0.001
Epoch [20/400], Training Loss: 21.6176, Validation Loss Current: 6.7982, Validation Loss AVG: 11.2943, lr: 0.001
Epoch [21/400], Training Loss: 20.9300, Validation Loss Current: 8.2236, Validation Loss AVG: 12.8830, lr: 0.001
Epoch [22/400], Training Loss: 20.7166, Validation Loss Current: 6.6613, Validation Loss AVG: 10.1884, lr: 0.001
Epoch [23/400], Training Loss: 21.2568, Validation Loss Current: 6.2688, Validation Loss AVG: 9.7515, lr: 0.001
Epoch [24/400], Training Loss: 21.3746, Validation Loss Current: 6.9935, Validation Loss AVG: 10.3574, lr: 0.001
Epoch [25/400], Training Loss: 21.3002, Validation Loss Current: 6.7906, Validation Loss AVG: 11.0658, lr: 0.001
Epoch [26/400], Training Loss: 20.4998, Validation Loss Current: 6.6287, Validation Loss AVG: 12.0326, lr: 0.001
Epoch [27/400], Training Loss: 19.0507, Validation Loss Current: 6.1725, Validation Loss AVG: 10.5052, lr: 0.001
Epoch [28/400], Training Loss: 18.4959, Validation Loss Current: 5.6161, Validation Loss AVG: 7.8886, lr: 0.001
Epoch [29/400], Training Loss: 16.6408, Validation Loss Current: 5.7933, Validation Loss AVG: 9.5646, lr: 0.001
Epoch [30/400], Training Loss: 16.7614, Validation Loss Current: 6.7731, Validation Loss AVG: 13.5498, lr: 0.001
Epoch [31/400], Training Loss: 17.1282, Validation Loss Current: 6.2097, Validation Loss AVG: 9.6301, lr: 0.001
Epoch [32/400], Training Loss: 15.1003, Validation Loss Current: 5.6755, Validation Loss AVG: 8.7829, lr: 0.001
Epoch [33/400], Training Loss: 15.0302, Validation Loss Current: 5.6228, Validation Loss AVG: 10.3241, lr: 0.001
Epoch [34/400], Training Loss: 13.9490, Validation Loss Current: 5.2247, Validation Loss AVG: 8.7775, lr: 0.001
Epoch [35/400], Training Loss: 13.7180, Validation Loss Current: 7.4216, Validation Loss AVG: 12.2854, lr: 0.001
Epoch [36/400], Training Loss: 15.3503, Validation Loss Current: 6.1653, Validation Loss AVG: 9.6173, lr: 0.001
Epoch [37/400], Training Loss: 12.8384, Validation Loss Current: 5.7026, Validation Loss AVG: 8.3459, lr: 0.001
Epoch [38/400], Training Loss: 11.2048, Validation Loss Current: 5.2847, Validation Loss AVG: 10.3125, lr: 0.001
Epoch [39/400], Training Loss: 10.5132, Validation Loss Current: 5.1171, Validation Loss AVG: 8.8134, lr: 0.001
Epoch [40/400], Training Loss: 9.9655, Validation Loss Current: 5.5546, Validation Loss AVG: 8.3691, lr: 0.001
Epoch [41/400], Training Loss: 10.4667, Validation Loss Current: 5.1472, Validation Loss AVG: 9.5983, lr: 0.001
Epoch [42/400], Training Loss: 8.2588, Validation Loss Current: 4.9826, Validation Loss AVG: 9.3018, lr: 0.001
Epoch [43/400], Training Loss: 6.9038, Validation Loss Current: 5.1046, Validation Loss AVG: 10.8728, lr: 0.001
Epoch [44/400], Training Loss: 6.1507, Validation Loss Current: 5.3443, Validation Loss AVG: 11.3700, lr: 0.001
Epoch [45/400], Training Loss: 7.6993, Validation Loss Current: 5.8579, Validation Loss AVG: 10.0930, lr: 0.001
Epoch [46/400], Training Loss: 10.0650, Validation Loss Current: 6.6811, Validation Loss AVG: 10.2050, lr: 0.001
Epoch [47/400], Training Loss: 7.9400, Validation Loss Current: 5.8399, Validation Loss AVG: 12.8678, lr: 0.001
Epoch [48/400], Training Loss: 6.3563, Validation Loss Current: 6.3865, Validation Loss AVG: 9.3881, lr: 0.001
Epoch [49/400], Training Loss: 5.9349, Validation Loss Current: 6.7533, Validation Loss AVG: 11.2035, lr: 0.001
Epoch [50/400], Training Loss: 6.5099, Validation Loss Current: 5.6699, Validation Loss AVG: 11.0650, lr: 0.001
Epoch [51/400], Training Loss: 4.4620, Validation Loss Current: 5.4954, Validation Loss AVG: 11.4494, lr: 0.001
Epoch [52/400], Training Loss: 3.8314, Validation Loss Current: 6.0788, Validation Loss AVG: 12.1643, lr: 0.001
Epoch [53/400], Training Loss: 4.4891, Validation Loss Current: 5.9346, Validation Loss AVG: 12.3766, lr: 0.001
Epoch [54/400], Training Loss: 2.7440, Validation Loss Current: 5.3400, Validation Loss AVG: 10.7813, lr: 0.001
Epoch [55/400], Training Loss: 2.7935, Validation Loss Current: 5.2816, Validation Loss AVG: 11.6254, lr: 0.001
Epoch [56/400], Training Loss: 2.9063, Validation Loss Current: 5.9963, Validation Loss AVG: 10.8750, lr: 0.001
Epoch [57/400], Training Loss: 2.9701, Validation Loss Current: 6.3160, Validation Loss AVG: 9.5246, lr: 0.001
Epoch [58/400], Training Loss: 5.1310, Validation Loss Current: 6.3339, Validation Loss AVG: 13.0950, lr: 0.001
Epoch [59/400], Training Loss: 6.0756, Validation Loss Current: 8.7903, Validation Loss AVG: 17.9680, lr: 0.001
Epoch [60/400], Training Loss: 4.4346, Validation Loss Current: 6.5199, Validation Loss AVG: 11.8219, lr: 0.001
Epoch [61/400], Training Loss: 2.7780, Validation Loss Current: 6.1397, Validation Loss AVG: 9.7835, lr: 0.001
Epoch [62/400], Training Loss: 2.9712, Validation Loss Current: 8.0921, Validation Loss AVG: 13.0601, lr: 0.001
Epoch [63/400], Training Loss: 5.8993, Validation Loss Current: 7.5444, Validation Loss AVG: 10.2934, lr: 0.001
Epoch [64/400], Training Loss: 8.4977, Validation Loss Current: 7.0596, Validation Loss AVG: 11.4703, lr: 0.001
Epoch [65/400], Training Loss: 4.4083, Validation Loss Current: 5.9580, Validation Loss AVG: 12.3986, lr: 0.001
Epoch [66/400], Training Loss: 3.1844, Validation Loss Current: 6.3960, Validation Loss AVG: 12.0443, lr: 0.001
Epoch [67/400], Training Loss: 3.5728, Validation Loss Current: 8.3786, Validation Loss AVG: 13.2181, lr: 0.001
Epoch [68/400], Training Loss: 3.2004, Validation Loss Current: 6.5643, Validation Loss AVG: 10.8229, lr: 0.001
Epoch [69/400], Training Loss: 3.0668, Validation Loss Current: 6.5620, Validation Loss AVG: 13.5504, lr: 0.001
Epoch [70/400], Training Loss: 1.4931, Validation Loss Current: 5.8947, Validation Loss AVG: 11.6435, lr: 0.001
Epoch [71/400], Training Loss: 3.8561, Validation Loss Current: 5.9381, Validation Loss AVG: 13.2959, lr: 0.001
Epoch [72/400], Training Loss: 2.9146, Validation Loss Current: 6.7515, Validation Loss AVG: 14.5209, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 42 Best val accuracy: [0.23026315789473684, 0.2779605263157895, 0.3042763157894737, 0.3470394736842105, 0.3536184210526316, 0.3651315789473684, 0.37006578947368424, 0.4194078947368421, 0.45230263157894735, 0.48848684210526316, 0.4901315789473684, 0.4473684210526316, 0.4967105263157895, 0.5115131578947368, 0.5148026315789473, 0.4934210526315789, 0.5542763157894737, 0.5180921052631579, 0.5032894736842105, 0.5394736842105263, 0.4440789473684211, 0.5509868421052632, 0.5641447368421053, 0.5098684210526315, 0.5411184210526315, 0.5608552631578947, 0.5756578947368421, 0.6101973684210527, 0.5805921052631579, 0.5657894736842105, 0.5608552631578947, 0.6069078947368421, 0.6134868421052632, 0.6332236842105263, 0.5542763157894737, 0.5904605263157895, 0.6052631578947368, 0.6480263157894737, 0.6430921052631579, 0.6282894736842105, 0.6661184210526315, 0.6546052631578947, 0.662828947368421, 0.6332236842105263, 0.6282894736842105, 0.5542763157894737, 0.6233552631578947, 0.6167763157894737, 0.5904605263157895, 0.6365131578947368, 0.6480263157894737, 0.6266447368421053, 0.6036184210526315, 0.6414473684210527, 0.6463815789473685, 0.6529605263157895, 0.6134868421052632, 0.625, 0.5476973684210527, 0.6167763157894737, 0.6052631578947368, 0.6134868421052632, 0.5657894736842105, 0.5789473684210527, 0.6529605263157895, 0.6430921052631579, 0.5460526315789473, 0.6430921052631579, 0.6365131578947368, 0.6546052631578947, 0.662828947368421, 0.6381578947368421] Best val loss: 4.982556104660034


Fold: 3
----- Training resnet18 with sequence: [0.2, 0.4, 0.6, 0.8, 1] -----
Current group: 0.2
Epoch [1/80], Training Loss: 40.2280, Validation Loss Current: 10.0364, Validation Loss AVG: 10.0364, lr: 0.001
Epoch [2/80], Training Loss: 39.4907, Validation Loss Current: 10.1378, Validation Loss AVG: 10.1378, lr: 0.001
Epoch [3/80], Training Loss: 39.3257, Validation Loss Current: 10.1489, Validation Loss AVG: 10.1489, lr: 0.001
Epoch [4/80], Training Loss: 38.7235, Validation Loss Current: 10.0267, Validation Loss AVG: 10.0267, lr: 0.001
Epoch [5/80], Training Loss: 37.0246, Validation Loss Current: 10.1117, Validation Loss AVG: 10.1117, lr: 0.001
Epoch [6/80], Training Loss: 36.6664, Validation Loss Current: 10.1195, Validation Loss AVG: 10.1195, lr: 0.001
Epoch [7/80], Training Loss: 36.0976, Validation Loss Current: 10.3360, Validation Loss AVG: 10.3360, lr: 0.001
Epoch [8/80], Training Loss: 34.8059, Validation Loss Current: 10.0753, Validation Loss AVG: 10.0753, lr: 0.001
Epoch [9/80], Training Loss: 33.7404, Validation Loss Current: 9.9354, Validation Loss AVG: 9.9354, lr: 0.001
Epoch [10/80], Training Loss: 33.9118, Validation Loss Current: 10.3918, Validation Loss AVG: 10.3918, lr: 0.001
Epoch [11/80], Training Loss: 32.1904, Validation Loss Current: 9.9759, Validation Loss AVG: 9.9759, lr: 0.001
Epoch [12/80], Training Loss: 31.9996, Validation Loss Current: 10.4062, Validation Loss AVG: 10.4062, lr: 0.001
Epoch [13/80], Training Loss: 30.7443, Validation Loss Current: 10.8897, Validation Loss AVG: 10.8897, lr: 0.001
Epoch [14/80], Training Loss: 30.8254, Validation Loss Current: 10.7419, Validation Loss AVG: 10.7419, lr: 0.001
Epoch [15/80], Training Loss: 29.7643, Validation Loss Current: 11.8987, Validation Loss AVG: 11.8987, lr: 0.001
Epoch [16/80], Training Loss: 28.8163, Validation Loss Current: 10.6213, Validation Loss AVG: 10.6213, lr: 0.001
Epoch [17/80], Training Loss: 28.1137, Validation Loss Current: 11.6522, Validation Loss AVG: 11.6522, lr: 0.001
Epoch [18/80], Training Loss: 28.0757, Validation Loss Current: 11.8298, Validation Loss AVG: 11.8298, lr: 0.001
Epoch [19/80], Training Loss: 27.9479, Validation Loss Current: 11.0054, Validation Loss AVG: 11.0054, lr: 0.001
Epoch [20/80], Training Loss: 26.1340, Validation Loss Current: 11.2410, Validation Loss AVG: 11.2410, lr: 0.001
Epoch [21/80], Training Loss: 24.8396, Validation Loss Current: 11.9652, Validation Loss AVG: 11.9652, lr: 0.001
Epoch [22/80], Training Loss: 26.7534, Validation Loss Current: 11.2368, Validation Loss AVG: 11.2368, lr: 0.001
Epoch [23/80], Training Loss: 24.4972, Validation Loss Current: 12.2316, Validation Loss AVG: 12.2316, lr: 0.001
Epoch [24/80], Training Loss: 23.1588, Validation Loss Current: 10.7183, Validation Loss AVG: 10.7183, lr: 0.001
Epoch [25/80], Training Loss: 22.1983, Validation Loss Current: 10.9482, Validation Loss AVG: 10.9482, lr: 0.001
Epoch [26/80], Training Loss: 20.9264, Validation Loss Current: 11.8699, Validation Loss AVG: 11.8699, lr: 0.001
Epoch [27/80], Training Loss: 20.7529, Validation Loss Current: 11.8628, Validation Loss AVG: 11.8628, lr: 0.001
Epoch [28/80], Training Loss: 20.2240, Validation Loss Current: 12.2780, Validation Loss AVG: 12.2780, lr: 0.001
Epoch [29/80], Training Loss: 19.9996, Validation Loss Current: 13.1289, Validation Loss AVG: 13.1289, lr: 0.001
Epoch [30/80], Training Loss: 22.5348, Validation Loss Current: 13.2555, Validation Loss AVG: 13.2555, lr: 0.001
Epoch [31/80], Training Loss: 20.1579, Validation Loss Current: 11.5621, Validation Loss AVG: 11.5621, lr: 0.001
Epoch [32/80], Training Loss: 17.9249, Validation Loss Current: 14.5356, Validation Loss AVG: 14.5356, lr: 0.001
Epoch [33/80], Training Loss: 17.7285, Validation Loss Current: 14.2564, Validation Loss AVG: 14.2564, lr: 0.001
Epoch [34/80], Training Loss: 16.9306, Validation Loss Current: 13.0099, Validation Loss AVG: 13.0099, lr: 0.001
Epoch [35/80], Training Loss: 14.0336, Validation Loss Current: 13.7227, Validation Loss AVG: 13.7227, lr: 0.001
Epoch [36/80], Training Loss: 14.1069, Validation Loss Current: 13.6757, Validation Loss AVG: 13.6757, lr: 0.001
Epoch [37/80], Training Loss: 13.4655, Validation Loss Current: 17.6429, Validation Loss AVG: 17.6429, lr: 0.001
Epoch [38/80], Training Loss: 11.8983, Validation Loss Current: 12.7047, Validation Loss AVG: 12.7047, lr: 0.001
Epoch [39/80], Training Loss: 12.7056, Validation Loss Current: 16.7896, Validation Loss AVG: 16.7896, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 9 Best val accuracy: [0.23717105263157895, 0.20657894736842106, 0.20526315789473681, 0.22960526315789473, 0.21907894736842107, 0.25526315789473686, 0.23980263157894738, 0.2789473684210526, 0.2598684210526316, 0.2542763157894737, 0.26217105263157897, 0.25592105263157894, 0.23815789473684212, 0.2424342105263158, 0.21085526315789474, 0.26414473684210527, 0.21710526315789475, 0.24046052631578946, 0.27532894736842106, 0.26875, 0.2657894736842105, 0.2605263157894737, 0.2582236842105263, 0.2779605263157895, 0.2934210526315789, 0.30493421052631575, 0.2605263157894736, 0.2644736842105263, 0.3003289473684211, 0.23914473684210527, 0.3503289473684211, 0.2621710526315789, 0.2710526315789473, 0.3134868421052632, 0.28388157894736843, 0.3371710526315789, 0.2789473684210526, 0.3279605263157895, 0.2532894736842105] Best val loss: 9.935396671295166


Current group: 0.4
Epoch [1/80], Training Loss: 35.1651, Validation Loss Current: 9.6522, Validation Loss AVG: 9.6522, lr: 0.001
Epoch [2/80], Training Loss: 30.3798, Validation Loss Current: 11.3244, Validation Loss AVG: 11.3244, lr: 0.001
Epoch [3/80], Training Loss: 28.3181, Validation Loss Current: 12.2369, Validation Loss AVG: 12.2369, lr: 0.001
Epoch [4/80], Training Loss: 26.4872, Validation Loss Current: 9.0680, Validation Loss AVG: 9.0680, lr: 0.001
Epoch [5/80], Training Loss: 25.6471, Validation Loss Current: 9.2089, Validation Loss AVG: 9.2089, lr: 0.001
Epoch [6/80], Training Loss: 23.5826, Validation Loss Current: 9.0764, Validation Loss AVG: 9.0764, lr: 0.001
Epoch [7/80], Training Loss: 20.8172, Validation Loss Current: 8.8031, Validation Loss AVG: 8.8031, lr: 0.001
Epoch [8/80], Training Loss: 19.2071, Validation Loss Current: 9.0449, Validation Loss AVG: 9.0449, lr: 0.001
Epoch [9/80], Training Loss: 18.6891, Validation Loss Current: 9.1782, Validation Loss AVG: 9.1782, lr: 0.001
Epoch [10/80], Training Loss: 17.3917, Validation Loss Current: 9.1555, Validation Loss AVG: 9.1555, lr: 0.001
Epoch [11/80], Training Loss: 14.1761, Validation Loss Current: 8.9318, Validation Loss AVG: 8.9318, lr: 0.001
Epoch [12/80], Training Loss: 13.1304, Validation Loss Current: 9.1343, Validation Loss AVG: 9.1343, lr: 0.001
Epoch [13/80], Training Loss: 10.5733, Validation Loss Current: 9.7840, Validation Loss AVG: 9.7840, lr: 0.001
Epoch [14/80], Training Loss: 10.7907, Validation Loss Current: 10.7741, Validation Loss AVG: 10.7741, lr: 0.001
Epoch [15/80], Training Loss: 12.0112, Validation Loss Current: 11.2573, Validation Loss AVG: 11.2573, lr: 0.001
Epoch [16/80], Training Loss: 14.1071, Validation Loss Current: 9.7061, Validation Loss AVG: 9.7061, lr: 0.001
Epoch [17/80], Training Loss: 8.9625, Validation Loss Current: 9.7856, Validation Loss AVG: 9.7856, lr: 0.001
Epoch [18/80], Training Loss: 6.7021, Validation Loss Current: 9.6996, Validation Loss AVG: 9.6996, lr: 0.001
Epoch [19/80], Training Loss: 9.2022, Validation Loss Current: 10.4997, Validation Loss AVG: 10.4997, lr: 0.001
Epoch [20/80], Training Loss: 8.7366, Validation Loss Current: 10.5869, Validation Loss AVG: 10.5869, lr: 0.001
Epoch [21/80], Training Loss: 8.0548, Validation Loss Current: 10.9625, Validation Loss AVG: 10.9625, lr: 0.001
Epoch [22/80], Training Loss: 6.6850, Validation Loss Current: 11.0716, Validation Loss AVG: 11.0716, lr: 0.001
Epoch [23/80], Training Loss: 9.4198, Validation Loss Current: 10.6915, Validation Loss AVG: 10.6915, lr: 0.001
Epoch [24/80], Training Loss: 9.4261, Validation Loss Current: 12.1558, Validation Loss AVG: 12.1558, lr: 0.001
Epoch [25/80], Training Loss: 6.4803, Validation Loss Current: 11.3414, Validation Loss AVG: 11.3414, lr: 0.001
Epoch [26/80], Training Loss: 4.1954, Validation Loss Current: 10.5164, Validation Loss AVG: 10.5164, lr: 0.001
Epoch [27/80], Training Loss: 3.8918, Validation Loss Current: 10.9310, Validation Loss AVG: 10.9310, lr: 0.001
Epoch [28/80], Training Loss: 6.4316, Validation Loss Current: 13.2784, Validation Loss AVG: 13.2784, lr: 0.001
Epoch [29/80], Training Loss: 6.6540, Validation Loss Current: 11.5523, Validation Loss AVG: 11.5523, lr: 0.001
Epoch [30/80], Training Loss: 6.8466, Validation Loss Current: 11.6250, Validation Loss AVG: 11.6250, lr: 0.001
Epoch [31/80], Training Loss: 4.2859, Validation Loss Current: 11.5521, Validation Loss AVG: 11.5521, lr: 0.001
Epoch [32/80], Training Loss: 4.5657, Validation Loss Current: 12.3246, Validation Loss AVG: 12.3246, lr: 0.001
Epoch [33/80], Training Loss: 8.4002, Validation Loss Current: 12.0893, Validation Loss AVG: 12.0893, lr: 0.001
Epoch [34/80], Training Loss: 6.1171, Validation Loss Current: 12.8664, Validation Loss AVG: 12.8664, lr: 0.001
Epoch [35/80], Training Loss: 3.0892, Validation Loss Current: 12.1952, Validation Loss AVG: 12.1952, lr: 0.001
Epoch [36/80], Training Loss: 4.4161, Validation Loss Current: 11.6686, Validation Loss AVG: 11.6686, lr: 0.001
Epoch [37/80], Training Loss: 3.8140, Validation Loss Current: 11.6404, Validation Loss AVG: 11.6404, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 7 Best val accuracy: [0.3539473684210527, 0.33585526315789477, 0.23190789473684212, 0.36217105263157895, 0.3631578947368421, 0.39901315789473685, 0.4098684210526316, 0.40921052631578947, 0.4108552631578948, 0.4338815789473684, 0.42664473684210524, 0.4319078947368421, 0.4286184210526316, 0.40625, 0.41414473684210523, 0.4088815789473685, 0.40888157894736843, 0.44046052631578947, 0.3911184210526316, 0.44210526315789467, 0.4213815789473684, 0.3792763157894737, 0.4233552631578947, 0.4098684210526316, 0.40592105263157896, 0.43355263157894736, 0.4322368421052632, 0.3480263157894737, 0.4286184210526316, 0.3805921052631579, 0.42960526315789477, 0.39111842105263156, 0.3625, 0.36809210526315794, 0.4006578947368421, 0.4266447368421053, 0.4236842105263158] Best val loss: 8.803083801269532


Current group: 0.6
Epoch [1/80], Training Loss: 35.4747, Validation Loss Current: 16.1071, Validation Loss AVG: 16.1071, lr: 0.001
Epoch [2/80], Training Loss: 27.4847, Validation Loss Current: 12.7918, Validation Loss AVG: 12.7918, lr: 0.001
Epoch [3/80], Training Loss: 20.5266, Validation Loss Current: 10.6199, Validation Loss AVG: 10.6199, lr: 0.001
Epoch [4/80], Training Loss: 16.1544, Validation Loss Current: 8.9802, Validation Loss AVG: 8.9802, lr: 0.001
Epoch [5/80], Training Loss: 14.5459, Validation Loss Current: 10.1890, Validation Loss AVG: 10.1890, lr: 0.001
Epoch [6/80], Training Loss: 15.5088, Validation Loss Current: 11.0387, Validation Loss AVG: 11.0387, lr: 0.001
Epoch [7/80], Training Loss: 10.8254, Validation Loss Current: 9.5812, Validation Loss AVG: 9.5812, lr: 0.001
Epoch [8/80], Training Loss: 10.9049, Validation Loss Current: 9.4625, Validation Loss AVG: 9.4625, lr: 0.001
Epoch [9/80], Training Loss: 11.2391, Validation Loss Current: 10.3559, Validation Loss AVG: 10.3559, lr: 0.001
Epoch [10/80], Training Loss: 10.0822, Validation Loss Current: 10.6990, Validation Loss AVG: 10.6990, lr: 0.001
Epoch [11/80], Training Loss: 7.2555, Validation Loss Current: 9.8777, Validation Loss AVG: 9.8777, lr: 0.001
Epoch [12/80], Training Loss: 5.4468, Validation Loss Current: 10.8622, Validation Loss AVG: 10.8622, lr: 0.001
Epoch [13/80], Training Loss: 6.9559, Validation Loss Current: 11.1259, Validation Loss AVG: 11.1259, lr: 0.001
Epoch [14/80], Training Loss: 6.6792, Validation Loss Current: 10.6986, Validation Loss AVG: 10.6986, lr: 0.001
Epoch [15/80], Training Loss: 4.6860, Validation Loss Current: 11.2646, Validation Loss AVG: 11.2646, lr: 0.001
Epoch [16/80], Training Loss: 4.3871, Validation Loss Current: 10.9339, Validation Loss AVG: 10.9339, lr: 0.001
Epoch [17/80], Training Loss: 7.1041, Validation Loss Current: 12.0497, Validation Loss AVG: 12.0497, lr: 0.001
Epoch [18/80], Training Loss: 4.6450, Validation Loss Current: 11.0381, Validation Loss AVG: 11.0381, lr: 0.001
Epoch [19/80], Training Loss: 4.7151, Validation Loss Current: 11.7911, Validation Loss AVG: 11.7911, lr: 0.001
Epoch [20/80], Training Loss: 3.8034, Validation Loss Current: 11.5675, Validation Loss AVG: 11.5675, lr: 0.001
Epoch [21/80], Training Loss: 5.0690, Validation Loss Current: 13.7175, Validation Loss AVG: 13.7175, lr: 0.001
Epoch [22/80], Training Loss: 4.2061, Validation Loss Current: 12.0467, Validation Loss AVG: 12.0467, lr: 0.001
Epoch [23/80], Training Loss: 3.0610, Validation Loss Current: 11.7534, Validation Loss AVG: 11.7534, lr: 0.001
Epoch [24/80], Training Loss: 2.1844, Validation Loss Current: 11.1512, Validation Loss AVG: 11.1512, lr: 0.001
Epoch [25/80], Training Loss: 3.3513, Validation Loss Current: 12.1333, Validation Loss AVG: 12.1333, lr: 0.001
Epoch [26/80], Training Loss: 4.5487, Validation Loss Current: 13.3988, Validation Loss AVG: 13.3988, lr: 0.001
Epoch [27/80], Training Loss: 4.1965, Validation Loss Current: 13.1091, Validation Loss AVG: 13.1091, lr: 0.001
Epoch [28/80], Training Loss: 8.6863, Validation Loss Current: 12.8500, Validation Loss AVG: 12.8500, lr: 0.001
Epoch [29/80], Training Loss: 5.9400, Validation Loss Current: 10.6713, Validation Loss AVG: 10.6713, lr: 0.001
Epoch [30/80], Training Loss: 4.9550, Validation Loss Current: 13.7597, Validation Loss AVG: 13.7597, lr: 0.001
Epoch [31/80], Training Loss: 4.5864, Validation Loss Current: 13.2549, Validation Loss AVG: 13.2549, lr: 0.001
Epoch [32/80], Training Loss: 5.2367, Validation Loss Current: 10.4677, Validation Loss AVG: 10.4677, lr: 0.001
Epoch [33/80], Training Loss: 2.3177, Validation Loss Current: 11.6517, Validation Loss AVG: 11.6517, lr: 0.001
Epoch [34/80], Training Loss: 3.2573, Validation Loss Current: 13.9575, Validation Loss AVG: 13.9575, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 4 Best val accuracy: [0.33223684210526316, 0.3884868421052632, 0.4273026315789473, 0.45921052631578946, 0.3904605263157895, 0.4125, 0.43618421052631584, 0.44835526315789476, 0.39506578947368426, 0.4342105263157895, 0.44539473684210523, 0.45131578947368417, 0.41480263157894737, 0.44506578947368425, 0.43717105263157896, 0.4148026315789474, 0.40888157894736843, 0.4667763157894737, 0.4384868421052631, 0.4328947368421052, 0.40690789473684214, 0.43684210526315786, 0.4220394736842105, 0.45921052631578946, 0.44013157894736843, 0.3674342105263158, 0.40361842105263157, 0.4207236842105263, 0.4483552631578947, 0.4098684210526316, 0.43980263157894733, 0.48125, 0.4328947368421052, 0.4309210526315789] Best val loss: 8.980203080177308


Current group: 0.8
Epoch [1/80], Training Loss: 30.5721, Validation Loss Current: 11.9626, Validation Loss AVG: 11.9626, lr: 0.001
Epoch [2/80], Training Loss: 17.0297, Validation Loss Current: 12.1766, Validation Loss AVG: 12.1766, lr: 0.001
Epoch [3/80], Training Loss: 11.7817, Validation Loss Current: 11.6556, Validation Loss AVG: 11.6556, lr: 0.001
Epoch [4/80], Training Loss: 6.2715, Validation Loss Current: 9.7193, Validation Loss AVG: 9.7193, lr: 0.001
Epoch [5/80], Training Loss: 6.6811, Validation Loss Current: 11.8182, Validation Loss AVG: 11.8182, lr: 0.001
Epoch [6/80], Training Loss: 4.2583, Validation Loss Current: 11.0792, Validation Loss AVG: 11.0792, lr: 0.001
Epoch [7/80], Training Loss: 3.2909, Validation Loss Current: 11.0290, Validation Loss AVG: 11.0290, lr: 0.001
Epoch [8/80], Training Loss: 4.6395, Validation Loss Current: 13.1970, Validation Loss AVG: 13.1970, lr: 0.001
Epoch [9/80], Training Loss: 3.4279, Validation Loss Current: 11.2945, Validation Loss AVG: 11.2945, lr: 0.001
Epoch [10/80], Training Loss: 4.8005, Validation Loss Current: 11.9056, Validation Loss AVG: 11.9056, lr: 0.001
Epoch [11/80], Training Loss: 7.0611, Validation Loss Current: 11.4820, Validation Loss AVG: 11.4820, lr: 0.001
Epoch [12/80], Training Loss: 10.9473, Validation Loss Current: 13.7798, Validation Loss AVG: 13.7798, lr: 0.001
Epoch [13/80], Training Loss: 8.7642, Validation Loss Current: 11.1140, Validation Loss AVG: 11.1140, lr: 0.001
Epoch [14/80], Training Loss: 4.9787, Validation Loss Current: 12.2965, Validation Loss AVG: 12.2965, lr: 0.001
Epoch [15/80], Training Loss: 4.7767, Validation Loss Current: 12.1595, Validation Loss AVG: 12.1595, lr: 0.001
Epoch [16/80], Training Loss: 4.6904, Validation Loss Current: 11.8476, Validation Loss AVG: 11.8476, lr: 0.001
Epoch [17/80], Training Loss: 6.9037, Validation Loss Current: 11.2182, Validation Loss AVG: 11.2182, lr: 0.001
Epoch [18/80], Training Loss: 7.6653, Validation Loss Current: 12.9396, Validation Loss AVG: 12.9396, lr: 0.001
Epoch [19/80], Training Loss: 5.1563, Validation Loss Current: 16.7754, Validation Loss AVG: 16.7754, lr: 0.001
Epoch [20/80], Training Loss: 3.9668, Validation Loss Current: 12.8073, Validation Loss AVG: 12.8073, lr: 0.001
Epoch [21/80], Training Loss: 6.0372, Validation Loss Current: 11.5845, Validation Loss AVG: 11.5845, lr: 0.001
Epoch [22/80], Training Loss: 4.4867, Validation Loss Current: 10.7808, Validation Loss AVG: 10.7808, lr: 0.001
Epoch [23/80], Training Loss: 3.8715, Validation Loss Current: 12.5831, Validation Loss AVG: 12.5831, lr: 0.001
Epoch [24/80], Training Loss: 5.0410, Validation Loss Current: 13.0487, Validation Loss AVG: 13.0487, lr: 0.001
Epoch [25/80], Training Loss: 4.2207, Validation Loss Current: 12.6947, Validation Loss AVG: 12.6947, lr: 0.001
Epoch [26/80], Training Loss: 7.3216, Validation Loss Current: 12.0230, Validation Loss AVG: 12.0230, lr: 0.001
Epoch [27/80], Training Loss: 4.2486, Validation Loss Current: 13.1981, Validation Loss AVG: 13.1981, lr: 0.001
Epoch [28/80], Training Loss: 2.8297, Validation Loss Current: 11.3116, Validation Loss AVG: 11.3116, lr: 0.001
Epoch [29/80], Training Loss: 3.5344, Validation Loss Current: 13.8641, Validation Loss AVG: 13.8641, lr: 0.001
Epoch [30/80], Training Loss: 1.9974, Validation Loss Current: 12.3075, Validation Loss AVG: 12.3075, lr: 0.001
Epoch [31/80], Training Loss: 2.7020, Validation Loss Current: 11.6778, Validation Loss AVG: 11.6778, lr: 0.001
Epoch [32/80], Training Loss: 2.9660, Validation Loss Current: 13.2308, Validation Loss AVG: 13.2308, lr: 0.001
Epoch [33/80], Training Loss: 4.1453, Validation Loss Current: 12.0216, Validation Loss AVG: 12.0216, lr: 0.001
Epoch [34/80], Training Loss: 4.1960, Validation Loss Current: 14.0028, Validation Loss AVG: 14.0028, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.41019736842105264, 0.40855263157894733, 0.4335526315789474, 0.46447368421052626, 0.4365131578947368, 0.4476973684210527, 0.46875, 0.41578947368421054, 0.45230263157894746, 0.44013157894736843, 0.4200657894736842, 0.40394736842105267, 0.44243421052631576, 0.4338815789473684, 0.43980263157894744, 0.4355263157894737, 0.43881578947368427, 0.4180921052631579, 0.41546052631578945, 0.4430921052631579, 0.4569078947368421, 0.46677631578947365, 0.4509868421052632, 0.4453947368421053, 0.4128289473684211, 0.3983552631578947, 0.42664473684210524, 0.4578947368421053, 0.4375, 0.43355263157894736, 0.4453947368421053, 0.43322368421052626, 0.44769736842105257, 0.4302631578947368] Best val loss: 9.719293546676635


Current group: 1
Epoch [1/80], Training Loss: 27.2091, Validation Loss Current: 8.9987, Validation Loss AVG: 12.0865, lr: 0.001
Epoch [2/80], Training Loss: 15.9269, Validation Loss Current: 9.6952, Validation Loss AVG: 12.9497, lr: 0.001
Epoch [3/80], Training Loss: 12.5578, Validation Loss Current: 8.3409, Validation Loss AVG: 13.0181, lr: 0.001
Epoch [4/80], Training Loss: 9.2819, Validation Loss Current: 7.7889, Validation Loss AVG: 12.5086, lr: 0.001
Epoch [5/80], Training Loss: 6.2857, Validation Loss Current: 8.4158, Validation Loss AVG: 12.7266, lr: 0.001
Epoch [6/80], Training Loss: 6.9870, Validation Loss Current: 7.8074, Validation Loss AVG: 12.1813, lr: 0.001
Epoch [7/80], Training Loss: 6.6177, Validation Loss Current: 8.3544, Validation Loss AVG: 13.5270, lr: 0.001
Epoch [8/80], Training Loss: 6.8611, Validation Loss Current: 8.6595, Validation Loss AVG: 13.0731, lr: 0.001
Epoch [9/80], Training Loss: 9.6745, Validation Loss Current: 8.3269, Validation Loss AVG: 14.7190, lr: 0.001
Epoch [10/80], Training Loss: 4.7934, Validation Loss Current: 7.7768, Validation Loss AVG: 12.2029, lr: 0.001
Epoch [11/80], Training Loss: 2.7408, Validation Loss Current: 8.3482, Validation Loss AVG: 13.8893, lr: 0.001
Epoch [12/80], Training Loss: 4.4074, Validation Loss Current: 7.6999, Validation Loss AVG: 11.8597, lr: 0.001
Epoch [13/80], Training Loss: 1.8702, Validation Loss Current: 9.1182, Validation Loss AVG: 13.4489, lr: 0.001
Epoch [14/80], Training Loss: 3.5376, Validation Loss Current: 8.3336, Validation Loss AVG: 13.0045, lr: 0.001
Epoch [15/80], Training Loss: 3.0479, Validation Loss Current: 8.6982, Validation Loss AVG: 15.0232, lr: 0.001
Epoch [16/80], Training Loss: 3.3624, Validation Loss Current: 8.4845, Validation Loss AVG: 14.2143, lr: 0.001
Epoch [17/80], Training Loss: 2.7127, Validation Loss Current: 9.3116, Validation Loss AVG: 14.7429, lr: 0.001
Epoch [18/80], Training Loss: 2.7916, Validation Loss Current: 8.2907, Validation Loss AVG: 16.0287, lr: 0.001
Epoch [19/80], Training Loss: 2.2538, Validation Loss Current: 8.6603, Validation Loss AVG: 11.9997, lr: 0.001
Epoch [20/80], Training Loss: 3.0548, Validation Loss Current: 8.1009, Validation Loss AVG: 13.3292, lr: 0.001
Epoch [21/80], Training Loss: 4.5579, Validation Loss Current: 8.7123, Validation Loss AVG: 12.3060, lr: 0.001
Epoch [22/80], Training Loss: 6.1433, Validation Loss Current: 8.8887, Validation Loss AVG: 13.2856, lr: 0.001
Epoch [23/80], Training Loss: 3.3281, Validation Loss Current: 8.6297, Validation Loss AVG: 14.3658, lr: 0.001
Epoch [24/80], Training Loss: 2.5081, Validation Loss Current: 9.6746, Validation Loss AVG: 14.0947, lr: 0.001
Epoch [25/80], Training Loss: 4.9095, Validation Loss Current: 10.4213, Validation Loss AVG: 17.3249, lr: 0.001
Epoch [26/80], Training Loss: 2.8103, Validation Loss Current: 8.9704, Validation Loss AVG: 14.7625, lr: 0.001
Epoch [27/80], Training Loss: 3.0307, Validation Loss Current: 9.5883, Validation Loss AVG: 14.1789, lr: 0.001
Epoch [28/80], Training Loss: 7.1023, Validation Loss Current: 9.4745, Validation Loss AVG: 15.4860, lr: 0.001
Epoch [29/80], Training Loss: 6.8090, Validation Loss Current: 13.0754, Validation Loss AVG: 15.5238, lr: 0.001
Epoch [30/80], Training Loss: 7.7239, Validation Loss Current: 11.1377, Validation Loss AVG: 16.9236, lr: 0.001
Epoch [31/80], Training Loss: 8.5082, Validation Loss Current: 12.1973, Validation Loss AVG: 16.5534, lr: 0.001
Epoch [32/80], Training Loss: 1.9572, Validation Loss Current: 8.3715, Validation Loss AVG: 14.0395, lr: 0.001
Epoch [33/80], Training Loss: 0.8477, Validation Loss Current: 8.3920, Validation Loss AVG: 13.3226, lr: 0.001
Epoch [34/80], Training Loss: 1.0860, Validation Loss Current: 8.4903, Validation Loss AVG: 14.3891, lr: 0.001
Epoch [35/80], Training Loss: 4.6458, Validation Loss Current: 9.2756, Validation Loss AVG: 13.7563, lr: 0.001
Epoch [36/80], Training Loss: 4.4596, Validation Loss Current: 9.6534, Validation Loss AVG: 15.7317, lr: 0.001
Epoch [37/80], Training Loss: 1.7759, Validation Loss Current: 8.4473, Validation Loss AVG: 13.2663, lr: 0.001
Epoch [38/80], Training Loss: 3.6365, Validation Loss Current: 9.5262, Validation Loss AVG: 16.2239, lr: 0.001
Epoch [39/80], Training Loss: 4.1878, Validation Loss Current: 9.7171, Validation Loss AVG: 15.0737, lr: 0.001
Epoch [40/80], Training Loss: 3.8591, Validation Loss Current: 8.5858, Validation Loss AVG: 16.2964, lr: 0.001
Epoch [41/80], Training Loss: 2.2866, Validation Loss Current: 9.2585, Validation Loss AVG: 13.8169, lr: 0.001
Epoch [42/80], Training Loss: 1.6441, Validation Loss Current: 8.4730, Validation Loss AVG: 13.6708, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 12 Best val accuracy: [0.5773026315789473, 0.5493421052631579, 0.5707236842105263, 0.5986842105263158, 0.5986842105263158, 0.5904605263157895, 0.5904605263157895, 0.5822368421052632, 0.5953947368421053, 0.6085526315789473, 0.6085526315789473, 0.6299342105263158, 0.5904605263157895, 0.587171052631579, 0.6101973684210527, 0.6052631578947368, 0.5674342105263158, 0.5921052631578947, 0.6151315789473685, 0.6036184210526315, 0.5888157894736842, 0.5888157894736842, 0.5855263157894737, 0.5707236842105263, 0.5838815789473685, 0.5904605263157895, 0.5674342105263158, 0.5657894736842105, 0.5476973684210527, 0.53125, 0.5592105263157895, 0.6036184210526315, 0.6101973684210527, 0.6118421052631579, 0.5921052631578947, 0.5986842105263158, 0.5838815789473685, 0.5723684210526315, 0.6036184210526315, 0.600328947368421, 0.5542763157894737, 0.5921052631578947] Best val loss: 7.699902296066284


----- Training resnet18 with sequence: [0.4, 0.6, 0.8, 1] -----
Current group: 0.4
Epoch [1/100], Training Loss: 40.8650, Validation Loss Current: 10.1191, Validation Loss AVG: 10.1191, lr: 0.001
Epoch [2/100], Training Loss: 39.3456, Validation Loss Current: 9.9817, Validation Loss AVG: 9.9817, lr: 0.001
Epoch [3/100], Training Loss: 39.2551, Validation Loss Current: 9.7624, Validation Loss AVG: 9.7624, lr: 0.001
Epoch [4/100], Training Loss: 38.4859, Validation Loss Current: 9.6017, Validation Loss AVG: 9.6017, lr: 0.001
Epoch [5/100], Training Loss: 38.1272, Validation Loss Current: 9.7629, Validation Loss AVG: 9.7629, lr: 0.001
Epoch [6/100], Training Loss: 36.6926, Validation Loss Current: 9.3481, Validation Loss AVG: 9.3481, lr: 0.001
Epoch [7/100], Training Loss: 35.4441, Validation Loss Current: 9.5194, Validation Loss AVG: 9.5194, lr: 0.001
Epoch [8/100], Training Loss: 35.0237, Validation Loss Current: 8.9908, Validation Loss AVG: 8.9908, lr: 0.001
Epoch [9/100], Training Loss: 33.3944, Validation Loss Current: 9.3063, Validation Loss AVG: 9.3063, lr: 0.001
Epoch [10/100], Training Loss: 33.5083, Validation Loss Current: 8.9042, Validation Loss AVG: 8.9042, lr: 0.001
Epoch [11/100], Training Loss: 32.2796, Validation Loss Current: 8.8824, Validation Loss AVG: 8.8824, lr: 0.001
Epoch [12/100], Training Loss: 30.9190, Validation Loss Current: 8.7130, Validation Loss AVG: 8.7130, lr: 0.001
Epoch [13/100], Training Loss: 29.5359, Validation Loss Current: 8.8304, Validation Loss AVG: 8.8304, lr: 0.001
Epoch [14/100], Training Loss: 29.0511, Validation Loss Current: 8.9087, Validation Loss AVG: 8.9087, lr: 0.001
Epoch [15/100], Training Loss: 28.4205, Validation Loss Current: 8.4512, Validation Loss AVG: 8.4512, lr: 0.001
Epoch [16/100], Training Loss: 27.5965, Validation Loss Current: 8.5620, Validation Loss AVG: 8.5620, lr: 0.001
Epoch [17/100], Training Loss: 28.8469, Validation Loss Current: 8.5218, Validation Loss AVG: 8.5218, lr: 0.001
Epoch [18/100], Training Loss: 27.4080, Validation Loss Current: 8.9835, Validation Loss AVG: 8.9835, lr: 0.001
Epoch [19/100], Training Loss: 27.5086, Validation Loss Current: 9.0409, Validation Loss AVG: 9.0409, lr: 0.001
Epoch [20/100], Training Loss: 26.1961, Validation Loss Current: 8.4060, Validation Loss AVG: 8.4060, lr: 0.001
Epoch [21/100], Training Loss: 26.7721, Validation Loss Current: 8.8835, Validation Loss AVG: 8.8835, lr: 0.001
Epoch [22/100], Training Loss: 26.6507, Validation Loss Current: 8.5984, Validation Loss AVG: 8.5984, lr: 0.001
Epoch [23/100], Training Loss: 25.2409, Validation Loss Current: 8.4780, Validation Loss AVG: 8.4780, lr: 0.001
Epoch [24/100], Training Loss: 24.2982, Validation Loss Current: 8.3861, Validation Loss AVG: 8.3861, lr: 0.001
Epoch [25/100], Training Loss: 22.1485, Validation Loss Current: 8.0459, Validation Loss AVG: 8.0459, lr: 0.001
Epoch [26/100], Training Loss: 22.8065, Validation Loss Current: 8.1259, Validation Loss AVG: 8.1259, lr: 0.001
Epoch [27/100], Training Loss: 22.1523, Validation Loss Current: 8.1399, Validation Loss AVG: 8.1399, lr: 0.001
Epoch [28/100], Training Loss: 20.1939, Validation Loss Current: 8.7980, Validation Loss AVG: 8.7980, lr: 0.001
Epoch [29/100], Training Loss: 20.2840, Validation Loss Current: 8.0431, Validation Loss AVG: 8.0431, lr: 0.001
Epoch [30/100], Training Loss: 18.1955, Validation Loss Current: 8.0416, Validation Loss AVG: 8.0416, lr: 0.001
Epoch [31/100], Training Loss: 17.7166, Validation Loss Current: 8.5526, Validation Loss AVG: 8.5526, lr: 0.001
Epoch [32/100], Training Loss: 17.9401, Validation Loss Current: 8.1734, Validation Loss AVG: 8.1734, lr: 0.001
Epoch [33/100], Training Loss: 16.4157, Validation Loss Current: 8.3019, Validation Loss AVG: 8.3019, lr: 0.001
Epoch [34/100], Training Loss: 14.8608, Validation Loss Current: 8.3610, Validation Loss AVG: 8.3610, lr: 0.001
Epoch [35/100], Training Loss: 14.1577, Validation Loss Current: 8.2806, Validation Loss AVG: 8.2806, lr: 0.001
Epoch [36/100], Training Loss: 13.6837, Validation Loss Current: 9.1865, Validation Loss AVG: 9.1865, lr: 0.001
Epoch [37/100], Training Loss: 12.5920, Validation Loss Current: 8.9474, Validation Loss AVG: 8.9474, lr: 0.001
Epoch [38/100], Training Loss: 11.4144, Validation Loss Current: 9.2156, Validation Loss AVG: 9.2156, lr: 0.001
Epoch [39/100], Training Loss: 10.4262, Validation Loss Current: 8.4458, Validation Loss AVG: 8.4458, lr: 0.001
Epoch [40/100], Training Loss: 9.5663, Validation Loss Current: 9.4003, Validation Loss AVG: 9.4003, lr: 0.001
Epoch [41/100], Training Loss: 11.0320, Validation Loss Current: 9.8918, Validation Loss AVG: 9.8918, lr: 0.001
Epoch [42/100], Training Loss: 10.7445, Validation Loss Current: 9.6398, Validation Loss AVG: 9.6398, lr: 0.001
Epoch [43/100], Training Loss: 10.0574, Validation Loss Current: 9.9086, Validation Loss AVG: 9.9086, lr: 0.001
Epoch [44/100], Training Loss: 12.7124, Validation Loss Current: 12.7080, Validation Loss AVG: 12.7080, lr: 0.001
Epoch [45/100], Training Loss: 9.0377, Validation Loss Current: 9.4948, Validation Loss AVG: 9.4948, lr: 0.001
Epoch [46/100], Training Loss: 8.5107, Validation Loss Current: 10.5431, Validation Loss AVG: 10.5431, lr: 0.001
Epoch [47/100], Training Loss: 12.1360, Validation Loss Current: 9.3214, Validation Loss AVG: 9.3214, lr: 0.001
Epoch [48/100], Training Loss: 9.1109, Validation Loss Current: 13.6535, Validation Loss AVG: 13.6535, lr: 0.001
Epoch [49/100], Training Loss: 6.4896, Validation Loss Current: 9.7983, Validation Loss AVG: 9.7983, lr: 0.001
Epoch [50/100], Training Loss: 6.8283, Validation Loss Current: 11.9687, Validation Loss AVG: 11.9687, lr: 0.001
Epoch [51/100], Training Loss: 6.0292, Validation Loss Current: 11.4969, Validation Loss AVG: 11.4969, lr: 0.001
Epoch [52/100], Training Loss: 5.7301, Validation Loss Current: 9.8733, Validation Loss AVG: 9.8733, lr: 0.001
Epoch [53/100], Training Loss: 4.9183, Validation Loss Current: 11.0368, Validation Loss AVG: 11.0368, lr: 0.001
Epoch [54/100], Training Loss: 4.5441, Validation Loss Current: 10.5331, Validation Loss AVG: 10.5331, lr: 0.001
Epoch [55/100], Training Loss: 4.8870, Validation Loss Current: 14.6584, Validation Loss AVG: 14.6584, lr: 0.001
Epoch [56/100], Training Loss: 6.3053, Validation Loss Current: 11.6223, Validation Loss AVG: 11.6223, lr: 0.001
Epoch [57/100], Training Loss: 4.5275, Validation Loss Current: 11.3593, Validation Loss AVG: 11.3593, lr: 0.001
Epoch [58/100], Training Loss: 4.5302, Validation Loss Current: 12.7581, Validation Loss AVG: 12.7581, lr: 0.001
Epoch [59/100], Training Loss: 2.7163, Validation Loss Current: 10.6931, Validation Loss AVG: 10.6931, lr: 0.001
Epoch [60/100], Training Loss: 4.0393, Validation Loss Current: 11.9510, Validation Loss AVG: 11.9510, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 30 Best val accuracy: [0.2335526315789474, 0.24046052631578946, 0.26480263157894735, 0.3052631578947368, 0.2621710526315789, 0.30296052631578946, 0.28848684210526315, 0.3740131578947369, 0.31315789473684214, 0.35789473684210527, 0.3404605263157895, 0.3901315789473684, 0.3713815789473684, 0.3851973684210527, 0.4220394736842105, 0.40197368421052637, 0.3973684210526316, 0.39736842105263154, 0.3559210526315789, 0.43256578947368424, 0.40493421052631573, 0.387828947368421, 0.4230263157894737, 0.40394736842105267, 0.4582236842105264, 0.44572368421052627, 0.4473684210526316, 0.44046052631578947, 0.4582236842105264, 0.46842105263157896, 0.4588815789473684, 0.4641447368421052, 0.4407894736842105, 0.44078947368421045, 0.46875, 0.40855263157894744, 0.44703947368421054, 0.43157894736842106, 0.4621710526315789, 0.42467105263157895, 0.4427631578947368, 0.42269736842105265, 0.43815789473684214, 0.3473684210526316, 0.4542763157894737, 0.3605263157894737, 0.4325657894736842, 0.3447368421052632, 0.43453947368421053, 0.4223684210526316, 0.41743421052631574, 0.45, 0.4151315789473684, 0.4569078947368421, 0.37269736842105267, 0.40657894736842104, 0.39769736842105263, 0.42894736842105263, 0.47368421052631576, 0.41480263157894737] Best val loss: 8.041612935066222


Current group: 0.6
Epoch [1/100], Training Loss: 31.4250, Validation Loss Current: 14.1451, Validation Loss AVG: 14.1451, lr: 0.001
Epoch [2/100], Training Loss: 22.7617, Validation Loss Current: 11.7280, Validation Loss AVG: 11.7280, lr: 0.001
Epoch [3/100], Training Loss: 17.5570, Validation Loss Current: 9.8266, Validation Loss AVG: 9.8266, lr: 0.001
Epoch [4/100], Training Loss: 14.1431, Validation Loss Current: 9.5083, Validation Loss AVG: 9.5083, lr: 0.001
Epoch [5/100], Training Loss: 11.8498, Validation Loss Current: 10.5985, Validation Loss AVG: 10.5985, lr: 0.001
Epoch [6/100], Training Loss: 11.8084, Validation Loss Current: 10.9915, Validation Loss AVG: 10.9915, lr: 0.001
Epoch [7/100], Training Loss: 11.2626, Validation Loss Current: 10.6380, Validation Loss AVG: 10.6380, lr: 0.001
Epoch [8/100], Training Loss: 10.1019, Validation Loss Current: 12.8036, Validation Loss AVG: 12.8036, lr: 0.001
Epoch [9/100], Training Loss: 8.5718, Validation Loss Current: 10.4980, Validation Loss AVG: 10.4980, lr: 0.001
Epoch [10/100], Training Loss: 6.6132, Validation Loss Current: 10.1746, Validation Loss AVG: 10.1746, lr: 0.001
Epoch [11/100], Training Loss: 6.7261, Validation Loss Current: 9.1336, Validation Loss AVG: 9.1336, lr: 0.001
Epoch [12/100], Training Loss: 8.5746, Validation Loss Current: 15.2512, Validation Loss AVG: 15.2512, lr: 0.001
Epoch [13/100], Training Loss: 19.0589, Validation Loss Current: 10.9405, Validation Loss AVG: 10.9405, lr: 0.001
Epoch [14/100], Training Loss: 13.8283, Validation Loss Current: 12.1970, Validation Loss AVG: 12.1970, lr: 0.001
Epoch [15/100], Training Loss: 11.2803, Validation Loss Current: 10.9995, Validation Loss AVG: 10.9995, lr: 0.001
Epoch [16/100], Training Loss: 10.3692, Validation Loss Current: 16.2728, Validation Loss AVG: 16.2728, lr: 0.001
Epoch [17/100], Training Loss: 8.9450, Validation Loss Current: 11.6039, Validation Loss AVG: 11.6039, lr: 0.001
Epoch [18/100], Training Loss: 4.5975, Validation Loss Current: 11.0613, Validation Loss AVG: 11.0613, lr: 0.001
Epoch [19/100], Training Loss: 2.6562, Validation Loss Current: 10.6231, Validation Loss AVG: 10.6231, lr: 0.001
Epoch [20/100], Training Loss: 2.4259, Validation Loss Current: 10.5942, Validation Loss AVG: 10.5942, lr: 0.001
Epoch [21/100], Training Loss: 3.2531, Validation Loss Current: 10.9972, Validation Loss AVG: 10.9972, lr: 0.001
Epoch [22/100], Training Loss: 4.3759, Validation Loss Current: 10.8930, Validation Loss AVG: 10.8930, lr: 0.001
Epoch [23/100], Training Loss: 3.4434, Validation Loss Current: 11.6150, Validation Loss AVG: 11.6150, lr: 0.001
Epoch [24/100], Training Loss: 2.2474, Validation Loss Current: 11.0277, Validation Loss AVG: 11.0277, lr: 0.001
Epoch [25/100], Training Loss: 3.0677, Validation Loss Current: 12.1153, Validation Loss AVG: 12.1153, lr: 0.001
Epoch [26/100], Training Loss: 2.0549, Validation Loss Current: 11.3649, Validation Loss AVG: 11.3649, lr: 0.001
Epoch [27/100], Training Loss: 6.0811, Validation Loss Current: 12.4645, Validation Loss AVG: 12.4645, lr: 0.001
Epoch [28/100], Training Loss: 5.0070, Validation Loss Current: 11.9709, Validation Loss AVG: 11.9709, lr: 0.001
Epoch [29/100], Training Loss: 7.0786, Validation Loss Current: 11.9455, Validation Loss AVG: 11.9455, lr: 0.001
Epoch [30/100], Training Loss: 13.1556, Validation Loss Current: 15.1323, Validation Loss AVG: 15.1323, lr: 0.001
Epoch [31/100], Training Loss: 10.7247, Validation Loss Current: 11.5810, Validation Loss AVG: 11.5810, lr: 0.001
Epoch [32/100], Training Loss: 7.8493, Validation Loss Current: 12.1294, Validation Loss AVG: 12.1294, lr: 0.001
Epoch [33/100], Training Loss: 8.6222, Validation Loss Current: 13.0565, Validation Loss AVG: 13.0565, lr: 0.001
Epoch [34/100], Training Loss: 4.6521, Validation Loss Current: 11.1213, Validation Loss AVG: 11.1213, lr: 0.001
Epoch [35/100], Training Loss: 3.0439, Validation Loss Current: 10.9929, Validation Loss AVG: 10.9929, lr: 0.001
Epoch [36/100], Training Loss: 2.4803, Validation Loss Current: 12.9134, Validation Loss AVG: 12.9134, lr: 0.001
Epoch [37/100], Training Loss: 1.6531, Validation Loss Current: 11.8236, Validation Loss AVG: 11.8236, lr: 0.001
Epoch [38/100], Training Loss: 1.5175, Validation Loss Current: 11.7655, Validation Loss AVG: 11.7655, lr: 0.001
Epoch [39/100], Training Loss: 2.1757, Validation Loss Current: 11.8592, Validation Loss AVG: 11.8592, lr: 0.001
Epoch [40/100], Training Loss: 2.6029, Validation Loss Current: 13.0446, Validation Loss AVG: 13.0446, lr: 0.001
Epoch [41/100], Training Loss: 4.5793, Validation Loss Current: 11.6234, Validation Loss AVG: 11.6234, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 11 Best val accuracy: [0.38355263157894737, 0.4180921052631579, 0.4407894736842105, 0.46019736842105263, 0.44013157894736843, 0.4233552631578948, 0.4463815789473684, 0.39342105263157895, 0.44671052631578945, 0.4618421052631579, 0.4578947368421053, 0.3822368421052632, 0.42796052631578946, 0.4013157894736842, 0.39671052631578946, 0.35625, 0.4338815789473684, 0.45493421052631583, 0.46578947368421053, 0.4848684210526316, 0.4444078947368421, 0.46447368421052637, 0.44177631578947374, 0.4608552631578947, 0.4457236842105264, 0.4720394736842105, 0.44605263157894737, 0.44835526315789476, 0.46447368421052637, 0.38256578947368425, 0.44835526315789476, 0.4529605263157895, 0.4141447368421053, 0.46743421052631573, 0.46052631578947373, 0.43059210526315794, 0.4473684210526315, 0.4549342105263158, 0.4430921052631579, 0.4569078947368421, 0.42467105263157895] Best val loss: 9.133641600608826


Current group: 0.8
Epoch [1/100], Training Loss: 28.3144, Validation Loss Current: 10.7665, Validation Loss AVG: 10.7665, lr: 0.001
Epoch [2/100], Training Loss: 18.6154, Validation Loss Current: 11.3327, Validation Loss AVG: 11.3327, lr: 0.001
Epoch [3/100], Training Loss: 11.6657, Validation Loss Current: 10.9007, Validation Loss AVG: 10.9007, lr: 0.001
Epoch [4/100], Training Loss: 6.6960, Validation Loss Current: 9.4099, Validation Loss AVG: 9.4099, lr: 0.001
Epoch [5/100], Training Loss: 6.3381, Validation Loss Current: 11.7981, Validation Loss AVG: 11.7981, lr: 0.001
Epoch [6/100], Training Loss: 6.1979, Validation Loss Current: 12.1393, Validation Loss AVG: 12.1393, lr: 0.001
Epoch [7/100], Training Loss: 7.5806, Validation Loss Current: 12.1756, Validation Loss AVG: 12.1756, lr: 0.001
Epoch [8/100], Training Loss: 12.8149, Validation Loss Current: 12.7532, Validation Loss AVG: 12.7532, lr: 0.001
Epoch [9/100], Training Loss: 9.8458, Validation Loss Current: 12.5355, Validation Loss AVG: 12.5355, lr: 0.001
Epoch [10/100], Training Loss: 5.8472, Validation Loss Current: 11.6810, Validation Loss AVG: 11.6810, lr: 0.001
Epoch [11/100], Training Loss: 4.3611, Validation Loss Current: 11.7965, Validation Loss AVG: 11.7965, lr: 0.001
Epoch [12/100], Training Loss: 4.8052, Validation Loss Current: 11.7403, Validation Loss AVG: 11.7403, lr: 0.001
Epoch [13/100], Training Loss: 4.7966, Validation Loss Current: 13.3330, Validation Loss AVG: 13.3330, lr: 0.001
Epoch [14/100], Training Loss: 7.5575, Validation Loss Current: 15.0539, Validation Loss AVG: 15.0539, lr: 0.001
Epoch [15/100], Training Loss: 8.5330, Validation Loss Current: 12.9688, Validation Loss AVG: 12.9688, lr: 0.001
Epoch [16/100], Training Loss: 6.4028, Validation Loss Current: 12.9880, Validation Loss AVG: 12.9880, lr: 0.001
Epoch [17/100], Training Loss: 5.3811, Validation Loss Current: 13.4417, Validation Loss AVG: 13.4417, lr: 0.001
Epoch [18/100], Training Loss: 2.5745, Validation Loss Current: 10.6613, Validation Loss AVG: 10.6613, lr: 0.001
Epoch [19/100], Training Loss: 3.5235, Validation Loss Current: 11.1508, Validation Loss AVG: 11.1508, lr: 0.001
Epoch [20/100], Training Loss: 5.1990, Validation Loss Current: 10.8390, Validation Loss AVG: 10.8390, lr: 0.001
Epoch [21/100], Training Loss: 1.9280, Validation Loss Current: 11.9513, Validation Loss AVG: 11.9513, lr: 0.001
Epoch [22/100], Training Loss: 4.3908, Validation Loss Current: 12.3756, Validation Loss AVG: 12.3756, lr: 0.001
Epoch [23/100], Training Loss: 3.1845, Validation Loss Current: 11.1231, Validation Loss AVG: 11.1231, lr: 0.001
Epoch [24/100], Training Loss: 5.3783, Validation Loss Current: 13.8248, Validation Loss AVG: 13.8248, lr: 0.001
Epoch [25/100], Training Loss: 3.9189, Validation Loss Current: 13.0395, Validation Loss AVG: 13.0395, lr: 0.001
Epoch [26/100], Training Loss: 1.7460, Validation Loss Current: 11.0279, Validation Loss AVG: 11.0279, lr: 0.001
Epoch [27/100], Training Loss: 1.2618, Validation Loss Current: 11.9571, Validation Loss AVG: 11.9571, lr: 0.001
Epoch [28/100], Training Loss: 1.5707, Validation Loss Current: 11.8907, Validation Loss AVG: 11.8907, lr: 0.001
Epoch [29/100], Training Loss: 3.5913, Validation Loss Current: 13.2212, Validation Loss AVG: 13.2212, lr: 0.001
Epoch [30/100], Training Loss: 6.1560, Validation Loss Current: 11.8982, Validation Loss AVG: 11.8982, lr: 0.001
Epoch [31/100], Training Loss: 2.5450, Validation Loss Current: 12.2157, Validation Loss AVG: 12.2157, lr: 0.001
Epoch [32/100], Training Loss: 1.5870, Validation Loss Current: 11.5984, Validation Loss AVG: 11.5984, lr: 0.001
Epoch [33/100], Training Loss: 1.2479, Validation Loss Current: 12.3295, Validation Loss AVG: 12.3295, lr: 0.001
Epoch [34/100], Training Loss: 1.8920, Validation Loss Current: 12.5647, Validation Loss AVG: 12.5647, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.43717105263157896, 0.45394736842105265, 0.4414473684210526, 0.4947368421052632, 0.4125, 0.46578947368421053, 0.4161184210526316, 0.44703947368421054, 0.4276315789473684, 0.46019736842105263, 0.449342105263158, 0.45230263157894735, 0.4236842105263158, 0.41710526315789476, 0.40032894736842106, 0.42993421052631575, 0.4342105263157895, 0.47105263157894733, 0.46907894736842104, 0.47796052631578945, 0.46578947368421053, 0.4713815789473685, 0.46282894736842106, 0.43717105263157896, 0.45000000000000007, 0.48355263157894735, 0.4697368421052632, 0.46809210526315786, 0.45723684210526316, 0.46052631578947373, 0.4453947368421053, 0.4927631578947368, 0.4447368421052632, 0.4756578947368421] Best val loss: 9.409852433204652


Current group: 1
Epoch [1/100], Training Loss: 23.3744, Validation Loss Current: 8.9661, Validation Loss AVG: 11.7035, lr: 0.001
Epoch [2/100], Training Loss: 12.7761, Validation Loss Current: 9.9692, Validation Loss AVG: 12.8447, lr: 0.001
Epoch [3/100], Training Loss: 7.4330, Validation Loss Current: 8.7920, Validation Loss AVG: 11.5411, lr: 0.001
Epoch [4/100], Training Loss: 8.2045, Validation Loss Current: 9.2323, Validation Loss AVG: 13.7680, lr: 0.001
Epoch [5/100], Training Loss: 9.5306, Validation Loss Current: 9.1610, Validation Loss AVG: 12.8335, lr: 0.001
Epoch [6/100], Training Loss: 13.0931, Validation Loss Current: 9.2592, Validation Loss AVG: 11.3504, lr: 0.001
Epoch [7/100], Training Loss: 8.7824, Validation Loss Current: 8.5930, Validation Loss AVG: 12.2901, lr: 0.001
Epoch [8/100], Training Loss: 8.5326, Validation Loss Current: 11.7339, Validation Loss AVG: 15.7815, lr: 0.001
Epoch [9/100], Training Loss: 4.5646, Validation Loss Current: 8.4807, Validation Loss AVG: 11.3834, lr: 0.001
Epoch [10/100], Training Loss: 2.8960, Validation Loss Current: 8.1308, Validation Loss AVG: 11.6923, lr: 0.001
Epoch [11/100], Training Loss: 3.0677, Validation Loss Current: 8.0911, Validation Loss AVG: 11.3599, lr: 0.001
Epoch [12/100], Training Loss: 3.0490, Validation Loss Current: 8.4918, Validation Loss AVG: 13.2899, lr: 0.001
Epoch [13/100], Training Loss: 2.9381, Validation Loss Current: 8.1401, Validation Loss AVG: 12.8448, lr: 0.001
Epoch [14/100], Training Loss: 4.1928, Validation Loss Current: 8.5180, Validation Loss AVG: 11.6028, lr: 0.001
Epoch [15/100], Training Loss: 3.7086, Validation Loss Current: 8.3713, Validation Loss AVG: 12.8459, lr: 0.001
Epoch [16/100], Training Loss: 3.0993, Validation Loss Current: 8.7653, Validation Loss AVG: 13.4981, lr: 0.001
Epoch [17/100], Training Loss: 2.5518, Validation Loss Current: 9.3360, Validation Loss AVG: 12.0134, lr: 0.001
Epoch [18/100], Training Loss: 2.9464, Validation Loss Current: 8.1126, Validation Loss AVG: 13.4848, lr: 0.001
Epoch [19/100], Training Loss: 2.7452, Validation Loss Current: 8.6483, Validation Loss AVG: 15.2633, lr: 0.001
Epoch [20/100], Training Loss: 4.8045, Validation Loss Current: 8.9274, Validation Loss AVG: 13.8693, lr: 0.001
Epoch [21/100], Training Loss: 1.6283, Validation Loss Current: 8.8464, Validation Loss AVG: 10.8999, lr: 0.001
Epoch [22/100], Training Loss: 4.2969, Validation Loss Current: 8.5663, Validation Loss AVG: 11.7169, lr: 0.001
Epoch [23/100], Training Loss: 4.8029, Validation Loss Current: 9.1530, Validation Loss AVG: 13.9934, lr: 0.001
Epoch [24/100], Training Loss: 3.0801, Validation Loss Current: 10.7918, Validation Loss AVG: 14.0177, lr: 0.001
Epoch [25/100], Training Loss: 3.8527, Validation Loss Current: 9.6190, Validation Loss AVG: 12.4397, lr: 0.001
Epoch [26/100], Training Loss: 3.2208, Validation Loss Current: 10.5418, Validation Loss AVG: 15.7121, lr: 0.001
Epoch [27/100], Training Loss: 4.3581, Validation Loss Current: 10.0897, Validation Loss AVG: 12.6406, lr: 0.001
Epoch [28/100], Training Loss: 4.5111, Validation Loss Current: 9.9739, Validation Loss AVG: 13.6135, lr: 0.001
Epoch [29/100], Training Loss: 5.1001, Validation Loss Current: 9.7239, Validation Loss AVG: 12.9482, lr: 0.001
Epoch [30/100], Training Loss: 6.6072, Validation Loss Current: 10.4182, Validation Loss AVG: 13.3169, lr: 0.001
Epoch [31/100], Training Loss: 6.3594, Validation Loss Current: 9.9870, Validation Loss AVG: 14.2321, lr: 0.001
Epoch [32/100], Training Loss: 2.8323, Validation Loss Current: 9.5199, Validation Loss AVG: 13.2679, lr: 0.001
Epoch [33/100], Training Loss: 5.4209, Validation Loss Current: 8.7682, Validation Loss AVG: 13.8080, lr: 0.001
Epoch [34/100], Training Loss: 2.1570, Validation Loss Current: 8.7064, Validation Loss AVG: 13.6063, lr: 0.001
Epoch [35/100], Training Loss: 2.9632, Validation Loss Current: 9.4542, Validation Loss AVG: 13.4227, lr: 0.001
Epoch [36/100], Training Loss: 7.1614, Validation Loss Current: 11.0115, Validation Loss AVG: 15.6745, lr: 0.001
Epoch [37/100], Training Loss: 3.6285, Validation Loss Current: 10.2897, Validation Loss AVG: 12.3405, lr: 0.001
Epoch [38/100], Training Loss: 3.6147, Validation Loss Current: 9.5535, Validation Loss AVG: 13.8156, lr: 0.001
Epoch [39/100], Training Loss: 4.9972, Validation Loss Current: 11.6122, Validation Loss AVG: 13.8614, lr: 0.001
Epoch [40/100], Training Loss: 6.4028, Validation Loss Current: 9.9368, Validation Loss AVG: 15.2373, lr: 0.001
Epoch [41/100], Training Loss: 9.2064, Validation Loss Current: 11.4983, Validation Loss AVG: 17.0386, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 11 Best val accuracy: [0.5509868421052632, 0.5180921052631579, 0.569078947368421, 0.5328947368421053, 0.5740131578947368, 0.5476973684210527, 0.5707236842105263, 0.5328947368421053, 0.5986842105263158, 0.600328947368421, 0.6019736842105263, 0.5641447368421053, 0.6101973684210527, 0.6036184210526315, 0.5723684210526315, 0.59375, 0.600328947368421, 0.6200657894736842, 0.6101973684210527, 0.6167763157894737, 0.5888157894736842, 0.6069078947368421, 0.5608552631578947, 0.5953947368421053, 0.5641447368421053, 0.5411184210526315, 0.5789473684210527, 0.5674342105263158, 0.5740131578947368, 0.5641447368421053, 0.5773026315789473, 0.5657894736842105, 0.600328947368421, 0.5888157894736842, 0.5756578947368421, 0.5657894736842105, 0.5657894736842105, 0.5953947368421053, 0.5180921052631579, 0.5542763157894737, 0.5197368421052632] Best val loss: 8.091133713722229


----- Training resnet18 with sequence: [0.6, 0.8, 1] -----
Current group: 0.6
Epoch [1/134], Training Loss: 41.3650, Validation Loss Current: 10.0564, Validation Loss AVG: 10.0564, lr: 0.001
Epoch [2/134], Training Loss: 39.5004, Validation Loss Current: 9.7989, Validation Loss AVG: 9.7989, lr: 0.001
Epoch [3/134], Training Loss: 39.0286, Validation Loss Current: 9.7221, Validation Loss AVG: 9.7221, lr: 0.001
Epoch [4/134], Training Loss: 37.6146, Validation Loss Current: 9.4769, Validation Loss AVG: 9.4769, lr: 0.001
Epoch [5/134], Training Loss: 35.8083, Validation Loss Current: 9.4306, Validation Loss AVG: 9.4306, lr: 0.001
Epoch [6/134], Training Loss: 35.8967, Validation Loss Current: 9.3026, Validation Loss AVG: 9.3026, lr: 0.001
Epoch [7/134], Training Loss: 34.2303, Validation Loss Current: 9.0751, Validation Loss AVG: 9.0751, lr: 0.001
Epoch [8/134], Training Loss: 32.6766, Validation Loss Current: 8.7972, Validation Loss AVG: 8.7972, lr: 0.001
Epoch [9/134], Training Loss: 31.7954, Validation Loss Current: 8.6740, Validation Loss AVG: 8.6740, lr: 0.001
Epoch [10/134], Training Loss: 31.5191, Validation Loss Current: 8.6446, Validation Loss AVG: 8.6446, lr: 0.001
Epoch [11/134], Training Loss: 30.3657, Validation Loss Current: 8.3889, Validation Loss AVG: 8.3889, lr: 0.001
Epoch [12/134], Training Loss: 28.8464, Validation Loss Current: 8.3847, Validation Loss AVG: 8.3847, lr: 0.001
Epoch [13/134], Training Loss: 28.5575, Validation Loss Current: 9.1290, Validation Loss AVG: 9.1290, lr: 0.001
Epoch [14/134], Training Loss: 29.3422, Validation Loss Current: 8.3255, Validation Loss AVG: 8.3255, lr: 0.001
Epoch [15/134], Training Loss: 27.5090, Validation Loss Current: 8.1601, Validation Loss AVG: 8.1601, lr: 0.001
Epoch [16/134], Training Loss: 25.6682, Validation Loss Current: 7.8992, Validation Loss AVG: 7.8992, lr: 0.001
Epoch [17/134], Training Loss: 25.0487, Validation Loss Current: 8.1368, Validation Loss AVG: 8.1368, lr: 0.001
Epoch [18/134], Training Loss: 26.6911, Validation Loss Current: 8.7533, Validation Loss AVG: 8.7533, lr: 0.001
Epoch [19/134], Training Loss: 25.6988, Validation Loss Current: 8.1030, Validation Loss AVG: 8.1030, lr: 0.001
Epoch [20/134], Training Loss: 24.4437, Validation Loss Current: 7.7881, Validation Loss AVG: 7.7881, lr: 0.001
Epoch [21/134], Training Loss: 22.9321, Validation Loss Current: 8.2017, Validation Loss AVG: 8.2017, lr: 0.001
Epoch [22/134], Training Loss: 22.5680, Validation Loss Current: 7.9458, Validation Loss AVG: 7.9458, lr: 0.001
Epoch [23/134], Training Loss: 21.4202, Validation Loss Current: 9.0363, Validation Loss AVG: 9.0363, lr: 0.001
Epoch [24/134], Training Loss: 20.7813, Validation Loss Current: 7.8759, Validation Loss AVG: 7.8759, lr: 0.001
Epoch [25/134], Training Loss: 19.5040, Validation Loss Current: 7.6729, Validation Loss AVG: 7.6729, lr: 0.001
Epoch [26/134], Training Loss: 18.7090, Validation Loss Current: 8.4160, Validation Loss AVG: 8.4160, lr: 0.001
Epoch [27/134], Training Loss: 18.4408, Validation Loss Current: 8.5924, Validation Loss AVG: 8.5924, lr: 0.001
Epoch [28/134], Training Loss: 18.0909, Validation Loss Current: 8.4153, Validation Loss AVG: 8.4153, lr: 0.001
Epoch [29/134], Training Loss: 16.7973, Validation Loss Current: 9.6681, Validation Loss AVG: 9.6681, lr: 0.001
Epoch [30/134], Training Loss: 17.9314, Validation Loss Current: 7.8402, Validation Loss AVG: 7.8402, lr: 0.001
Epoch [31/134], Training Loss: 15.0046, Validation Loss Current: 7.6185, Validation Loss AVG: 7.6185, lr: 0.001
Epoch [32/134], Training Loss: 14.7587, Validation Loss Current: 8.2762, Validation Loss AVG: 8.2762, lr: 0.001
Epoch [33/134], Training Loss: 15.4347, Validation Loss Current: 8.8115, Validation Loss AVG: 8.8115, lr: 0.001
Epoch [34/134], Training Loss: 14.0452, Validation Loss Current: 9.8687, Validation Loss AVG: 9.8687, lr: 0.001
Epoch [35/134], Training Loss: 13.5982, Validation Loss Current: 9.0960, Validation Loss AVG: 9.0960, lr: 0.001
Epoch [36/134], Training Loss: 15.2445, Validation Loss Current: 9.7324, Validation Loss AVG: 9.7324, lr: 0.001
Epoch [37/134], Training Loss: 15.3863, Validation Loss Current: 9.5145, Validation Loss AVG: 9.5145, lr: 0.001
Epoch [38/134], Training Loss: 12.8974, Validation Loss Current: 8.7126, Validation Loss AVG: 8.7126, lr: 0.001
Epoch [39/134], Training Loss: 11.8037, Validation Loss Current: 8.5972, Validation Loss AVG: 8.5972, lr: 0.001
Epoch [40/134], Training Loss: 9.4248, Validation Loss Current: 8.7174, Validation Loss AVG: 8.7174, lr: 0.001
Epoch [41/134], Training Loss: 10.1175, Validation Loss Current: 8.4736, Validation Loss AVG: 8.4736, lr: 0.001
Epoch [42/134], Training Loss: 10.1075, Validation Loss Current: 8.6715, Validation Loss AVG: 8.6715, lr: 0.001
Epoch [43/134], Training Loss: 10.7676, Validation Loss Current: 9.3746, Validation Loss AVG: 9.3746, lr: 0.001
Epoch [44/134], Training Loss: 8.8498, Validation Loss Current: 9.3980, Validation Loss AVG: 9.3980, lr: 0.001
Epoch [45/134], Training Loss: 9.4192, Validation Loss Current: 9.7887, Validation Loss AVG: 9.7887, lr: 0.001
Epoch [46/134], Training Loss: 8.2357, Validation Loss Current: 10.3735, Validation Loss AVG: 10.3735, lr: 0.001
Epoch [47/134], Training Loss: 9.3687, Validation Loss Current: 14.2164, Validation Loss AVG: 14.2164, lr: 0.001
Epoch [48/134], Training Loss: 8.5916, Validation Loss Current: 11.0315, Validation Loss AVG: 11.0315, lr: 0.001
Epoch [49/134], Training Loss: 6.0986, Validation Loss Current: 9.8807, Validation Loss AVG: 9.8807, lr: 0.001
Epoch [50/134], Training Loss: 5.4639, Validation Loss Current: 9.2190, Validation Loss AVG: 9.2190, lr: 0.001
Epoch [51/134], Training Loss: 6.7416, Validation Loss Current: 10.0136, Validation Loss AVG: 10.0136, lr: 0.001
Epoch [52/134], Training Loss: 5.1435, Validation Loss Current: 9.6569, Validation Loss AVG: 9.6569, lr: 0.001
Epoch [53/134], Training Loss: 8.9751, Validation Loss Current: 11.0076, Validation Loss AVG: 11.0076, lr: 0.001
Epoch [54/134], Training Loss: 11.7251, Validation Loss Current: 12.2908, Validation Loss AVG: 12.2908, lr: 0.001
Epoch [55/134], Training Loss: 9.4267, Validation Loss Current: 11.3444, Validation Loss AVG: 11.3444, lr: 0.001
Epoch [56/134], Training Loss: 7.5281, Validation Loss Current: 10.7973, Validation Loss AVG: 10.7973, lr: 0.001
Epoch [57/134], Training Loss: 4.0271, Validation Loss Current: 9.6821, Validation Loss AVG: 9.6821, lr: 0.001
Epoch [58/134], Training Loss: 2.5210, Validation Loss Current: 9.7884, Validation Loss AVG: 9.7884, lr: 0.001
Epoch [59/134], Training Loss: 4.6743, Validation Loss Current: 10.5034, Validation Loss AVG: 10.5034, lr: 0.001
Epoch [60/134], Training Loss: 4.2504, Validation Loss Current: 10.6559, Validation Loss AVG: 10.6559, lr: 0.001
Epoch [61/134], Training Loss: 4.0014, Validation Loss Current: 10.0682, Validation Loss AVG: 10.0682, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 31 Best val accuracy: [0.25526315789473686, 0.2618421052631579, 0.26151315789473684, 0.32401315789473684, 0.3174342105263158, 0.34375, 0.34407894736842104, 0.3970394736842105, 0.3911184210526316, 0.3828947368421053, 0.42796052631578946, 0.42796052631578946, 0.3891447368421053, 0.4006578947368421, 0.43322368421052626, 0.4519736842105263, 0.4319078947368421, 0.4009868421052632, 0.4480263157894737, 0.4483552631578947, 0.44572368421052627, 0.44835526315789476, 0.40197368421052637, 0.4490131578947369, 0.46940789473684214, 0.4384868421052632, 0.44703947368421054, 0.46019736842105263, 0.42434210526315785, 0.4667763157894737, 0.4786184210526316, 0.4805921052631579, 0.43717105263157896, 0.42269736842105265, 0.44703947368421054, 0.45592105263157895, 0.4440789473684211, 0.4723684210526316, 0.45197368421052636, 0.47796052631578945, 0.46907894736842104, 0.4513157894736842, 0.4348684210526315, 0.4759868421052632, 0.4411184210526315, 0.46578947368421053, 0.3779605263157894, 0.4220394736842105, 0.4703947368421053, 0.4720394736842105, 0.4615131578947368, 0.46611842105263157, 0.4240131578947368, 0.3917763157894737, 0.425, 0.45559210526315785, 0.4875, 0.4592105263157894, 0.46809210526315786, 0.4463815789473684, 0.4411184210526316] Best val loss: 7.618450331687927


Current group: 0.8
Epoch [1/134], Training Loss: 26.0527, Validation Loss Current: 12.5778, Validation Loss AVG: 12.5778, lr: 0.001
Epoch [2/134], Training Loss: 20.5247, Validation Loss Current: 9.1277, Validation Loss AVG: 9.1277, lr: 0.001
Epoch [3/134], Training Loss: 16.4439, Validation Loss Current: 10.5305, Validation Loss AVG: 10.5305, lr: 0.001
Epoch [4/134], Training Loss: 12.8785, Validation Loss Current: 9.4647, Validation Loss AVG: 9.4647, lr: 0.001
Epoch [5/134], Training Loss: 11.5114, Validation Loss Current: 8.8537, Validation Loss AVG: 8.8537, lr: 0.001
Epoch [6/134], Training Loss: 8.3455, Validation Loss Current: 8.8497, Validation Loss AVG: 8.8497, lr: 0.001
Epoch [7/134], Training Loss: 5.7908, Validation Loss Current: 9.5581, Validation Loss AVG: 9.5581, lr: 0.001
Epoch [8/134], Training Loss: 6.9067, Validation Loss Current: 9.0307, Validation Loss AVG: 9.0307, lr: 0.001
Epoch [9/134], Training Loss: 5.9187, Validation Loss Current: 10.4988, Validation Loss AVG: 10.4988, lr: 0.001
Epoch [10/134], Training Loss: 5.6592, Validation Loss Current: 11.4760, Validation Loss AVG: 11.4760, lr: 0.001
Epoch [11/134], Training Loss: 6.5901, Validation Loss Current: 11.1410, Validation Loss AVG: 11.1410, lr: 0.001
Epoch [12/134], Training Loss: 7.2420, Validation Loss Current: 10.4547, Validation Loss AVG: 10.4547, lr: 0.001
Epoch [13/134], Training Loss: 7.7893, Validation Loss Current: 10.4045, Validation Loss AVG: 10.4045, lr: 0.001
Epoch [14/134], Training Loss: 5.6160, Validation Loss Current: 12.0462, Validation Loss AVG: 12.0462, lr: 0.001
Epoch [15/134], Training Loss: 4.8901, Validation Loss Current: 12.1029, Validation Loss AVG: 12.1029, lr: 0.001
Epoch [16/134], Training Loss: 6.7791, Validation Loss Current: 10.6799, Validation Loss AVG: 10.6799, lr: 0.001
Epoch [17/134], Training Loss: 4.1067, Validation Loss Current: 9.1867, Validation Loss AVG: 9.1867, lr: 0.001
Epoch [18/134], Training Loss: 4.3766, Validation Loss Current: 11.0911, Validation Loss AVG: 11.0911, lr: 0.001
Epoch [19/134], Training Loss: 4.7684, Validation Loss Current: 10.9855, Validation Loss AVG: 10.9855, lr: 0.001
Epoch [20/134], Training Loss: 4.4299, Validation Loss Current: 12.7611, Validation Loss AVG: 12.7611, lr: 0.001
Epoch [21/134], Training Loss: 6.2065, Validation Loss Current: 12.9487, Validation Loss AVG: 12.9487, lr: 0.001
Epoch [22/134], Training Loss: 3.3926, Validation Loss Current: 11.6610, Validation Loss AVG: 11.6610, lr: 0.001
Epoch [23/134], Training Loss: 4.7844, Validation Loss Current: 10.5923, Validation Loss AVG: 10.5923, lr: 0.001
Epoch [24/134], Training Loss: 4.3225, Validation Loss Current: 11.4152, Validation Loss AVG: 11.4152, lr: 0.001
Epoch [25/134], Training Loss: 4.2280, Validation Loss Current: 12.5774, Validation Loss AVG: 12.5774, lr: 0.001
Epoch [26/134], Training Loss: 4.3344, Validation Loss Current: 12.9540, Validation Loss AVG: 12.9540, lr: 0.001
Epoch [27/134], Training Loss: 3.4449, Validation Loss Current: 13.4488, Validation Loss AVG: 13.4488, lr: 0.001
Epoch [28/134], Training Loss: 3.1149, Validation Loss Current: 14.1416, Validation Loss AVG: 14.1416, lr: 0.001
Epoch [29/134], Training Loss: 2.4701, Validation Loss Current: 15.3043, Validation Loss AVG: 15.3043, lr: 0.001
Epoch [30/134], Training Loss: 2.1739, Validation Loss Current: 12.0935, Validation Loss AVG: 12.0935, lr: 0.001
Epoch [31/134], Training Loss: 4.0869, Validation Loss Current: 15.2332, Validation Loss AVG: 15.2332, lr: 0.001
Epoch [32/134], Training Loss: 4.5374, Validation Loss Current: 14.8726, Validation Loss AVG: 14.8726, lr: 0.001
Epoch [33/134], Training Loss: 4.5495, Validation Loss Current: 12.3157, Validation Loss AVG: 12.3157, lr: 0.001
Epoch [34/134], Training Loss: 3.2409, Validation Loss Current: 13.5130, Validation Loss AVG: 13.5130, lr: 0.001
Epoch [35/134], Training Loss: 4.6649, Validation Loss Current: 13.7403, Validation Loss AVG: 13.7403, lr: 0.001
Epoch [36/134], Training Loss: 4.1538, Validation Loss Current: 15.3082, Validation Loss AVG: 15.3082, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 6 Best val accuracy: [0.3707236842105263, 0.47730263157894737, 0.42730263157894743, 0.4480263157894737, 0.48157894736842105, 0.4608552631578947, 0.4516447368421053, 0.48125, 0.45394736842105265, 0.4302631578947368, 0.45, 0.4480263157894737, 0.4625, 0.44703947368421054, 0.44671052631578956, 0.45065789473684215, 0.47730263157894737, 0.4565789473684211, 0.43256578947368424, 0.4532894736842105, 0.46085526315789477, 0.45, 0.48190789473684215, 0.46809210526315786, 0.4223684210526316, 0.419078947368421, 0.4516447368421053, 0.44243421052631576, 0.44868421052631574, 0.4625, 0.42598684210526316, 0.4230263157894737, 0.46118421052631575, 0.42434210526315785, 0.4328947368421052, 0.4217105263157895] Best val loss: 8.84965341091156


Current group: 1
Epoch [1/134], Training Loss: 25.0291, Validation Loss Current: 9.2546, Validation Loss AVG: 14.2501, lr: 0.001
Epoch [2/134], Training Loss: 19.6106, Validation Loss Current: 8.5476, Validation Loss AVG: 14.2614, lr: 0.001
Epoch [3/134], Training Loss: 12.0613, Validation Loss Current: 7.4087, Validation Loss AVG: 11.4320, lr: 0.001
Epoch [4/134], Training Loss: 7.8549, Validation Loss Current: 7.1102, Validation Loss AVG: 9.9088, lr: 0.001
Epoch [5/134], Training Loss: 7.6996, Validation Loss Current: 7.6857, Validation Loss AVG: 14.0872, lr: 0.001
Epoch [6/134], Training Loss: 4.8287, Validation Loss Current: 7.4172, Validation Loss AVG: 11.9088, lr: 0.001
Epoch [7/134], Training Loss: 5.0510, Validation Loss Current: 7.3548, Validation Loss AVG: 10.9616, lr: 0.001
Epoch [8/134], Training Loss: 3.2714, Validation Loss Current: 6.6374, Validation Loss AVG: 10.1659, lr: 0.001
Epoch [9/134], Training Loss: 2.9709, Validation Loss Current: 6.8014, Validation Loss AVG: 13.0965, lr: 0.001
Epoch [10/134], Training Loss: 5.6450, Validation Loss Current: 7.6364, Validation Loss AVG: 13.6008, lr: 0.001
Epoch [11/134], Training Loss: 8.0745, Validation Loss Current: 7.9360, Validation Loss AVG: 12.4194, lr: 0.001
Epoch [12/134], Training Loss: 6.4908, Validation Loss Current: 8.0311, Validation Loss AVG: 11.4589, lr: 0.001
Epoch [13/134], Training Loss: 9.3413, Validation Loss Current: 10.4260, Validation Loss AVG: 17.0212, lr: 0.001
Epoch [14/134], Training Loss: 4.0554, Validation Loss Current: 7.5499, Validation Loss AVG: 12.2507, lr: 0.001
Epoch [15/134], Training Loss: 4.1842, Validation Loss Current: 7.1055, Validation Loss AVG: 11.5831, lr: 0.001
Epoch [16/134], Training Loss: 1.7103, Validation Loss Current: 7.7570, Validation Loss AVG: 11.5517, lr: 0.001
Epoch [17/134], Training Loss: 2.1532, Validation Loss Current: 7.4995, Validation Loss AVG: 12.6577, lr: 0.001
Epoch [18/134], Training Loss: 5.9824, Validation Loss Current: 7.7408, Validation Loss AVG: 13.9967, lr: 0.001
Epoch [19/134], Training Loss: 5.8323, Validation Loss Current: 8.4725, Validation Loss AVG: 12.9824, lr: 0.001
Epoch [20/134], Training Loss: 3.2429, Validation Loss Current: 8.1483, Validation Loss AVG: 12.3096, lr: 0.001
Epoch [21/134], Training Loss: 1.4735, Validation Loss Current: 7.6638, Validation Loss AVG: 13.3109, lr: 0.001
Epoch [22/134], Training Loss: 3.4429, Validation Loss Current: 7.7282, Validation Loss AVG: 11.0681, lr: 0.001
Epoch [23/134], Training Loss: 2.8208, Validation Loss Current: 8.0289, Validation Loss AVG: 14.2594, lr: 0.001
Epoch [24/134], Training Loss: 5.2793, Validation Loss Current: 8.2123, Validation Loss AVG: 13.1444, lr: 0.001
Epoch [25/134], Training Loss: 6.0433, Validation Loss Current: 10.7921, Validation Loss AVG: 22.4510, lr: 0.001
Epoch [26/134], Training Loss: 4.3702, Validation Loss Current: 10.1309, Validation Loss AVG: 17.1705, lr: 0.001
Epoch [27/134], Training Loss: 6.5339, Validation Loss Current: 8.5355, Validation Loss AVG: 13.2117, lr: 0.001
Epoch [28/134], Training Loss: 4.7846, Validation Loss Current: 8.1667, Validation Loss AVG: 11.5637, lr: 0.001
Epoch [29/134], Training Loss: 3.3061, Validation Loss Current: 8.4095, Validation Loss AVG: 15.0803, lr: 0.001
Epoch [30/134], Training Loss: 3.5524, Validation Loss Current: 9.3314, Validation Loss AVG: 12.5020, lr: 0.001
Epoch [31/134], Training Loss: 4.9163, Validation Loss Current: 7.9138, Validation Loss AVG: 17.0131, lr: 0.001
Epoch [32/134], Training Loss: 4.0849, Validation Loss Current: 7.8437, Validation Loss AVG: 13.4647, lr: 0.001
Epoch [33/134], Training Loss: 4.2146, Validation Loss Current: 9.4578, Validation Loss AVG: 14.3767, lr: 0.001
Epoch [34/134], Training Loss: 5.2310, Validation Loss Current: 8.9400, Validation Loss AVG: 15.4985, lr: 0.001
Epoch [35/134], Training Loss: 3.9302, Validation Loss Current: 9.3391, Validation Loss AVG: 12.1785, lr: 0.001
Epoch [36/134], Training Loss: 4.6698, Validation Loss Current: 8.4582, Validation Loss AVG: 12.9575, lr: 0.001
Epoch [37/134], Training Loss: 3.1925, Validation Loss Current: 8.1521, Validation Loss AVG: 17.4019, lr: 0.001
Epoch [38/134], Training Loss: 5.5805, Validation Loss Current: 9.5989, Validation Loss AVG: 15.6041, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 8 Best val accuracy: [0.5394736842105263, 0.5674342105263158, 0.5838815789473685, 0.6036184210526315, 0.5855263157894737, 0.555921052631579, 0.618421052631579, 0.6381578947368421, 0.6299342105263158, 0.6463815789473685, 0.5953947368421053, 0.5953947368421053, 0.5328947368421053, 0.6167763157894737, 0.6546052631578947, 0.6430921052631579, 0.618421052631579, 0.5904605263157895, 0.587171052631579, 0.5986842105263158, 0.6200657894736842, 0.6233552631578947, 0.6217105263157895, 0.625, 0.524671052631579, 0.569078947368421, 0.587171052631579, 0.5970394736842105, 0.5822368421052632, 0.6069078947368421, 0.6085526315789473, 0.6200657894736842, 0.5855263157894737, 0.5953947368421053, 0.59375, 0.6217105263157895, 0.6019736842105263, 0.59375] Best val loss: 6.637400150299072


----- Training resnet18 with sequence: [0.8, 1] -----
Current group: 0.8
Epoch [1/200], Training Loss: 39.9624, Validation Loss Current: 9.9772, Validation Loss AVG: 9.9772, lr: 0.001
Epoch [2/200], Training Loss: 39.1950, Validation Loss Current: 9.8820, Validation Loss AVG: 9.8820, lr: 0.001
Epoch [3/200], Training Loss: 37.6998, Validation Loss Current: 9.7683, Validation Loss AVG: 9.7683, lr: 0.001
Epoch [4/200], Training Loss: 36.8800, Validation Loss Current: 9.5714, Validation Loss AVG: 9.5714, lr: 0.001
Epoch [5/200], Training Loss: 35.9305, Validation Loss Current: 9.4295, Validation Loss AVG: 9.4295, lr: 0.001
Epoch [6/200], Training Loss: 34.8066, Validation Loss Current: 9.3370, Validation Loss AVG: 9.3370, lr: 0.001
Epoch [7/200], Training Loss: 33.1945, Validation Loss Current: 9.4125, Validation Loss AVG: 9.4125, lr: 0.001
Epoch [8/200], Training Loss: 32.7584, Validation Loss Current: 9.3435, Validation Loss AVG: 9.3435, lr: 0.001
Epoch [9/200], Training Loss: 30.3233, Validation Loss Current: 9.1130, Validation Loss AVG: 9.1130, lr: 0.001
Epoch [10/200], Training Loss: 30.0128, Validation Loss Current: 9.2366, Validation Loss AVG: 9.2366, lr: 0.001
Epoch [11/200], Training Loss: 29.2579, Validation Loss Current: 8.7275, Validation Loss AVG: 8.7275, lr: 0.001
Epoch [12/200], Training Loss: 28.4702, Validation Loss Current: 8.6688, Validation Loss AVG: 8.6688, lr: 0.001
Epoch [13/200], Training Loss: 26.8182, Validation Loss Current: 8.7369, Validation Loss AVG: 8.7369, lr: 0.001
Epoch [14/200], Training Loss: 26.4509, Validation Loss Current: 9.0006, Validation Loss AVG: 9.0006, lr: 0.001
Epoch [15/200], Training Loss: 25.8409, Validation Loss Current: 8.9840, Validation Loss AVG: 8.9840, lr: 0.001
Epoch [16/200], Training Loss: 25.0337, Validation Loss Current: 10.1909, Validation Loss AVG: 10.1909, lr: 0.001
Epoch [17/200], Training Loss: 25.0111, Validation Loss Current: 8.8751, Validation Loss AVG: 8.8751, lr: 0.001
Epoch [18/200], Training Loss: 25.5260, Validation Loss Current: 9.7102, Validation Loss AVG: 9.7102, lr: 0.001
Epoch [19/200], Training Loss: 23.8908, Validation Loss Current: 9.0623, Validation Loss AVG: 9.0623, lr: 0.001
Epoch [20/200], Training Loss: 22.5101, Validation Loss Current: 10.0941, Validation Loss AVG: 10.0941, lr: 0.001
Epoch [21/200], Training Loss: 21.6450, Validation Loss Current: 8.2108, Validation Loss AVG: 8.2108, lr: 0.001
Epoch [22/200], Training Loss: 21.7792, Validation Loss Current: 8.6320, Validation Loss AVG: 8.6320, lr: 0.001
Epoch [23/200], Training Loss: 21.6004, Validation Loss Current: 10.7507, Validation Loss AVG: 10.7507, lr: 0.001
Epoch [24/200], Training Loss: 19.6319, Validation Loss Current: 8.4974, Validation Loss AVG: 8.4974, lr: 0.001
Epoch [25/200], Training Loss: 20.7229, Validation Loss Current: 8.7440, Validation Loss AVG: 8.7440, lr: 0.001
Epoch [26/200], Training Loss: 19.7589, Validation Loss Current: 8.0065, Validation Loss AVG: 8.0065, lr: 0.001
Epoch [27/200], Training Loss: 18.1767, Validation Loss Current: 9.2870, Validation Loss AVG: 9.2870, lr: 0.001
Epoch [28/200], Training Loss: 16.1540, Validation Loss Current: 8.9244, Validation Loss AVG: 8.9244, lr: 0.001
Epoch [29/200], Training Loss: 15.3014, Validation Loss Current: 10.8141, Validation Loss AVG: 10.8141, lr: 0.001
Epoch [30/200], Training Loss: 14.2440, Validation Loss Current: 8.3301, Validation Loss AVG: 8.3301, lr: 0.001
Epoch [31/200], Training Loss: 14.0626, Validation Loss Current: 11.4682, Validation Loss AVG: 11.4682, lr: 0.001
Epoch [32/200], Training Loss: 13.3714, Validation Loss Current: 8.3184, Validation Loss AVG: 8.3184, lr: 0.001
Epoch [33/200], Training Loss: 16.6247, Validation Loss Current: 13.6520, Validation Loss AVG: 13.6520, lr: 0.001
Epoch [34/200], Training Loss: 15.9209, Validation Loss Current: 10.6609, Validation Loss AVG: 10.6609, lr: 0.001
Epoch [35/200], Training Loss: 17.8454, Validation Loss Current: 10.8610, Validation Loss AVG: 10.8610, lr: 0.001
Epoch [36/200], Training Loss: 16.0210, Validation Loss Current: 11.8282, Validation Loss AVG: 11.8282, lr: 0.001
Epoch [37/200], Training Loss: 13.3169, Validation Loss Current: 9.3022, Validation Loss AVG: 9.3022, lr: 0.001
Epoch [38/200], Training Loss: 11.5010, Validation Loss Current: 9.7328, Validation Loss AVG: 9.7328, lr: 0.001
Epoch [39/200], Training Loss: 10.2374, Validation Loss Current: 10.4907, Validation Loss AVG: 10.4907, lr: 0.001
Epoch [40/200], Training Loss: 9.4151, Validation Loss Current: 11.0260, Validation Loss AVG: 11.0260, lr: 0.001
Epoch [41/200], Training Loss: 9.1060, Validation Loss Current: 8.3800, Validation Loss AVG: 8.3800, lr: 0.001
Epoch [42/200], Training Loss: 9.1390, Validation Loss Current: 8.4865, Validation Loss AVG: 8.4865, lr: 0.001
Epoch [43/200], Training Loss: 8.6502, Validation Loss Current: 9.9764, Validation Loss AVG: 9.9764, lr: 0.001
Epoch [44/200], Training Loss: 9.9337, Validation Loss Current: 9.0836, Validation Loss AVG: 9.0836, lr: 0.001
Epoch [45/200], Training Loss: 7.9519, Validation Loss Current: 13.4274, Validation Loss AVG: 13.4274, lr: 0.001
Epoch [46/200], Training Loss: 8.5230, Validation Loss Current: 11.8531, Validation Loss AVG: 11.8531, lr: 0.001
Epoch [47/200], Training Loss: 7.4139, Validation Loss Current: 9.0975, Validation Loss AVG: 9.0975, lr: 0.001
Epoch [48/200], Training Loss: 6.1216, Validation Loss Current: 11.2880, Validation Loss AVG: 11.2880, lr: 0.001
Epoch [49/200], Training Loss: 6.7070, Validation Loss Current: 12.6577, Validation Loss AVG: 12.6577, lr: 0.001
Epoch [50/200], Training Loss: 7.9865, Validation Loss Current: 12.2158, Validation Loss AVG: 12.2158, lr: 0.001
Epoch [51/200], Training Loss: 5.4657, Validation Loss Current: 16.1855, Validation Loss AVG: 16.1855, lr: 0.001
Epoch [52/200], Training Loss: 3.7354, Validation Loss Current: 11.9472, Validation Loss AVG: 11.9472, lr: 0.001
Epoch [53/200], Training Loss: 5.1327, Validation Loss Current: 9.8313, Validation Loss AVG: 9.8313, lr: 0.001
Epoch [54/200], Training Loss: 8.3765, Validation Loss Current: 14.1786, Validation Loss AVG: 14.1786, lr: 0.001
Epoch [55/200], Training Loss: 7.0813, Validation Loss Current: 14.0756, Validation Loss AVG: 14.0756, lr: 0.001
Epoch [56/200], Training Loss: 4.9694, Validation Loss Current: 10.5816, Validation Loss AVG: 10.5816, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 26 Best val accuracy: [0.23552631578947367, 0.2651315789473684, 0.26776315789473687, 0.2868421052631579, 0.3243421052631579, 0.3226973684210526, 0.3263157894736842, 0.3342105263157895, 0.3713815789473684, 0.37236842105263157, 0.3891447368421053, 0.39144736842105265, 0.38157894736842113, 0.36973684210526314, 0.39605263157894743, 0.37072368421052626, 0.40559210526315786, 0.37203947368421053, 0.3835526315789474, 0.38585526315789476, 0.4286184210526316, 0.42434210526315785, 0.3828947368421053, 0.42467105263157895, 0.40690789473684214, 0.4463815789473683, 0.4213815789473684, 0.4391447368421053, 0.40493421052631584, 0.43980263157894744, 0.39539473684210524, 0.43782894736842104, 0.35230263157894737, 0.38453947368421054, 0.3875, 0.3815789473684211, 0.4342105263157895, 0.4463815789473684, 0.43125, 0.4217105263157895, 0.4516447368421053, 0.4582236842105263, 0.44506578947368425, 0.4440789473684211, 0.3973684210526316, 0.41085526315789467, 0.4171052631578947, 0.44605263157894737, 0.425, 0.41447368421052627, 0.41447368421052627, 0.4355263157894737, 0.4490131578947369, 0.3960526315789473, 0.4167763157894736, 0.4411184210526315] Best val loss: 8.006528449058532


Current group: 1
Epoch [1/200], Training Loss: 21.2802, Validation Loss Current: 7.7548, Validation Loss AVG: 15.7631, lr: 0.001
Epoch [2/200], Training Loss: 16.7527, Validation Loss Current: 7.1642, Validation Loss AVG: 10.6781, lr: 0.001
Epoch [3/200], Training Loss: 13.9720, Validation Loss Current: 6.7430, Validation Loss AVG: 9.7992, lr: 0.001
Epoch [4/200], Training Loss: 14.1478, Validation Loss Current: 6.5784, Validation Loss AVG: 11.0448, lr: 0.001
Epoch [5/200], Training Loss: 11.6770, Validation Loss Current: 6.6835, Validation Loss AVG: 10.5621, lr: 0.001
Epoch [6/200], Training Loss: 12.1453, Validation Loss Current: 8.6685, Validation Loss AVG: 10.5779, lr: 0.001
Epoch [7/200], Training Loss: 14.7192, Validation Loss Current: 7.0836, Validation Loss AVG: 14.6477, lr: 0.001
Epoch [8/200], Training Loss: 13.2506, Validation Loss Current: 6.0983, Validation Loss AVG: 11.2017, lr: 0.001
Epoch [9/200], Training Loss: 8.8149, Validation Loss Current: 6.5701, Validation Loss AVG: 14.3175, lr: 0.001
Epoch [10/200], Training Loss: 8.8849, Validation Loss Current: 6.4417, Validation Loss AVG: 14.0172, lr: 0.001
Epoch [11/200], Training Loss: 9.5484, Validation Loss Current: 7.3875, Validation Loss AVG: 11.0735, lr: 0.001
Epoch [12/200], Training Loss: 8.6295, Validation Loss Current: 7.2883, Validation Loss AVG: 14.2864, lr: 0.001
Epoch [13/200], Training Loss: 6.7394, Validation Loss Current: 6.8027, Validation Loss AVG: 11.4664, lr: 0.001
Epoch [14/200], Training Loss: 6.6189, Validation Loss Current: 6.8488, Validation Loss AVG: 14.3302, lr: 0.001
Epoch [15/200], Training Loss: 8.1145, Validation Loss Current: 6.2147, Validation Loss AVG: 12.9369, lr: 0.001
Epoch [16/200], Training Loss: 7.2638, Validation Loss Current: 7.0537, Validation Loss AVG: 11.2016, lr: 0.001
Epoch [17/200], Training Loss: 7.1429, Validation Loss Current: 7.6726, Validation Loss AVG: 12.2087, lr: 0.001
Epoch [18/200], Training Loss: 7.8506, Validation Loss Current: 6.6439, Validation Loss AVG: 13.0973, lr: 0.001
Epoch [19/200], Training Loss: 5.7931, Validation Loss Current: 6.6372, Validation Loss AVG: 12.5512, lr: 0.001
Epoch [20/200], Training Loss: 4.7256, Validation Loss Current: 6.6649, Validation Loss AVG: 12.9338, lr: 0.001
Epoch [21/200], Training Loss: 4.0925, Validation Loss Current: 6.9684, Validation Loss AVG: 10.5550, lr: 0.001
Epoch [22/200], Training Loss: 3.1444, Validation Loss Current: 6.8203, Validation Loss AVG: 14.7883, lr: 0.001
Epoch [23/200], Training Loss: 3.9166, Validation Loss Current: 6.8920, Validation Loss AVG: 10.9358, lr: 0.001
Epoch [24/200], Training Loss: 4.2304, Validation Loss Current: 7.9289, Validation Loss AVG: 12.6028, lr: 0.001
Epoch [25/200], Training Loss: 4.8598, Validation Loss Current: 9.1989, Validation Loss AVG: 17.4912, lr: 0.001
Epoch [26/200], Training Loss: 5.4659, Validation Loss Current: 6.8018, Validation Loss AVG: 10.9942, lr: 0.001
Epoch [27/200], Training Loss: 7.4164, Validation Loss Current: 7.2450, Validation Loss AVG: 14.0488, lr: 0.001
Epoch [28/200], Training Loss: 3.5476, Validation Loss Current: 7.9682, Validation Loss AVG: 13.8812, lr: 0.001
Epoch [29/200], Training Loss: 4.3463, Validation Loss Current: 7.7485, Validation Loss AVG: 13.9431, lr: 0.001
Epoch [30/200], Training Loss: 1.9596, Validation Loss Current: 6.7640, Validation Loss AVG: 13.5260, lr: 0.001
Epoch [31/200], Training Loss: 1.9255, Validation Loss Current: 8.3379, Validation Loss AVG: 14.0644, lr: 0.001
Epoch [32/200], Training Loss: 3.2317, Validation Loss Current: 7.0654, Validation Loss AVG: 11.7374, lr: 0.001
Epoch [33/200], Training Loss: 6.8607, Validation Loss Current: 8.3285, Validation Loss AVG: 12.8581, lr: 0.001
Epoch [34/200], Training Loss: 5.8677, Validation Loss Current: 8.0990, Validation Loss AVG: 12.8098, lr: 0.001
Epoch [35/200], Training Loss: 3.9111, Validation Loss Current: 7.5802, Validation Loss AVG: 15.4179, lr: 0.001
Epoch [36/200], Training Loss: 6.7683, Validation Loss Current: 6.9643, Validation Loss AVG: 14.7304, lr: 0.001
Epoch [37/200], Training Loss: 3.1924, Validation Loss Current: 7.1696, Validation Loss AVG: 12.0899, lr: 0.001
Epoch [38/200], Training Loss: 3.9617, Validation Loss Current: 6.6813, Validation Loss AVG: 15.4290, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 8 Best val accuracy: [0.5493421052631579, 0.5838815789473685, 0.5986842105263158, 0.600328947368421, 0.5970394736842105, 0.5049342105263158, 0.5625, 0.6085526315789473, 0.5921052631578947, 0.5986842105263158, 0.5805921052631579, 0.5986842105263158, 0.6101973684210527, 0.5904605263157895, 0.631578947368421, 0.5986842105263158, 0.5855263157894737, 0.5953947368421053, 0.6348684210526315, 0.6151315789473685, 0.5921052631578947, 0.618421052631579, 0.6233552631578947, 0.5855263157894737, 0.5279605263157895, 0.6101973684210527, 0.5986842105263158, 0.5838815789473685, 0.6151315789473685, 0.6134868421052632, 0.6052631578947368, 0.6085526315789473, 0.5986842105263158, 0.5723684210526315, 0.5986842105263158, 0.6085526315789473, 0.6019736842105263, 0.6299342105263158] Best val loss: 6.098281383514404


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 39.8093, Validation Loss Current: 9.8860, Validation Loss AVG: 9.9787, lr: 0.001
Epoch [2/400], Training Loss: 37.8810, Validation Loss Current: 9.4032, Validation Loss AVG: 9.9867, lr: 0.001
Epoch [3/400], Training Loss: 36.4900, Validation Loss Current: 8.9045, Validation Loss AVG: 9.7308, lr: 0.001
Epoch [4/400], Training Loss: 34.3346, Validation Loss Current: 8.6298, Validation Loss AVG: 9.5444, lr: 0.001
Epoch [5/400], Training Loss: 33.8131, Validation Loss Current: 8.3520, Validation Loss AVG: 9.2653, lr: 0.001
Epoch [6/400], Training Loss: 32.8024, Validation Loss Current: 8.0805, Validation Loss AVG: 9.3027, lr: 0.001
Epoch [7/400], Training Loss: 31.6683, Validation Loss Current: 7.7206, Validation Loss AVG: 8.9846, lr: 0.001
Epoch [8/400], Training Loss: 30.0003, Validation Loss Current: 7.5887, Validation Loss AVG: 8.6662, lr: 0.001
Epoch [9/400], Training Loss: 28.3507, Validation Loss Current: 7.7259, Validation Loss AVG: 11.0887, lr: 0.001
Epoch [10/400], Training Loss: 27.7595, Validation Loss Current: 7.0870, Validation Loss AVG: 8.6305, lr: 0.001
Epoch [11/400], Training Loss: 26.6884, Validation Loss Current: 6.7081, Validation Loss AVG: 8.6442, lr: 0.001
Epoch [12/400], Training Loss: 27.3413, Validation Loss Current: 7.4468, Validation Loss AVG: 9.5399, lr: 0.001
Epoch [13/400], Training Loss: 27.3475, Validation Loss Current: 6.8218, Validation Loss AVG: 8.9110, lr: 0.001
Epoch [14/400], Training Loss: 24.7171, Validation Loss Current: 6.8397, Validation Loss AVG: 8.8282, lr: 0.001
Epoch [15/400], Training Loss: 23.5404, Validation Loss Current: 6.3096, Validation Loss AVG: 8.5528, lr: 0.001
Epoch [16/400], Training Loss: 22.1661, Validation Loss Current: 6.0018, Validation Loss AVG: 8.5766, lr: 0.001
Epoch [17/400], Training Loss: 22.6197, Validation Loss Current: 7.4921, Validation Loss AVG: 10.0711, lr: 0.001
Epoch [18/400], Training Loss: 22.6954, Validation Loss Current: 6.1526, Validation Loss AVG: 9.2070, lr: 0.001
Epoch [19/400], Training Loss: 22.0338, Validation Loss Current: 5.8764, Validation Loss AVG: 8.5818, lr: 0.001
Epoch [20/400], Training Loss: 20.4187, Validation Loss Current: 7.2617, Validation Loss AVG: 14.8759, lr: 0.001
Epoch [21/400], Training Loss: 20.5178, Validation Loss Current: 6.6625, Validation Loss AVG: 9.1793, lr: 0.001
Epoch [22/400], Training Loss: 19.0699, Validation Loss Current: 7.1027, Validation Loss AVG: 12.1007, lr: 0.001
Epoch [23/400], Training Loss: 19.2658, Validation Loss Current: 5.4742, Validation Loss AVG: 8.4443, lr: 0.001
Epoch [24/400], Training Loss: 17.7570, Validation Loss Current: 5.9704, Validation Loss AVG: 8.3093, lr: 0.001
Epoch [25/400], Training Loss: 17.7580, Validation Loss Current: 6.3914, Validation Loss AVG: 11.2998, lr: 0.001
Epoch [26/400], Training Loss: 17.2864, Validation Loss Current: 5.8335, Validation Loss AVG: 8.9119, lr: 0.001
Epoch [27/400], Training Loss: 21.1270, Validation Loss Current: 5.8409, Validation Loss AVG: 10.5188, lr: 0.001
Epoch [28/400], Training Loss: 19.1211, Validation Loss Current: 6.3360, Validation Loss AVG: 10.6351, lr: 0.001
Epoch [29/400], Training Loss: 17.6217, Validation Loss Current: 5.5732, Validation Loss AVG: 10.4601, lr: 0.001
Epoch [30/400], Training Loss: 15.0202, Validation Loss Current: 5.8048, Validation Loss AVG: 7.8600, lr: 0.001
Epoch [31/400], Training Loss: 13.0901, Validation Loss Current: 5.1262, Validation Loss AVG: 10.7376, lr: 0.001
Epoch [32/400], Training Loss: 12.4487, Validation Loss Current: 5.0139, Validation Loss AVG: 7.7476, lr: 0.001
Epoch [33/400], Training Loss: 13.8569, Validation Loss Current: 8.6380, Validation Loss AVG: 18.5673, lr: 0.001
Epoch [34/400], Training Loss: 13.8643, Validation Loss Current: 5.5606, Validation Loss AVG: 9.4582, lr: 0.001
Epoch [35/400], Training Loss: 12.2564, Validation Loss Current: 5.2053, Validation Loss AVG: 10.6198, lr: 0.001
Epoch [36/400], Training Loss: 10.8590, Validation Loss Current: 5.2532, Validation Loss AVG: 9.4131, lr: 0.001
Epoch [37/400], Training Loss: 9.8362, Validation Loss Current: 5.0611, Validation Loss AVG: 11.2010, lr: 0.001
Epoch [38/400], Training Loss: 9.7126, Validation Loss Current: 5.4681, Validation Loss AVG: 8.7335, lr: 0.001
Epoch [39/400], Training Loss: 8.8549, Validation Loss Current: 6.0632, Validation Loss AVG: 9.6898, lr: 0.001
Epoch [40/400], Training Loss: 8.9008, Validation Loss Current: 6.2233, Validation Loss AVG: 10.7430, lr: 0.001
Epoch [41/400], Training Loss: 8.5989, Validation Loss Current: 4.9777, Validation Loss AVG: 8.2079, lr: 0.001
Epoch [42/400], Training Loss: 7.0810, Validation Loss Current: 5.0917, Validation Loss AVG: 11.1283, lr: 0.001
Epoch [43/400], Training Loss: 6.3540, Validation Loss Current: 4.8505, Validation Loss AVG: 11.4053, lr: 0.001
Epoch [44/400], Training Loss: 9.2282, Validation Loss Current: 6.4189, Validation Loss AVG: 10.9854, lr: 0.001
Epoch [45/400], Training Loss: 5.9826, Validation Loss Current: 5.2105, Validation Loss AVG: 10.5429, lr: 0.001
Epoch [46/400], Training Loss: 4.0266, Validation Loss Current: 5.2282, Validation Loss AVG: 10.5770, lr: 0.001
Epoch [47/400], Training Loss: 5.2797, Validation Loss Current: 5.9736, Validation Loss AVG: 11.5740, lr: 0.001
Epoch [48/400], Training Loss: 8.2050, Validation Loss Current: 6.6589, Validation Loss AVG: 9.7996, lr: 0.001
Epoch [49/400], Training Loss: 5.9450, Validation Loss Current: 5.1888, Validation Loss AVG: 13.7564, lr: 0.001
Epoch [50/400], Training Loss: 4.9441, Validation Loss Current: 5.5518, Validation Loss AVG: 9.8219, lr: 0.001
Epoch [51/400], Training Loss: 4.1086, Validation Loss Current: 6.8316, Validation Loss AVG: 14.5412, lr: 0.001
Epoch [52/400], Training Loss: 7.5297, Validation Loss Current: 6.8961, Validation Loss AVG: 11.9247, lr: 0.001
Epoch [53/400], Training Loss: 7.9794, Validation Loss Current: 7.9405, Validation Loss AVG: 14.5105, lr: 0.001
Epoch [54/400], Training Loss: 5.9804, Validation Loss Current: 5.9757, Validation Loss AVG: 10.5713, lr: 0.001
Epoch [55/400], Training Loss: 4.7275, Validation Loss Current: 6.5178, Validation Loss AVG: 15.2112, lr: 0.001
Epoch [56/400], Training Loss: 4.9831, Validation Loss Current: 8.1117, Validation Loss AVG: 10.3987, lr: 0.001
Epoch [57/400], Training Loss: 6.6365, Validation Loss Current: 7.0486, Validation Loss AVG: 10.7553, lr: 0.001
Epoch [58/400], Training Loss: 6.2207, Validation Loss Current: 7.3642, Validation Loss AVG: 11.3292, lr: 0.001
Epoch [59/400], Training Loss: 7.3253, Validation Loss Current: 5.9642, Validation Loss AVG: 12.7830, lr: 0.001
Epoch [60/400], Training Loss: 4.6350, Validation Loss Current: 6.0219, Validation Loss AVG: 16.2431, lr: 0.001
Epoch [61/400], Training Loss: 6.3287, Validation Loss Current: 8.3257, Validation Loss AVG: 11.1927, lr: 0.001
Epoch [62/400], Training Loss: 5.7263, Validation Loss Current: 6.9056, Validation Loss AVG: 17.1138, lr: 0.001
Epoch [63/400], Training Loss: 9.5254, Validation Loss Current: 7.8082, Validation Loss AVG: 15.0621, lr: 0.001
Epoch [64/400], Training Loss: 5.3907, Validation Loss Current: 6.9542, Validation Loss AVG: 14.5251, lr: 0.001
Epoch [65/400], Training Loss: 5.1803, Validation Loss Current: 6.9001, Validation Loss AVG: 12.2778, lr: 0.001
Epoch [66/400], Training Loss: 6.1868, Validation Loss Current: 7.3372, Validation Loss AVG: 11.8009, lr: 0.001
Epoch [67/400], Training Loss: 7.5846, Validation Loss Current: 7.0644, Validation Loss AVG: 11.7564, lr: 0.001
Epoch [68/400], Training Loss: 5.4792, Validation Loss Current: 6.2189, Validation Loss AVG: 11.8937, lr: 0.001
Epoch [69/400], Training Loss: 4.0721, Validation Loss Current: 6.0705, Validation Loss AVG: 12.5994, lr: 0.001
Epoch [70/400], Training Loss: 5.2626, Validation Loss Current: 6.2964, Validation Loss AVG: 13.6665, lr: 0.001
Epoch [71/400], Training Loss: 3.5128, Validation Loss Current: 6.1992, Validation Loss AVG: 13.1164, lr: 0.001
Epoch [72/400], Training Loss: 4.5552, Validation Loss Current: 6.5712, Validation Loss AVG: 11.9812, lr: 0.001
Epoch [73/400], Training Loss: 5.5105, Validation Loss Current: 7.1576, Validation Loss AVG: 13.7450, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 43 Best val accuracy: [0.25, 0.29276315789473684, 0.38980263157894735, 0.37335526315789475, 0.3996710526315789, 0.4029605263157895, 0.4654605263157895, 0.43914473684210525, 0.45230263157894735, 0.5032894736842105, 0.53125, 0.43914473684210525, 0.5164473684210527, 0.5082236842105263, 0.5493421052631579, 0.587171052631579, 0.5148026315789473, 0.5756578947368421, 0.5921052631578947, 0.5279605263157895, 0.5592105263157895, 0.537828947368421, 0.625, 0.587171052631579, 0.569078947368421, 0.5986842105263158, 0.6151315789473685, 0.5723684210526315, 0.6299342105263158, 0.6200657894736842, 0.6677631578947368, 0.6710526315789473, 0.5131578947368421, 0.6299342105263158, 0.6480263157894737, 0.6513157894736842, 0.6463815789473685, 0.6611842105263158, 0.625, 0.6085526315789473, 0.6776315789473685, 0.6480263157894737, 0.6825657894736842, 0.6085526315789473, 0.6480263157894737, 0.6611842105263158, 0.6529605263157895, 0.600328947368421, 0.6595394736842105, 0.6578947368421053, 0.6200657894736842, 0.5805921052631579, 0.5756578947368421, 0.6365131578947368, 0.618421052631579, 0.59375, 0.5953947368421053, 0.5888157894736842, 0.625, 0.6200657894736842, 0.5888157894736842, 0.6217105263157895, 0.5904605263157895, 0.5756578947368421, 0.631578947368421, 0.5641447368421053, 0.5986842105263158, 0.6217105263157895, 0.6447368421052632, 0.631578947368421, 0.631578947368421, 0.6266447368421053, 0.6200657894736842] Best val loss: 4.850543916225433


Fold: 4
----- Training resnet18 with sequence: [0.2, 0.4, 0.6, 0.8, 1] -----
Current group: 0.2
Epoch [1/80], Training Loss: 41.0665, Validation Loss Current: 10.1128, Validation Loss AVG: 10.1128, lr: 0.001
Epoch [2/80], Training Loss: 39.3784, Validation Loss Current: 10.6631, Validation Loss AVG: 10.6631, lr: 0.001
Epoch [3/80], Training Loss: 39.2031, Validation Loss Current: 10.8665, Validation Loss AVG: 10.8665, lr: 0.001
Epoch [4/80], Training Loss: 37.6934, Validation Loss Current: 11.0895, Validation Loss AVG: 11.0895, lr: 0.001
Epoch [5/80], Training Loss: 37.1491, Validation Loss Current: 12.3231, Validation Loss AVG: 12.3231, lr: 0.001
Epoch [6/80], Training Loss: 36.7491, Validation Loss Current: 11.9040, Validation Loss AVG: 11.9040, lr: 0.001
Epoch [7/80], Training Loss: 35.6991, Validation Loss Current: 11.3528, Validation Loss AVG: 11.3528, lr: 0.001
Epoch [8/80], Training Loss: 34.5987, Validation Loss Current: 11.0108, Validation Loss AVG: 11.0108, lr: 0.001
Epoch [9/80], Training Loss: 33.5970, Validation Loss Current: 10.7815, Validation Loss AVG: 10.7815, lr: 0.001
Epoch [10/80], Training Loss: 32.4022, Validation Loss Current: 10.9419, Validation Loss AVG: 10.9419, lr: 0.001
Epoch [11/80], Training Loss: 33.1930, Validation Loss Current: 12.1822, Validation Loss AVG: 12.1822, lr: 0.001
Epoch [12/80], Training Loss: 32.2187, Validation Loss Current: 11.2290, Validation Loss AVG: 11.2290, lr: 0.001
Epoch [13/80], Training Loss: 31.7434, Validation Loss Current: 10.2091, Validation Loss AVG: 10.2091, lr: 0.001
Epoch [14/80], Training Loss: 29.8846, Validation Loss Current: 10.7585, Validation Loss AVG: 10.7585, lr: 0.001
Epoch [15/80], Training Loss: 28.9934, Validation Loss Current: 11.5221, Validation Loss AVG: 11.5221, lr: 0.001
Epoch [16/80], Training Loss: 28.0249, Validation Loss Current: 12.1687, Validation Loss AVG: 12.1687, lr: 0.001
Epoch [17/80], Training Loss: 26.5487, Validation Loss Current: 11.4238, Validation Loss AVG: 11.4238, lr: 0.001
Epoch [18/80], Training Loss: 26.1981, Validation Loss Current: 11.7784, Validation Loss AVG: 11.7784, lr: 0.001
Epoch [19/80], Training Loss: 26.7264, Validation Loss Current: 15.9730, Validation Loss AVG: 15.9730, lr: 0.001
Epoch [20/80], Training Loss: 25.1005, Validation Loss Current: 10.5327, Validation Loss AVG: 10.5327, lr: 0.001
Epoch [21/80], Training Loss: 25.5494, Validation Loss Current: 12.2310, Validation Loss AVG: 12.2310, lr: 0.001
Epoch [22/80], Training Loss: 24.2103, Validation Loss Current: 10.6283, Validation Loss AVG: 10.6283, lr: 0.001
Epoch [23/80], Training Loss: 23.4083, Validation Loss Current: 11.3111, Validation Loss AVG: 11.3111, lr: 0.001
Epoch [24/80], Training Loss: 21.1895, Validation Loss Current: 10.8908, Validation Loss AVG: 10.8908, lr: 0.001
Epoch [25/80], Training Loss: 20.9822, Validation Loss Current: 10.3655, Validation Loss AVG: 10.3655, lr: 0.001
Epoch [26/80], Training Loss: 19.4645, Validation Loss Current: 11.2921, Validation Loss AVG: 11.2921, lr: 0.001
Epoch [27/80], Training Loss: 19.1889, Validation Loss Current: 11.9200, Validation Loss AVG: 11.9200, lr: 0.001
Epoch [28/80], Training Loss: 17.4815, Validation Loss Current: 9.8799, Validation Loss AVG: 9.8799, lr: 0.001
Epoch [29/80], Training Loss: 17.3503, Validation Loss Current: 11.8894, Validation Loss AVG: 11.8894, lr: 0.001
Epoch [30/80], Training Loss: 18.7460, Validation Loss Current: 13.7124, Validation Loss AVG: 13.7124, lr: 0.001
Epoch [31/80], Training Loss: 16.4836, Validation Loss Current: 11.9519, Validation Loss AVG: 11.9519, lr: 0.001
Epoch [32/80], Training Loss: 14.1259, Validation Loss Current: 12.4464, Validation Loss AVG: 12.4464, lr: 0.001
Epoch [33/80], Training Loss: 14.4865, Validation Loss Current: 19.1861, Validation Loss AVG: 19.1861, lr: 0.001
Epoch [34/80], Training Loss: 16.2862, Validation Loss Current: 17.1404, Validation Loss AVG: 17.1404, lr: 0.001
Epoch [35/80], Training Loss: 14.7309, Validation Loss Current: 15.4362, Validation Loss AVG: 15.4362, lr: 0.001
Epoch [36/80], Training Loss: 14.8338, Validation Loss Current: 14.1512, Validation Loss AVG: 14.1512, lr: 0.001
Epoch [37/80], Training Loss: 12.3303, Validation Loss Current: 12.8518, Validation Loss AVG: 12.8518, lr: 0.001
Epoch [38/80], Training Loss: 10.3235, Validation Loss Current: 12.7524, Validation Loss AVG: 12.7524, lr: 0.001
Epoch [39/80], Training Loss: 9.9433, Validation Loss Current: 12.3829, Validation Loss AVG: 12.3829, lr: 0.001
Epoch [40/80], Training Loss: 10.3468, Validation Loss Current: 15.3825, Validation Loss AVG: 15.3825, lr: 0.001
Epoch [41/80], Training Loss: 8.7976, Validation Loss Current: 15.3830, Validation Loss AVG: 15.3830, lr: 0.001
Epoch [42/80], Training Loss: 8.8587, Validation Loss Current: 23.1387, Validation Loss AVG: 23.1387, lr: 0.001
Epoch [43/80], Training Loss: 16.2413, Validation Loss Current: 24.7725, Validation Loss AVG: 24.7725, lr: 0.001
Epoch [44/80], Training Loss: 21.7342, Validation Loss Current: 22.6369, Validation Loss AVG: 22.6369, lr: 0.001
Epoch [45/80], Training Loss: 16.6755, Validation Loss Current: 15.9344, Validation Loss AVG: 15.9344, lr: 0.001
Epoch [46/80], Training Loss: 17.9512, Validation Loss Current: 21.0802, Validation Loss AVG: 21.0802, lr: 0.001
Epoch [47/80], Training Loss: 12.7322, Validation Loss Current: 15.7314, Validation Loss AVG: 15.7314, lr: 0.001
Epoch [48/80], Training Loss: 11.2725, Validation Loss Current: 15.9146, Validation Loss AVG: 15.9146, lr: 0.001
Epoch [49/80], Training Loss: 14.1667, Validation Loss Current: 26.7669, Validation Loss AVG: 26.7669, lr: 0.001
Epoch [50/80], Training Loss: 14.8791, Validation Loss Current: 21.9586, Validation Loss AVG: 21.9586, lr: 0.001
Epoch [51/80], Training Loss: 11.9176, Validation Loss Current: 14.9458, Validation Loss AVG: 14.9458, lr: 0.001
Epoch [52/80], Training Loss: 8.5163, Validation Loss Current: 15.8164, Validation Loss AVG: 15.8164, lr: 0.001
Epoch [53/80], Training Loss: 6.4329, Validation Loss Current: 14.3873, Validation Loss AVG: 14.3873, lr: 0.001
Epoch [54/80], Training Loss: 4.7570, Validation Loss Current: 14.0760, Validation Loss AVG: 14.0760, lr: 0.001
Epoch [55/80], Training Loss: 6.1254, Validation Loss Current: 14.7039, Validation Loss AVG: 14.7039, lr: 0.001
Epoch [56/80], Training Loss: 4.8030, Validation Loss Current: 16.4765, Validation Loss AVG: 16.4765, lr: 0.001
Epoch [57/80], Training Loss: 5.9293, Validation Loss Current: 15.4110, Validation Loss AVG: 15.4110, lr: 0.001
Epoch [58/80], Training Loss: 8.6580, Validation Loss Current: 33.9478, Validation Loss AVG: 33.9478, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 28 Best val accuracy: [0.24144736842105266, 0.1993421052631579, 0.18782894736842107, 0.16710526315789473, 0.17335526315789473, 0.17500000000000002, 0.21085526315789474, 0.22039473684210525, 0.23848684210526314, 0.2302631578947368, 0.22269736842105262, 0.20197368421052633, 0.26875, 0.25065789473684214, 0.2529605263157895, 0.22467105263157894, 0.2654605263157895, 0.256578947368421, 0.21710526315789477, 0.30625, 0.2424342105263158, 0.30164473684210524, 0.2855263157894737, 0.3141447368421052, 0.33256578947368426, 0.32598684210526313, 0.2779605263157895, 0.38125, 0.28651315789473686, 0.31611842105263155, 0.30822368421052626, 0.29046052631578945, 0.23026315789473686, 0.2414473684210526, 0.2677631578947368, 0.26973684210526316, 0.3595394736842105, 0.34144736842105256, 0.3513157894736842, 0.3342105263157895, 0.34967105263157894, 0.22072368421052632, 0.33190789473684207, 0.18289473684210525, 0.3088815789473684, 0.23815789473684207, 0.2917763157894737, 0.24078947368421053, 0.3174342105263158, 0.20822368421052634, 0.32532894736842105, 0.32401315789473684, 0.33684210526315794, 0.32105263157894737, 0.3644736842105263, 0.2884868421052632, 0.3598684210526316, 0.18881578947368421] Best val loss: 9.879872798919678


Current group: 0.4
Epoch [1/80], Training Loss: 40.7082, Validation Loss Current: 10.2799, Validation Loss AVG: 10.2799, lr: 0.001
Epoch [2/80], Training Loss: 28.6887, Validation Loss Current: 10.5642, Validation Loss AVG: 10.5642, lr: 0.001
Epoch [3/80], Training Loss: 24.1890, Validation Loss Current: 8.7592, Validation Loss AVG: 8.7592, lr: 0.001
Epoch [4/80], Training Loss: 21.8658, Validation Loss Current: 11.2422, Validation Loss AVG: 11.2422, lr: 0.001
Epoch [5/80], Training Loss: 17.9314, Validation Loss Current: 9.5921, Validation Loss AVG: 9.5921, lr: 0.001
Epoch [6/80], Training Loss: 15.4490, Validation Loss Current: 9.3451, Validation Loss AVG: 9.3451, lr: 0.001
Epoch [7/80], Training Loss: 15.5192, Validation Loss Current: 8.8703, Validation Loss AVG: 8.8703, lr: 0.001
Epoch [8/80], Training Loss: 12.8908, Validation Loss Current: 10.3588, Validation Loss AVG: 10.3588, lr: 0.001
Epoch [9/80], Training Loss: 13.9340, Validation Loss Current: 9.0885, Validation Loss AVG: 9.0885, lr: 0.001
Epoch [10/80], Training Loss: 10.2533, Validation Loss Current: 10.4860, Validation Loss AVG: 10.4860, lr: 0.001
Epoch [11/80], Training Loss: 11.8846, Validation Loss Current: 12.5584, Validation Loss AVG: 12.5584, lr: 0.001
Epoch [12/80], Training Loss: 9.2732, Validation Loss Current: 11.2877, Validation Loss AVG: 11.2877, lr: 0.001
Epoch [13/80], Training Loss: 10.8132, Validation Loss Current: 11.1406, Validation Loss AVG: 11.1406, lr: 0.001
Epoch [14/80], Training Loss: 9.5269, Validation Loss Current: 9.8702, Validation Loss AVG: 9.8702, lr: 0.001
Epoch [15/80], Training Loss: 7.1955, Validation Loss Current: 11.5390, Validation Loss AVG: 11.5390, lr: 0.001
Epoch [16/80], Training Loss: 10.6491, Validation Loss Current: 10.1014, Validation Loss AVG: 10.1014, lr: 0.001
Epoch [17/80], Training Loss: 4.4232, Validation Loss Current: 9.7762, Validation Loss AVG: 9.7762, lr: 0.001
Epoch [18/80], Training Loss: 3.0160, Validation Loss Current: 10.1454, Validation Loss AVG: 10.1454, lr: 0.001
Epoch [19/80], Training Loss: 4.3680, Validation Loss Current: 11.3649, Validation Loss AVG: 11.3649, lr: 0.001
Epoch [20/80], Training Loss: 5.3572, Validation Loss Current: 13.0813, Validation Loss AVG: 13.0813, lr: 0.001
Epoch [21/80], Training Loss: 4.9579, Validation Loss Current: 11.5516, Validation Loss AVG: 11.5516, lr: 0.001
Epoch [22/80], Training Loss: 5.7491, Validation Loss Current: 10.4590, Validation Loss AVG: 10.4590, lr: 0.001
Epoch [23/80], Training Loss: 3.9697, Validation Loss Current: 12.5969, Validation Loss AVG: 12.5969, lr: 0.001
Epoch [24/80], Training Loss: 5.8940, Validation Loss Current: 11.2827, Validation Loss AVG: 11.2827, lr: 0.001
Epoch [25/80], Training Loss: 2.8098, Validation Loss Current: 11.5093, Validation Loss AVG: 11.5093, lr: 0.001
Epoch [26/80], Training Loss: 2.0260, Validation Loss Current: 11.1846, Validation Loss AVG: 11.1846, lr: 0.001
Epoch [27/80], Training Loss: 4.7744, Validation Loss Current: 12.2712, Validation Loss AVG: 12.2712, lr: 0.001
Epoch [28/80], Training Loss: 6.9532, Validation Loss Current: 13.6404, Validation Loss AVG: 13.6404, lr: 0.001
Epoch [29/80], Training Loss: 9.4923, Validation Loss Current: 13.2285, Validation Loss AVG: 13.2285, lr: 0.001
Epoch [30/80], Training Loss: 5.2480, Validation Loss Current: 12.1973, Validation Loss AVG: 12.1973, lr: 0.001
Epoch [31/80], Training Loss: 4.7282, Validation Loss Current: 12.5436, Validation Loss AVG: 12.5436, lr: 0.001
Epoch [32/80], Training Loss: 5.5967, Validation Loss Current: 12.9115, Validation Loss AVG: 12.9115, lr: 0.001
Epoch [33/80], Training Loss: 7.4739, Validation Loss Current: 15.1531, Validation Loss AVG: 15.1531, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 3 Best val accuracy: [0.36184210526315785, 0.35592105263157897, 0.42927631578947373, 0.31480263157894744, 0.4309210526315789, 0.41940789473684215, 0.4286184210526316, 0.3796052631578948, 0.3901315789473684, 0.41381578947368425, 0.41414473684210523, 0.36875, 0.39473684210526316, 0.41546052631578945, 0.42927631578947373, 0.43717105263157896, 0.4276315789473684, 0.43980263157894733, 0.42598684210526316, 0.30197368421052634, 0.43453947368421053, 0.41414473684210523, 0.3667763157894736, 0.4411184210526316, 0.4430921052631579, 0.40131578947368424, 0.36973684210526314, 0.35, 0.4026315789473684, 0.43157894736842106, 0.3694078947368421, 0.43618421052631573, 0.3723684210526316] Best val loss: 8.759230947494506


Current group: 0.6
Epoch [1/80], Training Loss: 39.0642, Validation Loss Current: 14.0721, Validation Loss AVG: 14.0721, lr: 0.001
Epoch [2/80], Training Loss: 31.5754, Validation Loss Current: 11.5039, Validation Loss AVG: 11.5039, lr: 0.001
Epoch [3/80], Training Loss: 21.1801, Validation Loss Current: 8.8810, Validation Loss AVG: 8.8810, lr: 0.001
Epoch [4/80], Training Loss: 17.5647, Validation Loss Current: 10.2307, Validation Loss AVG: 10.2307, lr: 0.001
Epoch [5/80], Training Loss: 15.1744, Validation Loss Current: 10.2902, Validation Loss AVG: 10.2902, lr: 0.001
Epoch [6/80], Training Loss: 12.2523, Validation Loss Current: 9.4703, Validation Loss AVG: 9.4703, lr: 0.001
Epoch [7/80], Training Loss: 12.6850, Validation Loss Current: 8.4594, Validation Loss AVG: 8.4594, lr: 0.001
Epoch [8/80], Training Loss: 7.9646, Validation Loss Current: 9.3374, Validation Loss AVG: 9.3374, lr: 0.001
Epoch [9/80], Training Loss: 7.4230, Validation Loss Current: 10.0266, Validation Loss AVG: 10.0266, lr: 0.001
Epoch [10/80], Training Loss: 5.4041, Validation Loss Current: 10.4772, Validation Loss AVG: 10.4772, lr: 0.001
Epoch [11/80], Training Loss: 3.2960, Validation Loss Current: 9.6182, Validation Loss AVG: 9.6182, lr: 0.001
Epoch [12/80], Training Loss: 4.1677, Validation Loss Current: 9.5275, Validation Loss AVG: 9.5275, lr: 0.001
Epoch [13/80], Training Loss: 6.7796, Validation Loss Current: 10.1417, Validation Loss AVG: 10.1417, lr: 0.001
Epoch [14/80], Training Loss: 5.3721, Validation Loss Current: 12.1642, Validation Loss AVG: 12.1642, lr: 0.001
Epoch [15/80], Training Loss: 6.9129, Validation Loss Current: 11.6009, Validation Loss AVG: 11.6009, lr: 0.001
Epoch [16/80], Training Loss: 6.3758, Validation Loss Current: 9.4327, Validation Loss AVG: 9.4327, lr: 0.001
Epoch [17/80], Training Loss: 4.2426, Validation Loss Current: 11.0665, Validation Loss AVG: 11.0665, lr: 0.001
Epoch [18/80], Training Loss: 2.7977, Validation Loss Current: 10.5945, Validation Loss AVG: 10.5945, lr: 0.001
Epoch [19/80], Training Loss: 3.5424, Validation Loss Current: 11.1012, Validation Loss AVG: 11.1012, lr: 0.001
Epoch [20/80], Training Loss: 5.5354, Validation Loss Current: 12.1485, Validation Loss AVG: 12.1485, lr: 0.001
Epoch [21/80], Training Loss: 5.4773, Validation Loss Current: 10.0577, Validation Loss AVG: 10.0577, lr: 0.001
Epoch [22/80], Training Loss: 2.6298, Validation Loss Current: 10.1134, Validation Loss AVG: 10.1134, lr: 0.001
Epoch [23/80], Training Loss: 3.4261, Validation Loss Current: 11.4541, Validation Loss AVG: 11.4541, lr: 0.001
Epoch [24/80], Training Loss: 4.4134, Validation Loss Current: 12.2330, Validation Loss AVG: 12.2330, lr: 0.001
Epoch [25/80], Training Loss: 6.1691, Validation Loss Current: 10.1947, Validation Loss AVG: 10.1947, lr: 0.001
Epoch [26/80], Training Loss: 5.5775, Validation Loss Current: 11.7119, Validation Loss AVG: 11.7119, lr: 0.001
Epoch [27/80], Training Loss: 6.8306, Validation Loss Current: 11.5422, Validation Loss AVG: 11.5422, lr: 0.001
Epoch [28/80], Training Loss: 8.7640, Validation Loss Current: 14.5223, Validation Loss AVG: 14.5223, lr: 0.001
Epoch [29/80], Training Loss: 9.7320, Validation Loss Current: 12.3386, Validation Loss AVG: 12.3386, lr: 0.001
Epoch [30/80], Training Loss: 4.7423, Validation Loss Current: 11.9146, Validation Loss AVG: 11.9146, lr: 0.001
Epoch [31/80], Training Loss: 2.6607, Validation Loss Current: 11.5747, Validation Loss AVG: 11.5747, lr: 0.001
Epoch [32/80], Training Loss: 3.6945, Validation Loss Current: 11.9755, Validation Loss AVG: 11.9755, lr: 0.001
Epoch [33/80], Training Loss: 2.2811, Validation Loss Current: 13.6313, Validation Loss AVG: 13.6313, lr: 0.001
Epoch [34/80], Training Loss: 2.1683, Validation Loss Current: 12.3650, Validation Loss AVG: 12.3650, lr: 0.001
Epoch [35/80], Training Loss: 3.5089, Validation Loss Current: 14.3155, Validation Loss AVG: 14.3155, lr: 0.001
Epoch [36/80], Training Loss: 5.0133, Validation Loss Current: 12.1038, Validation Loss AVG: 12.1038, lr: 0.001
Epoch [37/80], Training Loss: 5.1743, Validation Loss Current: 13.0068, Validation Loss AVG: 13.0068, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 7 Best val accuracy: [0.3134868421052631, 0.3503289473684211, 0.43782894736842104, 0.42269736842105265, 0.4256578947368421, 0.4088815789473685, 0.46381578947368424, 0.4440789473684211, 0.418092105263158, 0.44703947368421054, 0.4536184210526316, 0.44605263157894737, 0.4516447368421052, 0.45230263157894735, 0.41546052631578945, 0.4832236842105263, 0.437828947368421, 0.4447368421052631, 0.4427631578947368, 0.41875, 0.4638157894736842, 0.47006578947368427, 0.42467105263157895, 0.4213815789473685, 0.46118421052631586, 0.4286184210526315, 0.456578947368421, 0.37861842105263155, 0.4375, 0.4365131578947368, 0.43782894736842104, 0.4391447368421053, 0.41414473684210523, 0.44342105263157894, 0.40361842105263157, 0.41546052631578945, 0.3950657894736842] Best val loss: 8.459380626678467


Current group: 0.8
Epoch [1/80], Training Loss: 30.2589, Validation Loss Current: 12.9024, Validation Loss AVG: 12.9024, lr: 0.001
Epoch [2/80], Training Loss: 21.3129, Validation Loss Current: 11.7370, Validation Loss AVG: 11.7370, lr: 0.001
Epoch [3/80], Training Loss: 12.9881, Validation Loss Current: 12.2017, Validation Loss AVG: 12.2017, lr: 0.001
Epoch [4/80], Training Loss: 9.3788, Validation Loss Current: 11.1160, Validation Loss AVG: 11.1160, lr: 0.001
Epoch [5/80], Training Loss: 9.0541, Validation Loss Current: 12.0249, Validation Loss AVG: 12.0249, lr: 0.001
Epoch [6/80], Training Loss: 6.8667, Validation Loss Current: 11.7621, Validation Loss AVG: 11.7621, lr: 0.001
Epoch [7/80], Training Loss: 7.2757, Validation Loss Current: 11.3966, Validation Loss AVG: 11.3966, lr: 0.001
Epoch [8/80], Training Loss: 7.0485, Validation Loss Current: 10.6936, Validation Loss AVG: 10.6936, lr: 0.001
Epoch [9/80], Training Loss: 6.5012, Validation Loss Current: 10.7947, Validation Loss AVG: 10.7947, lr: 0.001
Epoch [10/80], Training Loss: 7.4088, Validation Loss Current: 11.7108, Validation Loss AVG: 11.7108, lr: 0.001
Epoch [11/80], Training Loss: 7.8323, Validation Loss Current: 12.4858, Validation Loss AVG: 12.4858, lr: 0.001
Epoch [12/80], Training Loss: 5.9423, Validation Loss Current: 12.4456, Validation Loss AVG: 12.4456, lr: 0.001
Epoch [13/80], Training Loss: 6.3038, Validation Loss Current: 12.7737, Validation Loss AVG: 12.7737, lr: 0.001
Epoch [14/80], Training Loss: 5.3833, Validation Loss Current: 12.9756, Validation Loss AVG: 12.9756, lr: 0.001
Epoch [15/80], Training Loss: 4.1712, Validation Loss Current: 12.9960, Validation Loss AVG: 12.9960, lr: 0.001
Epoch [16/80], Training Loss: 5.5073, Validation Loss Current: 13.2114, Validation Loss AVG: 13.2114, lr: 0.001
Epoch [17/80], Training Loss: 10.7179, Validation Loss Current: 14.7462, Validation Loss AVG: 14.7462, lr: 0.001
Epoch [18/80], Training Loss: 5.4938, Validation Loss Current: 13.0326, Validation Loss AVG: 13.0326, lr: 0.001
Epoch [19/80], Training Loss: 4.1837, Validation Loss Current: 13.1205, Validation Loss AVG: 13.1205, lr: 0.001
Epoch [20/80], Training Loss: 3.3772, Validation Loss Current: 12.2282, Validation Loss AVG: 12.2282, lr: 0.001
Epoch [21/80], Training Loss: 2.6377, Validation Loss Current: 12.3731, Validation Loss AVG: 12.3731, lr: 0.001
Epoch [22/80], Training Loss: 1.4358, Validation Loss Current: 12.1160, Validation Loss AVG: 12.1160, lr: 0.001
Epoch [23/80], Training Loss: 2.8620, Validation Loss Current: 11.1755, Validation Loss AVG: 11.1755, lr: 0.001
Epoch [24/80], Training Loss: 5.2075, Validation Loss Current: 11.8682, Validation Loss AVG: 11.8682, lr: 0.001
Epoch [25/80], Training Loss: 3.0978, Validation Loss Current: 13.1694, Validation Loss AVG: 13.1694, lr: 0.001
Epoch [26/80], Training Loss: 1.3581, Validation Loss Current: 12.0336, Validation Loss AVG: 12.0336, lr: 0.001
Epoch [27/80], Training Loss: 0.5702, Validation Loss Current: 11.7622, Validation Loss AVG: 11.7622, lr: 0.001
Epoch [28/80], Training Loss: 1.0615, Validation Loss Current: 11.5742, Validation Loss AVG: 11.5742, lr: 0.001
Epoch [29/80], Training Loss: 3.5681, Validation Loss Current: 14.7375, Validation Loss AVG: 14.7375, lr: 0.001
Epoch [30/80], Training Loss: 4.3630, Validation Loss Current: 12.1349, Validation Loss AVG: 12.1349, lr: 0.001
Epoch [31/80], Training Loss: 2.1755, Validation Loss Current: 12.0033, Validation Loss AVG: 12.0033, lr: 0.001
Epoch [32/80], Training Loss: 2.8470, Validation Loss Current: 13.4250, Validation Loss AVG: 13.4250, lr: 0.001
Epoch [33/80], Training Loss: 4.7730, Validation Loss Current: 13.1889, Validation Loss AVG: 13.1889, lr: 0.001
Epoch [34/80], Training Loss: 3.1352, Validation Loss Current: 11.1394, Validation Loss AVG: 11.1394, lr: 0.001
Epoch [35/80], Training Loss: 4.7607, Validation Loss Current: 13.7799, Validation Loss AVG: 13.7799, lr: 0.001
Epoch [36/80], Training Loss: 4.6752, Validation Loss Current: 12.7608, Validation Loss AVG: 12.7608, lr: 0.001
Epoch [37/80], Training Loss: 3.0373, Validation Loss Current: 13.3415, Validation Loss AVG: 13.3415, lr: 0.001
Epoch [38/80], Training Loss: 3.1662, Validation Loss Current: 12.4325, Validation Loss AVG: 12.4325, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 8 Best val accuracy: [0.4134868421052632, 0.4296052631578947, 0.405592105263158, 0.4536184210526316, 0.44046052631578947, 0.40559210526315786, 0.4319078947368421, 0.42631578947368426, 0.4598684210526316, 0.4444078947368421, 0.41940789473684215, 0.42105263157894735, 0.42072368421052636, 0.42598684210526316, 0.41381578947368425, 0.4164473684210527, 0.41381578947368425, 0.42828947368421055, 0.4161184210526316, 0.4322368421052632, 0.45592105263157895, 0.4447368421052631, 0.4720394736842105, 0.46578947368421053, 0.4207236842105263, 0.4407894736842105, 0.45921052631578946, 0.4625, 0.4180921052631579, 0.42927631578947373, 0.4631578947368421, 0.4335526315789474, 0.4180921052631579, 0.4473684210526317, 0.43552631578947365, 0.4427631578947368, 0.425, 0.45328947368421063] Best val loss: 10.693588423728944


Current group: 1
Epoch [1/80], Training Loss: 27.5345, Validation Loss Current: 10.2430, Validation Loss AVG: 15.2791, lr: 0.001
Epoch [2/80], Training Loss: 16.0037, Validation Loss Current: 8.3445, Validation Loss AVG: 13.0406, lr: 0.001
Epoch [3/80], Training Loss: 14.1939, Validation Loss Current: 9.1262, Validation Loss AVG: 11.8395, lr: 0.001
Epoch [4/80], Training Loss: 8.6922, Validation Loss Current: 7.9149, Validation Loss AVG: 13.3641, lr: 0.001
Epoch [5/80], Training Loss: 5.6126, Validation Loss Current: 7.8219, Validation Loss AVG: 13.7408, lr: 0.001
Epoch [6/80], Training Loss: 7.2617, Validation Loss Current: 8.2007, Validation Loss AVG: 14.0090, lr: 0.001
Epoch [7/80], Training Loss: 4.1867, Validation Loss Current: 7.3626, Validation Loss AVG: 12.5625, lr: 0.001
Epoch [8/80], Training Loss: 2.9455, Validation Loss Current: 8.2418, Validation Loss AVG: 15.3259, lr: 0.001
Epoch [9/80], Training Loss: 1.7682, Validation Loss Current: 7.5012, Validation Loss AVG: 13.3922, lr: 0.001
Epoch [10/80], Training Loss: 0.8728, Validation Loss Current: 7.1993, Validation Loss AVG: 13.1167, lr: 0.001
Epoch [11/80], Training Loss: 0.6660, Validation Loss Current: 7.0772, Validation Loss AVG: 13.3338, lr: 0.001
Epoch [12/80], Training Loss: 0.6180, Validation Loss Current: 7.5138, Validation Loss AVG: 13.6993, lr: 0.001
Epoch [13/80], Training Loss: 3.4391, Validation Loss Current: 8.4882, Validation Loss AVG: 13.9553, lr: 0.001
Epoch [14/80], Training Loss: 2.7969, Validation Loss Current: 8.7790, Validation Loss AVG: 13.8093, lr: 0.001
Epoch [15/80], Training Loss: 3.3267, Validation Loss Current: 7.9590, Validation Loss AVG: 13.0926, lr: 0.001
Epoch [16/80], Training Loss: 2.9981, Validation Loss Current: 7.7070, Validation Loss AVG: 14.3205, lr: 0.001
Epoch [17/80], Training Loss: 1.5413, Validation Loss Current: 8.0339, Validation Loss AVG: 13.2574, lr: 0.001
Epoch [18/80], Training Loss: 2.1078, Validation Loss Current: 8.5961, Validation Loss AVG: 14.6939, lr: 0.001
Epoch [19/80], Training Loss: 5.5807, Validation Loss Current: 8.5088, Validation Loss AVG: 14.0721, lr: 0.001
Epoch [20/80], Training Loss: 3.4027, Validation Loss Current: 9.4615, Validation Loss AVG: 15.6916, lr: 0.001
Epoch [21/80], Training Loss: 1.5131, Validation Loss Current: 8.3397, Validation Loss AVG: 15.6840, lr: 0.001
Epoch [22/80], Training Loss: 2.7648, Validation Loss Current: 8.7690, Validation Loss AVG: 13.1972, lr: 0.001
Epoch [23/80], Training Loss: 3.3071, Validation Loss Current: 9.8988, Validation Loss AVG: 15.0168, lr: 0.001
Epoch [24/80], Training Loss: 4.0875, Validation Loss Current: 9.5816, Validation Loss AVG: 15.2464, lr: 0.001
Epoch [25/80], Training Loss: 6.7715, Validation Loss Current: 10.2577, Validation Loss AVG: 15.3773, lr: 0.001
Epoch [26/80], Training Loss: 3.1265, Validation Loss Current: 9.0986, Validation Loss AVG: 13.6199, lr: 0.001
Epoch [27/80], Training Loss: 2.3057, Validation Loss Current: 9.4863, Validation Loss AVG: 16.6722, lr: 0.001
Epoch [28/80], Training Loss: 3.9272, Validation Loss Current: 9.3842, Validation Loss AVG: 16.9930, lr: 0.001
Epoch [29/80], Training Loss: 4.5327, Validation Loss Current: 10.7916, Validation Loss AVG: 15.7361, lr: 0.001
Epoch [30/80], Training Loss: 5.0794, Validation Loss Current: 10.7617, Validation Loss AVG: 16.3158, lr: 0.001
Epoch [31/80], Training Loss: 5.8614, Validation Loss Current: 11.3181, Validation Loss AVG: 15.2233, lr: 0.001
Epoch [32/80], Training Loss: 5.7138, Validation Loss Current: 9.3548, Validation Loss AVG: 15.6386, lr: 0.001
Epoch [33/80], Training Loss: 6.4963, Validation Loss Current: 9.8094, Validation Loss AVG: 13.0922, lr: 0.001
Epoch [34/80], Training Loss: 2.6274, Validation Loss Current: 8.0780, Validation Loss AVG: 13.6233, lr: 0.001
Epoch [35/80], Training Loss: 3.3803, Validation Loss Current: 7.6095, Validation Loss AVG: 13.8827, lr: 0.001
Epoch [36/80], Training Loss: 3.7268, Validation Loss Current: 8.0416, Validation Loss AVG: 13.4390, lr: 0.001
Epoch [37/80], Training Loss: 2.4877, Validation Loss Current: 8.3456, Validation Loss AVG: 14.0228, lr: 0.001
Epoch [38/80], Training Loss: 3.1410, Validation Loss Current: 8.4128, Validation Loss AVG: 12.9410, lr: 0.001
Epoch [39/80], Training Loss: 3.1483, Validation Loss Current: 8.7042, Validation Loss AVG: 14.2682, lr: 0.001
Epoch [40/80], Training Loss: 5.4155, Validation Loss Current: 8.7440, Validation Loss AVG: 12.3305, lr: 0.001
Epoch [41/80], Training Loss: 3.5140, Validation Loss Current: 8.7673, Validation Loss AVG: 13.2924, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 11 Best val accuracy: [0.5707236842105263, 0.5953947368421053, 0.5888157894736842, 0.6085526315789473, 0.6282894736842105, 0.59375, 0.6365131578947368, 0.6101973684210527, 0.631578947368421, 0.6546052631578947, 0.649671052631579, 0.6398026315789473, 0.6266447368421053, 0.5888157894736842, 0.6430921052631579, 0.6332236842105263, 0.6134868421052632, 0.6217105263157895, 0.618421052631579, 0.5904605263157895, 0.6167763157894737, 0.6085526315789473, 0.5542763157894737, 0.6085526315789473, 0.5953947368421053, 0.5888157894736842, 0.59375, 0.5805921052631579, 0.5723684210526315, 0.5345394736842105, 0.5674342105263158, 0.6019736842105263, 0.6069078947368421, 0.625, 0.6398026315789473, 0.6167763157894737, 0.6118421052631579, 0.6167763157894737, 0.6217105263157895, 0.5953947368421053, 0.6069078947368421] Best val loss: 7.077195405960083


----- Training resnet18 with sequence: [0.4, 0.6, 0.8, 1] -----
Current group: 0.4
Epoch [1/100], Training Loss: 40.3612, Validation Loss Current: 9.9313, Validation Loss AVG: 9.9313, lr: 0.001
Epoch [2/100], Training Loss: 39.5565, Validation Loss Current: 9.9135, Validation Loss AVG: 9.9135, lr: 0.001
Epoch [3/100], Training Loss: 38.7981, Validation Loss Current: 9.8017, Validation Loss AVG: 9.8017, lr: 0.001
Epoch [4/100], Training Loss: 38.3850, Validation Loss Current: 9.8377, Validation Loss AVG: 9.8377, lr: 0.001
Epoch [5/100], Training Loss: 37.2746, Validation Loss Current: 9.6141, Validation Loss AVG: 9.6141, lr: 0.001
Epoch [6/100], Training Loss: 36.7122, Validation Loss Current: 9.3975, Validation Loss AVG: 9.3975, lr: 0.001
Epoch [7/100], Training Loss: 35.9532, Validation Loss Current: 9.5966, Validation Loss AVG: 9.5966, lr: 0.001
Epoch [8/100], Training Loss: 33.9700, Validation Loss Current: 9.3843, Validation Loss AVG: 9.3843, lr: 0.001
Epoch [9/100], Training Loss: 34.2711, Validation Loss Current: 9.4731, Validation Loss AVG: 9.4731, lr: 0.001
Epoch [10/100], Training Loss: 33.4456, Validation Loss Current: 9.3060, Validation Loss AVG: 9.3060, lr: 0.001
Epoch [11/100], Training Loss: 31.4375, Validation Loss Current: 9.0646, Validation Loss AVG: 9.0646, lr: 0.001
Epoch [12/100], Training Loss: 31.6604, Validation Loss Current: 8.8993, Validation Loss AVG: 8.8993, lr: 0.001
Epoch [13/100], Training Loss: 30.0820, Validation Loss Current: 8.4868, Validation Loss AVG: 8.4868, lr: 0.001
Epoch [14/100], Training Loss: 29.0957, Validation Loss Current: 9.4577, Validation Loss AVG: 9.4577, lr: 0.001
Epoch [15/100], Training Loss: 27.9964, Validation Loss Current: 8.8712, Validation Loss AVG: 8.8712, lr: 0.001
Epoch [16/100], Training Loss: 28.3861, Validation Loss Current: 8.8614, Validation Loss AVG: 8.8614, lr: 0.001
Epoch [17/100], Training Loss: 27.6803, Validation Loss Current: 8.6369, Validation Loss AVG: 8.6369, lr: 0.001
Epoch [18/100], Training Loss: 26.9884, Validation Loss Current: 8.7759, Validation Loss AVG: 8.7759, lr: 0.001
Epoch [19/100], Training Loss: 25.1501, Validation Loss Current: 8.4548, Validation Loss AVG: 8.4548, lr: 0.001
Epoch [20/100], Training Loss: 24.5266, Validation Loss Current: 9.4990, Validation Loss AVG: 9.4990, lr: 0.001
Epoch [21/100], Training Loss: 24.4644, Validation Loss Current: 8.5540, Validation Loss AVG: 8.5540, lr: 0.001
Epoch [22/100], Training Loss: 22.3606, Validation Loss Current: 8.3982, Validation Loss AVG: 8.3982, lr: 0.001
Epoch [23/100], Training Loss: 22.7466, Validation Loss Current: 8.3384, Validation Loss AVG: 8.3384, lr: 0.001
Epoch [24/100], Training Loss: 21.9900, Validation Loss Current: 8.5757, Validation Loss AVG: 8.5757, lr: 0.001
Epoch [25/100], Training Loss: 22.3653, Validation Loss Current: 9.2897, Validation Loss AVG: 9.2897, lr: 0.001
Epoch [26/100], Training Loss: 22.3428, Validation Loss Current: 9.5231, Validation Loss AVG: 9.5231, lr: 0.001
Epoch [27/100], Training Loss: 21.6764, Validation Loss Current: 10.9793, Validation Loss AVG: 10.9793, lr: 0.001
Epoch [28/100], Training Loss: 20.1446, Validation Loss Current: 8.4474, Validation Loss AVG: 8.4474, lr: 0.001
Epoch [29/100], Training Loss: 19.1984, Validation Loss Current: 8.6713, Validation Loss AVG: 8.6713, lr: 0.001
Epoch [30/100], Training Loss: 17.2300, Validation Loss Current: 8.8881, Validation Loss AVG: 8.8881, lr: 0.001
Epoch [31/100], Training Loss: 17.7582, Validation Loss Current: 9.0337, Validation Loss AVG: 9.0337, lr: 0.001
Epoch [32/100], Training Loss: 14.8979, Validation Loss Current: 8.6595, Validation Loss AVG: 8.6595, lr: 0.001
Epoch [33/100], Training Loss: 15.1447, Validation Loss Current: 9.4393, Validation Loss AVG: 9.4393, lr: 0.001
Epoch [34/100], Training Loss: 12.4040, Validation Loss Current: 8.7463, Validation Loss AVG: 8.7463, lr: 0.001
Epoch [35/100], Training Loss: 12.1119, Validation Loss Current: 9.6022, Validation Loss AVG: 9.6022, lr: 0.001
Epoch [36/100], Training Loss: 12.9462, Validation Loss Current: 9.1411, Validation Loss AVG: 9.1411, lr: 0.001
Epoch [37/100], Training Loss: 11.6891, Validation Loss Current: 14.9145, Validation Loss AVG: 14.9145, lr: 0.001
Epoch [38/100], Training Loss: 13.4088, Validation Loss Current: 10.3815, Validation Loss AVG: 10.3815, lr: 0.001
Epoch [39/100], Training Loss: 14.5281, Validation Loss Current: 9.0542, Validation Loss AVG: 9.0542, lr: 0.001
Epoch [40/100], Training Loss: 11.2359, Validation Loss Current: 10.1633, Validation Loss AVG: 10.1633, lr: 0.001
Epoch [41/100], Training Loss: 11.4693, Validation Loss Current: 11.0399, Validation Loss AVG: 11.0399, lr: 0.001
Epoch [42/100], Training Loss: 8.4896, Validation Loss Current: 10.0488, Validation Loss AVG: 10.0488, lr: 0.001
Epoch [43/100], Training Loss: 6.6858, Validation Loss Current: 9.3844, Validation Loss AVG: 9.3844, lr: 0.001
Epoch [44/100], Training Loss: 7.2837, Validation Loss Current: 10.4614, Validation Loss AVG: 10.4614, lr: 0.001
Epoch [45/100], Training Loss: 7.1651, Validation Loss Current: 10.0378, Validation Loss AVG: 10.0378, lr: 0.001
Epoch [46/100], Training Loss: 6.4356, Validation Loss Current: 10.1941, Validation Loss AVG: 10.1941, lr: 0.001
Epoch [47/100], Training Loss: 7.8101, Validation Loss Current: 10.9439, Validation Loss AVG: 10.9439, lr: 0.001
Epoch [48/100], Training Loss: 8.5135, Validation Loss Current: 12.2455, Validation Loss AVG: 12.2455, lr: 0.001
Epoch [49/100], Training Loss: 10.3122, Validation Loss Current: 12.9186, Validation Loss AVG: 12.9186, lr: 0.001
Epoch [50/100], Training Loss: 8.0374, Validation Loss Current: 11.5153, Validation Loss AVG: 11.5153, lr: 0.001
Epoch [51/100], Training Loss: 9.5508, Validation Loss Current: 11.8579, Validation Loss AVG: 11.8579, lr: 0.001
Epoch [52/100], Training Loss: 8.7217, Validation Loss Current: 11.6383, Validation Loss AVG: 11.6383, lr: 0.001
Epoch [53/100], Training Loss: 5.8156, Validation Loss Current: 12.1264, Validation Loss AVG: 12.1264, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 23 Best val accuracy: [0.2625, 0.2572368421052632, 0.2779605263157895, 0.26875, 0.2976973684210526, 0.3049342105263158, 0.26085526315789476, 0.3023026315789474, 0.28092105263157896, 0.3157894736842105, 0.33289473684210524, 0.3246710526315789, 0.38651315789473684, 0.32171052631578945, 0.3338815789473685, 0.3332236842105263, 0.37467105263157896, 0.36447368421052634, 0.3911184210526316, 0.3680921052631579, 0.38125, 0.38848684210526313, 0.39539473684210524, 0.4167763157894736, 0.38618421052631574, 0.3384868421052632, 0.3539473684210526, 0.4006578947368421, 0.38585526315789476, 0.3697368421052632, 0.3996710526315789, 0.4118421052631579, 0.39342105263157895, 0.38717105263157897, 0.3881578947368421, 0.4009868421052632, 0.34539473684210525, 0.3871710526315789, 0.42894736842105263, 0.3983552631578947, 0.33421052631578946, 0.38388157894736846, 0.399671052631579, 0.39342105263157895, 0.4184210526315789, 0.37894736842105264, 0.38223684210526315, 0.39407894736842103, 0.33782894736842106, 0.32894736842105265, 0.3217105263157895, 0.35526315789473684, 0.3773026315789474] Best val loss: 8.33837969303131


Current group: 0.6
Epoch [1/100], Training Loss: 31.3415, Validation Loss Current: 10.5752, Validation Loss AVG: 10.5752, lr: 0.001
Epoch [2/100], Training Loss: 23.4758, Validation Loss Current: 9.7958, Validation Loss AVG: 9.7958, lr: 0.001
Epoch [3/100], Training Loss: 18.9399, Validation Loss Current: 10.0221, Validation Loss AVG: 10.0221, lr: 0.001
Epoch [4/100], Training Loss: 17.5577, Validation Loss Current: 11.0672, Validation Loss AVG: 11.0672, lr: 0.001
Epoch [5/100], Training Loss: 14.8604, Validation Loss Current: 9.0117, Validation Loss AVG: 9.0117, lr: 0.001
Epoch [6/100], Training Loss: 15.1616, Validation Loss Current: 11.5379, Validation Loss AVG: 11.5379, lr: 0.001
Epoch [7/100], Training Loss: 11.2903, Validation Loss Current: 10.2307, Validation Loss AVG: 10.2307, lr: 0.001
Epoch [8/100], Training Loss: 8.7639, Validation Loss Current: 8.9418, Validation Loss AVG: 8.9418, lr: 0.001
Epoch [9/100], Training Loss: 7.3796, Validation Loss Current: 10.2682, Validation Loss AVG: 10.2682, lr: 0.001
Epoch [10/100], Training Loss: 6.6866, Validation Loss Current: 10.1287, Validation Loss AVG: 10.1287, lr: 0.001
Epoch [11/100], Training Loss: 6.6363, Validation Loss Current: 10.7351, Validation Loss AVG: 10.7351, lr: 0.001
Epoch [12/100], Training Loss: 5.1198, Validation Loss Current: 10.5082, Validation Loss AVG: 10.5082, lr: 0.001
Epoch [13/100], Training Loss: 4.9042, Validation Loss Current: 10.1402, Validation Loss AVG: 10.1402, lr: 0.001
Epoch [14/100], Training Loss: 3.9025, Validation Loss Current: 10.7902, Validation Loss AVG: 10.7902, lr: 0.001
Epoch [15/100], Training Loss: 6.8375, Validation Loss Current: 12.6912, Validation Loss AVG: 12.6912, lr: 0.001
Epoch [16/100], Training Loss: 12.3773, Validation Loss Current: 10.6442, Validation Loss AVG: 10.6442, lr: 0.001
Epoch [17/100], Training Loss: 11.1606, Validation Loss Current: 12.0786, Validation Loss AVG: 12.0786, lr: 0.001
Epoch [18/100], Training Loss: 5.7817, Validation Loss Current: 11.2467, Validation Loss AVG: 11.2467, lr: 0.001
Epoch [19/100], Training Loss: 5.0398, Validation Loss Current: 11.5678, Validation Loss AVG: 11.5678, lr: 0.001
Epoch [20/100], Training Loss: 4.6447, Validation Loss Current: 11.1424, Validation Loss AVG: 11.1424, lr: 0.001
Epoch [21/100], Training Loss: 4.4655, Validation Loss Current: 10.8437, Validation Loss AVG: 10.8437, lr: 0.001
Epoch [22/100], Training Loss: 7.6275, Validation Loss Current: 11.2641, Validation Loss AVG: 11.2641, lr: 0.001
Epoch [23/100], Training Loss: 6.3822, Validation Loss Current: 11.3620, Validation Loss AVG: 11.3620, lr: 0.001
Epoch [24/100], Training Loss: 7.8302, Validation Loss Current: 13.0243, Validation Loss AVG: 13.0243, lr: 0.001
Epoch [25/100], Training Loss: 7.0026, Validation Loss Current: 11.6355, Validation Loss AVG: 11.6355, lr: 0.001
Epoch [26/100], Training Loss: 6.6198, Validation Loss Current: 11.8558, Validation Loss AVG: 11.8558, lr: 0.001
Epoch [27/100], Training Loss: 3.3631, Validation Loss Current: 11.3865, Validation Loss AVG: 11.3865, lr: 0.001
Epoch [28/100], Training Loss: 3.3079, Validation Loss Current: 12.0034, Validation Loss AVG: 12.0034, lr: 0.001
Epoch [29/100], Training Loss: 2.4603, Validation Loss Current: 12.2137, Validation Loss AVG: 12.2137, lr: 0.001
Epoch [30/100], Training Loss: 2.3106, Validation Loss Current: 12.1876, Validation Loss AVG: 12.1876, lr: 0.001
Epoch [31/100], Training Loss: 2.9637, Validation Loss Current: 13.2508, Validation Loss AVG: 13.2508, lr: 0.001
Epoch [32/100], Training Loss: 3.9969, Validation Loss Current: 13.3254, Validation Loss AVG: 13.3254, lr: 0.001
Epoch [33/100], Training Loss: 6.6602, Validation Loss Current: 14.1300, Validation Loss AVG: 14.1300, lr: 0.001
Epoch [34/100], Training Loss: 3.0085, Validation Loss Current: 12.1341, Validation Loss AVG: 12.1341, lr: 0.001
Epoch [35/100], Training Loss: 3.2148, Validation Loss Current: 12.2610, Validation Loss AVG: 12.2610, lr: 0.001
Epoch [36/100], Training Loss: 3.4179, Validation Loss Current: 13.5879, Validation Loss AVG: 13.5879, lr: 0.001
Epoch [37/100], Training Loss: 2.0955, Validation Loss Current: 12.2466, Validation Loss AVG: 12.2466, lr: 0.001
Epoch [38/100], Training Loss: 3.2929, Validation Loss Current: 11.9638, Validation Loss AVG: 11.9638, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 8 Best val accuracy: [0.40394736842105267, 0.40855263157894733, 0.4302631578947368, 0.34671052631578947, 0.4565789473684211, 0.38848684210526313, 0.42796052631578946, 0.45921052631578946, 0.41578947368421054, 0.42434210526315785, 0.4384868421052632, 0.4203947368421053, 0.44177631578947374, 0.4342105263157895, 0.4253289473684211, 0.43289473684210533, 0.4338815789473684, 0.4358552631578947, 0.41546052631578945, 0.4286184210526316, 0.41940789473684215, 0.42796052631578946, 0.4424342105263158, 0.40131578947368424, 0.44506578947368425, 0.39473684210526316, 0.4529605263157895, 0.44703947368421054, 0.43322368421052637, 0.4200657894736842, 0.4167763157894736, 0.4131578947368421, 0.4115131578947368, 0.4473684210526316, 0.4197368421052632, 0.4220394736842105, 0.4220394736842105, 0.4259868421052631] Best val loss: 8.9417640209198


Current group: 0.8
Epoch [1/100], Training Loss: 30.5672, Validation Loss Current: 11.7156, Validation Loss AVG: 11.7156, lr: 0.001
Epoch [2/100], Training Loss: 16.8247, Validation Loss Current: 13.9744, Validation Loss AVG: 13.9744, lr: 0.001
Epoch [3/100], Training Loss: 9.6014, Validation Loss Current: 10.8516, Validation Loss AVG: 10.8516, lr: 0.001
Epoch [4/100], Training Loss: 12.1029, Validation Loss Current: 10.1620, Validation Loss AVG: 10.1620, lr: 0.001
Epoch [5/100], Training Loss: 10.1987, Validation Loss Current: 13.4619, Validation Loss AVG: 13.4619, lr: 0.001
Epoch [6/100], Training Loss: 7.2032, Validation Loss Current: 10.8679, Validation Loss AVG: 10.8679, lr: 0.001
Epoch [7/100], Training Loss: 6.0115, Validation Loss Current: 10.0548, Validation Loss AVG: 10.0548, lr: 0.001
Epoch [8/100], Training Loss: 5.3131, Validation Loss Current: 11.8423, Validation Loss AVG: 11.8423, lr: 0.001
Epoch [9/100], Training Loss: 4.1927, Validation Loss Current: 11.0811, Validation Loss AVG: 11.0811, lr: 0.001
Epoch [10/100], Training Loss: 2.4741, Validation Loss Current: 12.8263, Validation Loss AVG: 12.8263, lr: 0.001
Epoch [11/100], Training Loss: 2.3633, Validation Loss Current: 11.8976, Validation Loss AVG: 11.8976, lr: 0.001
Epoch [12/100], Training Loss: 3.9671, Validation Loss Current: 12.7000, Validation Loss AVG: 12.7000, lr: 0.001
Epoch [13/100], Training Loss: 5.2249, Validation Loss Current: 14.5817, Validation Loss AVG: 14.5817, lr: 0.001
Epoch [14/100], Training Loss: 3.0176, Validation Loss Current: 12.6021, Validation Loss AVG: 12.6021, lr: 0.001
Epoch [15/100], Training Loss: 5.0355, Validation Loss Current: 13.9595, Validation Loss AVG: 13.9595, lr: 0.001
Epoch [16/100], Training Loss: 4.8680, Validation Loss Current: 12.6039, Validation Loss AVG: 12.6039, lr: 0.001
Epoch [17/100], Training Loss: 9.2590, Validation Loss Current: 12.4475, Validation Loss AVG: 12.4475, lr: 0.001
Epoch [18/100], Training Loss: 4.7876, Validation Loss Current: 13.6343, Validation Loss AVG: 13.6343, lr: 0.001
Epoch [19/100], Training Loss: 4.0070, Validation Loss Current: 12.2544, Validation Loss AVG: 12.2544, lr: 0.001
Epoch [20/100], Training Loss: 2.4162, Validation Loss Current: 12.5868, Validation Loss AVG: 12.5868, lr: 0.001
Epoch [21/100], Training Loss: 4.9149, Validation Loss Current: 12.3262, Validation Loss AVG: 12.3262, lr: 0.001
Epoch [22/100], Training Loss: 5.8475, Validation Loss Current: 16.0539, Validation Loss AVG: 16.0539, lr: 0.001
Epoch [23/100], Training Loss: 9.1896, Validation Loss Current: 15.9700, Validation Loss AVG: 15.9700, lr: 0.001
Epoch [24/100], Training Loss: 4.6688, Validation Loss Current: 14.5369, Validation Loss AVG: 14.5369, lr: 0.001
Epoch [25/100], Training Loss: 4.8728, Validation Loss Current: 11.4867, Validation Loss AVG: 11.4867, lr: 0.001
Epoch [26/100], Training Loss: 3.9185, Validation Loss Current: 12.4692, Validation Loss AVG: 12.4692, lr: 0.001
Epoch [27/100], Training Loss: 5.6685, Validation Loss Current: 15.0576, Validation Loss AVG: 15.0576, lr: 0.001
Epoch [28/100], Training Loss: 8.5560, Validation Loss Current: 18.0007, Validation Loss AVG: 18.0007, lr: 0.001
Epoch [29/100], Training Loss: 17.6629, Validation Loss Current: 16.1359, Validation Loss AVG: 16.1359, lr: 0.001
Epoch [30/100], Training Loss: 11.3927, Validation Loss Current: 12.6903, Validation Loss AVG: 12.6903, lr: 0.001
Epoch [31/100], Training Loss: 6.2798, Validation Loss Current: 13.6472, Validation Loss AVG: 13.6472, lr: 0.001
Epoch [32/100], Training Loss: 4.9975, Validation Loss Current: 12.6776, Validation Loss AVG: 12.6776, lr: 0.001
Epoch [33/100], Training Loss: 2.7885, Validation Loss Current: 12.7242, Validation Loss AVG: 12.7242, lr: 0.001
Epoch [34/100], Training Loss: 2.3066, Validation Loss Current: 12.8965, Validation Loss AVG: 12.8965, lr: 0.001
Epoch [35/100], Training Loss: 4.4252, Validation Loss Current: 12.1468, Validation Loss AVG: 12.1468, lr: 0.001
Epoch [36/100], Training Loss: 5.0729, Validation Loss Current: 15.0363, Validation Loss AVG: 15.0363, lr: 0.001
Epoch [37/100], Training Loss: 4.3997, Validation Loss Current: 14.2112, Validation Loss AVG: 14.2112, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 7 Best val accuracy: [0.42203947368421063, 0.3740131578947369, 0.43618421052631573, 0.4473684210526316, 0.40690789473684214, 0.44144736842105264, 0.4483552631578947, 0.44703947368421054, 0.43947368421052635, 0.4460526315789474, 0.44342105263157894, 0.3904605263157895, 0.4253289473684211, 0.43519736842105256, 0.40921052631578947, 0.4230263157894737, 0.4095394736842105, 0.4167763157894736, 0.4358552631578947, 0.43815789473684214, 0.44703947368421043, 0.3851973684210526, 0.375, 0.4108552631578948, 0.4411184210526316, 0.4444078947368421, 0.3957236842105263, 0.41052631578947374, 0.38289473684210523, 0.41217105263157894, 0.40230263157894736, 0.4144736842105264, 0.42105263157894735, 0.42796052631578946, 0.4273026315789473, 0.3684210526315789, 0.4180921052631579] Best val loss: 10.054763221740723


Current group: 1
Epoch [1/100], Training Loss: 25.9875, Validation Loss Current: 8.4097, Validation Loss AVG: 12.7258, lr: 0.001
Epoch [2/100], Training Loss: 14.7166, Validation Loss Current: 8.2743, Validation Loss AVG: 10.6456, lr: 0.001
Epoch [3/100], Training Loss: 10.8537, Validation Loss Current: 8.5807, Validation Loss AVG: 18.1023, lr: 0.001
Epoch [4/100], Training Loss: 7.7414, Validation Loss Current: 8.4205, Validation Loss AVG: 12.4448, lr: 0.001
Epoch [5/100], Training Loss: 6.8109, Validation Loss Current: 8.3842, Validation Loss AVG: 14.2627, lr: 0.001
Epoch [6/100], Training Loss: 3.4939, Validation Loss Current: 8.7830, Validation Loss AVG: 15.9307, lr: 0.001
Epoch [7/100], Training Loss: 2.0666, Validation Loss Current: 7.4578, Validation Loss AVG: 13.6262, lr: 0.001
Epoch [8/100], Training Loss: 2.4799, Validation Loss Current: 7.5531, Validation Loss AVG: 15.7482, lr: 0.001
Epoch [9/100], Training Loss: 5.6103, Validation Loss Current: 8.0895, Validation Loss AVG: 13.4395, lr: 0.001
Epoch [10/100], Training Loss: 4.4592, Validation Loss Current: 9.8404, Validation Loss AVG: 17.0068, lr: 0.001
Epoch [11/100], Training Loss: 5.9161, Validation Loss Current: 9.6149, Validation Loss AVG: 16.1240, lr: 0.001
Epoch [12/100], Training Loss: 5.0895, Validation Loss Current: 10.6109, Validation Loss AVG: 14.6172, lr: 0.001
Epoch [13/100], Training Loss: 5.0674, Validation Loss Current: 8.6570, Validation Loss AVG: 13.3475, lr: 0.001
Epoch [14/100], Training Loss: 3.9194, Validation Loss Current: 7.9140, Validation Loss AVG: 14.1370, lr: 0.001
Epoch [15/100], Training Loss: 2.2722, Validation Loss Current: 8.2930, Validation Loss AVG: 16.1514, lr: 0.001
Epoch [16/100], Training Loss: 3.5906, Validation Loss Current: 7.7161, Validation Loss AVG: 11.6265, lr: 0.001
Epoch [17/100], Training Loss: 5.0356, Validation Loss Current: 8.2107, Validation Loss AVG: 16.6985, lr: 0.001
Epoch [18/100], Training Loss: 1.8218, Validation Loss Current: 8.2671, Validation Loss AVG: 15.0389, lr: 0.001
Epoch [19/100], Training Loss: 3.3819, Validation Loss Current: 9.6785, Validation Loss AVG: 18.6476, lr: 0.001
Epoch [20/100], Training Loss: 6.9800, Validation Loss Current: 9.5526, Validation Loss AVG: 15.5589, lr: 0.001
Epoch [21/100], Training Loss: 5.8213, Validation Loss Current: 8.5528, Validation Loss AVG: 17.4479, lr: 0.001
Epoch [22/100], Training Loss: 4.2323, Validation Loss Current: 8.1323, Validation Loss AVG: 16.6715, lr: 0.001
Epoch [23/100], Training Loss: 2.3575, Validation Loss Current: 7.8177, Validation Loss AVG: 13.6190, lr: 0.001
Epoch [24/100], Training Loss: 6.3248, Validation Loss Current: 8.5716, Validation Loss AVG: 15.1779, lr: 0.001
Epoch [25/100], Training Loss: 6.1369, Validation Loss Current: 8.5294, Validation Loss AVG: 17.3577, lr: 0.001
Epoch [26/100], Training Loss: 3.9946, Validation Loss Current: 8.7623, Validation Loss AVG: 13.5591, lr: 0.001
Epoch [27/100], Training Loss: 4.1668, Validation Loss Current: 9.0323, Validation Loss AVG: 14.8857, lr: 0.001
Epoch [28/100], Training Loss: 2.4070, Validation Loss Current: 9.1771, Validation Loss AVG: 17.7318, lr: 0.001
Epoch [29/100], Training Loss: 1.1442, Validation Loss Current: 8.5370, Validation Loss AVG: 15.3208, lr: 0.001
Epoch [30/100], Training Loss: 0.9771, Validation Loss Current: 8.4162, Validation Loss AVG: 14.3653, lr: 0.001
Epoch [31/100], Training Loss: 3.3215, Validation Loss Current: 8.3056, Validation Loss AVG: 12.7848, lr: 0.001
Epoch [32/100], Training Loss: 2.5716, Validation Loss Current: 8.4608, Validation Loss AVG: 17.4069, lr: 0.001
Epoch [33/100], Training Loss: 2.7505, Validation Loss Current: 8.8866, Validation Loss AVG: 19.2846, lr: 0.001
Epoch [34/100], Training Loss: 6.7311, Validation Loss Current: 8.6558, Validation Loss AVG: 16.3145, lr: 0.001
Epoch [35/100], Training Loss: 1.6715, Validation Loss Current: 8.4453, Validation Loss AVG: 12.6205, lr: 0.001
Epoch [36/100], Training Loss: 1.9325, Validation Loss Current: 7.9398, Validation Loss AVG: 13.6358, lr: 0.001
Epoch [37/100], Training Loss: 2.5402, Validation Loss Current: 10.4898, Validation Loss AVG: 14.9431, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 7 Best val accuracy: [0.5493421052631579, 0.5592105263157895, 0.5740131578947368, 0.5822368421052632, 0.5822368421052632, 0.5756578947368421, 0.6200657894736842, 0.600328947368421, 0.6019736842105263, 0.524671052631579, 0.5427631578947368, 0.5296052631578947, 0.5838815789473685, 0.6299342105263158, 0.5805921052631579, 0.5970394736842105, 0.6052631578947368, 0.6019736842105263, 0.59375, 0.5592105263157895, 0.569078947368421, 0.5789473684210527, 0.587171052631579, 0.6101973684210527, 0.5904605263157895, 0.5674342105263158, 0.5921052631578947, 0.5526315789473685, 0.5986842105263158, 0.5888157894736842, 0.5838815789473685, 0.5822368421052632, 0.6052631578947368, 0.5888157894736842, 0.5986842105263158, 0.6282894736842105, 0.5608552631578947] Best val loss: 7.4578022956848145


----- Training resnet18 with sequence: [0.6, 0.8, 1] -----
Current group: 0.6
Epoch [1/134], Training Loss: 40.7406, Validation Loss Current: 9.8858, Validation Loss AVG: 9.8858, lr: 0.001
Epoch [2/134], Training Loss: 39.6515, Validation Loss Current: 9.8768, Validation Loss AVG: 9.8768, lr: 0.001
Epoch [3/134], Training Loss: 38.9419, Validation Loss Current: 9.7719, Validation Loss AVG: 9.7719, lr: 0.001
Epoch [4/134], Training Loss: 38.6570, Validation Loss Current: 9.6132, Validation Loss AVG: 9.6132, lr: 0.001
Epoch [5/134], Training Loss: 37.1146, Validation Loss Current: 9.4363, Validation Loss AVG: 9.4363, lr: 0.001
Epoch [6/134], Training Loss: 36.3277, Validation Loss Current: 9.5214, Validation Loss AVG: 9.5214, lr: 0.001
Epoch [7/134], Training Loss: 35.3335, Validation Loss Current: 9.1142, Validation Loss AVG: 9.1142, lr: 0.001
Epoch [8/134], Training Loss: 33.8037, Validation Loss Current: 9.1782, Validation Loss AVG: 9.1782, lr: 0.001
Epoch [9/134], Training Loss: 33.5748, Validation Loss Current: 9.0753, Validation Loss AVG: 9.0753, lr: 0.001
Epoch [10/134], Training Loss: 31.7207, Validation Loss Current: 8.9622, Validation Loss AVG: 8.9622, lr: 0.001
Epoch [11/134], Training Loss: 31.8683, Validation Loss Current: 8.9202, Validation Loss AVG: 8.9202, lr: 0.001
Epoch [12/134], Training Loss: 30.8951, Validation Loss Current: 8.9288, Validation Loss AVG: 8.9288, lr: 0.001
Epoch [13/134], Training Loss: 29.5881, Validation Loss Current: 8.6747, Validation Loss AVG: 8.6747, lr: 0.001
Epoch [14/134], Training Loss: 28.5282, Validation Loss Current: 8.7594, Validation Loss AVG: 8.7594, lr: 0.001
Epoch [15/134], Training Loss: 27.8125, Validation Loss Current: 8.9338, Validation Loss AVG: 8.9338, lr: 0.001
Epoch [16/134], Training Loss: 27.6440, Validation Loss Current: 8.3565, Validation Loss AVG: 8.3565, lr: 0.001
Epoch [17/134], Training Loss: 26.8806, Validation Loss Current: 8.4655, Validation Loss AVG: 8.4655, lr: 0.001
Epoch [18/134], Training Loss: 26.4447, Validation Loss Current: 8.3036, Validation Loss AVG: 8.3036, lr: 0.001
Epoch [19/134], Training Loss: 24.6624, Validation Loss Current: 9.2508, Validation Loss AVG: 9.2508, lr: 0.001
Epoch [20/134], Training Loss: 24.5875, Validation Loss Current: 8.1198, Validation Loss AVG: 8.1198, lr: 0.001
Epoch [21/134], Training Loss: 22.9068, Validation Loss Current: 9.0100, Validation Loss AVG: 9.0100, lr: 0.001
Epoch [22/134], Training Loss: 22.6543, Validation Loss Current: 9.4791, Validation Loss AVG: 9.4791, lr: 0.001
Epoch [23/134], Training Loss: 22.2690, Validation Loss Current: 8.0454, Validation Loss AVG: 8.0454, lr: 0.001
Epoch [24/134], Training Loss: 20.6440, Validation Loss Current: 8.2414, Validation Loss AVG: 8.2414, lr: 0.001
Epoch [25/134], Training Loss: 20.5699, Validation Loss Current: 8.5299, Validation Loss AVG: 8.5299, lr: 0.001
Epoch [26/134], Training Loss: 20.0863, Validation Loss Current: 8.5142, Validation Loss AVG: 8.5142, lr: 0.001
Epoch [27/134], Training Loss: 18.3709, Validation Loss Current: 8.4730, Validation Loss AVG: 8.4730, lr: 0.001
Epoch [28/134], Training Loss: 16.5486, Validation Loss Current: 10.3998, Validation Loss AVG: 10.3998, lr: 0.001
Epoch [29/134], Training Loss: 15.7492, Validation Loss Current: 9.0163, Validation Loss AVG: 9.0163, lr: 0.001
Epoch [30/134], Training Loss: 16.6367, Validation Loss Current: 9.4615, Validation Loss AVG: 9.4615, lr: 0.001
Epoch [31/134], Training Loss: 19.6613, Validation Loss Current: 8.2577, Validation Loss AVG: 8.2577, lr: 0.001
Epoch [32/134], Training Loss: 15.9125, Validation Loss Current: 8.2215, Validation Loss AVG: 8.2215, lr: 0.001
Epoch [33/134], Training Loss: 13.7535, Validation Loss Current: 8.1705, Validation Loss AVG: 8.1705, lr: 0.001
Epoch [34/134], Training Loss: 12.1564, Validation Loss Current: 8.1481, Validation Loss AVG: 8.1481, lr: 0.001
Epoch [35/134], Training Loss: 11.5477, Validation Loss Current: 8.8001, Validation Loss AVG: 8.8001, lr: 0.001
Epoch [36/134], Training Loss: 11.0585, Validation Loss Current: 9.2953, Validation Loss AVG: 9.2953, lr: 0.001
Epoch [37/134], Training Loss: 10.3010, Validation Loss Current: 9.1494, Validation Loss AVG: 9.1494, lr: 0.001
Epoch [38/134], Training Loss: 11.9694, Validation Loss Current: 8.0835, Validation Loss AVG: 8.0835, lr: 0.001
Epoch [39/134], Training Loss: 12.5573, Validation Loss Current: 9.2015, Validation Loss AVG: 9.2015, lr: 0.001
Epoch [40/134], Training Loss: 10.7501, Validation Loss Current: 8.6472, Validation Loss AVG: 8.6472, lr: 0.001
Epoch [41/134], Training Loss: 10.2721, Validation Loss Current: 13.7580, Validation Loss AVG: 13.7580, lr: 0.001
Epoch [42/134], Training Loss: 16.6201, Validation Loss Current: 10.8355, Validation Loss AVG: 10.8355, lr: 0.001
Epoch [43/134], Training Loss: 10.7262, Validation Loss Current: 10.4004, Validation Loss AVG: 10.4004, lr: 0.001
Epoch [44/134], Training Loss: 10.9155, Validation Loss Current: 11.0064, Validation Loss AVG: 11.0064, lr: 0.001
Epoch [45/134], Training Loss: 12.2350, Validation Loss Current: 9.4982, Validation Loss AVG: 9.4982, lr: 0.001
Epoch [46/134], Training Loss: 9.5426, Validation Loss Current: 9.8145, Validation Loss AVG: 9.8145, lr: 0.001
Epoch [47/134], Training Loss: 9.2520, Validation Loss Current: 8.5469, Validation Loss AVG: 8.5469, lr: 0.001
Epoch [48/134], Training Loss: 7.6900, Validation Loss Current: 10.5740, Validation Loss AVG: 10.5740, lr: 0.001
Epoch [49/134], Training Loss: 10.5916, Validation Loss Current: 10.9983, Validation Loss AVG: 10.9983, lr: 0.001
Epoch [50/134], Training Loss: 8.8114, Validation Loss Current: 9.6966, Validation Loss AVG: 9.6966, lr: 0.001
Epoch [51/134], Training Loss: 7.1926, Validation Loss Current: 10.7627, Validation Loss AVG: 10.7627, lr: 0.001
Epoch [52/134], Training Loss: 7.3355, Validation Loss Current: 11.5850, Validation Loss AVG: 11.5850, lr: 0.001
Epoch [53/134], Training Loss: 7.8543, Validation Loss Current: 9.8530, Validation Loss AVG: 9.8530, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 23 Best val accuracy: [0.2621710526315789, 0.26315789473684215, 0.2713815789473684, 0.3108552631578948, 0.30953947368421053, 0.2980263157894737, 0.3338815789473684, 0.3200657894736842, 0.319078947368421, 0.35, 0.32664473684210527, 0.3677631578947369, 0.3838815789473684, 0.3506578947368421, 0.3450657894736842, 0.38782894736842105, 0.3796052631578948, 0.3940789473684211, 0.3713815789473684, 0.4180921052631579, 0.3726973684210526, 0.40197368421052637, 0.4266447368421053, 0.4197368421052631, 0.4240131578947368, 0.4098684210526316, 0.41743421052631585, 0.34671052631578947, 0.41085526315789467, 0.3828947368421053, 0.41578947368421054, 0.424671052631579, 0.4319078947368421, 0.42368421052631583, 0.41907894736842105, 0.40230263157894736, 0.42631578947368415, 0.44703947368421054, 0.3805921052631579, 0.4391447368421053, 0.2891447368421053, 0.35625, 0.40361842105263157, 0.33092105263157895, 0.3917763157894737, 0.44144736842105264, 0.4286184210526316, 0.39375, 0.3680921052631579, 0.4273026315789473, 0.4026315789473684, 0.3901315789473684, 0.4180921052631579] Best val loss: 8.045445251464844


Current group: 0.8
Epoch [1/134], Training Loss: 26.6019, Validation Loss Current: 10.6484, Validation Loss AVG: 10.6484, lr: 0.001
Epoch [2/134], Training Loss: 21.0234, Validation Loss Current: 9.7837, Validation Loss AVG: 9.7837, lr: 0.001
Epoch [3/134], Training Loss: 19.4182, Validation Loss Current: 12.2880, Validation Loss AVG: 12.2880, lr: 0.001
Epoch [4/134], Training Loss: 20.9768, Validation Loss Current: 10.1510, Validation Loss AVG: 10.1510, lr: 0.001
Epoch [5/134], Training Loss: 17.2497, Validation Loss Current: 9.0629, Validation Loss AVG: 9.0629, lr: 0.001
Epoch [6/134], Training Loss: 12.4229, Validation Loss Current: 8.8273, Validation Loss AVG: 8.8273, lr: 0.001
Epoch [7/134], Training Loss: 13.5129, Validation Loss Current: 10.3100, Validation Loss AVG: 10.3100, lr: 0.001
Epoch [8/134], Training Loss: 14.5562, Validation Loss Current: 10.0316, Validation Loss AVG: 10.0316, lr: 0.001
Epoch [9/134], Training Loss: 11.2804, Validation Loss Current: 11.1958, Validation Loss AVG: 11.1958, lr: 0.001
Epoch [10/134], Training Loss: 8.9177, Validation Loss Current: 9.6793, Validation Loss AVG: 9.6793, lr: 0.001
Epoch [11/134], Training Loss: 6.7854, Validation Loss Current: 9.3128, Validation Loss AVG: 9.3128, lr: 0.001
Epoch [12/134], Training Loss: 7.0430, Validation Loss Current: 9.7125, Validation Loss AVG: 9.7125, lr: 0.001
Epoch [13/134], Training Loss: 6.3400, Validation Loss Current: 9.7841, Validation Loss AVG: 9.7841, lr: 0.001
Epoch [14/134], Training Loss: 8.2019, Validation Loss Current: 12.4479, Validation Loss AVG: 12.4479, lr: 0.001
Epoch [15/134], Training Loss: 9.8425, Validation Loss Current: 9.5130, Validation Loss AVG: 9.5130, lr: 0.001
Epoch [16/134], Training Loss: 6.8740, Validation Loss Current: 9.5021, Validation Loss AVG: 9.5021, lr: 0.001
Epoch [17/134], Training Loss: 7.4816, Validation Loss Current: 12.0785, Validation Loss AVG: 12.0785, lr: 0.001
Epoch [18/134], Training Loss: 6.4788, Validation Loss Current: 8.9676, Validation Loss AVG: 8.9676, lr: 0.001
Epoch [19/134], Training Loss: 4.8727, Validation Loss Current: 11.1498, Validation Loss AVG: 11.1498, lr: 0.001
Epoch [20/134], Training Loss: 3.6016, Validation Loss Current: 11.9336, Validation Loss AVG: 11.9336, lr: 0.001
Epoch [21/134], Training Loss: 4.2115, Validation Loss Current: 11.4820, Validation Loss AVG: 11.4820, lr: 0.001
Epoch [22/134], Training Loss: 5.0716, Validation Loss Current: 11.4965, Validation Loss AVG: 11.4965, lr: 0.001
Epoch [23/134], Training Loss: 3.5672, Validation Loss Current: 12.6747, Validation Loss AVG: 12.6747, lr: 0.001
Epoch [24/134], Training Loss: 2.9915, Validation Loss Current: 11.5241, Validation Loss AVG: 11.5241, lr: 0.001
Epoch [25/134], Training Loss: 3.7380, Validation Loss Current: 10.5288, Validation Loss AVG: 10.5288, lr: 0.001
Epoch [26/134], Training Loss: 3.1875, Validation Loss Current: 11.7887, Validation Loss AVG: 11.7887, lr: 0.001
Epoch [27/134], Training Loss: 5.6436, Validation Loss Current: 11.5795, Validation Loss AVG: 11.5795, lr: 0.001
Epoch [28/134], Training Loss: 3.0066, Validation Loss Current: 12.3790, Validation Loss AVG: 12.3790, lr: 0.001
Epoch [29/134], Training Loss: 5.1516, Validation Loss Current: 10.2440, Validation Loss AVG: 10.2440, lr: 0.001
Epoch [30/134], Training Loss: 6.1828, Validation Loss Current: 13.6897, Validation Loss AVG: 13.6897, lr: 0.001
Epoch [31/134], Training Loss: 4.4788, Validation Loss Current: 11.2798, Validation Loss AVG: 11.2798, lr: 0.001
Epoch [32/134], Training Loss: 4.9576, Validation Loss Current: 16.5212, Validation Loss AVG: 16.5212, lr: 0.001
Epoch [33/134], Training Loss: 4.3758, Validation Loss Current: 11.3107, Validation Loss AVG: 11.3107, lr: 0.001
Epoch [34/134], Training Loss: 4.0707, Validation Loss Current: 11.5684, Validation Loss AVG: 11.5684, lr: 0.001
Epoch [35/134], Training Loss: 3.0596, Validation Loss Current: 13.0021, Validation Loss AVG: 13.0021, lr: 0.001
Epoch [36/134], Training Loss: 3.4237, Validation Loss Current: 13.9404, Validation Loss AVG: 13.9404, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 6 Best val accuracy: [0.3661184210526316, 0.3993421052631579, 0.37269736842105267, 0.4269736842105264, 0.44506578947368425, 0.4476973684210527, 0.44177631578947374, 0.41414473684210523, 0.4256578947368421, 0.4634868421052632, 0.47368421052631576, 0.46019736842105263, 0.4588815789473684, 0.4082236842105263, 0.45756578947368426, 0.4677631578947368, 0.4394736842105263, 0.4565789473684211, 0.4463815789473685, 0.4444078947368421, 0.4213815789473684, 0.43125, 0.42828947368421055, 0.45, 0.4654605263157895, 0.4384868421052632, 0.42105263157894735, 0.45230263157894735, 0.4463815789473684, 0.42467105263157895, 0.4375, 0.33947368421052626, 0.4269736842105263, 0.43881578947368427, 0.44144736842105264, 0.43881578947368416] Best val loss: 8.82730827331543


Current group: 1
Epoch [1/134], Training Loss: 21.5798, Validation Loss Current: 8.1427, Validation Loss AVG: 13.4693, lr: 0.001
Epoch [2/134], Training Loss: 14.6322, Validation Loss Current: 7.6916, Validation Loss AVG: 10.8595, lr: 0.001
Epoch [3/134], Training Loss: 16.4023, Validation Loss Current: 8.5634, Validation Loss AVG: 13.2349, lr: 0.001
Epoch [4/134], Training Loss: 16.9412, Validation Loss Current: 8.4411, Validation Loss AVG: 13.7929, lr: 0.001
Epoch [5/134], Training Loss: 14.1293, Validation Loss Current: 9.3279, Validation Loss AVG: 16.3978, lr: 0.001
Epoch [6/134], Training Loss: 11.0755, Validation Loss Current: 7.0617, Validation Loss AVG: 9.9670, lr: 0.001
Epoch [7/134], Training Loss: 9.5281, Validation Loss Current: 7.1732, Validation Loss AVG: 11.6344, lr: 0.001
Epoch [8/134], Training Loss: 7.2085, Validation Loss Current: 7.0033, Validation Loss AVG: 10.2899, lr: 0.001
Epoch [9/134], Training Loss: 7.4178, Validation Loss Current: 7.0356, Validation Loss AVG: 12.3171, lr: 0.001
Epoch [10/134], Training Loss: 3.8813, Validation Loss Current: 6.6124, Validation Loss AVG: 11.6376, lr: 0.001
Epoch [11/134], Training Loss: 5.1423, Validation Loss Current: 7.1486, Validation Loss AVG: 11.9074, lr: 0.001
Epoch [12/134], Training Loss: 5.6570, Validation Loss Current: 8.1895, Validation Loss AVG: 13.8740, lr: 0.001
Epoch [13/134], Training Loss: 4.4168, Validation Loss Current: 7.2688, Validation Loss AVG: 12.4554, lr: 0.001
Epoch [14/134], Training Loss: 6.1639, Validation Loss Current: 7.5073, Validation Loss AVG: 12.0350, lr: 0.001
Epoch [15/134], Training Loss: 3.8133, Validation Loss Current: 7.9803, Validation Loss AVG: 14.5043, lr: 0.001
Epoch [16/134], Training Loss: 3.0634, Validation Loss Current: 7.2266, Validation Loss AVG: 11.2385, lr: 0.001
Epoch [17/134], Training Loss: 6.3906, Validation Loss Current: 8.2435, Validation Loss AVG: 13.3829, lr: 0.001
Epoch [18/134], Training Loss: 5.3144, Validation Loss Current: 7.5666, Validation Loss AVG: 11.8749, lr: 0.001
Epoch [19/134], Training Loss: 3.6031, Validation Loss Current: 7.9949, Validation Loss AVG: 13.0782, lr: 0.001
Epoch [20/134], Training Loss: 3.2975, Validation Loss Current: 7.9159, Validation Loss AVG: 15.1127, lr: 0.001
Epoch [21/134], Training Loss: 6.6540, Validation Loss Current: 7.1669, Validation Loss AVG: 12.2723, lr: 0.001
Epoch [22/134], Training Loss: 4.7445, Validation Loss Current: 7.9106, Validation Loss AVG: 15.9976, lr: 0.001
Epoch [23/134], Training Loss: 5.5948, Validation Loss Current: 8.2350, Validation Loss AVG: 12.5826, lr: 0.001
Epoch [24/134], Training Loss: 3.0282, Validation Loss Current: 7.7327, Validation Loss AVG: 15.5523, lr: 0.001
Epoch [25/134], Training Loss: 1.9144, Validation Loss Current: 7.5199, Validation Loss AVG: 15.8537, lr: 0.001
Epoch [26/134], Training Loss: 2.2648, Validation Loss Current: 8.0511, Validation Loss AVG: 13.7354, lr: 0.001
Epoch [27/134], Training Loss: 2.6605, Validation Loss Current: 8.1499, Validation Loss AVG: 15.2296, lr: 0.001
Epoch [28/134], Training Loss: 3.4335, Validation Loss Current: 7.6126, Validation Loss AVG: 12.6235, lr: 0.001
Epoch [29/134], Training Loss: 2.6704, Validation Loss Current: 8.9647, Validation Loss AVG: 12.5615, lr: 0.001
Epoch [30/134], Training Loss: 3.7429, Validation Loss Current: 7.6631, Validation Loss AVG: 13.6615, lr: 0.001
Epoch [31/134], Training Loss: 1.4922, Validation Loss Current: 8.6969, Validation Loss AVG: 13.6257, lr: 0.001
Epoch [32/134], Training Loss: 1.2106, Validation Loss Current: 7.4654, Validation Loss AVG: 12.8430, lr: 0.001
Epoch [33/134], Training Loss: 3.5574, Validation Loss Current: 8.7559, Validation Loss AVG: 14.6985, lr: 0.001
Epoch [34/134], Training Loss: 7.2781, Validation Loss Current: 8.8109, Validation Loss AVG: 14.8888, lr: 0.001
Epoch [35/134], Training Loss: 7.3273, Validation Loss Current: 8.2599, Validation Loss AVG: 16.0365, lr: 0.001
Epoch [36/134], Training Loss: 3.9417, Validation Loss Current: 8.5522, Validation Loss AVG: 14.2169, lr: 0.001
Epoch [37/134], Training Loss: 2.5935, Validation Loss Current: 7.8975, Validation Loss AVG: 14.2060, lr: 0.001
Epoch [38/134], Training Loss: 2.2389, Validation Loss Current: 8.3514, Validation Loss AVG: 15.2109, lr: 0.001
Epoch [39/134], Training Loss: 2.0107, Validation Loss Current: 7.8517, Validation Loss AVG: 11.7240, lr: 0.001
Epoch [40/134], Training Loss: 4.2331, Validation Loss Current: 8.2520, Validation Loss AVG: 12.6815, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 10 Best val accuracy: [0.5476973684210527, 0.5838815789473685, 0.5756578947368421, 0.5526315789473685, 0.49506578947368424, 0.5921052631578947, 0.6118421052631579, 0.5986842105263158, 0.5953947368421053, 0.6233552631578947, 0.6332236842105263, 0.5789473684210527, 0.6217105263157895, 0.6019736842105263, 0.587171052631579, 0.625, 0.569078947368421, 0.59375, 0.6134868421052632, 0.6101973684210527, 0.6381578947368421, 0.6069078947368421, 0.6052631578947368, 0.6200657894736842, 0.6266447368421053, 0.6118421052631579, 0.5970394736842105, 0.6332236842105263, 0.5805921052631579, 0.6069078947368421, 0.59375, 0.6332236842105263, 0.5986842105263158, 0.5986842105263158, 0.5855263157894737, 0.5888157894736842, 0.6118421052631579, 0.600328947368421, 0.6217105263157895, 0.59375] Best val loss: 6.612416386604309


----- Training resnet18 with sequence: [0.8, 1] -----
Current group: 0.8
Epoch [1/200], Training Loss: 40.6738, Validation Loss Current: 9.9155, Validation Loss AVG: 9.9155, lr: 0.001
Epoch [2/200], Training Loss: 39.1467, Validation Loss Current: 9.7950, Validation Loss AVG: 9.7950, lr: 0.001
Epoch [3/200], Training Loss: 38.2368, Validation Loss Current: 9.5835, Validation Loss AVG: 9.5835, lr: 0.001
Epoch [4/200], Training Loss: 37.2742, Validation Loss Current: 9.5836, Validation Loss AVG: 9.5836, lr: 0.001
Epoch [5/200], Training Loss: 36.7388, Validation Loss Current: 9.1966, Validation Loss AVG: 9.1966, lr: 0.001
Epoch [6/200], Training Loss: 34.7305, Validation Loss Current: 9.1316, Validation Loss AVG: 9.1316, lr: 0.001
Epoch [7/200], Training Loss: 33.4031, Validation Loss Current: 8.9351, Validation Loss AVG: 8.9351, lr: 0.001
Epoch [8/200], Training Loss: 31.5118, Validation Loss Current: 8.8630, Validation Loss AVG: 8.8630, lr: 0.001
Epoch [9/200], Training Loss: 30.7684, Validation Loss Current: 8.7723, Validation Loss AVG: 8.7723, lr: 0.001
Epoch [10/200], Training Loss: 28.8140, Validation Loss Current: 8.8169, Validation Loss AVG: 8.8169, lr: 0.001
Epoch [11/200], Training Loss: 28.0409, Validation Loss Current: 9.1251, Validation Loss AVG: 9.1251, lr: 0.001
Epoch [12/200], Training Loss: 26.4399, Validation Loss Current: 8.5593, Validation Loss AVG: 8.5593, lr: 0.001
Epoch [13/200], Training Loss: 26.3887, Validation Loss Current: 9.3044, Validation Loss AVG: 9.3044, lr: 0.001
Epoch [14/200], Training Loss: 24.9819, Validation Loss Current: 8.4365, Validation Loss AVG: 8.4365, lr: 0.001
Epoch [15/200], Training Loss: 23.9035, Validation Loss Current: 9.1807, Validation Loss AVG: 9.1807, lr: 0.001
Epoch [16/200], Training Loss: 24.3790, Validation Loss Current: 8.2061, Validation Loss AVG: 8.2061, lr: 0.001
Epoch [17/200], Training Loss: 23.2616, Validation Loss Current: 8.7117, Validation Loss AVG: 8.7117, lr: 0.001
Epoch [18/200], Training Loss: 21.6130, Validation Loss Current: 8.2789, Validation Loss AVG: 8.2789, lr: 0.001
Epoch [19/200], Training Loss: 20.6602, Validation Loss Current: 9.7120, Validation Loss AVG: 9.7120, lr: 0.001
Epoch [20/200], Training Loss: 20.8733, Validation Loss Current: 8.2214, Validation Loss AVG: 8.2214, lr: 0.001
Epoch [21/200], Training Loss: 18.9562, Validation Loss Current: 8.6497, Validation Loss AVG: 8.6497, lr: 0.001
Epoch [22/200], Training Loss: 19.0765, Validation Loss Current: 9.0679, Validation Loss AVG: 9.0679, lr: 0.001
Epoch [23/200], Training Loss: 19.1534, Validation Loss Current: 9.2091, Validation Loss AVG: 9.2091, lr: 0.001
Epoch [24/200], Training Loss: 19.3857, Validation Loss Current: 9.5999, Validation Loss AVG: 9.5999, lr: 0.001
Epoch [25/200], Training Loss: 18.3089, Validation Loss Current: 9.3720, Validation Loss AVG: 9.3720, lr: 0.001
Epoch [26/200], Training Loss: 17.6241, Validation Loss Current: 9.5855, Validation Loss AVG: 9.5855, lr: 0.001
Epoch [27/200], Training Loss: 16.6109, Validation Loss Current: 8.6394, Validation Loss AVG: 8.6394, lr: 0.001
Epoch [28/200], Training Loss: 16.1933, Validation Loss Current: 11.1040, Validation Loss AVG: 11.1040, lr: 0.001
Epoch [29/200], Training Loss: 18.5672, Validation Loss Current: 8.7242, Validation Loss AVG: 8.7242, lr: 0.001
Epoch [30/200], Training Loss: 15.6837, Validation Loss Current: 10.3600, Validation Loss AVG: 10.3600, lr: 0.001
Epoch [31/200], Training Loss: 13.8482, Validation Loss Current: 10.6406, Validation Loss AVG: 10.6406, lr: 0.001
Epoch [32/200], Training Loss: 13.2863, Validation Loss Current: 10.5931, Validation Loss AVG: 10.5931, lr: 0.001
Epoch [33/200], Training Loss: 16.7731, Validation Loss Current: 9.5109, Validation Loss AVG: 9.5109, lr: 0.001
Epoch [34/200], Training Loss: 14.6792, Validation Loss Current: 8.1943, Validation Loss AVG: 8.1943, lr: 0.001
Epoch [35/200], Training Loss: 13.1544, Validation Loss Current: 9.6916, Validation Loss AVG: 9.6916, lr: 0.001
Epoch [36/200], Training Loss: 11.5695, Validation Loss Current: 8.5327, Validation Loss AVG: 8.5327, lr: 0.001
Epoch [37/200], Training Loss: 10.8391, Validation Loss Current: 9.5142, Validation Loss AVG: 9.5142, lr: 0.001
Epoch [38/200], Training Loss: 9.1147, Validation Loss Current: 9.8234, Validation Loss AVG: 9.8234, lr: 0.001
Epoch [39/200], Training Loss: 8.9315, Validation Loss Current: 9.3171, Validation Loss AVG: 9.3171, lr: 0.001
Epoch [40/200], Training Loss: 10.8534, Validation Loss Current: 10.5418, Validation Loss AVG: 10.5418, lr: 0.001
Epoch [41/200], Training Loss: 7.5028, Validation Loss Current: 8.9572, Validation Loss AVG: 8.9572, lr: 0.001
Epoch [42/200], Training Loss: 6.5816, Validation Loss Current: 8.8237, Validation Loss AVG: 8.8237, lr: 0.001
Epoch [43/200], Training Loss: 7.6226, Validation Loss Current: 9.4453, Validation Loss AVG: 9.4453, lr: 0.001
Epoch [44/200], Training Loss: 6.1723, Validation Loss Current: 10.6331, Validation Loss AVG: 10.6331, lr: 0.001
Epoch [45/200], Training Loss: 6.2940, Validation Loss Current: 10.8549, Validation Loss AVG: 10.8549, lr: 0.001
Epoch [46/200], Training Loss: 5.4585, Validation Loss Current: 10.7026, Validation Loss AVG: 10.7026, lr: 0.001
Epoch [47/200], Training Loss: 7.0796, Validation Loss Current: 10.4239, Validation Loss AVG: 10.4239, lr: 0.001
Epoch [48/200], Training Loss: 6.2328, Validation Loss Current: 10.7729, Validation Loss AVG: 10.7729, lr: 0.001
Epoch [49/200], Training Loss: 5.6798, Validation Loss Current: 10.1653, Validation Loss AVG: 10.1653, lr: 0.001
Epoch [50/200], Training Loss: 6.1037, Validation Loss Current: 9.1109, Validation Loss AVG: 9.1109, lr: 0.001
Epoch [51/200], Training Loss: 5.2615, Validation Loss Current: 11.5562, Validation Loss AVG: 11.5562, lr: 0.001
Epoch [52/200], Training Loss: 6.5952, Validation Loss Current: 11.2381, Validation Loss AVG: 11.2381, lr: 0.001
Epoch [53/200], Training Loss: 5.5812, Validation Loss Current: 12.1438, Validation Loss AVG: 12.1438, lr: 0.001
Epoch [54/200], Training Loss: 6.2290, Validation Loss Current: 13.1462, Validation Loss AVG: 13.1462, lr: 0.001
Epoch [55/200], Training Loss: 8.1365, Validation Loss Current: 12.0721, Validation Loss AVG: 12.0721, lr: 0.001
Epoch [56/200], Training Loss: 8.5093, Validation Loss Current: 10.3928, Validation Loss AVG: 10.3928, lr: 0.001
Epoch [57/200], Training Loss: 8.6343, Validation Loss Current: 10.5510, Validation Loss AVG: 10.5510, lr: 0.001
Epoch [58/200], Training Loss: 6.5959, Validation Loss Current: 12.9116, Validation Loss AVG: 12.9116, lr: 0.001
Epoch [59/200], Training Loss: 5.1451, Validation Loss Current: 13.2052, Validation Loss AVG: 13.2052, lr: 0.001
Epoch [60/200], Training Loss: 8.0423, Validation Loss Current: 10.4560, Validation Loss AVG: 10.4560, lr: 0.001
Epoch [61/200], Training Loss: 6.6773, Validation Loss Current: 9.6376, Validation Loss AVG: 9.6376, lr: 0.001
Epoch [62/200], Training Loss: 6.8002, Validation Loss Current: 17.9540, Validation Loss AVG: 17.9540, lr: 0.001
Epoch [63/200], Training Loss: 7.4161, Validation Loss Current: 17.0704, Validation Loss AVG: 17.0704, lr: 0.001
Epoch [64/200], Training Loss: 5.2637, Validation Loss Current: 10.7835, Validation Loss AVG: 10.7835, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 34 Best val accuracy: [0.2651315789473684, 0.2868421052631579, 0.29901315789473687, 0.27039473684210524, 0.32532894736842105, 0.31480263157894733, 0.3391447368421053, 0.35, 0.3799342105263158, 0.34638157894736843, 0.36546052631578946, 0.40164473684210533, 0.3769736842105263, 0.4082236842105263, 0.3917763157894737, 0.44046052631578947, 0.4026315789473685, 0.43355263157894736, 0.3973684210526316, 0.43815789473684214, 0.4217105263157895, 0.4098684210526315, 0.4167763157894736, 0.37467105263157896, 0.39802631578947373, 0.42072368421052636, 0.42993421052631575, 0.3963815789473684, 0.4322368421052632, 0.38881578947368417, 0.39572368421052634, 0.3940789473684211, 0.4207236842105263, 0.45789473684210524, 0.4319078947368421, 0.44506578947368425, 0.42828947368421055, 0.43486842105263157, 0.45, 0.37894736842105264, 0.45394736842105265, 0.46019736842105263, 0.4223684210526315, 0.4259868421052631, 0.42796052631578946, 0.43618421052631584, 0.4203947368421053, 0.42598684210526316, 0.45723684210526316, 0.4740131578947368, 0.4134868421052632, 0.4319078947368421, 0.3924342105263158, 0.3993421052631579, 0.4180921052631579, 0.42467105263157895, 0.4276315789473684, 0.4213815789473684, 0.39276315789473687, 0.4509868421052632, 0.4546052631578947, 0.37532894736842104, 0.3582236842105263, 0.4546052631578947] Best val loss: 8.19433081150055


Current group: 1
Epoch [1/200], Training Loss: 21.8783, Validation Loss Current: 6.7196, Validation Loss AVG: 9.9908, lr: 0.001
Epoch [2/200], Training Loss: 16.3859, Validation Loss Current: 6.1809, Validation Loss AVG: 10.0920, lr: 0.001
Epoch [3/200], Training Loss: 14.6559, Validation Loss Current: 6.5588, Validation Loss AVG: 13.2816, lr: 0.001
Epoch [4/200], Training Loss: 10.9803, Validation Loss Current: 6.0539, Validation Loss AVG: 10.4873, lr: 0.001
Epoch [5/200], Training Loss: 7.7344, Validation Loss Current: 6.1621, Validation Loss AVG: 11.6456, lr: 0.001
Epoch [6/200], Training Loss: 8.5508, Validation Loss Current: 5.8567, Validation Loss AVG: 9.6536, lr: 0.001
Epoch [7/200], Training Loss: 7.0416, Validation Loss Current: 5.7048, Validation Loss AVG: 9.8080, lr: 0.001
Epoch [8/200], Training Loss: 8.6334, Validation Loss Current: 7.3065, Validation Loss AVG: 11.0916, lr: 0.001
Epoch [9/200], Training Loss: 8.7290, Validation Loss Current: 5.9060, Validation Loss AVG: 11.4347, lr: 0.001
Epoch [10/200], Training Loss: 8.2061, Validation Loss Current: 5.5815, Validation Loss AVG: 11.0786, lr: 0.001
Epoch [11/200], Training Loss: 4.7919, Validation Loss Current: 5.7576, Validation Loss AVG: 11.5578, lr: 0.001
Epoch [12/200], Training Loss: 3.7191, Validation Loss Current: 6.3067, Validation Loss AVG: 15.8006, lr: 0.001
Epoch [13/200], Training Loss: 2.4153, Validation Loss Current: 5.6790, Validation Loss AVG: 12.1553, lr: 0.001
Epoch [14/200], Training Loss: 3.5716, Validation Loss Current: 5.3200, Validation Loss AVG: 11.3098, lr: 0.001
Epoch [15/200], Training Loss: 2.5154, Validation Loss Current: 6.1291, Validation Loss AVG: 13.0917, lr: 0.001
Epoch [16/200], Training Loss: 4.1442, Validation Loss Current: 6.6006, Validation Loss AVG: 13.6638, lr: 0.001
Epoch [17/200], Training Loss: 3.6691, Validation Loss Current: 9.2619, Validation Loss AVG: 17.4792, lr: 0.001
Epoch [18/200], Training Loss: 1.9055, Validation Loss Current: 5.9033, Validation Loss AVG: 11.8530, lr: 0.001
Epoch [19/200], Training Loss: 1.2637, Validation Loss Current: 5.7272, Validation Loss AVG: 11.5040, lr: 0.001
Epoch [20/200], Training Loss: 1.4052, Validation Loss Current: 6.1616, Validation Loss AVG: 12.4633, lr: 0.001
Epoch [21/200], Training Loss: 3.7667, Validation Loss Current: 6.3921, Validation Loss AVG: 13.0534, lr: 0.001
Epoch [22/200], Training Loss: 4.0823, Validation Loss Current: 7.7705, Validation Loss AVG: 12.6055, lr: 0.001
Epoch [23/200], Training Loss: 6.6850, Validation Loss Current: 8.7507, Validation Loss AVG: 19.0349, lr: 0.001
Epoch [24/200], Training Loss: 2.8603, Validation Loss Current: 7.6501, Validation Loss AVG: 13.2598, lr: 0.001
Epoch [25/200], Training Loss: 2.7242, Validation Loss Current: 6.4416, Validation Loss AVG: 12.7462, lr: 0.001
Epoch [26/200], Training Loss: 2.7240, Validation Loss Current: 6.7920, Validation Loss AVG: 13.5149, lr: 0.001
Epoch [27/200], Training Loss: 2.2357, Validation Loss Current: 7.9210, Validation Loss AVG: 14.8468, lr: 0.001
Epoch [28/200], Training Loss: 1.7957, Validation Loss Current: 6.3084, Validation Loss AVG: 13.4498, lr: 0.001
Epoch [29/200], Training Loss: 3.9671, Validation Loss Current: 6.4776, Validation Loss AVG: 12.8988, lr: 0.001
Epoch [30/200], Training Loss: 4.9820, Validation Loss Current: 7.1129, Validation Loss AVG: 13.5841, lr: 0.001
Epoch [31/200], Training Loss: 5.3749, Validation Loss Current: 10.4956, Validation Loss AVG: 18.4556, lr: 0.001
Epoch [32/200], Training Loss: 13.3104, Validation Loss Current: 9.9215, Validation Loss AVG: 14.4249, lr: 0.001
Epoch [33/200], Training Loss: 11.8972, Validation Loss Current: 8.4456, Validation Loss AVG: 12.6119, lr: 0.001
Epoch [34/200], Training Loss: 6.6320, Validation Loss Current: 8.0517, Validation Loss AVG: 12.2822, lr: 0.001
Epoch [35/200], Training Loss: 8.0921, Validation Loss Current: 7.4981, Validation Loss AVG: 13.5003, lr: 0.001
Epoch [36/200], Training Loss: 3.8506, Validation Loss Current: 6.9307, Validation Loss AVG: 14.6278, lr: 0.001
Epoch [37/200], Training Loss: 2.6261, Validation Loss Current: 7.8323, Validation Loss AVG: 16.3538, lr: 0.001
Epoch [38/200], Training Loss: 2.5747, Validation Loss Current: 6.9122, Validation Loss AVG: 12.5854, lr: 0.001
Epoch [39/200], Training Loss: 3.9585, Validation Loss Current: 8.0673, Validation Loss AVG: 16.3034, lr: 0.001
Epoch [40/200], Training Loss: 4.3575, Validation Loss Current: 8.6561, Validation Loss AVG: 17.9379, lr: 0.001
Epoch [41/200], Training Loss: 2.5745, Validation Loss Current: 7.9092, Validation Loss AVG: 15.7259, lr: 0.001
Epoch [42/200], Training Loss: 3.3383, Validation Loss Current: 7.3752, Validation Loss AVG: 16.4324, lr: 0.001
Epoch [43/200], Training Loss: 7.2720, Validation Loss Current: 8.2207, Validation Loss AVG: 13.9612, lr: 0.001
Epoch [44/200], Training Loss: 4.4468, Validation Loss Current: 8.7751, Validation Loss AVG: 17.8260, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 14 Best val accuracy: [0.6085526315789473, 0.6200657894736842, 0.5986842105263158, 0.6381578947368421, 0.6151315789473685, 0.6365131578947368, 0.6299342105263158, 0.5970394736842105, 0.6266447368421053, 0.6513157894736842, 0.6217105263157895, 0.6233552631578947, 0.6578947368421053, 0.680921052631579, 0.6546052631578947, 0.6266447368421053, 0.5625, 0.6480263157894737, 0.6759868421052632, 0.6529605263157895, 0.6611842105263158, 0.6200657894736842, 0.5592105263157895, 0.6134868421052632, 0.6266447368421053, 0.6299342105263158, 0.6134868421052632, 0.6447368421052632, 0.6578947368421053, 0.6299342105263158, 0.5427631578947368, 0.5460526315789473, 0.569078947368421, 0.5740131578947368, 0.5970394736842105, 0.6200657894736842, 0.6233552631578947, 0.6299342105263158, 0.5855263157894737, 0.5904605263157895, 0.5855263157894737, 0.6332236842105263, 0.59375, 0.5855263157894737] Best val loss: 5.320002555847168


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.3382, Validation Loss Current: 9.9738, Validation Loss AVG: 10.0640, lr: 0.001
Epoch [2/400], Training Loss: 39.4002, Validation Loss Current: 9.4113, Validation Loss AVG: 9.7543, lr: 0.001
Epoch [3/400], Training Loss: 37.1321, Validation Loss Current: 9.1286, Validation Loss AVG: 9.6648, lr: 0.001
Epoch [4/400], Training Loss: 35.0790, Validation Loss Current: 8.5904, Validation Loss AVG: 9.5399, lr: 0.001
Epoch [5/400], Training Loss: 33.8417, Validation Loss Current: 8.2107, Validation Loss AVG: 9.2643, lr: 0.001
Epoch [6/400], Training Loss: 32.1844, Validation Loss Current: 8.4450, Validation Loss AVG: 10.8009, lr: 0.001
Epoch [7/400], Training Loss: 30.0435, Validation Loss Current: 7.6338, Validation Loss AVG: 9.2467, lr: 0.001
Epoch [8/400], Training Loss: 28.9388, Validation Loss Current: 7.4693, Validation Loss AVG: 10.0073, lr: 0.001
Epoch [9/400], Training Loss: 28.5780, Validation Loss Current: 7.1433, Validation Loss AVG: 9.1152, lr: 0.001
Epoch [10/400], Training Loss: 26.7108, Validation Loss Current: 7.8860, Validation Loss AVG: 12.1292, lr: 0.001
Epoch [11/400], Training Loss: 26.5793, Validation Loss Current: 6.9956, Validation Loss AVG: 10.0987, lr: 0.001
Epoch [12/400], Training Loss: 26.2374, Validation Loss Current: 7.9338, Validation Loss AVG: 11.2255, lr: 0.001
Epoch [13/400], Training Loss: 25.5920, Validation Loss Current: 7.2745, Validation Loss AVG: 12.6982, lr: 0.001
Epoch [14/400], Training Loss: 24.6758, Validation Loss Current: 6.6515, Validation Loss AVG: 9.3674, lr: 0.001
Epoch [15/400], Training Loss: 23.6489, Validation Loss Current: 6.9524, Validation Loss AVG: 10.5632, lr: 0.001
Epoch [16/400], Training Loss: 22.4657, Validation Loss Current: 6.7235, Validation Loss AVG: 11.1358, lr: 0.001
Epoch [17/400], Training Loss: 21.6645, Validation Loss Current: 6.3462, Validation Loss AVG: 9.6233, lr: 0.001
Epoch [18/400], Training Loss: 20.2192, Validation Loss Current: 6.1681, Validation Loss AVG: 10.5431, lr: 0.001
Epoch [19/400], Training Loss: 20.3626, Validation Loss Current: 7.1080, Validation Loss AVG: 11.8290, lr: 0.001
Epoch [20/400], Training Loss: 21.4169, Validation Loss Current: 6.4535, Validation Loss AVG: 10.9559, lr: 0.001
Epoch [21/400], Training Loss: 20.9760, Validation Loss Current: 6.3455, Validation Loss AVG: 10.0408, lr: 0.001
Epoch [22/400], Training Loss: 20.8949, Validation Loss Current: 6.7531, Validation Loss AVG: 10.8476, lr: 0.001
Epoch [23/400], Training Loss: 19.6494, Validation Loss Current: 5.7906, Validation Loss AVG: 8.7415, lr: 0.001
Epoch [24/400], Training Loss: 18.3560, Validation Loss Current: 6.0813, Validation Loss AVG: 11.5656, lr: 0.001
Epoch [25/400], Training Loss: 18.5282, Validation Loss Current: 6.1340, Validation Loss AVG: 9.7581, lr: 0.001
Epoch [26/400], Training Loss: 17.7411, Validation Loss Current: 6.2589, Validation Loss AVG: 11.4156, lr: 0.001
Epoch [27/400], Training Loss: 16.9728, Validation Loss Current: 5.5221, Validation Loss AVG: 8.4311, lr: 0.001
Epoch [28/400], Training Loss: 16.0163, Validation Loss Current: 6.2774, Validation Loss AVG: 9.1255, lr: 0.001
Epoch [29/400], Training Loss: 16.0076, Validation Loss Current: 5.8831, Validation Loss AVG: 12.0491, lr: 0.001
Epoch [30/400], Training Loss: 16.0909, Validation Loss Current: 5.8120, Validation Loss AVG: 10.4087, lr: 0.001
Epoch [31/400], Training Loss: 14.3846, Validation Loss Current: 6.0990, Validation Loss AVG: 13.3234, lr: 0.001
Epoch [32/400], Training Loss: 14.3933, Validation Loss Current: 6.3670, Validation Loss AVG: 12.0484, lr: 0.001
Epoch [33/400], Training Loss: 12.6711, Validation Loss Current: 5.9576, Validation Loss AVG: 10.3474, lr: 0.001
Epoch [34/400], Training Loss: 11.8559, Validation Loss Current: 5.9372, Validation Loss AVG: 10.4306, lr: 0.001
Epoch [35/400], Training Loss: 11.9042, Validation Loss Current: 7.2239, Validation Loss AVG: 10.7331, lr: 0.001
Epoch [36/400], Training Loss: 10.5608, Validation Loss Current: 6.1245, Validation Loss AVG: 12.0564, lr: 0.001
Epoch [37/400], Training Loss: 10.8648, Validation Loss Current: 6.3670, Validation Loss AVG: 12.7551, lr: 0.001
Epoch [38/400], Training Loss: 12.8199, Validation Loss Current: 5.8096, Validation Loss AVG: 9.0937, lr: 0.001
Epoch [39/400], Training Loss: 10.3292, Validation Loss Current: 6.9389, Validation Loss AVG: 15.3468, lr: 0.001
Epoch [40/400], Training Loss: 8.9198, Validation Loss Current: 5.5624, Validation Loss AVG: 8.4746, lr: 0.001
Epoch [41/400], Training Loss: 7.4121, Validation Loss Current: 5.8268, Validation Loss AVG: 11.3347, lr: 0.001
Epoch [42/400], Training Loss: 9.5196, Validation Loss Current: 7.8188, Validation Loss AVG: 11.5286, lr: 0.001
Epoch [43/400], Training Loss: 8.2814, Validation Loss Current: 6.4825, Validation Loss AVG: 10.7036, lr: 0.001
Epoch [44/400], Training Loss: 8.1195, Validation Loss Current: 7.0671, Validation Loss AVG: 10.2531, lr: 0.001
Epoch [45/400], Training Loss: 7.9088, Validation Loss Current: 8.4256, Validation Loss AVG: 14.0978, lr: 0.001
Epoch [46/400], Training Loss: 12.5049, Validation Loss Current: 7.5690, Validation Loss AVG: 15.9180, lr: 0.001
Epoch [47/400], Training Loss: 10.2243, Validation Loss Current: 5.7228, Validation Loss AVG: 9.8237, lr: 0.001
Epoch [48/400], Training Loss: 8.5123, Validation Loss Current: 6.5618, Validation Loss AVG: 9.0248, lr: 0.001
Epoch [49/400], Training Loss: 11.5293, Validation Loss Current: 6.7312, Validation Loss AVG: 10.0513, lr: 0.001
Epoch [50/400], Training Loss: 8.3381, Validation Loss Current: 6.9719, Validation Loss AVG: 10.1341, lr: 0.001
Epoch [51/400], Training Loss: 11.5515, Validation Loss Current: 8.6473, Validation Loss AVG: 20.4426, lr: 0.001
Epoch [52/400], Training Loss: 8.4096, Validation Loss Current: 7.1527, Validation Loss AVG: 13.9612, lr: 0.001
Epoch [53/400], Training Loss: 6.9944, Validation Loss Current: 6.8609, Validation Loss AVG: 10.9412, lr: 0.001
Epoch [54/400], Training Loss: 8.0499, Validation Loss Current: 8.1495, Validation Loss AVG: 16.5386, lr: 0.001
Epoch [55/400], Training Loss: 4.6050, Validation Loss Current: 7.1816, Validation Loss AVG: 10.1558, lr: 0.001
Epoch [56/400], Training Loss: 4.1601, Validation Loss Current: 9.0821, Validation Loss AVG: 19.9746, lr: 0.001
Epoch [57/400], Training Loss: 6.9481, Validation Loss Current: 7.0797, Validation Loss AVG: 15.3236, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 27 Best val accuracy: [0.23848684210526316, 0.30098684210526316, 0.36019736842105265, 0.3930921052631579, 0.40789473684210525, 0.3684210526315789, 0.43914473684210525, 0.4473684210526316, 0.506578947368421, 0.44243421052631576, 0.5016447368421053, 0.4440789473684211, 0.4917763157894737, 0.53125, 0.5361842105263158, 0.5148026315789473, 0.5575657894736842, 0.5723684210526315, 0.5345394736842105, 0.555921052631579, 0.5592105263157895, 0.5049342105263158, 0.59375, 0.569078947368421, 0.5822368421052632, 0.5657894736842105, 0.6282894736842105, 0.5723684210526315, 0.5904605263157895, 0.6085526315789473, 0.5723684210526315, 0.5970394736842105, 0.5822368421052632, 0.6151315789473685, 0.5641447368421053, 0.6233552631578947, 0.5773026315789473, 0.6233552631578947, 0.5822368421052632, 0.6414473684210527, 0.6299342105263158, 0.5542763157894737, 0.5921052631578947, 0.5805921052631579, 0.5476973684210527, 0.5756578947368421, 0.6595394736842105, 0.59375, 0.6167763157894737, 0.5986842105263158, 0.5049342105263158, 0.5986842105263158, 0.6069078947368421, 0.5493421052631579, 0.6085526315789473, 0.555921052631579, 0.6101973684210527] Best val loss: 5.522083401679993


-------------------- All training done --------------------


 --- Evaluating ---
Fold: 0
---- Testing model trained on sequence: [0.2, 0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.19633307868601987
Test set distance: 0.8 Top 1 Accuracy: 0.533231474407945
Test set distance: 0.4 Top 1 Accuracy: 0.36440030557677616
Test set distance: 0.6 Top 1 Accuracy: 0.44385026737967914
Test set distance: 1 Top 1 Accuracy: 0.5584415584415584
---- Testing model trained on sequence: [0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18563789152024446
Test set distance: 0.8 Top 1 Accuracy: 0.5317035905271199
Test set distance: 0.4 Top 1 Accuracy: 0.3422459893048128
Test set distance: 0.6 Top 1 Accuracy: 0.4660045836516425
Test set distance: 1 Top 1 Accuracy: 0.5653170359052712
---- Testing model trained on sequence: [0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.13750954927425516
Test set distance: 0.8 Top 1 Accuracy: 0.5721925133689839
Test set distance: 0.4 Top 1 Accuracy: 0.33460656990068754
Test set distance: 0.6 Top 1 Accuracy: 0.4919786096256685
Test set distance: 1 Top 1 Accuracy: 0.6103896103896104
---- Testing model trained on sequence: [0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.16348357524828114
Test set distance: 0.8 Top 1 Accuracy: 0.5454545454545454
Test set distance: 0.4 Top 1 Accuracy: 0.2902979373567609
Test set distance: 0.6 Top 1 Accuracy: 0.41940412528647825
Test set distance: 1 Top 1 Accuracy: 0.6080977845683728
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1436210847975554
Test set distance: 0.8 Top 1 Accuracy: 0.5194805194805194
Test set distance: 0.4 Top 1 Accuracy: 0.22077922077922077
Test set distance: 0.6 Top 1 Accuracy: 0.387318563789152
Test set distance: 1 Top 1 Accuracy: 0.6027501909854851
Fold: 1
---- Testing model trained on sequence: [0.2, 0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18487394957983194
Test set distance: 0.8 Top 1 Accuracy: 0.5599694423223835
Test set distance: 0.4 Top 1 Accuracy: 0.24140565317035906
Test set distance: 0.6 Top 1 Accuracy: 0.4110007639419404
Test set distance: 1 Top 1 Accuracy: 0.6103896103896104
---- Testing model trained on sequence: [0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.16959511077158135
Test set distance: 0.8 Top 1 Accuracy: 0.5752482811306341
Test set distance: 0.4 Top 1 Accuracy: 0.3040488922841864
Test set distance: 0.6 Top 1 Accuracy: 0.48663101604278075
Test set distance: 1 Top 1 Accuracy: 0.586707410236822
---- Testing model trained on sequence: [0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1703590527119939
Test set distance: 0.8 Top 1 Accuracy: 0.440794499618029
Test set distance: 0.4 Top 1 Accuracy: 0.21695951107715813
Test set distance: 0.6 Top 1 Accuracy: 0.32620320855614976
Test set distance: 1 Top 1 Accuracy: 0.5057295645530939
---- Testing model trained on sequence: [0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.17188693659281895
Test set distance: 0.8 Top 1 Accuracy: 0.5851795263559969
Test set distance: 0.4 Top 1 Accuracy: 0.25439266615737205
Test set distance: 0.6 Top 1 Accuracy: 0.4346829640947288
Test set distance: 1 Top 1 Accuracy: 0.6096256684491979
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.16806722689075632
Test set distance: 0.8 Top 1 Accuracy: 0.46829640947288004
Test set distance: 0.4 Top 1 Accuracy: 0.29640947288006114
Test set distance: 0.6 Top 1 Accuracy: 0.4125286478227655
Test set distance: 1 Top 1 Accuracy: 0.5217723453017571
Fold: 2
---- Testing model trained on sequence: [0.2, 0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.0985485103132162
Test set distance: 0.8 Top 1 Accuracy: 0.5599694423223835
Test set distance: 0.4 Top 1 Accuracy: 0.2857142857142857
Test set distance: 0.6 Top 1 Accuracy: 0.4499618029029794
Test set distance: 1 Top 1 Accuracy: 0.6134453781512605
---- Testing model trained on sequence: [0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.11917494270435447
Test set distance: 0.8 Top 1 Accuracy: 0.5576776165011459
Test set distance: 0.4 Top 1 Accuracy: 0.29411764705882354
Test set distance: 0.6 Top 1 Accuracy: 0.479755538579068
Test set distance: 1 Top 1 Accuracy: 0.5912910618792971
---- Testing model trained on sequence: [0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.19098548510313215
Test set distance: 0.8 Top 1 Accuracy: 0.5584415584415584
Test set distance: 0.4 Top 1 Accuracy: 0.3139801375095493
Test set distance: 0.6 Top 1 Accuracy: 0.466768525592055
Test set distance: 1 Top 1 Accuracy: 0.5828877005347594
---- Testing model trained on sequence: [0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.07563025210084033
Test set distance: 0.8 Top 1 Accuracy: 0.5630252100840336
Test set distance: 0.4 Top 1 Accuracy: 0.3269671504965623
Test set distance: 0.6 Top 1 Accuracy: 0.47058823529411764
Test set distance: 1 Top 1 Accuracy: 0.5974025974025974
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1573720397249809
Test set distance: 0.8 Top 1 Accuracy: 0.5347593582887701
Test set distance: 0.4 Top 1 Accuracy: 0.23376623376623376
Test set distance: 0.6 Top 1 Accuracy: 0.40412528647822765
Test set distance: 1 Top 1 Accuracy: 0.599694423223835
Fold: 3
---- Testing model trained on sequence: [0.2, 0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.2077922077922078
Test set distance: 0.8 Top 1 Accuracy: 0.5492742551566081
Test set distance: 0.4 Top 1 Accuracy: 0.27043544690603516
Test set distance: 0.6 Top 1 Accuracy: 0.479755538579068
Test set distance: 1 Top 1 Accuracy: 0.6058059587471352
---- Testing model trained on sequence: [0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.17188693659281895
Test set distance: 0.8 Top 1 Accuracy: 0.5240641711229946
Test set distance: 0.4 Top 1 Accuracy: 0.26737967914438504
Test set distance: 0.6 Top 1 Accuracy: 0.43315508021390375
Test set distance: 1 Top 1 Accuracy: 0.5286478227654698
---- Testing model trained on sequence: [0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.16195569136745608
Test set distance: 0.8 Top 1 Accuracy: 0.5339954163483576
Test set distance: 0.4 Top 1 Accuracy: 0.3093964858670741
Test set distance: 0.6 Top 1 Accuracy: 0.48739495798319327
Test set distance: 1 Top 1 Accuracy: 0.5699006875477464
---- Testing model trained on sequence: [0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1436210847975554
Test set distance: 0.8 Top 1 Accuracy: 0.5622612681436211
Test set distance: 0.4 Top 1 Accuracy: 0.2215431627196333
Test set distance: 0.6 Top 1 Accuracy: 0.4094728800611154
Test set distance: 1 Top 1 Accuracy: 0.6035141329258976
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.13445378151260504
Test set distance: 0.8 Top 1 Accuracy: 0.5202444614209321
Test set distance: 0.4 Top 1 Accuracy: 0.2322383498854087
Test set distance: 0.6 Top 1 Accuracy: 0.40336134453781514
Test set distance: 1 Top 1 Accuracy: 0.5897631779984721
Fold: 4
---- Testing model trained on sequence: [0.2, 0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18716577540106952
Test set distance: 0.8 Top 1 Accuracy: 0.5569136745607334
Test set distance: 0.4 Top 1 Accuracy: 0.31321619556913677
Test set distance: 0.6 Top 1 Accuracy: 0.4637127578304049
Test set distance: 1 Top 1 Accuracy: 0.586707410236822
---- Testing model trained on sequence: [0.4, 0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.186401833460657
Test set distance: 0.8 Top 1 Accuracy: 0.5194805194805194
Test set distance: 0.4 Top 1 Accuracy: 0.2910618792971734
Test set distance: 0.6 Top 1 Accuracy: 0.4155844155844156
Test set distance: 1 Top 1 Accuracy: 0.5538579067990833
---- Testing model trained on sequence: [0.6, 0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18258212375859434
Test set distance: 0.8 Top 1 Accuracy: 0.5744843391902216
Test set distance: 0.4 Top 1 Accuracy: 0.33613445378151263
Test set distance: 0.6 Top 1 Accuracy: 0.4690603514132926
Test set distance: 1 Top 1 Accuracy: 0.6088617265087853
---- Testing model trained on sequence: [0.8, 1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1657754010695187
Test set distance: 0.8 Top 1 Accuracy: 0.5217723453017571
Test set distance: 0.4 Top 1 Accuracy: 0.2643239113827349
Test set distance: 0.6 Top 1 Accuracy: 0.40106951871657753
Test set distance: 1 Top 1 Accuracy: 0.5859434682964094
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1489686783804431
Test set distance: 0.8 Top 1 Accuracy: 0.5416348357524828
Test set distance: 0.4 Top 1 Accuracy: 0.22536287242169595
Test set distance: 0.6 Top 1 Accuracy: 0.4117647058823529
Test set distance: 1 Top 1 Accuracy: 0.5943468296409473
------------------------------ End ------------------------------


 # ------------------ Running pipeline on single color run_0 -------------------- #
cuda:0
 ------ Pipeline with following parameters ------
training_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/train
val_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/val
test_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/test
dataset_name :  VOC
target_distances :  [0.2, 0.8, 0.4, 0.6, 1]
training_mode :  single
n_distances :  None
training_size :  None
background :  color
size :  (150, 150)
cls_to_use :  ['aeroplane', 'bicycle', 'bird', 'boat', 'car', 'cat', 'train', 'tvmonitor']
batch_size :  128
val_size :  1
epochs :  400
resize_method :  long
n_folds :  5
num_workers :  16
model_name :  resnet18
device :  cuda:0
random_seed :  40
result_dirpath :  /u/erdos/students/xcui32/cnslab/results/VOC8R18BlackCUR
save_checkpoints :  False
save_progress_checkpoints :  False
verbose :  0
 ---  Loading datasets ---
 ---  Running  ---
Parameters: --------------------
{'scheduler_kwargs': {'mode': 'min', 'factor': 0.1, 'patience': 5}, 'optim_kwargs': {'lr': 0.001, 'momentum': 0.9}, 'max_norm': None, 'val_target': 'current', 'patience': 30, 'early_stopping': True, 'scheduler_object': None, 'optimizer_object': <class 'torch.optim.sgd.SGD'>, 'criterion_object': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'self': <pipelineCV2.RunModel object at 0x2aac786ee438>}
--------------------
Fold: 0
----- Training resnet18 with sequence: [0.2] -----
Current group: 0.2
Epoch [1/400], Training Loss: 40.5652, Validation Loss Current: 10.1138, Validation Loss AVG: 10.1138, lr: 0.001
Epoch [2/400], Training Loss: 38.9961, Validation Loss Current: 10.6296, Validation Loss AVG: 10.6296, lr: 0.001
Epoch [3/400], Training Loss: 38.6974, Validation Loss Current: 11.2699, Validation Loss AVG: 11.2699, lr: 0.001
Epoch [4/400], Training Loss: 38.1259, Validation Loss Current: 12.0258, Validation Loss AVG: 12.0258, lr: 0.001
Epoch [5/400], Training Loss: 37.7556, Validation Loss Current: 12.1150, Validation Loss AVG: 12.1150, lr: 0.001
Epoch [6/400], Training Loss: 36.7311, Validation Loss Current: 11.2892, Validation Loss AVG: 11.2892, lr: 0.001
Epoch [7/400], Training Loss: 36.1759, Validation Loss Current: 12.7921, Validation Loss AVG: 12.7921, lr: 0.001
Epoch [8/400], Training Loss: 35.0039, Validation Loss Current: 10.9911, Validation Loss AVG: 10.9911, lr: 0.001
Epoch [9/400], Training Loss: 34.4676, Validation Loss Current: 11.7167, Validation Loss AVG: 11.7167, lr: 0.001
Epoch [10/400], Training Loss: 33.6790, Validation Loss Current: 11.2409, Validation Loss AVG: 11.2409, lr: 0.001
Epoch [11/400], Training Loss: 32.6584, Validation Loss Current: 11.2607, Validation Loss AVG: 11.2607, lr: 0.001
Epoch [12/400], Training Loss: 31.2532, Validation Loss Current: 10.6263, Validation Loss AVG: 10.6263, lr: 0.001
Epoch [13/400], Training Loss: 30.9623, Validation Loss Current: 11.3222, Validation Loss AVG: 11.3222, lr: 0.001
Epoch [14/400], Training Loss: 29.6005, Validation Loss Current: 11.4878, Validation Loss AVG: 11.4878, lr: 0.001
Epoch [15/400], Training Loss: 28.7982, Validation Loss Current: 11.9917, Validation Loss AVG: 11.9917, lr: 0.001
Epoch [16/400], Training Loss: 28.1655, Validation Loss Current: 11.8922, Validation Loss AVG: 11.8922, lr: 0.001
Epoch [17/400], Training Loss: 27.2474, Validation Loss Current: 10.2770, Validation Loss AVG: 10.2770, lr: 0.001
Epoch [18/400], Training Loss: 26.5055, Validation Loss Current: 11.5333, Validation Loss AVG: 11.5333, lr: 0.001
Epoch [19/400], Training Loss: 25.4504, Validation Loss Current: 11.8464, Validation Loss AVG: 11.8464, lr: 0.001
Epoch [20/400], Training Loss: 24.7662, Validation Loss Current: 11.2978, Validation Loss AVG: 11.2978, lr: 0.001
Epoch [21/400], Training Loss: 24.5431, Validation Loss Current: 11.5648, Validation Loss AVG: 11.5648, lr: 0.001
Epoch [22/400], Training Loss: 23.2652, Validation Loss Current: 12.2324, Validation Loss AVG: 12.2324, lr: 0.001
Epoch [23/400], Training Loss: 22.8681, Validation Loss Current: 13.2732, Validation Loss AVG: 13.2732, lr: 0.001
Epoch [24/400], Training Loss: 22.4025, Validation Loss Current: 10.9376, Validation Loss AVG: 10.9376, lr: 0.001
Epoch [25/400], Training Loss: 21.3945, Validation Loss Current: 11.4052, Validation Loss AVG: 11.4052, lr: 0.001
Epoch [26/400], Training Loss: 20.6604, Validation Loss Current: 12.0627, Validation Loss AVG: 12.0627, lr: 0.001
Epoch [27/400], Training Loss: 20.0935, Validation Loss Current: 12.1877, Validation Loss AVG: 12.1877, lr: 0.001
Epoch [28/400], Training Loss: 18.7554, Validation Loss Current: 11.5046, Validation Loss AVG: 11.5046, lr: 0.001
Epoch [29/400], Training Loss: 17.1724, Validation Loss Current: 11.9730, Validation Loss AVG: 11.9730, lr: 0.001
Epoch [30/400], Training Loss: 16.0435, Validation Loss Current: 12.1885, Validation Loss AVG: 12.1885, lr: 0.001
Epoch [31/400], Training Loss: 14.3194, Validation Loss Current: 12.9762, Validation Loss AVG: 12.9762, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 1 Best val accuracy: [0.20032894736842105, 0.17796052631578946, 0.14901315789473685, 0.16677631578947366, 0.16480263157894737, 0.21447368421052632, 0.17434210526315788, 0.22796052631578947, 0.2036184210526316, 0.23092105263157894, 0.24703947368421053, 0.2845394736842105, 0.2549342105263158, 0.2799342105263158, 0.2644736842105263, 0.2539473684210526, 0.33519736842105263, 0.3256578947368421, 0.2930921052631579, 0.3490131578947368, 0.2743421052631579, 0.29342105263157897, 0.27894736842105267, 0.3694078947368421, 0.3651315789473684, 0.32006578947368425, 0.30526315789473685, 0.3473684210526316, 0.3585526315789474, 0.34309210526315786, 0.3638157894736842] Best val loss: 10.113801383972168


----- Training resnet18 with sequence: [0.8] -----
Current group: 0.8
Epoch [1/400], Training Loss: 40.3329, Validation Loss Current: 9.9359, Validation Loss AVG: 9.9359, lr: 0.001
Epoch [2/400], Training Loss: 38.8607, Validation Loss Current: 9.7629, Validation Loss AVG: 9.7629, lr: 0.001
Epoch [3/400], Training Loss: 37.5007, Validation Loss Current: 9.4992, Validation Loss AVG: 9.4992, lr: 0.001
Epoch [4/400], Training Loss: 35.9855, Validation Loss Current: 9.4390, Validation Loss AVG: 9.4390, lr: 0.001
Epoch [5/400], Training Loss: 35.0379, Validation Loss Current: 9.3022, Validation Loss AVG: 9.3022, lr: 0.001
Epoch [6/400], Training Loss: 34.0728, Validation Loss Current: 9.5319, Validation Loss AVG: 9.5319, lr: 0.001
Epoch [7/400], Training Loss: 33.4374, Validation Loss Current: 9.1942, Validation Loss AVG: 9.1942, lr: 0.001
Epoch [8/400], Training Loss: 31.3356, Validation Loss Current: 9.2022, Validation Loss AVG: 9.2022, lr: 0.001
Epoch [9/400], Training Loss: 30.6608, Validation Loss Current: 9.1064, Validation Loss AVG: 9.1064, lr: 0.001
Epoch [10/400], Training Loss: 29.9177, Validation Loss Current: 8.8515, Validation Loss AVG: 8.8515, lr: 0.001
Epoch [11/400], Training Loss: 29.0008, Validation Loss Current: 10.0862, Validation Loss AVG: 10.0862, lr: 0.001
Epoch [12/400], Training Loss: 27.6733, Validation Loss Current: 8.8446, Validation Loss AVG: 8.8446, lr: 0.001
Epoch [13/400], Training Loss: 27.7665, Validation Loss Current: 8.4452, Validation Loss AVG: 8.4452, lr: 0.001
Epoch [14/400], Training Loss: 25.9476, Validation Loss Current: 8.9400, Validation Loss AVG: 8.9400, lr: 0.001
Epoch [15/400], Training Loss: 25.3122, Validation Loss Current: 8.0827, Validation Loss AVG: 8.0827, lr: 0.001
Epoch [16/400], Training Loss: 24.4317, Validation Loss Current: 8.2625, Validation Loss AVG: 8.2625, lr: 0.001
Epoch [17/400], Training Loss: 24.2467, Validation Loss Current: 8.2089, Validation Loss AVG: 8.2089, lr: 0.001
Epoch [18/400], Training Loss: 23.9115, Validation Loss Current: 8.0461, Validation Loss AVG: 8.0461, lr: 0.001
Epoch [19/400], Training Loss: 24.0074, Validation Loss Current: 8.6932, Validation Loss AVG: 8.6932, lr: 0.001
Epoch [20/400], Training Loss: 22.7601, Validation Loss Current: 8.4684, Validation Loss AVG: 8.4684, lr: 0.001
Epoch [21/400], Training Loss: 21.9010, Validation Loss Current: 8.3604, Validation Loss AVG: 8.3604, lr: 0.001
Epoch [22/400], Training Loss: 21.3870, Validation Loss Current: 8.6357, Validation Loss AVG: 8.6357, lr: 0.001
Epoch [23/400], Training Loss: 20.4889, Validation Loss Current: 8.7543, Validation Loss AVG: 8.7543, lr: 0.001
Epoch [24/400], Training Loss: 20.6050, Validation Loss Current: 8.6048, Validation Loss AVG: 8.6048, lr: 0.001
Epoch [25/400], Training Loss: 20.7100, Validation Loss Current: 8.6745, Validation Loss AVG: 8.6745, lr: 0.001
Epoch [26/400], Training Loss: 18.5134, Validation Loss Current: 7.9810, Validation Loss AVG: 7.9810, lr: 0.001
Epoch [27/400], Training Loss: 17.2286, Validation Loss Current: 11.7262, Validation Loss AVG: 11.7262, lr: 0.001
Epoch [28/400], Training Loss: 16.1417, Validation Loss Current: 9.2267, Validation Loss AVG: 9.2267, lr: 0.001
Epoch [29/400], Training Loss: 15.6700, Validation Loss Current: 8.7854, Validation Loss AVG: 8.7854, lr: 0.001
Epoch [30/400], Training Loss: 15.9060, Validation Loss Current: 9.9009, Validation Loss AVG: 9.9009, lr: 0.001
Epoch [31/400], Training Loss: 15.2878, Validation Loss Current: 10.8225, Validation Loss AVG: 10.8225, lr: 0.001
Epoch [32/400], Training Loss: 16.4027, Validation Loss Current: 8.8824, Validation Loss AVG: 8.8824, lr: 0.001
Epoch [33/400], Training Loss: 14.0237, Validation Loss Current: 7.5775, Validation Loss AVG: 7.5775, lr: 0.001
Epoch [34/400], Training Loss: 11.9002, Validation Loss Current: 8.5124, Validation Loss AVG: 8.5124, lr: 0.001
Epoch [35/400], Training Loss: 11.3583, Validation Loss Current: 9.7077, Validation Loss AVG: 9.7077, lr: 0.001
Epoch [36/400], Training Loss: 11.6137, Validation Loss Current: 8.8484, Validation Loss AVG: 8.8484, lr: 0.001
Epoch [37/400], Training Loss: 13.1225, Validation Loss Current: 9.2756, Validation Loss AVG: 9.2756, lr: 0.001
Epoch [38/400], Training Loss: 12.0133, Validation Loss Current: 8.3057, Validation Loss AVG: 8.3057, lr: 0.001
Epoch [39/400], Training Loss: 10.7061, Validation Loss Current: 8.9072, Validation Loss AVG: 8.9072, lr: 0.001
Epoch [40/400], Training Loss: 8.5475, Validation Loss Current: 9.4247, Validation Loss AVG: 9.4247, lr: 0.001
Epoch [41/400], Training Loss: 7.4648, Validation Loss Current: 8.9127, Validation Loss AVG: 8.9127, lr: 0.001
Epoch [42/400], Training Loss: 7.0097, Validation Loss Current: 10.9103, Validation Loss AVG: 10.9103, lr: 0.001
Epoch [43/400], Training Loss: 8.5879, Validation Loss Current: 11.4650, Validation Loss AVG: 11.4650, lr: 0.001
Epoch [44/400], Training Loss: 9.2824, Validation Loss Current: 13.5439, Validation Loss AVG: 13.5439, lr: 0.001
Epoch [45/400], Training Loss: 15.7557, Validation Loss Current: 9.2152, Validation Loss AVG: 9.2152, lr: 0.001
Epoch [46/400], Training Loss: 12.7471, Validation Loss Current: 8.7995, Validation Loss AVG: 8.7995, lr: 0.001
Epoch [47/400], Training Loss: 8.2419, Validation Loss Current: 8.6022, Validation Loss AVG: 8.6022, lr: 0.001
Epoch [48/400], Training Loss: 7.4056, Validation Loss Current: 8.8275, Validation Loss AVG: 8.8275, lr: 0.001
Epoch [49/400], Training Loss: 9.1076, Validation Loss Current: 9.9799, Validation Loss AVG: 9.9799, lr: 0.001
Epoch [50/400], Training Loss: 6.7055, Validation Loss Current: 9.0246, Validation Loss AVG: 9.0246, lr: 0.001
Epoch [51/400], Training Loss: 7.3516, Validation Loss Current: 12.2025, Validation Loss AVG: 12.2025, lr: 0.001
Epoch [52/400], Training Loss: 7.6175, Validation Loss Current: 8.8345, Validation Loss AVG: 8.8345, lr: 0.001
Epoch [53/400], Training Loss: 8.7318, Validation Loss Current: 11.6042, Validation Loss AVG: 11.6042, lr: 0.001
Epoch [54/400], Training Loss: 6.6931, Validation Loss Current: 12.0423, Validation Loss AVG: 12.0423, lr: 0.001
Epoch [55/400], Training Loss: 4.5361, Validation Loss Current: 8.5867, Validation Loss AVG: 8.5867, lr: 0.001
Epoch [56/400], Training Loss: 5.5156, Validation Loss Current: 12.2701, Validation Loss AVG: 12.2701, lr: 0.001
Epoch [57/400], Training Loss: 5.5142, Validation Loss Current: 9.7163, Validation Loss AVG: 9.7163, lr: 0.001
Epoch [58/400], Training Loss: 4.4961, Validation Loss Current: 10.1946, Validation Loss AVG: 10.1946, lr: 0.001
Epoch [59/400], Training Loss: 3.8076, Validation Loss Current: 10.2311, Validation Loss AVG: 10.2311, lr: 0.001
Epoch [60/400], Training Loss: 6.6689, Validation Loss Current: 12.0251, Validation Loss AVG: 12.0251, lr: 0.001
Epoch [61/400], Training Loss: 3.6611, Validation Loss Current: 9.7999, Validation Loss AVG: 9.7999, lr: 0.001
Epoch [62/400], Training Loss: 4.4131, Validation Loss Current: 10.3512, Validation Loss AVG: 10.3512, lr: 0.001
Epoch [63/400], Training Loss: 3.2636, Validation Loss Current: 11.8607, Validation Loss AVG: 11.8607, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 33 Best val accuracy: [0.22631578947368425, 0.27269736842105263, 0.28289473684210525, 0.27269736842105263, 0.30164473684210524, 0.2957236842105263, 0.31282894736842104, 0.35723684210526313, 0.33453947368421055, 0.37434210526315786, 0.3355263157894737, 0.37927631578947374, 0.3986842105263158, 0.39440789473684207, 0.41907894736842105, 0.38848684210526313, 0.4240131578947368, 0.4240131578947369, 0.36249999999999993, 0.4582236842105264, 0.4509868421052632, 0.41381578947368425, 0.41743421052631585, 0.4217105263157895, 0.4220394736842105, 0.43519736842105267, 0.41118421052631576, 0.4052631578947368, 0.41118421052631576, 0.4141447368421053, 0.40756578947368427, 0.4296052631578947, 0.4532894736842105, 0.4552631578947368, 0.42302631578947364, 0.4565789473684211, 0.4233552631578947, 0.44868421052631574, 0.4618421052631579, 0.4483552631578947, 0.4335526315789474, 0.4309210526315789, 0.3759868421052632, 0.35230263157894737, 0.4197368421052632, 0.4164473684210527, 0.43717105263157896, 0.42796052631578946, 0.43355263157894736, 0.45230263157894735, 0.39013157894736844, 0.44539473684210523, 0.4088815789473685, 0.39473684210526316, 0.4542763157894737, 0.4269736842105263, 0.4197368421052632, 0.43782894736842104, 0.4384868421052632, 0.36907894736842106, 0.44868421052631585, 0.4289473684210526, 0.43782894736842104] Best val loss: 7.577546787261963


----- Training resnet18 with sequence: [0.4] -----
Current group: 0.4
Epoch [1/400], Training Loss: 41.6855, Validation Loss Current: 10.0262, Validation Loss AVG: 10.0262, lr: 0.001
Epoch [2/400], Training Loss: 40.4185, Validation Loss Current: 10.1807, Validation Loss AVG: 10.1807, lr: 0.001
Epoch [3/400], Training Loss: 38.9697, Validation Loss Current: 9.9484, Validation Loss AVG: 9.9484, lr: 0.001
Epoch [4/400], Training Loss: 38.4295, Validation Loss Current: 9.8188, Validation Loss AVG: 9.8188, lr: 0.001
Epoch [5/400], Training Loss: 37.7310, Validation Loss Current: 9.5515, Validation Loss AVG: 9.5515, lr: 0.001
Epoch [6/400], Training Loss: 36.3678, Validation Loss Current: 9.3081, Validation Loss AVG: 9.3081, lr: 0.001
Epoch [7/400], Training Loss: 35.1824, Validation Loss Current: 9.1536, Validation Loss AVG: 9.1536, lr: 0.001
Epoch [8/400], Training Loss: 34.5915, Validation Loss Current: 9.2059, Validation Loss AVG: 9.2059, lr: 0.001
Epoch [9/400], Training Loss: 33.1683, Validation Loss Current: 9.2279, Validation Loss AVG: 9.2279, lr: 0.001
Epoch [10/400], Training Loss: 32.9120, Validation Loss Current: 9.1906, Validation Loss AVG: 9.1906, lr: 0.001
Epoch [11/400], Training Loss: 31.0739, Validation Loss Current: 8.9472, Validation Loss AVG: 8.9472, lr: 0.001
Epoch [12/400], Training Loss: 30.5857, Validation Loss Current: 8.8270, Validation Loss AVG: 8.8270, lr: 0.001
Epoch [13/400], Training Loss: 29.9635, Validation Loss Current: 8.7951, Validation Loss AVG: 8.7951, lr: 0.001
Epoch [14/400], Training Loss: 29.5599, Validation Loss Current: 9.1457, Validation Loss AVG: 9.1457, lr: 0.001
Epoch [15/400], Training Loss: 28.7291, Validation Loss Current: 9.4746, Validation Loss AVG: 9.4746, lr: 0.001
Epoch [16/400], Training Loss: 28.7749, Validation Loss Current: 9.0953, Validation Loss AVG: 9.0953, lr: 0.001
Epoch [17/400], Training Loss: 28.4381, Validation Loss Current: 8.6171, Validation Loss AVG: 8.6171, lr: 0.001
Epoch [18/400], Training Loss: 26.8871, Validation Loss Current: 8.8000, Validation Loss AVG: 8.8000, lr: 0.001
Epoch [19/400], Training Loss: 26.4260, Validation Loss Current: 8.5048, Validation Loss AVG: 8.5048, lr: 0.001
Epoch [20/400], Training Loss: 25.8199, Validation Loss Current: 8.0846, Validation Loss AVG: 8.0846, lr: 0.001
Epoch [21/400], Training Loss: 25.0345, Validation Loss Current: 8.1981, Validation Loss AVG: 8.1981, lr: 0.001
Epoch [22/400], Training Loss: 24.2926, Validation Loss Current: 8.4164, Validation Loss AVG: 8.4164, lr: 0.001
Epoch [23/400], Training Loss: 23.4774, Validation Loss Current: 8.0909, Validation Loss AVG: 8.0909, lr: 0.001
Epoch [24/400], Training Loss: 22.7880, Validation Loss Current: 8.0001, Validation Loss AVG: 8.0001, lr: 0.001
Epoch [25/400], Training Loss: 22.1848, Validation Loss Current: 8.5485, Validation Loss AVG: 8.5485, lr: 0.001
Epoch [26/400], Training Loss: 21.9547, Validation Loss Current: 8.0257, Validation Loss AVG: 8.0257, lr: 0.001
Epoch [27/400], Training Loss: 20.6426, Validation Loss Current: 8.9340, Validation Loss AVG: 8.9340, lr: 0.001
Epoch [28/400], Training Loss: 21.7181, Validation Loss Current: 9.1657, Validation Loss AVG: 9.1657, lr: 0.001
Epoch [29/400], Training Loss: 20.1156, Validation Loss Current: 7.9935, Validation Loss AVG: 7.9935, lr: 0.001
Epoch [30/400], Training Loss: 18.8305, Validation Loss Current: 8.3332, Validation Loss AVG: 8.3332, lr: 0.001
Epoch [31/400], Training Loss: 18.7438, Validation Loss Current: 8.2251, Validation Loss AVG: 8.2251, lr: 0.001
Epoch [32/400], Training Loss: 17.1865, Validation Loss Current: 8.6953, Validation Loss AVG: 8.6953, lr: 0.001
Epoch [33/400], Training Loss: 16.7070, Validation Loss Current: 8.5313, Validation Loss AVG: 8.5313, lr: 0.001
Epoch [34/400], Training Loss: 15.5727, Validation Loss Current: 8.1590, Validation Loss AVG: 8.1590, lr: 0.001
Epoch [35/400], Training Loss: 14.3190, Validation Loss Current: 10.2279, Validation Loss AVG: 10.2279, lr: 0.001
Epoch [36/400], Training Loss: 13.8274, Validation Loss Current: 9.4345, Validation Loss AVG: 9.4345, lr: 0.001
Epoch [37/400], Training Loss: 12.4331, Validation Loss Current: 8.7819, Validation Loss AVG: 8.7819, lr: 0.001
Epoch [38/400], Training Loss: 12.1857, Validation Loss Current: 10.1446, Validation Loss AVG: 10.1446, lr: 0.001
Epoch [39/400], Training Loss: 12.7209, Validation Loss Current: 13.4727, Validation Loss AVG: 13.4727, lr: 0.001
Epoch [40/400], Training Loss: 16.8978, Validation Loss Current: 12.0922, Validation Loss AVG: 12.0922, lr: 0.001
Epoch [41/400], Training Loss: 12.2800, Validation Loss Current: 9.8143, Validation Loss AVG: 9.8143, lr: 0.001
Epoch [42/400], Training Loss: 9.7994, Validation Loss Current: 9.4040, Validation Loss AVG: 9.4040, lr: 0.001
Epoch [43/400], Training Loss: 8.7250, Validation Loss Current: 9.2002, Validation Loss AVG: 9.2002, lr: 0.001
Epoch [44/400], Training Loss: 9.5525, Validation Loss Current: 10.6053, Validation Loss AVG: 10.6053, lr: 0.001
Epoch [45/400], Training Loss: 9.8967, Validation Loss Current: 13.5374, Validation Loss AVG: 13.5374, lr: 0.001
Epoch [46/400], Training Loss: 15.0383, Validation Loss Current: 14.1555, Validation Loss AVG: 14.1555, lr: 0.001
Epoch [47/400], Training Loss: 9.6099, Validation Loss Current: 10.6505, Validation Loss AVG: 10.6505, lr: 0.001
Epoch [48/400], Training Loss: 7.6020, Validation Loss Current: 9.5356, Validation Loss AVG: 9.5356, lr: 0.001
Epoch [49/400], Training Loss: 7.2024, Validation Loss Current: 9.9499, Validation Loss AVG: 9.9499, lr: 0.001
Epoch [50/400], Training Loss: 10.4434, Validation Loss Current: 12.9326, Validation Loss AVG: 12.9326, lr: 0.001
Epoch [51/400], Training Loss: 7.2028, Validation Loss Current: 13.0583, Validation Loss AVG: 13.0583, lr: 0.001
Epoch [52/400], Training Loss: 8.4500, Validation Loss Current: 10.5122, Validation Loss AVG: 10.5122, lr: 0.001
Epoch [53/400], Training Loss: 7.2735, Validation Loss Current: 11.6503, Validation Loss AVG: 11.6503, lr: 0.001
Epoch [54/400], Training Loss: 11.1798, Validation Loss Current: 13.4197, Validation Loss AVG: 13.4197, lr: 0.001
Epoch [55/400], Training Loss: 9.6385, Validation Loss Current: 11.1398, Validation Loss AVG: 11.1398, lr: 0.001
Epoch [56/400], Training Loss: 7.0097, Validation Loss Current: 11.0602, Validation Loss AVG: 11.0602, lr: 0.001
Epoch [57/400], Training Loss: 7.3408, Validation Loss Current: 10.5938, Validation Loss AVG: 10.5938, lr: 0.001
Epoch [58/400], Training Loss: 5.8503, Validation Loss Current: 12.0146, Validation Loss AVG: 12.0146, lr: 0.001
Epoch [59/400], Training Loss: 4.6389, Validation Loss Current: 11.0229, Validation Loss AVG: 11.0229, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 29 Best val accuracy: [0.22401315789473686, 0.23355263157894735, 0.2299342105263158, 0.2532894736842105, 0.26184210526315793, 0.31546052631578947, 0.31710526315789467, 0.29736842105263156, 0.3246710526315789, 0.2973684210526316, 0.3427631578947368, 0.3490131578947368, 0.3697368421052632, 0.3256578947368421, 0.36085526315789473, 0.3598684210526316, 0.3575657894736842, 0.3786184210526316, 0.38585526315789476, 0.42598684210526316, 0.4342105263157895, 0.3950657894736842, 0.4358552631578948, 0.4276315789473684, 0.3759868421052631, 0.44177631578947374, 0.4305921052631579, 0.3759868421052631, 0.44342105263157894, 0.42598684210526316, 0.4203947368421052, 0.425, 0.4203947368421053, 0.43815789473684214, 0.40361842105263157, 0.3894736842105263, 0.4305921052631579, 0.3717105263157895, 0.34342105263157896, 0.3286184210526316, 0.3805921052631579, 0.40855263157894744, 0.44572368421052627, 0.3993421052631579, 0.3473684210526316, 0.31809210526315795, 0.40625, 0.3963815789473684, 0.40592105263157896, 0.38881578947368417, 0.31282894736842104, 0.39769736842105263, 0.3447368421052632, 0.37664473684210525, 0.3980263157894737, 0.40690789473684214, 0.3615131578947369, 0.37730263157894733, 0.38585526315789476] Best val loss: 7.993532705307007


----- Training resnet18 with sequence: [0.6] -----
Current group: 0.6
Epoch [1/400], Training Loss: 42.4695, Validation Loss Current: 10.0534, Validation Loss AVG: 10.0534, lr: 0.001
Epoch [2/400], Training Loss: 40.1686, Validation Loss Current: 10.0216, Validation Loss AVG: 10.0216, lr: 0.001
Epoch [3/400], Training Loss: 39.9715, Validation Loss Current: 9.8259, Validation Loss AVG: 9.8259, lr: 0.001
Epoch [4/400], Training Loss: 38.7398, Validation Loss Current: 9.6742, Validation Loss AVG: 9.6742, lr: 0.001
Epoch [5/400], Training Loss: 37.6966, Validation Loss Current: 9.5505, Validation Loss AVG: 9.5505, lr: 0.001
Epoch [6/400], Training Loss: 36.3287, Validation Loss Current: 9.3216, Validation Loss AVG: 9.3216, lr: 0.001
Epoch [7/400], Training Loss: 36.2272, Validation Loss Current: 9.3905, Validation Loss AVG: 9.3905, lr: 0.001
Epoch [8/400], Training Loss: 34.2651, Validation Loss Current: 9.0577, Validation Loss AVG: 9.0577, lr: 0.001
Epoch [9/400], Training Loss: 33.9707, Validation Loss Current: 8.8278, Validation Loss AVG: 8.8278, lr: 0.001
Epoch [10/400], Training Loss: 32.8349, Validation Loss Current: 8.5665, Validation Loss AVG: 8.5665, lr: 0.001
Epoch [11/400], Training Loss: 29.9317, Validation Loss Current: 8.5005, Validation Loss AVG: 8.5005, lr: 0.001
Epoch [12/400], Training Loss: 29.5551, Validation Loss Current: 8.6529, Validation Loss AVG: 8.6529, lr: 0.001
Epoch [13/400], Training Loss: 30.4516, Validation Loss Current: 8.3635, Validation Loss AVG: 8.3635, lr: 0.001
Epoch [14/400], Training Loss: 27.9065, Validation Loss Current: 8.2786, Validation Loss AVG: 8.2786, lr: 0.001
Epoch [15/400], Training Loss: 28.2949, Validation Loss Current: 8.2077, Validation Loss AVG: 8.2077, lr: 0.001
Epoch [16/400], Training Loss: 27.3222, Validation Loss Current: 8.0799, Validation Loss AVG: 8.0799, lr: 0.001
Epoch [17/400], Training Loss: 27.5163, Validation Loss Current: 8.2714, Validation Loss AVG: 8.2714, lr: 0.001
Epoch [18/400], Training Loss: 27.3400, Validation Loss Current: 8.8755, Validation Loss AVG: 8.8755, lr: 0.001
Epoch [19/400], Training Loss: 26.0550, Validation Loss Current: 7.8402, Validation Loss AVG: 7.8402, lr: 0.001
Epoch [20/400], Training Loss: 26.3870, Validation Loss Current: 8.2149, Validation Loss AVG: 8.2149, lr: 0.001
Epoch [21/400], Training Loss: 24.6295, Validation Loss Current: 8.4167, Validation Loss AVG: 8.4167, lr: 0.001
Epoch [22/400], Training Loss: 23.3061, Validation Loss Current: 7.7369, Validation Loss AVG: 7.7369, lr: 0.001
Epoch [23/400], Training Loss: 23.7115, Validation Loss Current: 7.9552, Validation Loss AVG: 7.9552, lr: 0.001
Epoch [24/400], Training Loss: 23.7139, Validation Loss Current: 7.6558, Validation Loss AVG: 7.6558, lr: 0.001
Epoch [25/400], Training Loss: 21.8837, Validation Loss Current: 7.8676, Validation Loss AVG: 7.8676, lr: 0.001
Epoch [26/400], Training Loss: 20.6148, Validation Loss Current: 8.2858, Validation Loss AVG: 8.2858, lr: 0.001
Epoch [27/400], Training Loss: 20.0636, Validation Loss Current: 8.2240, Validation Loss AVG: 8.2240, lr: 0.001
Epoch [28/400], Training Loss: 19.5892, Validation Loss Current: 8.9679, Validation Loss AVG: 8.9679, lr: 0.001
Epoch [29/400], Training Loss: 19.6836, Validation Loss Current: 8.0495, Validation Loss AVG: 8.0495, lr: 0.001
Epoch [30/400], Training Loss: 20.3772, Validation Loss Current: 7.7501, Validation Loss AVG: 7.7501, lr: 0.001
Epoch [31/400], Training Loss: 19.3561, Validation Loss Current: 8.6613, Validation Loss AVG: 8.6613, lr: 0.001
Epoch [32/400], Training Loss: 17.6500, Validation Loss Current: 8.0109, Validation Loss AVG: 8.0109, lr: 0.001
Epoch [33/400], Training Loss: 16.6865, Validation Loss Current: 7.7049, Validation Loss AVG: 7.7049, lr: 0.001
Epoch [34/400], Training Loss: 15.5134, Validation Loss Current: 7.7892, Validation Loss AVG: 7.7892, lr: 0.001
Epoch [35/400], Training Loss: 15.6203, Validation Loss Current: 8.6196, Validation Loss AVG: 8.6196, lr: 0.001
Epoch [36/400], Training Loss: 14.7195, Validation Loss Current: 8.3002, Validation Loss AVG: 8.3002, lr: 0.001
Epoch [37/400], Training Loss: 13.7144, Validation Loss Current: 8.1695, Validation Loss AVG: 8.1695, lr: 0.001
Epoch [38/400], Training Loss: 12.8650, Validation Loss Current: 8.8409, Validation Loss AVG: 8.8409, lr: 0.001
Epoch [39/400], Training Loss: 12.9801, Validation Loss Current: 8.3191, Validation Loss AVG: 8.3191, lr: 0.001
Epoch [40/400], Training Loss: 11.3453, Validation Loss Current: 7.8648, Validation Loss AVG: 7.8648, lr: 0.001
Epoch [41/400], Training Loss: 10.3294, Validation Loss Current: 9.8091, Validation Loss AVG: 9.8091, lr: 0.001
Epoch [42/400], Training Loss: 10.7321, Validation Loss Current: 9.4353, Validation Loss AVG: 9.4353, lr: 0.001
Epoch [43/400], Training Loss: 9.7963, Validation Loss Current: 8.2944, Validation Loss AVG: 8.2944, lr: 0.001
Epoch [44/400], Training Loss: 7.8967, Validation Loss Current: 8.8470, Validation Loss AVG: 8.8470, lr: 0.001
Epoch [45/400], Training Loss: 10.4370, Validation Loss Current: 9.2597, Validation Loss AVG: 9.2597, lr: 0.001
Epoch [46/400], Training Loss: 8.2124, Validation Loss Current: 9.3868, Validation Loss AVG: 9.3868, lr: 0.001
Epoch [47/400], Training Loss: 8.9137, Validation Loss Current: 9.3073, Validation Loss AVG: 9.3073, lr: 0.001
Epoch [48/400], Training Loss: 7.9213, Validation Loss Current: 8.9761, Validation Loss AVG: 8.9761, lr: 0.001
Epoch [49/400], Training Loss: 6.4311, Validation Loss Current: 9.6218, Validation Loss AVG: 9.6218, lr: 0.001
Epoch [50/400], Training Loss: 8.5170, Validation Loss Current: 9.1448, Validation Loss AVG: 9.1448, lr: 0.001
Epoch [51/400], Training Loss: 5.9571, Validation Loss Current: 8.8687, Validation Loss AVG: 8.8687, lr: 0.001
Epoch [52/400], Training Loss: 4.5691, Validation Loss Current: 10.7764, Validation Loss AVG: 10.7764, lr: 0.001
Epoch [53/400], Training Loss: 7.2861, Validation Loss Current: 11.9176, Validation Loss AVG: 11.9176, lr: 0.001
Epoch [54/400], Training Loss: 8.3383, Validation Loss Current: 10.6144, Validation Loss AVG: 10.6144, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 24 Best val accuracy: [0.2276315789473684, 0.23618421052631575, 0.2542763157894737, 0.27664473684210533, 0.2986842105263158, 0.3200657894736842, 0.29769736842105265, 0.3328947368421053, 0.35986842105263156, 0.38322368421052627, 0.38092105263157894, 0.36743421052631586, 0.3983552631578947, 0.425, 0.4180921052631579, 0.4256578947368421, 0.41052631578947374, 0.4072368421052632, 0.4460526315789474, 0.42894736842105263, 0.40657894736842104, 0.44506578947368425, 0.4394736842105263, 0.45065789473684215, 0.4572368421052631, 0.39868421052631575, 0.4463815789473685, 0.4006578947368421, 0.45756578947368426, 0.4546052631578948, 0.4358552631578948, 0.4414473684210526, 0.45394736842105254, 0.47828947368421054, 0.4180921052631579, 0.4532894736842105, 0.43157894736842106, 0.44177631578947374, 0.44243421052631576, 0.4578947368421053, 0.3963815789473685, 0.4453947368421053, 0.45953947368421055, 0.44177631578947363, 0.4305921052631579, 0.4151315789473685, 0.44868421052631574, 0.4296052631578947, 0.46743421052631584, 0.4509868421052631, 0.4516447368421052, 0.4463815789473684, 0.3661184210526316, 0.4496710526315789] Best val loss: 7.655794215202332


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.2991, Validation Loss Current: 9.9473, Validation Loss AVG: 10.0334, lr: 0.001
Epoch [2/400], Training Loss: 38.7606, Validation Loss Current: 9.6177, Validation Loss AVG: 9.9886, lr: 0.001
Epoch [3/400], Training Loss: 36.4492, Validation Loss Current: 9.4504, Validation Loss AVG: 9.8342, lr: 0.001
Epoch [4/400], Training Loss: 36.1041, Validation Loss Current: 8.9148, Validation Loss AVG: 9.5435, lr: 0.001
Epoch [5/400], Training Loss: 35.1631, Validation Loss Current: 8.6887, Validation Loss AVG: 9.9720, lr: 0.001
Epoch [6/400], Training Loss: 33.7482, Validation Loss Current: 8.6337, Validation Loss AVG: 9.5016, lr: 0.001
Epoch [7/400], Training Loss: 31.5974, Validation Loss Current: 8.1869, Validation Loss AVG: 9.0396, lr: 0.001
Epoch [8/400], Training Loss: 31.1548, Validation Loss Current: 8.0562, Validation Loss AVG: 8.9434, lr: 0.001
Epoch [9/400], Training Loss: 29.7858, Validation Loss Current: 7.6811, Validation Loss AVG: 10.1685, lr: 0.001
Epoch [10/400], Training Loss: 28.6930, Validation Loss Current: 7.5778, Validation Loss AVG: 10.2232, lr: 0.001
Epoch [11/400], Training Loss: 28.8548, Validation Loss Current: 7.4582, Validation Loss AVG: 8.8490, lr: 0.001
Epoch [12/400], Training Loss: 27.8656, Validation Loss Current: 7.2913, Validation Loss AVG: 10.2356, lr: 0.001
Epoch [13/400], Training Loss: 27.0540, Validation Loss Current: 6.8797, Validation Loss AVG: 8.3776, lr: 0.001
Epoch [14/400], Training Loss: 26.7894, Validation Loss Current: 7.5607, Validation Loss AVG: 10.7188, lr: 0.001
Epoch [15/400], Training Loss: 27.1728, Validation Loss Current: 7.2925, Validation Loss AVG: 10.6921, lr: 0.001
Epoch [16/400], Training Loss: 25.3495, Validation Loss Current: 7.1652, Validation Loss AVG: 9.2723, lr: 0.001
Epoch [17/400], Training Loss: 24.9569, Validation Loss Current: 6.5733, Validation Loss AVG: 8.5337, lr: 0.001
Epoch [18/400], Training Loss: 23.3206, Validation Loss Current: 9.7485, Validation Loss AVG: 16.7538, lr: 0.001
Epoch [19/400], Training Loss: 24.1965, Validation Loss Current: 6.4323, Validation Loss AVG: 8.1883, lr: 0.001
Epoch [20/400], Training Loss: 22.6274, Validation Loss Current: 6.7733, Validation Loss AVG: 11.9157, lr: 0.001
Epoch [21/400], Training Loss: 20.2081, Validation Loss Current: 7.0077, Validation Loss AVG: 12.4892, lr: 0.001
Epoch [22/400], Training Loss: 21.3234, Validation Loss Current: 6.1084, Validation Loss AVG: 8.5068, lr: 0.001
Epoch [23/400], Training Loss: 20.3713, Validation Loss Current: 7.2534, Validation Loss AVG: 10.1939, lr: 0.001
Epoch [24/400], Training Loss: 19.2062, Validation Loss Current: 6.3717, Validation Loss AVG: 11.9302, lr: 0.001
Epoch [25/400], Training Loss: 17.6221, Validation Loss Current: 5.9138, Validation Loss AVG: 10.8668, lr: 0.001
Epoch [26/400], Training Loss: 17.1808, Validation Loss Current: 6.4411, Validation Loss AVG: 8.6322, lr: 0.001
Epoch [27/400], Training Loss: 16.5773, Validation Loss Current: 8.2193, Validation Loss AVG: 13.7190, lr: 0.001
Epoch [28/400], Training Loss: 15.0013, Validation Loss Current: 6.0987, Validation Loss AVG: 9.1992, lr: 0.001
Epoch [29/400], Training Loss: 15.2221, Validation Loss Current: 8.6041, Validation Loss AVG: 15.6500, lr: 0.001
Epoch [30/400], Training Loss: 17.9075, Validation Loss Current: 6.4856, Validation Loss AVG: 9.0376, lr: 0.001
Epoch [31/400], Training Loss: 16.8171, Validation Loss Current: 6.2865, Validation Loss AVG: 10.2287, lr: 0.001
Epoch [32/400], Training Loss: 15.0250, Validation Loss Current: 6.4701, Validation Loss AVG: 11.3610, lr: 0.001
Epoch [33/400], Training Loss: 13.8499, Validation Loss Current: 5.8609, Validation Loss AVG: 8.1331, lr: 0.001
Epoch [34/400], Training Loss: 13.8840, Validation Loss Current: 6.3341, Validation Loss AVG: 11.6116, lr: 0.001
Epoch [35/400], Training Loss: 13.5908, Validation Loss Current: 6.1454, Validation Loss AVG: 8.9101, lr: 0.001
Epoch [36/400], Training Loss: 12.3508, Validation Loss Current: 5.8812, Validation Loss AVG: 8.8173, lr: 0.001
Epoch [37/400], Training Loss: 11.5984, Validation Loss Current: 6.0762, Validation Loss AVG: 8.1955, lr: 0.001
Epoch [38/400], Training Loss: 9.1443, Validation Loss Current: 5.7903, Validation Loss AVG: 10.8831, lr: 0.001
Epoch [39/400], Training Loss: 9.3387, Validation Loss Current: 6.5699, Validation Loss AVG: 9.5853, lr: 0.001
Epoch [40/400], Training Loss: 10.7595, Validation Loss Current: 6.1353, Validation Loss AVG: 10.9244, lr: 0.001
Epoch [41/400], Training Loss: 8.6576, Validation Loss Current: 5.9787, Validation Loss AVG: 13.3528, lr: 0.001
Epoch [42/400], Training Loss: 7.1013, Validation Loss Current: 5.9298, Validation Loss AVG: 9.0173, lr: 0.001
Epoch [43/400], Training Loss: 5.4073, Validation Loss Current: 5.6595, Validation Loss AVG: 9.8237, lr: 0.001
Epoch [44/400], Training Loss: 5.5586, Validation Loss Current: 6.6573, Validation Loss AVG: 10.1177, lr: 0.001
Epoch [45/400], Training Loss: 7.8520, Validation Loss Current: 6.6275, Validation Loss AVG: 11.7606, lr: 0.001
Epoch [46/400], Training Loss: 5.8729, Validation Loss Current: 5.9034, Validation Loss AVG: 9.9354, lr: 0.001
Epoch [47/400], Training Loss: 7.2838, Validation Loss Current: 7.3166, Validation Loss AVG: 19.1976, lr: 0.001
Epoch [48/400], Training Loss: 7.7327, Validation Loss Current: 7.6071, Validation Loss AVG: 10.3345, lr: 0.001
Epoch [49/400], Training Loss: 6.9717, Validation Loss Current: 6.1763, Validation Loss AVG: 12.6178, lr: 0.001
Epoch [50/400], Training Loss: 9.7820, Validation Loss Current: 8.9496, Validation Loss AVG: 10.6958, lr: 0.001
Epoch [51/400], Training Loss: 5.6816, Validation Loss Current: 6.6131, Validation Loss AVG: 11.0440, lr: 0.001
Epoch [52/400], Training Loss: 5.0100, Validation Loss Current: 6.7408, Validation Loss AVG: 10.4794, lr: 0.001
Epoch [53/400], Training Loss: 5.1515, Validation Loss Current: 6.2279, Validation Loss AVG: 12.0637, lr: 0.001
Epoch [54/400], Training Loss: 4.7386, Validation Loss Current: 6.9390, Validation Loss AVG: 13.7844, lr: 0.001
Epoch [55/400], Training Loss: 7.4371, Validation Loss Current: 6.8004, Validation Loss AVG: 15.2197, lr: 0.001
Epoch [56/400], Training Loss: 4.4562, Validation Loss Current: 6.5563, Validation Loss AVG: 10.0413, lr: 0.001
Epoch [57/400], Training Loss: 3.5959, Validation Loss Current: 7.1678, Validation Loss AVG: 11.0007, lr: 0.001
Epoch [58/400], Training Loss: 2.8188, Validation Loss Current: 7.4918, Validation Loss AVG: 11.9550, lr: 0.001
Epoch [59/400], Training Loss: 6.7752, Validation Loss Current: 20.5886, Validation Loss AVG: 33.8877, lr: 0.001
Epoch [60/400], Training Loss: 13.4569, Validation Loss Current: 9.4976, Validation Loss AVG: 13.9973, lr: 0.001
Epoch [61/400], Training Loss: 5.1508, Validation Loss Current: 8.3820, Validation Loss AVG: 11.8106, lr: 0.001
Epoch [62/400], Training Loss: 3.5031, Validation Loss Current: 6.3814, Validation Loss AVG: 12.2837, lr: 0.001
Epoch [63/400], Training Loss: 3.1972, Validation Loss Current: 7.6821, Validation Loss AVG: 11.7038, lr: 0.001
Epoch [64/400], Training Loss: 4.8011, Validation Loss Current: 8.2240, Validation Loss AVG: 11.3951, lr: 0.001
Epoch [65/400], Training Loss: 8.4373, Validation Loss Current: 8.2065, Validation Loss AVG: 15.8398, lr: 0.001
Epoch [66/400], Training Loss: 7.7393, Validation Loss Current: 7.8606, Validation Loss AVG: 13.6561, lr: 0.001
Epoch [67/400], Training Loss: 7.1093, Validation Loss Current: 10.3528, Validation Loss AVG: 17.0421, lr: 0.001
Epoch [68/400], Training Loss: 5.5677, Validation Loss Current: 9.3315, Validation Loss AVG: 14.6521, lr: 0.001
Epoch [69/400], Training Loss: 2.5931, Validation Loss Current: 6.8079, Validation Loss AVG: 11.9103, lr: 0.001
Epoch [70/400], Training Loss: 4.2802, Validation Loss Current: 6.9728, Validation Loss AVG: 11.6807, lr: 0.001
Epoch [71/400], Training Loss: 2.6224, Validation Loss Current: 7.3153, Validation Loss AVG: 11.5463, lr: 0.001
Epoch [72/400], Training Loss: 4.1646, Validation Loss Current: 7.0614, Validation Loss AVG: 12.2775, lr: 0.001
Epoch [73/400], Training Loss: 4.8679, Validation Loss Current: 7.1284, Validation Loss AVG: 11.2598, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 43 Best val accuracy: [0.22532894736842105, 0.27631578947368424, 0.2713815789473684, 0.3503289473684211, 0.3996710526315789, 0.33881578947368424, 0.4292763157894737, 0.39473684210526316, 0.4407894736842105, 0.4588815789473684, 0.49506578947368424, 0.47039473684210525, 0.5230263157894737, 0.4819078947368421, 0.4605263157894737, 0.49506578947368424, 0.5345394736842105, 0.43256578947368424, 0.5460526315789473, 0.53125, 0.5263157894736842, 0.5723684210526315, 0.49835526315789475, 0.5526315789473685, 0.5592105263157895, 0.5625, 0.45723684210526316, 0.5904605263157895, 0.48848684210526316, 0.5608552631578947, 0.5542763157894737, 0.5592105263157895, 0.5904605263157895, 0.5657894736842105, 0.5970394736842105, 0.600328947368421, 0.6085526315789473, 0.5953947368421053, 0.5953947368421053, 0.5855263157894737, 0.587171052631579, 0.618421052631579, 0.6332236842105263, 0.587171052631579, 0.5674342105263158, 0.5986842105263158, 0.5328947368421053, 0.5509868421052632, 0.6134868421052632, 0.48519736842105265, 0.5888157894736842, 0.5756578947368421, 0.59375, 0.5674342105263158, 0.555921052631579, 0.587171052631579, 0.5970394736842105, 0.5526315789473685, 0.3190789473684211, 0.537828947368421, 0.5328947368421053, 0.5904605263157895, 0.5493421052631579, 0.5493421052631579, 0.5411184210526315, 0.5657894736842105, 0.4769736842105263, 0.5493421052631579, 0.600328947368421, 0.5953947368421053, 0.5904605263157895, 0.6069078947368421, 0.6019736842105263] Best val loss: 5.659459590911865


Fold: 1
----- Training resnet18 with sequence: [0.2] -----
Current group: 0.2
Epoch [1/400], Training Loss: 41.6804, Validation Loss Current: 10.0449, Validation Loss AVG: 10.0449, lr: 0.001
Epoch [2/400], Training Loss: 39.5657, Validation Loss Current: 10.5547, Validation Loss AVG: 10.5547, lr: 0.001
Epoch [3/400], Training Loss: 39.3922, Validation Loss Current: 10.8963, Validation Loss AVG: 10.8963, lr: 0.001
Epoch [4/400], Training Loss: 39.1065, Validation Loss Current: 11.1869, Validation Loss AVG: 11.1869, lr: 0.001
Epoch [5/400], Training Loss: 38.7488, Validation Loss Current: 11.5229, Validation Loss AVG: 11.5229, lr: 0.001
Epoch [6/400], Training Loss: 36.9010, Validation Loss Current: 11.1988, Validation Loss AVG: 11.1988, lr: 0.001
Epoch [7/400], Training Loss: 36.8324, Validation Loss Current: 11.9771, Validation Loss AVG: 11.9771, lr: 0.001
Epoch [8/400], Training Loss: 36.0766, Validation Loss Current: 11.9434, Validation Loss AVG: 11.9434, lr: 0.001
Epoch [9/400], Training Loss: 35.0289, Validation Loss Current: 12.4822, Validation Loss AVG: 12.4822, lr: 0.001
Epoch [10/400], Training Loss: 34.8796, Validation Loss Current: 10.5907, Validation Loss AVG: 10.5907, lr: 0.001
Epoch [11/400], Training Loss: 34.6263, Validation Loss Current: 11.7056, Validation Loss AVG: 11.7056, lr: 0.001
Epoch [12/400], Training Loss: 33.1125, Validation Loss Current: 12.2738, Validation Loss AVG: 12.2738, lr: 0.001
Epoch [13/400], Training Loss: 32.9067, Validation Loss Current: 11.7957, Validation Loss AVG: 11.7957, lr: 0.001
Epoch [14/400], Training Loss: 32.2515, Validation Loss Current: 10.7274, Validation Loss AVG: 10.7274, lr: 0.001
Epoch [15/400], Training Loss: 31.7371, Validation Loss Current: 10.9589, Validation Loss AVG: 10.9589, lr: 0.001
Epoch [16/400], Training Loss: 31.2965, Validation Loss Current: 11.0390, Validation Loss AVG: 11.0390, lr: 0.001
Epoch [17/400], Training Loss: 29.4676, Validation Loss Current: 9.9461, Validation Loss AVG: 9.9461, lr: 0.001
Epoch [18/400], Training Loss: 29.4873, Validation Loss Current: 13.0134, Validation Loss AVG: 13.0134, lr: 0.001
Epoch [19/400], Training Loss: 27.4971, Validation Loss Current: 10.2514, Validation Loss AVG: 10.2514, lr: 0.001
Epoch [20/400], Training Loss: 26.3629, Validation Loss Current: 11.4672, Validation Loss AVG: 11.4672, lr: 0.001
Epoch [21/400], Training Loss: 26.0295, Validation Loss Current: 10.8339, Validation Loss AVG: 10.8339, lr: 0.001
Epoch [22/400], Training Loss: 24.2003, Validation Loss Current: 9.7306, Validation Loss AVG: 9.7306, lr: 0.001
Epoch [23/400], Training Loss: 24.2793, Validation Loss Current: 11.2819, Validation Loss AVG: 11.2819, lr: 0.001
Epoch [24/400], Training Loss: 24.0902, Validation Loss Current: 10.4338, Validation Loss AVG: 10.4338, lr: 0.001
Epoch [25/400], Training Loss: 23.3583, Validation Loss Current: 11.4312, Validation Loss AVG: 11.4312, lr: 0.001
Epoch [26/400], Training Loss: 21.5151, Validation Loss Current: 14.7763, Validation Loss AVG: 14.7763, lr: 0.001
Epoch [27/400], Training Loss: 20.7923, Validation Loss Current: 13.8047, Validation Loss AVG: 13.8047, lr: 0.001
Epoch [28/400], Training Loss: 22.2165, Validation Loss Current: 14.0757, Validation Loss AVG: 14.0757, lr: 0.001
Epoch [29/400], Training Loss: 20.3255, Validation Loss Current: 11.7612, Validation Loss AVG: 11.7612, lr: 0.001
Epoch [30/400], Training Loss: 18.6831, Validation Loss Current: 10.5179, Validation Loss AVG: 10.5179, lr: 0.001
Epoch [31/400], Training Loss: 17.2932, Validation Loss Current: 17.9494, Validation Loss AVG: 17.9494, lr: 0.001
Epoch [32/400], Training Loss: 18.1127, Validation Loss Current: 12.3240, Validation Loss AVG: 12.3240, lr: 0.001
Epoch [33/400], Training Loss: 18.2442, Validation Loss Current: 11.0276, Validation Loss AVG: 11.0276, lr: 0.001
Epoch [34/400], Training Loss: 16.9361, Validation Loss Current: 15.6316, Validation Loss AVG: 15.6316, lr: 0.001
Epoch [35/400], Training Loss: 14.6418, Validation Loss Current: 11.6743, Validation Loss AVG: 11.6743, lr: 0.001
Epoch [36/400], Training Loss: 18.0403, Validation Loss Current: 16.0890, Validation Loss AVG: 16.0890, lr: 0.001
Epoch [37/400], Training Loss: 13.9000, Validation Loss Current: 12.8301, Validation Loss AVG: 12.8301, lr: 0.001
Epoch [38/400], Training Loss: 12.5102, Validation Loss Current: 14.1565, Validation Loss AVG: 14.1565, lr: 0.001
Epoch [39/400], Training Loss: 12.5990, Validation Loss Current: 12.2325, Validation Loss AVG: 12.2325, lr: 0.001
Epoch [40/400], Training Loss: 12.5068, Validation Loss Current: 14.0037, Validation Loss AVG: 14.0037, lr: 0.001
Epoch [41/400], Training Loss: 10.9026, Validation Loss Current: 15.9454, Validation Loss AVG: 15.9454, lr: 0.001
Epoch [42/400], Training Loss: 9.3857, Validation Loss Current: 15.8674, Validation Loss AVG: 15.8674, lr: 0.001
Epoch [43/400], Training Loss: 10.5704, Validation Loss Current: 16.3896, Validation Loss AVG: 16.3896, lr: 0.001
Epoch [44/400], Training Loss: 10.1875, Validation Loss Current: 16.7953, Validation Loss AVG: 16.7953, lr: 0.001
Epoch [45/400], Training Loss: 9.2136, Validation Loss Current: 15.7685, Validation Loss AVG: 15.7685, lr: 0.001
Epoch [46/400], Training Loss: 10.0311, Validation Loss Current: 17.2530, Validation Loss AVG: 17.2530, lr: 0.001
Epoch [47/400], Training Loss: 17.2172, Validation Loss Current: 23.9624, Validation Loss AVG: 23.9624, lr: 0.001
Epoch [48/400], Training Loss: 16.9244, Validation Loss Current: 15.3883, Validation Loss AVG: 15.3883, lr: 0.001
Epoch [49/400], Training Loss: 14.1731, Validation Loss Current: 17.2352, Validation Loss AVG: 17.2352, lr: 0.001
Epoch [50/400], Training Loss: 10.6486, Validation Loss Current: 16.3760, Validation Loss AVG: 16.3760, lr: 0.001
Epoch [51/400], Training Loss: 10.2613, Validation Loss Current: 15.8202, Validation Loss AVG: 15.8202, lr: 0.001
Epoch [52/400], Training Loss: 13.0118, Validation Loss Current: 25.6481, Validation Loss AVG: 25.6481, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 22 Best val accuracy: [0.2450657894736842, 0.18157894736842106, 0.15493421052631579, 0.15756578947368421, 0.17105263157894735, 0.175, 0.18322368421052632, 0.19407894736842107, 0.18914473684210525, 0.24605263157894738, 0.20131578947368425, 0.21907894736842107, 0.2138157894736842, 0.2480263157894737, 0.2631578947368421, 0.2523026315789474, 0.30361842105263154, 0.22730263157894734, 0.2654605263157895, 0.2536184210526316, 0.26249999999999996, 0.3503289473684211, 0.28157894736842104, 0.2970394736842105, 0.29901315789473687, 0.30953947368421053, 0.21809210526315792, 0.33782894736842106, 0.2638157894736842, 0.36546052631578946, 0.3026315789473685, 0.29177631578947366, 0.3421052631578948, 0.262828947368421, 0.35296052631578945, 0.26151315789473684, 0.33256578947368426, 0.2733552631578947, 0.3401315789473684, 0.3072368421052632, 0.3483552631578948, 0.28651315789473686, 0.3384868421052632, 0.28486842105263155, 0.30394736842105263, 0.2358552631578948, 0.19703947368421054, 0.33947368421052626, 0.2766447368421053, 0.3588815789473684, 0.2868421052631579, 0.3006578947368421] Best val loss: 9.730588340759278


----- Training resnet18 with sequence: [0.8] -----
Current group: 0.8
Epoch [1/400], Training Loss: 40.8631, Validation Loss Current: 9.9872, Validation Loss AVG: 9.9872, lr: 0.001
Epoch [2/400], Training Loss: 38.9979, Validation Loss Current: 9.8026, Validation Loss AVG: 9.8026, lr: 0.001
Epoch [3/400], Training Loss: 37.6691, Validation Loss Current: 9.6367, Validation Loss AVG: 9.6367, lr: 0.001
Epoch [4/400], Training Loss: 36.8519, Validation Loss Current: 9.5082, Validation Loss AVG: 9.5082, lr: 0.001
Epoch [5/400], Training Loss: 35.1300, Validation Loss Current: 9.0821, Validation Loss AVG: 9.0821, lr: 0.001
Epoch [6/400], Training Loss: 33.4868, Validation Loss Current: 8.9762, Validation Loss AVG: 8.9762, lr: 0.001
Epoch [7/400], Training Loss: 32.1166, Validation Loss Current: 8.9215, Validation Loss AVG: 8.9215, lr: 0.001
Epoch [8/400], Training Loss: 31.1458, Validation Loss Current: 8.8199, Validation Loss AVG: 8.8199, lr: 0.001
Epoch [9/400], Training Loss: 29.8939, Validation Loss Current: 8.7332, Validation Loss AVG: 8.7332, lr: 0.001
Epoch [10/400], Training Loss: 29.0680, Validation Loss Current: 9.1501, Validation Loss AVG: 9.1501, lr: 0.001
Epoch [11/400], Training Loss: 28.9641, Validation Loss Current: 8.3998, Validation Loss AVG: 8.3998, lr: 0.001
Epoch [12/400], Training Loss: 27.7443, Validation Loss Current: 8.8021, Validation Loss AVG: 8.8021, lr: 0.001
Epoch [13/400], Training Loss: 25.9000, Validation Loss Current: 8.8301, Validation Loss AVG: 8.8301, lr: 0.001
Epoch [14/400], Training Loss: 25.1213, Validation Loss Current: 8.8953, Validation Loss AVG: 8.8953, lr: 0.001
Epoch [15/400], Training Loss: 24.5381, Validation Loss Current: 8.7507, Validation Loss AVG: 8.7507, lr: 0.001
Epoch [16/400], Training Loss: 26.3304, Validation Loss Current: 8.9960, Validation Loss AVG: 8.9960, lr: 0.001
Epoch [17/400], Training Loss: 24.3032, Validation Loss Current: 10.4150, Validation Loss AVG: 10.4150, lr: 0.001
Epoch [18/400], Training Loss: 23.7788, Validation Loss Current: 8.6777, Validation Loss AVG: 8.6777, lr: 0.001
Epoch [19/400], Training Loss: 23.0513, Validation Loss Current: 7.9926, Validation Loss AVG: 7.9926, lr: 0.001
Epoch [20/400], Training Loss: 21.0834, Validation Loss Current: 9.1454, Validation Loss AVG: 9.1454, lr: 0.001
Epoch [21/400], Training Loss: 21.7460, Validation Loss Current: 8.3510, Validation Loss AVG: 8.3510, lr: 0.001
Epoch [22/400], Training Loss: 22.1173, Validation Loss Current: 7.9294, Validation Loss AVG: 7.9294, lr: 0.001
Epoch [23/400], Training Loss: 21.0665, Validation Loss Current: 8.1850, Validation Loss AVG: 8.1850, lr: 0.001
Epoch [24/400], Training Loss: 20.9603, Validation Loss Current: 11.1899, Validation Loss AVG: 11.1899, lr: 0.001
Epoch [25/400], Training Loss: 19.9141, Validation Loss Current: 11.5755, Validation Loss AVG: 11.5755, lr: 0.001
Epoch [26/400], Training Loss: 20.1907, Validation Loss Current: 10.5949, Validation Loss AVG: 10.5949, lr: 0.001
Epoch [27/400], Training Loss: 18.8195, Validation Loss Current: 9.2490, Validation Loss AVG: 9.2490, lr: 0.001
Epoch [28/400], Training Loss: 16.8294, Validation Loss Current: 8.3546, Validation Loss AVG: 8.3546, lr: 0.001
Epoch [29/400], Training Loss: 16.6106, Validation Loss Current: 8.7702, Validation Loss AVG: 8.7702, lr: 0.001
Epoch [30/400], Training Loss: 16.7087, Validation Loss Current: 8.2430, Validation Loss AVG: 8.2430, lr: 0.001
Epoch [31/400], Training Loss: 15.6954, Validation Loss Current: 7.9671, Validation Loss AVG: 7.9671, lr: 0.001
Epoch [32/400], Training Loss: 15.5647, Validation Loss Current: 8.5157, Validation Loss AVG: 8.5157, lr: 0.001
Epoch [33/400], Training Loss: 16.4641, Validation Loss Current: 8.0919, Validation Loss AVG: 8.0919, lr: 0.001
Epoch [34/400], Training Loss: 14.8149, Validation Loss Current: 9.6899, Validation Loss AVG: 9.6899, lr: 0.001
Epoch [35/400], Training Loss: 15.4215, Validation Loss Current: 8.6483, Validation Loss AVG: 8.6483, lr: 0.001
Epoch [36/400], Training Loss: 12.5383, Validation Loss Current: 10.9397, Validation Loss AVG: 10.9397, lr: 0.001
Epoch [37/400], Training Loss: 10.9687, Validation Loss Current: 10.8682, Validation Loss AVG: 10.8682, lr: 0.001
Epoch [38/400], Training Loss: 11.9023, Validation Loss Current: 9.1204, Validation Loss AVG: 9.1204, lr: 0.001
Epoch [39/400], Training Loss: 11.2017, Validation Loss Current: 9.5430, Validation Loss AVG: 9.5430, lr: 0.001
Epoch [40/400], Training Loss: 8.7157, Validation Loss Current: 11.9427, Validation Loss AVG: 11.9427, lr: 0.001
Epoch [41/400], Training Loss: 8.4812, Validation Loss Current: 8.9354, Validation Loss AVG: 8.9354, lr: 0.001
Epoch [42/400], Training Loss: 9.1210, Validation Loss Current: 9.8595, Validation Loss AVG: 9.8595, lr: 0.001
Epoch [43/400], Training Loss: 10.4951, Validation Loss Current: 10.1760, Validation Loss AVG: 10.1760, lr: 0.001
Epoch [44/400], Training Loss: 7.4307, Validation Loss Current: 10.4130, Validation Loss AVG: 10.4130, lr: 0.001
Epoch [45/400], Training Loss: 7.5103, Validation Loss Current: 9.0882, Validation Loss AVG: 9.0882, lr: 0.001
Epoch [46/400], Training Loss: 9.2380, Validation Loss Current: 11.4597, Validation Loss AVG: 11.4597, lr: 0.001
Epoch [47/400], Training Loss: 6.0086, Validation Loss Current: 11.3918, Validation Loss AVG: 11.3918, lr: 0.001
Epoch [48/400], Training Loss: 5.9310, Validation Loss Current: 12.7783, Validation Loss AVG: 12.7783, lr: 0.001
Epoch [49/400], Training Loss: 9.8695, Validation Loss Current: 17.7063, Validation Loss AVG: 17.7063, lr: 0.001
Epoch [50/400], Training Loss: 20.0492, Validation Loss Current: 9.7148, Validation Loss AVG: 9.7148, lr: 0.001
Epoch [51/400], Training Loss: 14.7667, Validation Loss Current: 13.8764, Validation Loss AVG: 13.8764, lr: 0.001
Epoch [52/400], Training Loss: 13.9727, Validation Loss Current: 19.5763, Validation Loss AVG: 19.5763, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 22 Best val accuracy: [0.24934210526315786, 0.26414473684210527, 0.2944078947368421, 0.3302631578947368, 0.3470394736842105, 0.3631578947368421, 0.375, 0.38453947368421054, 0.37236842105263157, 0.3703947368421053, 0.4184210526315789, 0.41743421052631585, 0.39539473684210524, 0.38815789473684215, 0.41644736842105257, 0.4029605263157895, 0.3671052631578947, 0.4167763157894737, 0.4601973684210526, 0.4161184210526316, 0.4375, 0.4384868421052632, 0.4421052631578948, 0.34638157894736843, 0.3480263157894737, 0.4111842105263158, 0.40855263157894744, 0.4516447368421053, 0.43947368421052635, 0.4516447368421052, 0.4671052631578948, 0.4134868421052632, 0.45230263157894746, 0.44342105263157894, 0.4444078947368421, 0.40328947368421053, 0.3605263157894737, 0.4375, 0.4453947368421053, 0.37072368421052626, 0.4480263157894736, 0.4407894736842105, 0.4546052631578947, 0.4203947368421053, 0.44703947368421043, 0.4203947368421053, 0.3924342105263158, 0.3740131578947368, 0.3575657894736842, 0.42006578947368417, 0.37203947368421053, 0.4171052631578947] Best val loss: 7.929370927810669


----- Training resnet18 with sequence: [0.4] -----
Current group: 0.4
Epoch [1/400], Training Loss: 41.3453, Validation Loss Current: 10.0107, Validation Loss AVG: 10.0107, lr: 0.001
Epoch [2/400], Training Loss: 39.9843, Validation Loss Current: 9.8996, Validation Loss AVG: 9.8996, lr: 0.001
Epoch [3/400], Training Loss: 39.1211, Validation Loss Current: 9.8579, Validation Loss AVG: 9.8579, lr: 0.001
Epoch [4/400], Training Loss: 38.3790, Validation Loss Current: 10.0131, Validation Loss AVG: 10.0131, lr: 0.001
Epoch [5/400], Training Loss: 37.7434, Validation Loss Current: 9.6963, Validation Loss AVG: 9.6963, lr: 0.001
Epoch [6/400], Training Loss: 37.4027, Validation Loss Current: 9.7144, Validation Loss AVG: 9.7144, lr: 0.001
Epoch [7/400], Training Loss: 36.5607, Validation Loss Current: 9.3437, Validation Loss AVG: 9.3437, lr: 0.001
Epoch [8/400], Training Loss: 35.4180, Validation Loss Current: 9.2749, Validation Loss AVG: 9.2749, lr: 0.001
Epoch [9/400], Training Loss: 34.6553, Validation Loss Current: 9.4355, Validation Loss AVG: 9.4355, lr: 0.001
Epoch [10/400], Training Loss: 33.7077, Validation Loss Current: 9.0330, Validation Loss AVG: 9.0330, lr: 0.001
Epoch [11/400], Training Loss: 32.5974, Validation Loss Current: 9.2038, Validation Loss AVG: 9.2038, lr: 0.001
Epoch [12/400], Training Loss: 31.2042, Validation Loss Current: 8.7508, Validation Loss AVG: 8.7508, lr: 0.001
Epoch [13/400], Training Loss: 30.0799, Validation Loss Current: 8.7305, Validation Loss AVG: 8.7305, lr: 0.001
Epoch [14/400], Training Loss: 29.7220, Validation Loss Current: 8.8053, Validation Loss AVG: 8.8053, lr: 0.001
Epoch [15/400], Training Loss: 28.6679, Validation Loss Current: 8.6335, Validation Loss AVG: 8.6335, lr: 0.001
Epoch [16/400], Training Loss: 27.3074, Validation Loss Current: 8.8081, Validation Loss AVG: 8.8081, lr: 0.001
Epoch [17/400], Training Loss: 27.6865, Validation Loss Current: 8.4991, Validation Loss AVG: 8.4991, lr: 0.001
Epoch [18/400], Training Loss: 26.3513, Validation Loss Current: 8.2082, Validation Loss AVG: 8.2082, lr: 0.001
Epoch [19/400], Training Loss: 25.5806, Validation Loss Current: 8.6225, Validation Loss AVG: 8.6225, lr: 0.001
Epoch [20/400], Training Loss: 25.7084, Validation Loss Current: 9.2033, Validation Loss AVG: 9.2033, lr: 0.001
Epoch [21/400], Training Loss: 24.4230, Validation Loss Current: 8.5928, Validation Loss AVG: 8.5928, lr: 0.001
Epoch [22/400], Training Loss: 23.3157, Validation Loss Current: 8.4282, Validation Loss AVG: 8.4282, lr: 0.001
Epoch [23/400], Training Loss: 22.9116, Validation Loss Current: 8.3910, Validation Loss AVG: 8.3910, lr: 0.001
Epoch [24/400], Training Loss: 21.5952, Validation Loss Current: 8.1782, Validation Loss AVG: 8.1782, lr: 0.001
Epoch [25/400], Training Loss: 20.4740, Validation Loss Current: 8.1720, Validation Loss AVG: 8.1720, lr: 0.001
Epoch [26/400], Training Loss: 19.2984, Validation Loss Current: 8.2250, Validation Loss AVG: 8.2250, lr: 0.001
Epoch [27/400], Training Loss: 18.9129, Validation Loss Current: 8.4918, Validation Loss AVG: 8.4918, lr: 0.001
Epoch [28/400], Training Loss: 18.5382, Validation Loss Current: 8.4870, Validation Loss AVG: 8.4870, lr: 0.001
Epoch [29/400], Training Loss: 18.4491, Validation Loss Current: 8.5081, Validation Loss AVG: 8.5081, lr: 0.001
Epoch [30/400], Training Loss: 17.9018, Validation Loss Current: 8.2179, Validation Loss AVG: 8.2179, lr: 0.001
Epoch [31/400], Training Loss: 17.2816, Validation Loss Current: 9.2619, Validation Loss AVG: 9.2619, lr: 0.001
Epoch [32/400], Training Loss: 16.5390, Validation Loss Current: 8.5755, Validation Loss AVG: 8.5755, lr: 0.001
Epoch [33/400], Training Loss: 16.1579, Validation Loss Current: 8.9097, Validation Loss AVG: 8.9097, lr: 0.001
Epoch [34/400], Training Loss: 15.5006, Validation Loss Current: 10.0791, Validation Loss AVG: 10.0791, lr: 0.001
Epoch [35/400], Training Loss: 14.1466, Validation Loss Current: 8.8211, Validation Loss AVG: 8.8211, lr: 0.001
Epoch [36/400], Training Loss: 12.1996, Validation Loss Current: 10.3296, Validation Loss AVG: 10.3296, lr: 0.001
Epoch [37/400], Training Loss: 12.0945, Validation Loss Current: 9.5642, Validation Loss AVG: 9.5642, lr: 0.001
Epoch [38/400], Training Loss: 11.1986, Validation Loss Current: 8.9863, Validation Loss AVG: 8.9863, lr: 0.001
Epoch [39/400], Training Loss: 13.0354, Validation Loss Current: 9.7616, Validation Loss AVG: 9.7616, lr: 0.001
Epoch [40/400], Training Loss: 11.6055, Validation Loss Current: 10.8445, Validation Loss AVG: 10.8445, lr: 0.001
Epoch [41/400], Training Loss: 10.1238, Validation Loss Current: 9.3951, Validation Loss AVG: 9.3951, lr: 0.001
Epoch [42/400], Training Loss: 9.0338, Validation Loss Current: 9.8245, Validation Loss AVG: 9.8245, lr: 0.001
Epoch [43/400], Training Loss: 8.8765, Validation Loss Current: 9.7014, Validation Loss AVG: 9.7014, lr: 0.001
Epoch [44/400], Training Loss: 7.5239, Validation Loss Current: 9.8431, Validation Loss AVG: 9.8431, lr: 0.001
Epoch [45/400], Training Loss: 9.3663, Validation Loss Current: 14.1211, Validation Loss AVG: 14.1211, lr: 0.001
Epoch [46/400], Training Loss: 11.3138, Validation Loss Current: 11.2681, Validation Loss AVG: 11.2681, lr: 0.001
Epoch [47/400], Training Loss: 11.8016, Validation Loss Current: 11.9364, Validation Loss AVG: 11.9364, lr: 0.001
Epoch [48/400], Training Loss: 12.5635, Validation Loss Current: 10.6519, Validation Loss AVG: 10.6519, lr: 0.001
Epoch [49/400], Training Loss: 7.5122, Validation Loss Current: 10.3688, Validation Loss AVG: 10.3688, lr: 0.001
Epoch [50/400], Training Loss: 6.3944, Validation Loss Current: 12.2324, Validation Loss AVG: 12.2324, lr: 0.001
Epoch [51/400], Training Loss: 8.2798, Validation Loss Current: 11.7466, Validation Loss AVG: 11.7466, lr: 0.001
Epoch [52/400], Training Loss: 7.0668, Validation Loss Current: 12.4486, Validation Loss AVG: 12.4486, lr: 0.001
Epoch [53/400], Training Loss: 6.2822, Validation Loss Current: 14.0120, Validation Loss AVG: 14.0120, lr: 0.001
Epoch [54/400], Training Loss: 10.8125, Validation Loss Current: 16.5190, Validation Loss AVG: 16.5190, lr: 0.001
Epoch [55/400], Training Loss: 10.5739, Validation Loss Current: 15.3839, Validation Loss AVG: 15.3839, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 25 Best val accuracy: [0.24407894736842106, 0.24769736842105267, 0.2569078947368421, 0.2509868421052631, 0.2539473684210526, 0.2368421052631579, 0.31842105263157894, 0.2924342105263158, 0.28618421052631576, 0.3470394736842105, 0.3203947368421053, 0.36249999999999993, 0.3621710526315789, 0.33223684210526316, 0.37006578947368424, 0.36710526315789477, 0.37236842105263157, 0.42368421052631583, 0.35098684210526315, 0.3713815789473684, 0.3796052631578947, 0.39769736842105263, 0.41710526315789476, 0.40756578947368427, 0.4427631578947368, 0.42203947368421046, 0.39013157894736844, 0.42828947368421055, 0.41546052631578945, 0.4473684210526316, 0.39572368421052634, 0.4052631578947368, 0.4253289473684211, 0.31447368421052635, 0.40756578947368427, 0.40032894736842106, 0.3924342105263158, 0.4118421052631579, 0.39046052631578954, 0.3871710526315789, 0.40394736842105256, 0.4009868421052632, 0.41381578947368425, 0.4078947368421053, 0.2983552631578947, 0.3838815789473684, 0.3707236842105263, 0.3447368421052632, 0.41940789473684215, 0.31217105263157896, 0.41217105263157894, 0.32960526315789473, 0.29605263157894735, 0.2924342105263158, 0.3894736842105263] Best val loss: 8.171976280212402


----- Training resnet18 with sequence: [0.6] -----
Current group: 0.6
Epoch [1/400], Training Loss: 41.0110, Validation Loss Current: 9.9690, Validation Loss AVG: 9.9690, lr: 0.001
Epoch [2/400], Training Loss: 39.2100, Validation Loss Current: 9.8297, Validation Loss AVG: 9.8297, lr: 0.001
Epoch [3/400], Training Loss: 38.8832, Validation Loss Current: 9.7591, Validation Loss AVG: 9.7591, lr: 0.001
Epoch [4/400], Training Loss: 37.0899, Validation Loss Current: 9.5221, Validation Loss AVG: 9.5221, lr: 0.001
Epoch [5/400], Training Loss: 36.8727, Validation Loss Current: 9.3165, Validation Loss AVG: 9.3165, lr: 0.001
Epoch [6/400], Training Loss: 35.0565, Validation Loss Current: 9.2396, Validation Loss AVG: 9.2396, lr: 0.001
Epoch [7/400], Training Loss: 34.0372, Validation Loss Current: 9.0492, Validation Loss AVG: 9.0492, lr: 0.001
Epoch [8/400], Training Loss: 32.9878, Validation Loss Current: 9.2072, Validation Loss AVG: 9.2072, lr: 0.001
Epoch [9/400], Training Loss: 31.7800, Validation Loss Current: 8.9640, Validation Loss AVG: 8.9640, lr: 0.001
Epoch [10/400], Training Loss: 31.0359, Validation Loss Current: 8.4423, Validation Loss AVG: 8.4423, lr: 0.001
Epoch [11/400], Training Loss: 29.9986, Validation Loss Current: 8.3360, Validation Loss AVG: 8.3360, lr: 0.001
Epoch [12/400], Training Loss: 28.7408, Validation Loss Current: 8.3474, Validation Loss AVG: 8.3474, lr: 0.001
Epoch [13/400], Training Loss: 26.9664, Validation Loss Current: 8.2329, Validation Loss AVG: 8.2329, lr: 0.001
Epoch [14/400], Training Loss: 26.3485, Validation Loss Current: 8.0603, Validation Loss AVG: 8.0603, lr: 0.001
Epoch [15/400], Training Loss: 26.1345, Validation Loss Current: 8.8993, Validation Loss AVG: 8.8993, lr: 0.001
Epoch [16/400], Training Loss: 28.0589, Validation Loss Current: 8.7065, Validation Loss AVG: 8.7065, lr: 0.001
Epoch [17/400], Training Loss: 25.3199, Validation Loss Current: 8.0991, Validation Loss AVG: 8.0991, lr: 0.001
Epoch [18/400], Training Loss: 25.3503, Validation Loss Current: 8.3544, Validation Loss AVG: 8.3544, lr: 0.001
Epoch [19/400], Training Loss: 24.7322, Validation Loss Current: 8.2778, Validation Loss AVG: 8.2778, lr: 0.001
Epoch [20/400], Training Loss: 22.7057, Validation Loss Current: 8.0536, Validation Loss AVG: 8.0536, lr: 0.001
Epoch [21/400], Training Loss: 21.6449, Validation Loss Current: 7.9474, Validation Loss AVG: 7.9474, lr: 0.001
Epoch [22/400], Training Loss: 22.0447, Validation Loss Current: 7.8794, Validation Loss AVG: 7.8794, lr: 0.001
Epoch [23/400], Training Loss: 20.7790, Validation Loss Current: 9.0692, Validation Loss AVG: 9.0692, lr: 0.001
Epoch [24/400], Training Loss: 20.4132, Validation Loss Current: 7.7891, Validation Loss AVG: 7.7891, lr: 0.001
Epoch [25/400], Training Loss: 19.6818, Validation Loss Current: 7.6451, Validation Loss AVG: 7.6451, lr: 0.001
Epoch [26/400], Training Loss: 20.1641, Validation Loss Current: 8.3624, Validation Loss AVG: 8.3624, lr: 0.001
Epoch [27/400], Training Loss: 18.4689, Validation Loss Current: 9.9809, Validation Loss AVG: 9.9809, lr: 0.001
Epoch [28/400], Training Loss: 19.5208, Validation Loss Current: 8.7046, Validation Loss AVG: 8.7046, lr: 0.001
Epoch [29/400], Training Loss: 17.9178, Validation Loss Current: 7.8448, Validation Loss AVG: 7.8448, lr: 0.001
Epoch [30/400], Training Loss: 14.7106, Validation Loss Current: 8.3512, Validation Loss AVG: 8.3512, lr: 0.001
Epoch [31/400], Training Loss: 14.3935, Validation Loss Current: 8.5307, Validation Loss AVG: 8.5307, lr: 0.001
Epoch [32/400], Training Loss: 14.4255, Validation Loss Current: 8.1699, Validation Loss AVG: 8.1699, lr: 0.001
Epoch [33/400], Training Loss: 15.3103, Validation Loss Current: 8.9491, Validation Loss AVG: 8.9491, lr: 0.001
Epoch [34/400], Training Loss: 13.3555, Validation Loss Current: 8.3240, Validation Loss AVG: 8.3240, lr: 0.001
Epoch [35/400], Training Loss: 13.6740, Validation Loss Current: 8.3246, Validation Loss AVG: 8.3246, lr: 0.001
Epoch [36/400], Training Loss: 13.8898, Validation Loss Current: 9.0304, Validation Loss AVG: 9.0304, lr: 0.001
Epoch [37/400], Training Loss: 11.4172, Validation Loss Current: 8.6512, Validation Loss AVG: 8.6512, lr: 0.001
Epoch [38/400], Training Loss: 8.7287, Validation Loss Current: 9.1676, Validation Loss AVG: 9.1676, lr: 0.001
Epoch [39/400], Training Loss: 8.9131, Validation Loss Current: 8.3141, Validation Loss AVG: 8.3141, lr: 0.001
Epoch [40/400], Training Loss: 9.7686, Validation Loss Current: 9.0506, Validation Loss AVG: 9.0506, lr: 0.001
Epoch [41/400], Training Loss: 8.5487, Validation Loss Current: 9.3085, Validation Loss AVG: 9.3085, lr: 0.001
Epoch [42/400], Training Loss: 8.3949, Validation Loss Current: 8.8371, Validation Loss AVG: 8.8371, lr: 0.001
Epoch [43/400], Training Loss: 7.8828, Validation Loss Current: 9.3641, Validation Loss AVG: 9.3641, lr: 0.001
Epoch [44/400], Training Loss: 7.5737, Validation Loss Current: 9.3282, Validation Loss AVG: 9.3282, lr: 0.001
Epoch [45/400], Training Loss: 5.3860, Validation Loss Current: 9.6966, Validation Loss AVG: 9.6966, lr: 0.001
Epoch [46/400], Training Loss: 5.3798, Validation Loss Current: 9.5324, Validation Loss AVG: 9.5324, lr: 0.001
Epoch [47/400], Training Loss: 6.1002, Validation Loss Current: 10.6299, Validation Loss AVG: 10.6299, lr: 0.001
Epoch [48/400], Training Loss: 4.8262, Validation Loss Current: 9.9227, Validation Loss AVG: 9.9227, lr: 0.001
Epoch [49/400], Training Loss: 4.5335, Validation Loss Current: 11.0410, Validation Loss AVG: 11.0410, lr: 0.001
Epoch [50/400], Training Loss: 5.7892, Validation Loss Current: 11.0568, Validation Loss AVG: 11.0568, lr: 0.001
Epoch [51/400], Training Loss: 7.5350, Validation Loss Current: 13.6402, Validation Loss AVG: 13.6402, lr: 0.001
Epoch [52/400], Training Loss: 6.0656, Validation Loss Current: 10.7241, Validation Loss AVG: 10.7241, lr: 0.001
Epoch [53/400], Training Loss: 4.6763, Validation Loss Current: 9.6289, Validation Loss AVG: 9.6289, lr: 0.001
Epoch [54/400], Training Loss: 4.1301, Validation Loss Current: 9.7282, Validation Loss AVG: 9.7282, lr: 0.001
Epoch [55/400], Training Loss: 6.2900, Validation Loss Current: 10.0900, Validation Loss AVG: 10.0900, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 25 Best val accuracy: [0.24440789473684213, 0.2664473684210526, 0.25723684210526315, 0.28552631578947374, 0.325328947368421, 0.33486842105263154, 0.3542763157894737, 0.33453947368421055, 0.35, 0.39539473684210524, 0.40230263157894736, 0.4256578947368421, 0.4203947368421053, 0.4355263157894737, 0.4082236842105263, 0.3996710526315789, 0.4430921052631579, 0.4200657894736842, 0.425, 0.44375, 0.4358552631578948, 0.44210526315789467, 0.40164473684210533, 0.4634868421052632, 0.4638157894736842, 0.43947368421052635, 0.42434210526315785, 0.4164473684210527, 0.4618421052631579, 0.4384868421052631, 0.45065789473684215, 0.4273026315789473, 0.43453947368421053, 0.43059210526315794, 0.4842105263157895, 0.43322368421052626, 0.4569078947368421, 0.44342105263157894, 0.4720394736842105, 0.4375, 0.41381578947368425, 0.4115131578947368, 0.4217105263157895, 0.47171052631578947, 0.44506578947368414, 0.3789473684210526, 0.4207236842105263, 0.44605263157894737, 0.3848684210526316, 0.4134868421052632, 0.39440789473684207, 0.4302631578947368, 0.4546052631578947, 0.4375, 0.4161184210526315] Best val loss: 7.645108342170715


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.7352, Validation Loss Current: 9.8711, Validation Loss AVG: 9.9650, lr: 0.001
Epoch [2/400], Training Loss: 38.4525, Validation Loss Current: 9.4672, Validation Loss AVG: 9.8330, lr: 0.001
Epoch [3/400], Training Loss: 37.0297, Validation Loss Current: 9.1804, Validation Loss AVG: 9.7399, lr: 0.001
Epoch [4/400], Training Loss: 35.5721, Validation Loss Current: 8.7073, Validation Loss AVG: 9.5195, lr: 0.001
Epoch [5/400], Training Loss: 34.2011, Validation Loss Current: 8.2866, Validation Loss AVG: 9.1863, lr: 0.001
Epoch [6/400], Training Loss: 33.0626, Validation Loss Current: 8.1465, Validation Loss AVG: 9.1921, lr: 0.001
Epoch [7/400], Training Loss: 32.3039, Validation Loss Current: 7.9932, Validation Loss AVG: 9.2388, lr: 0.001
Epoch [8/400], Training Loss: 29.8465, Validation Loss Current: 7.6418, Validation Loss AVG: 8.9758, lr: 0.001
Epoch [9/400], Training Loss: 29.4960, Validation Loss Current: 8.5655, Validation Loss AVG: 12.5257, lr: 0.001
Epoch [10/400], Training Loss: 28.8025, Validation Loss Current: 7.5812, Validation Loss AVG: 8.7911, lr: 0.001
Epoch [11/400], Training Loss: 27.7709, Validation Loss Current: 7.2962, Validation Loss AVG: 10.5235, lr: 0.001
Epoch [12/400], Training Loss: 26.4489, Validation Loss Current: 6.9879, Validation Loss AVG: 8.5340, lr: 0.001
Epoch [13/400], Training Loss: 25.4311, Validation Loss Current: 7.5061, Validation Loss AVG: 12.4747, lr: 0.001
Epoch [14/400], Training Loss: 24.9324, Validation Loss Current: 6.6019, Validation Loss AVG: 9.0253, lr: 0.001
Epoch [15/400], Training Loss: 24.7339, Validation Loss Current: 7.0723, Validation Loss AVG: 11.1417, lr: 0.001
Epoch [16/400], Training Loss: 24.0374, Validation Loss Current: 7.2340, Validation Loss AVG: 9.7580, lr: 0.001
Epoch [17/400], Training Loss: 24.8804, Validation Loss Current: 6.9103, Validation Loss AVG: 9.6511, lr: 0.001
Epoch [18/400], Training Loss: 23.8093, Validation Loss Current: 7.1320, Validation Loss AVG: 9.7389, lr: 0.001
Epoch [19/400], Training Loss: 22.3810, Validation Loss Current: 6.6441, Validation Loss AVG: 9.3891, lr: 0.001
Epoch [20/400], Training Loss: 25.6560, Validation Loss Current: 7.1755, Validation Loss AVG: 11.5612, lr: 0.001
Epoch [21/400], Training Loss: 23.7714, Validation Loss Current: 6.8310, Validation Loss AVG: 12.1999, lr: 0.001
Epoch [22/400], Training Loss: 23.3315, Validation Loss Current: 6.3477, Validation Loss AVG: 9.4714, lr: 0.001
Epoch [23/400], Training Loss: 20.5911, Validation Loss Current: 6.1172, Validation Loss AVG: 9.2034, lr: 0.001
Epoch [24/400], Training Loss: 19.6541, Validation Loss Current: 6.3592, Validation Loss AVG: 12.1222, lr: 0.001
Epoch [25/400], Training Loss: 20.7339, Validation Loss Current: 9.5575, Validation Loss AVG: 19.1093, lr: 0.001
Epoch [26/400], Training Loss: 20.1651, Validation Loss Current: 6.6054, Validation Loss AVG: 9.2022, lr: 0.001
Epoch [27/400], Training Loss: 19.7323, Validation Loss Current: 6.6643, Validation Loss AVG: 9.3673, lr: 0.001
Epoch [28/400], Training Loss: 17.9793, Validation Loss Current: 6.5437, Validation Loss AVG: 12.9145, lr: 0.001
Epoch [29/400], Training Loss: 16.7098, Validation Loss Current: 5.7963, Validation Loss AVG: 9.4738, lr: 0.001
Epoch [30/400], Training Loss: 15.7394, Validation Loss Current: 5.6528, Validation Loss AVG: 8.6263, lr: 0.001
Epoch [31/400], Training Loss: 15.5058, Validation Loss Current: 6.8893, Validation Loss AVG: 13.2062, lr: 0.001
Epoch [32/400], Training Loss: 16.8022, Validation Loss Current: 6.0492, Validation Loss AVG: 10.5095, lr: 0.001
Epoch [33/400], Training Loss: 15.6685, Validation Loss Current: 7.2123, Validation Loss AVG: 8.8831, lr: 0.001
Epoch [34/400], Training Loss: 14.1026, Validation Loss Current: 7.0949, Validation Loss AVG: 12.0912, lr: 0.001
Epoch [35/400], Training Loss: 15.3425, Validation Loss Current: 6.0923, Validation Loss AVG: 8.9521, lr: 0.001
Epoch [36/400], Training Loss: 13.2870, Validation Loss Current: 5.7722, Validation Loss AVG: 9.2964, lr: 0.001
Epoch [37/400], Training Loss: 12.3239, Validation Loss Current: 5.6467, Validation Loss AVG: 11.3643, lr: 0.001
Epoch [38/400], Training Loss: 10.6773, Validation Loss Current: 5.6568, Validation Loss AVG: 9.8498, lr: 0.001
Epoch [39/400], Training Loss: 10.5968, Validation Loss Current: 5.7284, Validation Loss AVG: 8.3684, lr: 0.001
Epoch [40/400], Training Loss: 9.6707, Validation Loss Current: 5.6805, Validation Loss AVG: 10.7127, lr: 0.001
Epoch [41/400], Training Loss: 8.2624, Validation Loss Current: 5.6636, Validation Loss AVG: 12.3476, lr: 0.001
Epoch [42/400], Training Loss: 7.9041, Validation Loss Current: 6.6128, Validation Loss AVG: 9.7883, lr: 0.001
Epoch [43/400], Training Loss: 10.0147, Validation Loss Current: 6.7549, Validation Loss AVG: 10.4665, lr: 0.001
Epoch [44/400], Training Loss: 8.9366, Validation Loss Current: 6.2067, Validation Loss AVG: 11.2187, lr: 0.001
Epoch [45/400], Training Loss: 6.7776, Validation Loss Current: 6.1651, Validation Loss AVG: 10.4312, lr: 0.001
Epoch [46/400], Training Loss: 7.3207, Validation Loss Current: 5.7419, Validation Loss AVG: 10.8640, lr: 0.001
Epoch [47/400], Training Loss: 6.6607, Validation Loss Current: 6.5406, Validation Loss AVG: 13.9385, lr: 0.001
Epoch [48/400], Training Loss: 6.8009, Validation Loss Current: 6.0643, Validation Loss AVG: 9.4361, lr: 0.001
Epoch [49/400], Training Loss: 6.7303, Validation Loss Current: 5.6410, Validation Loss AVG: 10.9840, lr: 0.001
Epoch [50/400], Training Loss: 5.5509, Validation Loss Current: 6.5711, Validation Loss AVG: 13.5164, lr: 0.001
Epoch [51/400], Training Loss: 6.7091, Validation Loss Current: 6.8172, Validation Loss AVG: 12.5917, lr: 0.001
Epoch [52/400], Training Loss: 5.3076, Validation Loss Current: 6.6809, Validation Loss AVG: 13.6963, lr: 0.001
Epoch [53/400], Training Loss: 6.6390, Validation Loss Current: 6.2514, Validation Loss AVG: 10.3645, lr: 0.001
Epoch [54/400], Training Loss: 6.9471, Validation Loss Current: 9.0688, Validation Loss AVG: 18.7733, lr: 0.001
Epoch [55/400], Training Loss: 6.8574, Validation Loss Current: 7.6944, Validation Loss AVG: 12.5183, lr: 0.001
Epoch [56/400], Training Loss: 5.9631, Validation Loss Current: 7.9461, Validation Loss AVG: 10.0957, lr: 0.001
Epoch [57/400], Training Loss: 4.5331, Validation Loss Current: 6.5518, Validation Loss AVG: 15.3659, lr: 0.001
Epoch [58/400], Training Loss: 5.5524, Validation Loss Current: 7.8854, Validation Loss AVG: 14.5104, lr: 0.001
Epoch [59/400], Training Loss: 7.0027, Validation Loss Current: 7.2980, Validation Loss AVG: 14.2577, lr: 0.001
Epoch [60/400], Training Loss: 5.4655, Validation Loss Current: 8.1715, Validation Loss AVG: 15.2514, lr: 0.001
Epoch [61/400], Training Loss: 4.0514, Validation Loss Current: 6.4179, Validation Loss AVG: 12.9851, lr: 0.001
Epoch [62/400], Training Loss: 4.3685, Validation Loss Current: 7.2728, Validation Loss AVG: 17.3767, lr: 0.001
Epoch [63/400], Training Loss: 4.5092, Validation Loss Current: 7.2324, Validation Loss AVG: 11.3452, lr: 0.001
Epoch [64/400], Training Loss: 4.0276, Validation Loss Current: 7.7906, Validation Loss AVG: 15.2165, lr: 0.001
Epoch [65/400], Training Loss: 4.8245, Validation Loss Current: 6.8115, Validation Loss AVG: 11.7064, lr: 0.001
Epoch [66/400], Training Loss: 4.8410, Validation Loss Current: 6.5226, Validation Loss AVG: 13.7474, lr: 0.001
Epoch [67/400], Training Loss: 3.7565, Validation Loss Current: 6.2014, Validation Loss AVG: 10.5789, lr: 0.001
Epoch [68/400], Training Loss: 4.5280, Validation Loss Current: 7.0320, Validation Loss AVG: 11.5430, lr: 0.001
Epoch [69/400], Training Loss: 5.5991, Validation Loss Current: 8.0249, Validation Loss AVG: 13.1144, lr: 0.001
Epoch [70/400], Training Loss: 6.1666, Validation Loss Current: 7.9907, Validation Loss AVG: 14.0962, lr: 0.001
Epoch [71/400], Training Loss: 3.6825, Validation Loss Current: 7.0655, Validation Loss AVG: 12.7896, lr: 0.001
Epoch [72/400], Training Loss: 2.2801, Validation Loss Current: 7.1308, Validation Loss AVG: 13.5050, lr: 0.001
Epoch [73/400], Training Loss: 1.2494, Validation Loss Current: 6.6424, Validation Loss AVG: 12.0942, lr: 0.001
Epoch [74/400], Training Loss: 0.8764, Validation Loss Current: 6.2566, Validation Loss AVG: 12.7729, lr: 0.001
Epoch [75/400], Training Loss: 0.7534, Validation Loss Current: 6.4297, Validation Loss AVG: 11.6971, lr: 0.001
Epoch [76/400], Training Loss: 0.5900, Validation Loss Current: 6.1618, Validation Loss AVG: 12.7905, lr: 0.001
Epoch [77/400], Training Loss: 1.6438, Validation Loss Current: 6.3689, Validation Loss AVG: 12.3158, lr: 0.001
Epoch [78/400], Training Loss: 3.7534, Validation Loss Current: 8.3565, Validation Loss AVG: 12.2550, lr: 0.001
Epoch [79/400], Training Loss: 6.6346, Validation Loss Current: 8.6245, Validation Loss AVG: 16.0677, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 49 Best val accuracy: [0.25, 0.29605263157894735, 0.34210526315789475, 0.3519736842105263, 0.4243421052631579, 0.43914473684210525, 0.4473684210526316, 0.44901315789473684, 0.4194078947368421, 0.47368421052631576, 0.49835526315789475, 0.5148026315789473, 0.4934210526315789, 0.5674342105263158, 0.5131578947368421, 0.5049342105263158, 0.506578947368421, 0.5213815789473685, 0.5279605263157895, 0.5164473684210527, 0.5328947368421053, 0.5427631578947368, 0.5625, 0.5592105263157895, 0.45723684210526316, 0.5460526315789473, 0.5411184210526315, 0.5493421052631579, 0.59375, 0.5986842105263158, 0.5789473684210527, 0.5838815789473685, 0.524671052631579, 0.5444078947368421, 0.5674342105263158, 0.6101973684210527, 0.6282894736842105, 0.6233552631578947, 0.5986842105263158, 0.6282894736842105, 0.6282894736842105, 0.5592105263157895, 0.5674342105263158, 0.6036184210526315, 0.6299342105263158, 0.6052631578947368, 0.5904605263157895, 0.6101973684210527, 0.6447368421052632, 0.5970394736842105, 0.5773026315789473, 0.6052631578947368, 0.6151315789473685, 0.4934210526315789, 0.6085526315789473, 0.537828947368421, 0.6381578947368421, 0.5855263157894737, 0.5657894736842105, 0.524671052631579, 0.6233552631578947, 0.5921052631578947, 0.5953947368421053, 0.5361842105263158, 0.6332236842105263, 0.6233552631578947, 0.6447368421052632, 0.6332236842105263, 0.59375, 0.569078947368421, 0.5921052631578947, 0.625, 0.631578947368421, 0.6430921052631579, 0.6578947368421053, 0.6513157894736842, 0.6463815789473685, 0.6036184210526315, 0.569078947368421] Best val loss: 5.640961647033691


Fold: 2
----- Training resnet18 with sequence: [0.2] -----
Current group: 0.2
Epoch [1/400], Training Loss: 40.1763, Validation Loss Current: 10.2071, Validation Loss AVG: 10.2071, lr: 0.001
Epoch [2/400], Training Loss: 39.4818, Validation Loss Current: 10.6648, Validation Loss AVG: 10.6648, lr: 0.001
Epoch [3/400], Training Loss: 39.2153, Validation Loss Current: 11.1518, Validation Loss AVG: 11.1518, lr: 0.001
Epoch [4/400], Training Loss: 38.3833, Validation Loss Current: 10.6303, Validation Loss AVG: 10.6303, lr: 0.001
Epoch [5/400], Training Loss: 37.7224, Validation Loss Current: 11.0031, Validation Loss AVG: 11.0031, lr: 0.001
Epoch [6/400], Training Loss: 36.2209, Validation Loss Current: 10.1072, Validation Loss AVG: 10.1072, lr: 0.001
Epoch [7/400], Training Loss: 35.5214, Validation Loss Current: 10.9116, Validation Loss AVG: 10.9116, lr: 0.001
Epoch [8/400], Training Loss: 33.9022, Validation Loss Current: 10.2086, Validation Loss AVG: 10.2086, lr: 0.001
Epoch [9/400], Training Loss: 33.8534, Validation Loss Current: 10.7203, Validation Loss AVG: 10.7203, lr: 0.001
Epoch [10/400], Training Loss: 32.8500, Validation Loss Current: 10.5744, Validation Loss AVG: 10.5744, lr: 0.001
Epoch [11/400], Training Loss: 31.8682, Validation Loss Current: 10.5322, Validation Loss AVG: 10.5322, lr: 0.001
Epoch [12/400], Training Loss: 30.5778, Validation Loss Current: 10.8419, Validation Loss AVG: 10.8419, lr: 0.001
Epoch [13/400], Training Loss: 29.9390, Validation Loss Current: 10.1138, Validation Loss AVG: 10.1138, lr: 0.001
Epoch [14/400], Training Loss: 28.5457, Validation Loss Current: 10.6592, Validation Loss AVG: 10.6592, lr: 0.001
Epoch [15/400], Training Loss: 28.7843, Validation Loss Current: 10.8816, Validation Loss AVG: 10.8816, lr: 0.001
Epoch [16/400], Training Loss: 27.2326, Validation Loss Current: 11.1610, Validation Loss AVG: 11.1610, lr: 0.001
Epoch [17/400], Training Loss: 27.1426, Validation Loss Current: 10.7807, Validation Loss AVG: 10.7807, lr: 0.001
Epoch [18/400], Training Loss: 26.3538, Validation Loss Current: 11.0999, Validation Loss AVG: 11.0999, lr: 0.001
Epoch [19/400], Training Loss: 25.6341, Validation Loss Current: 10.4883, Validation Loss AVG: 10.4883, lr: 0.001
Epoch [20/400], Training Loss: 25.9745, Validation Loss Current: 11.8902, Validation Loss AVG: 11.8902, lr: 0.001
Epoch [21/400], Training Loss: 26.4233, Validation Loss Current: 11.1485, Validation Loss AVG: 11.1485, lr: 0.001
Epoch [22/400], Training Loss: 24.4356, Validation Loss Current: 10.5890, Validation Loss AVG: 10.5890, lr: 0.001
Epoch [23/400], Training Loss: 23.0895, Validation Loss Current: 12.8291, Validation Loss AVG: 12.8291, lr: 0.001
Epoch [24/400], Training Loss: 22.2605, Validation Loss Current: 12.3708, Validation Loss AVG: 12.3708, lr: 0.001
Epoch [25/400], Training Loss: 22.1887, Validation Loss Current: 13.6860, Validation Loss AVG: 13.6860, lr: 0.001
Epoch [26/400], Training Loss: 21.8055, Validation Loss Current: 11.9398, Validation Loss AVG: 11.9398, lr: 0.001
Epoch [27/400], Training Loss: 21.0043, Validation Loss Current: 13.3418, Validation Loss AVG: 13.3418, lr: 0.001
Epoch [28/400], Training Loss: 21.5901, Validation Loss Current: 11.8210, Validation Loss AVG: 11.8210, lr: 0.001
Epoch [29/400], Training Loss: 19.7048, Validation Loss Current: 12.0868, Validation Loss AVG: 12.0868, lr: 0.001
Epoch [30/400], Training Loss: 19.6132, Validation Loss Current: 13.7979, Validation Loss AVG: 13.7979, lr: 0.001
Epoch [31/400], Training Loss: 18.0781, Validation Loss Current: 11.0668, Validation Loss AVG: 11.0668, lr: 0.001
Epoch [32/400], Training Loss: 15.4869, Validation Loss Current: 10.9789, Validation Loss AVG: 10.9789, lr: 0.001
Epoch [33/400], Training Loss: 14.7896, Validation Loss Current: 13.7344, Validation Loss AVG: 13.7344, lr: 0.001
Epoch [34/400], Training Loss: 12.7108, Validation Loss Current: 12.6526, Validation Loss AVG: 12.6526, lr: 0.001
Epoch [35/400], Training Loss: 13.1123, Validation Loss Current: 14.2150, Validation Loss AVG: 14.2150, lr: 0.001
Epoch [36/400], Training Loss: 19.3833, Validation Loss Current: 18.2141, Validation Loss AVG: 18.2141, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 6 Best val accuracy: [0.22927631578947372, 0.1582236842105263, 0.15000000000000002, 0.18651315789473683, 0.17763157894736842, 0.25625, 0.2230263157894737, 0.26710526315789473, 0.22861842105263158, 0.26842105263157895, 0.2411184210526316, 0.24539473684210528, 0.2677631578947368, 0.26151315789473684, 0.26710526315789473, 0.27960526315789475, 0.27532894736842106, 0.26282894736842105, 0.31052631578947365, 0.2601973684210527, 0.2924342105263158, 0.2868421052631579, 0.2973684210526316, 0.2792763157894737, 0.3088815789473684, 0.2894736842105264, 0.2348684210526316, 0.3167763157894737, 0.28717105263157894, 0.2766447368421053, 0.3118421052631579, 0.3799342105263158, 0.28815789473684206, 0.3279605263157895, 0.26776315789473687, 0.2733552631578947] Best val loss: 10.107212376594543


----- Training resnet18 with sequence: [0.8] -----
Current group: 0.8
Epoch [1/400], Training Loss: 41.1802, Validation Loss Current: 10.0839, Validation Loss AVG: 10.0839, lr: 0.001
Epoch [2/400], Training Loss: 39.0560, Validation Loss Current: 10.1238, Validation Loss AVG: 10.1238, lr: 0.001
Epoch [3/400], Training Loss: 38.4924, Validation Loss Current: 10.5121, Validation Loss AVG: 10.5121, lr: 0.001
Epoch [4/400], Training Loss: 37.2131, Validation Loss Current: 9.8503, Validation Loss AVG: 9.8503, lr: 0.001
Epoch [5/400], Training Loss: 35.8036, Validation Loss Current: 9.7629, Validation Loss AVG: 9.7629, lr: 0.001
Epoch [6/400], Training Loss: 34.4786, Validation Loss Current: 9.4421, Validation Loss AVG: 9.4421, lr: 0.001
Epoch [7/400], Training Loss: 33.2183, Validation Loss Current: 9.7288, Validation Loss AVG: 9.7288, lr: 0.001
Epoch [8/400], Training Loss: 31.6454, Validation Loss Current: 9.3391, Validation Loss AVG: 9.3391, lr: 0.001
Epoch [9/400], Training Loss: 31.3936, Validation Loss Current: 9.4014, Validation Loss AVG: 9.4014, lr: 0.001
Epoch [10/400], Training Loss: 30.0395, Validation Loss Current: 9.0589, Validation Loss AVG: 9.0589, lr: 0.001
Epoch [11/400], Training Loss: 29.0331, Validation Loss Current: 9.1555, Validation Loss AVG: 9.1555, lr: 0.001
Epoch [12/400], Training Loss: 27.1490, Validation Loss Current: 9.9897, Validation Loss AVG: 9.9897, lr: 0.001
Epoch [13/400], Training Loss: 27.2020, Validation Loss Current: 8.7073, Validation Loss AVG: 8.7073, lr: 0.001
Epoch [14/400], Training Loss: 27.4496, Validation Loss Current: 8.5694, Validation Loss AVG: 8.5694, lr: 0.001
Epoch [15/400], Training Loss: 26.3574, Validation Loss Current: 8.3180, Validation Loss AVG: 8.3180, lr: 0.001
Epoch [16/400], Training Loss: 25.6121, Validation Loss Current: 8.8854, Validation Loss AVG: 8.8854, lr: 0.001
Epoch [17/400], Training Loss: 25.6431, Validation Loss Current: 9.8693, Validation Loss AVG: 9.8693, lr: 0.001
Epoch [18/400], Training Loss: 23.4261, Validation Loss Current: 8.5779, Validation Loss AVG: 8.5779, lr: 0.001
Epoch [19/400], Training Loss: 23.3109, Validation Loss Current: 8.6168, Validation Loss AVG: 8.6168, lr: 0.001
Epoch [20/400], Training Loss: 22.6899, Validation Loss Current: 8.4526, Validation Loss AVG: 8.4526, lr: 0.001
Epoch [21/400], Training Loss: 22.5292, Validation Loss Current: 9.7989, Validation Loss AVG: 9.7989, lr: 0.001
Epoch [22/400], Training Loss: 21.7859, Validation Loss Current: 9.0316, Validation Loss AVG: 9.0316, lr: 0.001
Epoch [23/400], Training Loss: 20.1451, Validation Loss Current: 8.6985, Validation Loss AVG: 8.6985, lr: 0.001
Epoch [24/400], Training Loss: 18.8699, Validation Loss Current: 9.2227, Validation Loss AVG: 9.2227, lr: 0.001
Epoch [25/400], Training Loss: 18.8443, Validation Loss Current: 9.4352, Validation Loss AVG: 9.4352, lr: 0.001
Epoch [26/400], Training Loss: 18.1081, Validation Loss Current: 8.2187, Validation Loss AVG: 8.2187, lr: 0.001
Epoch [27/400], Training Loss: 17.3010, Validation Loss Current: 9.6619, Validation Loss AVG: 9.6619, lr: 0.001
Epoch [28/400], Training Loss: 17.4386, Validation Loss Current: 8.4859, Validation Loss AVG: 8.4859, lr: 0.001
Epoch [29/400], Training Loss: 17.0454, Validation Loss Current: 8.2889, Validation Loss AVG: 8.2889, lr: 0.001
Epoch [30/400], Training Loss: 16.8024, Validation Loss Current: 9.0661, Validation Loss AVG: 9.0661, lr: 0.001
Epoch [31/400], Training Loss: 15.3842, Validation Loss Current: 8.9826, Validation Loss AVG: 8.9826, lr: 0.001
Epoch [32/400], Training Loss: 14.5992, Validation Loss Current: 8.9298, Validation Loss AVG: 8.9298, lr: 0.001
Epoch [33/400], Training Loss: 16.0361, Validation Loss Current: 8.8941, Validation Loss AVG: 8.8941, lr: 0.001
Epoch [34/400], Training Loss: 13.6004, Validation Loss Current: 11.7327, Validation Loss AVG: 11.7327, lr: 0.001
Epoch [35/400], Training Loss: 11.9422, Validation Loss Current: 8.2427, Validation Loss AVG: 8.2427, lr: 0.001
Epoch [36/400], Training Loss: 11.2894, Validation Loss Current: 8.9617, Validation Loss AVG: 8.9617, lr: 0.001
Epoch [37/400], Training Loss: 10.4571, Validation Loss Current: 8.3499, Validation Loss AVG: 8.3499, lr: 0.001
Epoch [38/400], Training Loss: 10.1958, Validation Loss Current: 8.1674, Validation Loss AVG: 8.1674, lr: 0.001
Epoch [39/400], Training Loss: 13.7518, Validation Loss Current: 10.3860, Validation Loss AVG: 10.3860, lr: 0.001
Epoch [40/400], Training Loss: 9.7820, Validation Loss Current: 8.8246, Validation Loss AVG: 8.8246, lr: 0.001
Epoch [41/400], Training Loss: 10.0670, Validation Loss Current: 8.9425, Validation Loss AVG: 8.9425, lr: 0.001
Epoch [42/400], Training Loss: 9.8953, Validation Loss Current: 9.0079, Validation Loss AVG: 9.0079, lr: 0.001
Epoch [43/400], Training Loss: 8.9351, Validation Loss Current: 10.1887, Validation Loss AVG: 10.1887, lr: 0.001
Epoch [44/400], Training Loss: 7.6685, Validation Loss Current: 9.2114, Validation Loss AVG: 9.2114, lr: 0.001
Epoch [45/400], Training Loss: 8.6200, Validation Loss Current: 9.9140, Validation Loss AVG: 9.9140, lr: 0.001
Epoch [46/400], Training Loss: 9.5198, Validation Loss Current: 12.5675, Validation Loss AVG: 12.5675, lr: 0.001
Epoch [47/400], Training Loss: 6.8138, Validation Loss Current: 9.2062, Validation Loss AVG: 9.2062, lr: 0.001
Epoch [48/400], Training Loss: 5.7357, Validation Loss Current: 12.2639, Validation Loss AVG: 12.2639, lr: 0.001
Epoch [49/400], Training Loss: 4.9489, Validation Loss Current: 13.0102, Validation Loss AVG: 13.0102, lr: 0.001
Epoch [50/400], Training Loss: 6.6764, Validation Loss Current: 11.1963, Validation Loss AVG: 11.1963, lr: 0.001
Epoch [51/400], Training Loss: 5.2221, Validation Loss Current: 11.4178, Validation Loss AVG: 11.4178, lr: 0.001
Epoch [52/400], Training Loss: 6.3389, Validation Loss Current: 11.1988, Validation Loss AVG: 11.1988, lr: 0.001
Epoch [53/400], Training Loss: 6.5308, Validation Loss Current: 11.8432, Validation Loss AVG: 11.8432, lr: 0.001
Epoch [54/400], Training Loss: 7.7475, Validation Loss Current: 10.8110, Validation Loss AVG: 10.8110, lr: 0.001
Epoch [55/400], Training Loss: 5.1874, Validation Loss Current: 10.8400, Validation Loss AVG: 10.8400, lr: 0.001
Epoch [56/400], Training Loss: 4.9383, Validation Loss Current: 9.7396, Validation Loss AVG: 9.7396, lr: 0.001
Epoch [57/400], Training Loss: 2.8661, Validation Loss Current: 10.0917, Validation Loss AVG: 10.0917, lr: 0.001
Epoch [58/400], Training Loss: 2.8127, Validation Loss Current: 10.5163, Validation Loss AVG: 10.5163, lr: 0.001
Epoch [59/400], Training Loss: 2.6577, Validation Loss Current: 9.1059, Validation Loss AVG: 9.1059, lr: 0.001
Epoch [60/400], Training Loss: 2.4270, Validation Loss Current: 11.5394, Validation Loss AVG: 11.5394, lr: 0.001
Epoch [61/400], Training Loss: 3.5496, Validation Loss Current: 11.4684, Validation Loss AVG: 11.4684, lr: 0.001
Epoch [62/400], Training Loss: 3.3873, Validation Loss Current: 9.6305, Validation Loss AVG: 9.6305, lr: 0.001
Epoch [63/400], Training Loss: 2.8602, Validation Loss Current: 10.5821, Validation Loss AVG: 10.5821, lr: 0.001
Epoch [64/400], Training Loss: 3.9562, Validation Loss Current: 10.6077, Validation Loss AVG: 10.6077, lr: 0.001
Epoch [65/400], Training Loss: 2.6736, Validation Loss Current: 10.2831, Validation Loss AVG: 10.2831, lr: 0.001
Epoch [66/400], Training Loss: 2.9017, Validation Loss Current: 9.8040, Validation Loss AVG: 9.8040, lr: 0.001
Epoch [67/400], Training Loss: 6.7258, Validation Loss Current: 14.6587, Validation Loss AVG: 14.6587, lr: 0.001
Epoch [68/400], Training Loss: 8.1257, Validation Loss Current: 14.3092, Validation Loss AVG: 14.3092, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 38 Best val accuracy: [0.22335526315789472, 0.2006578947368421, 0.19177631578947368, 0.2733552631578947, 0.27993421052631573, 0.32171052631578945, 0.30394736842105263, 0.32565789473684215, 0.3279605263157895, 0.3598684210526316, 0.3730263157894737, 0.3595394736842105, 0.37532894736842104, 0.39901315789473685, 0.41019736842105264, 0.37532894736842104, 0.3697368421052632, 0.41743421052631574, 0.4217105263157895, 0.42368421052631583, 0.39144736842105265, 0.4167763157894736, 0.42631578947368426, 0.4171052631578947, 0.4180921052631579, 0.4427631578947368, 0.41743421052631574, 0.43519736842105267, 0.4519736842105263, 0.4394736842105263, 0.4430921052631579, 0.44243421052631576, 0.4322368421052632, 0.3851973684210527, 0.4703947368421053, 0.43618421052631573, 0.4667763157894737, 0.46447368421052637, 0.3697368421052632, 0.4516447368421053, 0.43322368421052626, 0.4036184210526315, 0.41875, 0.46743421052631573, 0.4473684210526316, 0.4269736842105264, 0.4651315789473684, 0.42796052631578957, 0.4358552631578947, 0.41414473684210523, 0.42269736842105265, 0.43717105263157896, 0.4375, 0.40625, 0.4253289473684211, 0.45328947368421063, 0.46282894736842106, 0.45921052631578946, 0.45921052631578946, 0.4463815789473684, 0.4328947368421052, 0.4625, 0.4460526315789474, 0.4276315789473684, 0.46085526315789477, 0.45065789473684215, 0.3921052631578948, 0.42434210526315785] Best val loss: 8.167433071136475


----- Training resnet18 with sequence: [0.4] -----
Current group: 0.4
Epoch [1/400], Training Loss: 40.8237, Validation Loss Current: 10.0989, Validation Loss AVG: 10.0989, lr: 0.001
Epoch [2/400], Training Loss: 39.8873, Validation Loss Current: 10.1003, Validation Loss AVG: 10.1003, lr: 0.001
Epoch [3/400], Training Loss: 40.1318, Validation Loss Current: 9.9689, Validation Loss AVG: 9.9689, lr: 0.001
Epoch [4/400], Training Loss: 38.9443, Validation Loss Current: 9.8815, Validation Loss AVG: 9.8815, lr: 0.001
Epoch [5/400], Training Loss: 37.6860, Validation Loss Current: 9.7278, Validation Loss AVG: 9.7278, lr: 0.001
Epoch [6/400], Training Loss: 36.9497, Validation Loss Current: 9.8644, Validation Loss AVG: 9.8644, lr: 0.001
Epoch [7/400], Training Loss: 36.0376, Validation Loss Current: 9.3928, Validation Loss AVG: 9.3928, lr: 0.001
Epoch [8/400], Training Loss: 34.4818, Validation Loss Current: 9.3126, Validation Loss AVG: 9.3126, lr: 0.001
Epoch [9/400], Training Loss: 34.3494, Validation Loss Current: 9.5183, Validation Loss AVG: 9.5183, lr: 0.001
Epoch [10/400], Training Loss: 33.9178, Validation Loss Current: 9.4362, Validation Loss AVG: 9.4362, lr: 0.001
Epoch [11/400], Training Loss: 32.9016, Validation Loss Current: 9.3205, Validation Loss AVG: 9.3205, lr: 0.001
Epoch [12/400], Training Loss: 32.1020, Validation Loss Current: 8.9648, Validation Loss AVG: 8.9648, lr: 0.001
Epoch [13/400], Training Loss: 30.8728, Validation Loss Current: 8.8567, Validation Loss AVG: 8.8567, lr: 0.001
Epoch [14/400], Training Loss: 29.8919, Validation Loss Current: 9.5008, Validation Loss AVG: 9.5008, lr: 0.001
Epoch [15/400], Training Loss: 29.7182, Validation Loss Current: 9.3518, Validation Loss AVG: 9.3518, lr: 0.001
Epoch [16/400], Training Loss: 28.1589, Validation Loss Current: 8.4898, Validation Loss AVG: 8.4898, lr: 0.001
Epoch [17/400], Training Loss: 27.2935, Validation Loss Current: 9.0534, Validation Loss AVG: 9.0534, lr: 0.001
Epoch [18/400], Training Loss: 27.5719, Validation Loss Current: 8.6728, Validation Loss AVG: 8.6728, lr: 0.001
Epoch [19/400], Training Loss: 27.8434, Validation Loss Current: 8.9462, Validation Loss AVG: 8.9462, lr: 0.001
Epoch [20/400], Training Loss: 26.7196, Validation Loss Current: 9.4569, Validation Loss AVG: 9.4569, lr: 0.001
Epoch [21/400], Training Loss: 25.1765, Validation Loss Current: 8.7939, Validation Loss AVG: 8.7939, lr: 0.001
Epoch [22/400], Training Loss: 25.4181, Validation Loss Current: 8.2801, Validation Loss AVG: 8.2801, lr: 0.001
Epoch [23/400], Training Loss: 24.2161, Validation Loss Current: 8.3214, Validation Loss AVG: 8.3214, lr: 0.001
Epoch [24/400], Training Loss: 22.4019, Validation Loss Current: 9.1135, Validation Loss AVG: 9.1135, lr: 0.001
Epoch [25/400], Training Loss: 22.4528, Validation Loss Current: 8.3745, Validation Loss AVG: 8.3745, lr: 0.001
Epoch [26/400], Training Loss: 20.1262, Validation Loss Current: 8.4793, Validation Loss AVG: 8.4793, lr: 0.001
Epoch [27/400], Training Loss: 19.7902, Validation Loss Current: 8.4106, Validation Loss AVG: 8.4106, lr: 0.001
Epoch [28/400], Training Loss: 19.7181, Validation Loss Current: 8.9344, Validation Loss AVG: 8.9344, lr: 0.001
Epoch [29/400], Training Loss: 18.1499, Validation Loss Current: 8.1799, Validation Loss AVG: 8.1799, lr: 0.001
Epoch [30/400], Training Loss: 17.8336, Validation Loss Current: 8.2216, Validation Loss AVG: 8.2216, lr: 0.001
Epoch [31/400], Training Loss: 15.4092, Validation Loss Current: 8.7619, Validation Loss AVG: 8.7619, lr: 0.001
Epoch [32/400], Training Loss: 15.2921, Validation Loss Current: 11.3070, Validation Loss AVG: 11.3070, lr: 0.001
Epoch [33/400], Training Loss: 18.4490, Validation Loss Current: 9.2183, Validation Loss AVG: 9.2183, lr: 0.001
Epoch [34/400], Training Loss: 14.7110, Validation Loss Current: 8.7901, Validation Loss AVG: 8.7901, lr: 0.001
Epoch [35/400], Training Loss: 13.2779, Validation Loss Current: 8.5065, Validation Loss AVG: 8.5065, lr: 0.001
Epoch [36/400], Training Loss: 13.1908, Validation Loss Current: 8.8389, Validation Loss AVG: 8.8389, lr: 0.001
Epoch [37/400], Training Loss: 11.0748, Validation Loss Current: 8.9196, Validation Loss AVG: 8.9196, lr: 0.001
Epoch [38/400], Training Loss: 10.2396, Validation Loss Current: 9.1247, Validation Loss AVG: 9.1247, lr: 0.001
Epoch [39/400], Training Loss: 14.4992, Validation Loss Current: 11.8849, Validation Loss AVG: 11.8849, lr: 0.001
Epoch [40/400], Training Loss: 13.5893, Validation Loss Current: 9.9143, Validation Loss AVG: 9.9143, lr: 0.001
Epoch [41/400], Training Loss: 16.0877, Validation Loss Current: 13.3425, Validation Loss AVG: 13.3425, lr: 0.001
Epoch [42/400], Training Loss: 11.9738, Validation Loss Current: 9.5401, Validation Loss AVG: 9.5401, lr: 0.001
Epoch [43/400], Training Loss: 9.4325, Validation Loss Current: 11.0067, Validation Loss AVG: 11.0067, lr: 0.001
Epoch [44/400], Training Loss: 8.7645, Validation Loss Current: 9.8878, Validation Loss AVG: 9.8878, lr: 0.001
Epoch [45/400], Training Loss: 8.0380, Validation Loss Current: 10.3421, Validation Loss AVG: 10.3421, lr: 0.001
Epoch [46/400], Training Loss: 12.6834, Validation Loss Current: 11.8390, Validation Loss AVG: 11.8390, lr: 0.001
Epoch [47/400], Training Loss: 11.2717, Validation Loss Current: 10.3270, Validation Loss AVG: 10.3270, lr: 0.001
Epoch [48/400], Training Loss: 8.9455, Validation Loss Current: 9.8397, Validation Loss AVG: 9.8397, lr: 0.001
Epoch [49/400], Training Loss: 11.8566, Validation Loss Current: 11.1337, Validation Loss AVG: 11.1337, lr: 0.001
Epoch [50/400], Training Loss: 12.9914, Validation Loss Current: 18.0592, Validation Loss AVG: 18.0592, lr: 0.001
Epoch [51/400], Training Loss: 12.6535, Validation Loss Current: 11.0750, Validation Loss AVG: 11.0750, lr: 0.001
Epoch [52/400], Training Loss: 10.3083, Validation Loss Current: 11.0493, Validation Loss AVG: 11.0493, lr: 0.001
Epoch [53/400], Training Loss: 9.7141, Validation Loss Current: 10.4435, Validation Loss AVG: 10.4435, lr: 0.001
Epoch [54/400], Training Loss: 8.9574, Validation Loss Current: 10.6470, Validation Loss AVG: 10.6470, lr: 0.001
Epoch [55/400], Training Loss: 5.8766, Validation Loss Current: 10.7287, Validation Loss AVG: 10.7287, lr: 0.001
Epoch [56/400], Training Loss: 3.8361, Validation Loss Current: 9.6281, Validation Loss AVG: 9.6281, lr: 0.001
Epoch [57/400], Training Loss: 5.5486, Validation Loss Current: 9.6341, Validation Loss AVG: 9.6341, lr: 0.001
Epoch [58/400], Training Loss: 5.9807, Validation Loss Current: 11.3655, Validation Loss AVG: 11.3655, lr: 0.001
Epoch [59/400], Training Loss: 3.5347, Validation Loss Current: 9.7815, Validation Loss AVG: 9.7815, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 29 Best val accuracy: [0.23125, 0.20526315789473681, 0.24046052631578946, 0.23421052631578948, 0.2565789473684211, 0.22368421052631576, 0.3069078947368421, 0.30065789473684207, 0.25032894736842104, 0.3177631578947368, 0.30098684210526316, 0.33980263157894736, 0.36710526315789477, 0.3375, 0.32401315789473684, 0.3973684210526316, 0.3516447368421053, 0.3740131578947368, 0.34671052631578947, 0.3516447368421053, 0.39046052631578954, 0.41217105263157894, 0.4111842105263158, 0.3815789473684211, 0.39375, 0.4213815789473684, 0.4305921052631579, 0.3717105263157895, 0.42927631578947373, 0.4289473684210526, 0.39309210526315785, 0.3480263157894737, 0.36085526315789473, 0.43322368421052637, 0.43782894736842104, 0.3888157894736842, 0.4394736842105263, 0.4197368421052632, 0.3875, 0.36546052631578946, 0.32598684210526313, 0.39572368421052634, 0.3592105263157895, 0.43717105263157896, 0.35, 0.37368421052631573, 0.3625, 0.42598684210526316, 0.3572368421052632, 0.3069078947368421, 0.37796052631578947, 0.4072368421052632, 0.3927631578947369, 0.3789473684210526, 0.41743421052631585, 0.44342105263157894, 0.4513157894736842, 0.4253289473684211, 0.43256578947368424] Best val loss: 8.179948782920837


----- Training resnet18 with sequence: [0.6] -----
Current group: 0.6
Epoch [1/400], Training Loss: 40.5908, Validation Loss Current: 10.1126, Validation Loss AVG: 10.1126, lr: 0.001
Epoch [2/400], Training Loss: 39.9797, Validation Loss Current: 9.9510, Validation Loss AVG: 9.9510, lr: 0.001
Epoch [3/400], Training Loss: 38.4715, Validation Loss Current: 9.8160, Validation Loss AVG: 9.8160, lr: 0.001
Epoch [4/400], Training Loss: 37.1916, Validation Loss Current: 9.5441, Validation Loss AVG: 9.5441, lr: 0.001
Epoch [5/400], Training Loss: 36.4121, Validation Loss Current: 9.4187, Validation Loss AVG: 9.4187, lr: 0.001
Epoch [6/400], Training Loss: 34.8781, Validation Loss Current: 9.8445, Validation Loss AVG: 9.8445, lr: 0.001
Epoch [7/400], Training Loss: 34.0156, Validation Loss Current: 9.1386, Validation Loss AVG: 9.1386, lr: 0.001
Epoch [8/400], Training Loss: 32.3165, Validation Loss Current: 9.1743, Validation Loss AVG: 9.1743, lr: 0.001
Epoch [9/400], Training Loss: 31.0749, Validation Loss Current: 8.9984, Validation Loss AVG: 8.9984, lr: 0.001
Epoch [10/400], Training Loss: 30.6419, Validation Loss Current: 8.7252, Validation Loss AVG: 8.7252, lr: 0.001
Epoch [11/400], Training Loss: 29.6229, Validation Loss Current: 8.5381, Validation Loss AVG: 8.5381, lr: 0.001
Epoch [12/400], Training Loss: 29.7344, Validation Loss Current: 8.4789, Validation Loss AVG: 8.4789, lr: 0.001
Epoch [13/400], Training Loss: 27.8047, Validation Loss Current: 8.3265, Validation Loss AVG: 8.3265, lr: 0.001
Epoch [14/400], Training Loss: 27.8260, Validation Loss Current: 8.6868, Validation Loss AVG: 8.6868, lr: 0.001
Epoch [15/400], Training Loss: 27.4901, Validation Loss Current: 8.3317, Validation Loss AVG: 8.3317, lr: 0.001
Epoch [16/400], Training Loss: 26.8773, Validation Loss Current: 8.3485, Validation Loss AVG: 8.3485, lr: 0.001
Epoch [17/400], Training Loss: 25.3869, Validation Loss Current: 8.0836, Validation Loss AVG: 8.0836, lr: 0.001
Epoch [18/400], Training Loss: 23.3647, Validation Loss Current: 8.1220, Validation Loss AVG: 8.1220, lr: 0.001
Epoch [19/400], Training Loss: 23.0610, Validation Loss Current: 8.9233, Validation Loss AVG: 8.9233, lr: 0.001
Epoch [20/400], Training Loss: 22.6241, Validation Loss Current: 7.9133, Validation Loss AVG: 7.9133, lr: 0.001
Epoch [21/400], Training Loss: 23.4036, Validation Loss Current: 8.3707, Validation Loss AVG: 8.3707, lr: 0.001
Epoch [22/400], Training Loss: 22.6471, Validation Loss Current: 8.2254, Validation Loss AVG: 8.2254, lr: 0.001
Epoch [23/400], Training Loss: 22.9766, Validation Loss Current: 8.0794, Validation Loss AVG: 8.0794, lr: 0.001
Epoch [24/400], Training Loss: 19.9677, Validation Loss Current: 7.9431, Validation Loss AVG: 7.9431, lr: 0.001
Epoch [25/400], Training Loss: 18.9854, Validation Loss Current: 8.0958, Validation Loss AVG: 8.0958, lr: 0.001
Epoch [26/400], Training Loss: 18.8126, Validation Loss Current: 7.8887, Validation Loss AVG: 7.8887, lr: 0.001
Epoch [27/400], Training Loss: 18.0061, Validation Loss Current: 8.1049, Validation Loss AVG: 8.1049, lr: 0.001
Epoch [28/400], Training Loss: 17.8972, Validation Loss Current: 8.3357, Validation Loss AVG: 8.3357, lr: 0.001
Epoch [29/400], Training Loss: 15.8265, Validation Loss Current: 8.0531, Validation Loss AVG: 8.0531, lr: 0.001
Epoch [30/400], Training Loss: 15.4983, Validation Loss Current: 9.4984, Validation Loss AVG: 9.4984, lr: 0.001
Epoch [31/400], Training Loss: 16.0351, Validation Loss Current: 7.6414, Validation Loss AVG: 7.6414, lr: 0.001
Epoch [32/400], Training Loss: 14.5146, Validation Loss Current: 10.2817, Validation Loss AVG: 10.2817, lr: 0.001
Epoch [33/400], Training Loss: 16.5069, Validation Loss Current: 10.2717, Validation Loss AVG: 10.2717, lr: 0.001
Epoch [34/400], Training Loss: 14.6134, Validation Loss Current: 7.8803, Validation Loss AVG: 7.8803, lr: 0.001
Epoch [35/400], Training Loss: 13.7587, Validation Loss Current: 8.7508, Validation Loss AVG: 8.7508, lr: 0.001
Epoch [36/400], Training Loss: 16.2894, Validation Loss Current: 8.6267, Validation Loss AVG: 8.6267, lr: 0.001
Epoch [37/400], Training Loss: 13.0983, Validation Loss Current: 9.9379, Validation Loss AVG: 9.9379, lr: 0.001
Epoch [38/400], Training Loss: 12.1510, Validation Loss Current: 9.2517, Validation Loss AVG: 9.2517, lr: 0.001
Epoch [39/400], Training Loss: 11.5213, Validation Loss Current: 10.7984, Validation Loss AVG: 10.7984, lr: 0.001
Epoch [40/400], Training Loss: 10.6580, Validation Loss Current: 8.2199, Validation Loss AVG: 8.2199, lr: 0.001
Epoch [41/400], Training Loss: 9.6545, Validation Loss Current: 9.2940, Validation Loss AVG: 9.2940, lr: 0.001
Epoch [42/400], Training Loss: 13.2055, Validation Loss Current: 10.3403, Validation Loss AVG: 10.3403, lr: 0.001
Epoch [43/400], Training Loss: 13.8973, Validation Loss Current: 9.9811, Validation Loss AVG: 9.9811, lr: 0.001
Epoch [44/400], Training Loss: 9.3378, Validation Loss Current: 9.3872, Validation Loss AVG: 9.3872, lr: 0.001
Epoch [45/400], Training Loss: 7.4137, Validation Loss Current: 9.1331, Validation Loss AVG: 9.1331, lr: 0.001
Epoch [46/400], Training Loss: 6.6285, Validation Loss Current: 8.6639, Validation Loss AVG: 8.6639, lr: 0.001
Epoch [47/400], Training Loss: 6.7028, Validation Loss Current: 9.7358, Validation Loss AVG: 9.7358, lr: 0.001
Epoch [48/400], Training Loss: 7.0308, Validation Loss Current: 9.1759, Validation Loss AVG: 9.1759, lr: 0.001
Epoch [49/400], Training Loss: 7.3764, Validation Loss Current: 10.2225, Validation Loss AVG: 10.2225, lr: 0.001
Epoch [50/400], Training Loss: 5.8709, Validation Loss Current: 10.1686, Validation Loss AVG: 10.1686, lr: 0.001
Epoch [51/400], Training Loss: 5.5772, Validation Loss Current: 9.1730, Validation Loss AVG: 9.1730, lr: 0.001
Epoch [52/400], Training Loss: 4.5529, Validation Loss Current: 11.4182, Validation Loss AVG: 11.4182, lr: 0.001
Epoch [53/400], Training Loss: 4.6336, Validation Loss Current: 10.9266, Validation Loss AVG: 10.9266, lr: 0.001
Epoch [54/400], Training Loss: 3.8900, Validation Loss Current: 10.2727, Validation Loss AVG: 10.2727, lr: 0.001
Epoch [55/400], Training Loss: 5.2322, Validation Loss Current: 10.3957, Validation Loss AVG: 10.3957, lr: 0.001
Epoch [56/400], Training Loss: 5.5034, Validation Loss Current: 11.7155, Validation Loss AVG: 11.7155, lr: 0.001
Epoch [57/400], Training Loss: 6.2376, Validation Loss Current: 14.2733, Validation Loss AVG: 14.2733, lr: 0.001
Epoch [58/400], Training Loss: 4.0712, Validation Loss Current: 11.8246, Validation Loss AVG: 11.8246, lr: 0.001
Epoch [59/400], Training Loss: 5.8037, Validation Loss Current: 11.0265, Validation Loss AVG: 11.0265, lr: 0.001
Epoch [60/400], Training Loss: 6.7028, Validation Loss Current: 10.1354, Validation Loss AVG: 10.1354, lr: 0.001
Epoch [61/400], Training Loss: 3.2965, Validation Loss Current: 10.5946, Validation Loss AVG: 10.5946, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 31 Best val accuracy: [0.22434210526315787, 0.24342105263157893, 0.27171052631578946, 0.3006578947368421, 0.3154605263157895, 0.26743421052631583, 0.3315789473684211, 0.3180921052631579, 0.3338815789473684, 0.39144736842105265, 0.4029605263157895, 0.38651315789473684, 0.3967105263157895, 0.36973684210526314, 0.40361842105263157, 0.39572368421052634, 0.41447368421052627, 0.4233552631578947, 0.3828947368421053, 0.44572368421052627, 0.42631578947368426, 0.43157894736842106, 0.43256578947368424, 0.42960526315789477, 0.4394736842105263, 0.44375, 0.4414473684210526, 0.42927631578947373, 0.45394736842105265, 0.4016447368421052, 0.47105263157894744, 0.3740131578947369, 0.3680921052631579, 0.45559210526315785, 0.4213815789473684, 0.42828947368421055, 0.40855263157894744, 0.4338815789473685, 0.3680921052631579, 0.4740131578947368, 0.42993421052631575, 0.3960526315789473, 0.4335526315789474, 0.45953947368421055, 0.45625, 0.4430921052631579, 0.44506578947368425, 0.43980263157894733, 0.42434210526315785, 0.40328947368421053, 0.46052631578947373, 0.42302631578947364, 0.42796052631578946, 0.4509868421052632, 0.44375, 0.4029605263157895, 0.36907894736842106, 0.4082236842105263, 0.42434210526315785, 0.43980263157894733, 0.45559210526315785] Best val loss: 7.641391801834106


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.8605, Validation Loss Current: 10.0113, Validation Loss AVG: 10.0989, lr: 0.001
Epoch [2/400], Training Loss: 39.2471, Validation Loss Current: 9.7724, Validation Loss AVG: 10.2683, lr: 0.001
Epoch [3/400], Training Loss: 36.7849, Validation Loss Current: 9.7194, Validation Loss AVG: 10.8785, lr: 0.001
Epoch [4/400], Training Loss: 36.3931, Validation Loss Current: 9.1329, Validation Loss AVG: 10.0123, lr: 0.001
Epoch [5/400], Training Loss: 35.0941, Validation Loss Current: 8.9454, Validation Loss AVG: 10.0992, lr: 0.001
Epoch [6/400], Training Loss: 35.0898, Validation Loss Current: 8.9280, Validation Loss AVG: 9.6109, lr: 0.001
Epoch [7/400], Training Loss: 33.0203, Validation Loss Current: 8.4848, Validation Loss AVG: 10.8666, lr: 0.001
Epoch [8/400], Training Loss: 31.6920, Validation Loss Current: 8.1047, Validation Loss AVG: 10.1496, lr: 0.001
Epoch [9/400], Training Loss: 30.4561, Validation Loss Current: 7.9532, Validation Loss AVG: 9.6642, lr: 0.001
Epoch [10/400], Training Loss: 28.1895, Validation Loss Current: 7.6400, Validation Loss AVG: 10.5443, lr: 0.001
Epoch [11/400], Training Loss: 27.3849, Validation Loss Current: 8.0480, Validation Loss AVG: 10.5148, lr: 0.001
Epoch [12/400], Training Loss: 27.7132, Validation Loss Current: 7.5448, Validation Loss AVG: 10.0633, lr: 0.001
Epoch [13/400], Training Loss: 27.5660, Validation Loss Current: 7.1173, Validation Loss AVG: 9.8060, lr: 0.001
Epoch [14/400], Training Loss: 26.7711, Validation Loss Current: 7.2041, Validation Loss AVG: 10.5237, lr: 0.001
Epoch [15/400], Training Loss: 25.1538, Validation Loss Current: 7.0766, Validation Loss AVG: 10.4488, lr: 0.001
Epoch [16/400], Training Loss: 25.4573, Validation Loss Current: 7.5801, Validation Loss AVG: 14.7086, lr: 0.001
Epoch [17/400], Training Loss: 24.0060, Validation Loss Current: 6.9471, Validation Loss AVG: 8.7973, lr: 0.001
Epoch [18/400], Training Loss: 22.9231, Validation Loss Current: 7.0596, Validation Loss AVG: 8.9915, lr: 0.001
Epoch [19/400], Training Loss: 21.5462, Validation Loss Current: 7.3686, Validation Loss AVG: 9.5394, lr: 0.001
Epoch [20/400], Training Loss: 20.9186, Validation Loss Current: 6.5450, Validation Loss AVG: 8.2840, lr: 0.001
Epoch [21/400], Training Loss: 20.4301, Validation Loss Current: 6.5146, Validation Loss AVG: 8.6895, lr: 0.001
Epoch [22/400], Training Loss: 19.0616, Validation Loss Current: 6.6157, Validation Loss AVG: 9.2348, lr: 0.001
Epoch [23/400], Training Loss: 19.1283, Validation Loss Current: 7.0521, Validation Loss AVG: 9.1849, lr: 0.001
Epoch [24/400], Training Loss: 20.8890, Validation Loss Current: 7.3296, Validation Loss AVG: 9.0348, lr: 0.001
Epoch [25/400], Training Loss: 19.6155, Validation Loss Current: 6.9862, Validation Loss AVG: 9.6394, lr: 0.001
Epoch [26/400], Training Loss: 18.6241, Validation Loss Current: 6.8371, Validation Loss AVG: 8.7537, lr: 0.001
Epoch [27/400], Training Loss: 17.3088, Validation Loss Current: 6.0855, Validation Loss AVG: 8.4891, lr: 0.001
Epoch [28/400], Training Loss: 16.5317, Validation Loss Current: 6.0226, Validation Loss AVG: 9.6849, lr: 0.001
Epoch [29/400], Training Loss: 15.7441, Validation Loss Current: 6.6799, Validation Loss AVG: 12.0966, lr: 0.001
Epoch [30/400], Training Loss: 19.3073, Validation Loss Current: 6.2763, Validation Loss AVG: 8.2573, lr: 0.001
Epoch [31/400], Training Loss: 16.8796, Validation Loss Current: 5.7583, Validation Loss AVG: 9.1519, lr: 0.001
Epoch [32/400], Training Loss: 15.3828, Validation Loss Current: 5.9739, Validation Loss AVG: 9.3089, lr: 0.001
Epoch [33/400], Training Loss: 15.7700, Validation Loss Current: 6.1518, Validation Loss AVG: 11.1170, lr: 0.001
Epoch [34/400], Training Loss: 14.8099, Validation Loss Current: 6.3272, Validation Loss AVG: 12.0346, lr: 0.001
Epoch [35/400], Training Loss: 12.8652, Validation Loss Current: 6.2225, Validation Loss AVG: 10.2677, lr: 0.001
Epoch [36/400], Training Loss: 11.9196, Validation Loss Current: 5.7019, Validation Loss AVG: 11.7677, lr: 0.001
Epoch [37/400], Training Loss: 11.5703, Validation Loss Current: 6.0597, Validation Loss AVG: 9.8076, lr: 0.001
Epoch [38/400], Training Loss: 10.9525, Validation Loss Current: 5.8642, Validation Loss AVG: 12.2413, lr: 0.001
Epoch [39/400], Training Loss: 9.9433, Validation Loss Current: 6.3647, Validation Loss AVG: 11.8423, lr: 0.001
Epoch [40/400], Training Loss: 9.0328, Validation Loss Current: 5.7339, Validation Loss AVG: 9.0470, lr: 0.001
Epoch [41/400], Training Loss: 7.9602, Validation Loss Current: 5.8626, Validation Loss AVG: 11.4829, lr: 0.001
Epoch [42/400], Training Loss: 7.1131, Validation Loss Current: 6.2542, Validation Loss AVG: 11.9410, lr: 0.001
Epoch [43/400], Training Loss: 7.8150, Validation Loss Current: 5.8310, Validation Loss AVG: 10.2773, lr: 0.001
Epoch [44/400], Training Loss: 7.6505, Validation Loss Current: 6.1001, Validation Loss AVG: 10.2652, lr: 0.001
Epoch [45/400], Training Loss: 7.9297, Validation Loss Current: 6.4062, Validation Loss AVG: 12.1883, lr: 0.001
Epoch [46/400], Training Loss: 6.7949, Validation Loss Current: 6.6503, Validation Loss AVG: 13.5246, lr: 0.001
Epoch [47/400], Training Loss: 6.1731, Validation Loss Current: 6.7510, Validation Loss AVG: 9.1238, lr: 0.001
Epoch [48/400], Training Loss: 5.5426, Validation Loss Current: 6.3520, Validation Loss AVG: 10.6270, lr: 0.001
Epoch [49/400], Training Loss: 6.8622, Validation Loss Current: 6.5193, Validation Loss AVG: 12.6953, lr: 0.001
Epoch [50/400], Training Loss: 7.2954, Validation Loss Current: 11.3738, Validation Loss AVG: 18.4380, lr: 0.001
Epoch [51/400], Training Loss: 12.6377, Validation Loss Current: 7.5058, Validation Loss AVG: 11.3181, lr: 0.001
Epoch [52/400], Training Loss: 8.7139, Validation Loss Current: 6.6939, Validation Loss AVG: 10.6681, lr: 0.001
Epoch [53/400], Training Loss: 7.4197, Validation Loss Current: 6.9320, Validation Loss AVG: 18.7768, lr: 0.001
Epoch [54/400], Training Loss: 6.0793, Validation Loss Current: 6.9121, Validation Loss AVG: 11.6776, lr: 0.001
Epoch [55/400], Training Loss: 9.1380, Validation Loss Current: 8.6466, Validation Loss AVG: 11.3175, lr: 0.001
Epoch [56/400], Training Loss: 5.2577, Validation Loss Current: 6.5944, Validation Loss AVG: 11.6006, lr: 0.001
Epoch [57/400], Training Loss: 3.3915, Validation Loss Current: 6.4573, Validation Loss AVG: 11.7845, lr: 0.001
Epoch [58/400], Training Loss: 3.4022, Validation Loss Current: 7.1364, Validation Loss AVG: 14.9924, lr: 0.001
Epoch [59/400], Training Loss: 5.0787, Validation Loss Current: 6.6723, Validation Loss AVG: 12.5724, lr: 0.001
Epoch [60/400], Training Loss: 5.7702, Validation Loss Current: 6.4673, Validation Loss AVG: 10.6477, lr: 0.001
Epoch [61/400], Training Loss: 4.5612, Validation Loss Current: 6.3177, Validation Loss AVG: 9.5419, lr: 0.001
Epoch [62/400], Training Loss: 2.7483, Validation Loss Current: 7.1563, Validation Loss AVG: 13.4740, lr: 0.001
Epoch [63/400], Training Loss: 2.6575, Validation Loss Current: 6.8585, Validation Loss AVG: 14.2832, lr: 0.001
Epoch [64/400], Training Loss: 4.5196, Validation Loss Current: 7.0705, Validation Loss AVG: 9.7119, lr: 0.001
Epoch [65/400], Training Loss: 5.8422, Validation Loss Current: 7.3413, Validation Loss AVG: 11.3325, lr: 0.001
Epoch [66/400], Training Loss: 4.7435, Validation Loss Current: 9.5084, Validation Loss AVG: 19.0614, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 36 Best val accuracy: [0.24342105263157895, 0.26151315789473684, 0.31085526315789475, 0.3717105263157895, 0.36348684210526316, 0.37335526315789475, 0.3963815789473684, 0.45723684210526316, 0.4407894736842105, 0.46381578947368424, 0.42598684210526316, 0.4588815789473684, 0.5049342105263158, 0.5, 0.506578947368421, 0.4819078947368421, 0.524671052631579, 0.524671052631579, 0.4786184210526316, 0.5542763157894737, 0.5444078947368421, 0.5460526315789473, 0.5148026315789473, 0.5148026315789473, 0.53125, 0.537828947368421, 0.5888157894736842, 0.5838815789473685, 0.5394736842105263, 0.5641447368421053, 0.6085526315789473, 0.5904605263157895, 0.5822368421052632, 0.5723684210526315, 0.5805921052631579, 0.618421052631579, 0.6036184210526315, 0.59375, 0.5904605263157895, 0.6134868421052632, 0.6101973684210527, 0.5904605263157895, 0.6118421052631579, 0.6085526315789473, 0.6069078947368421, 0.5740131578947368, 0.5855263157894737, 0.5970394736842105, 0.5970394736842105, 0.4407894736842105, 0.5756578947368421, 0.5838815789473685, 0.600328947368421, 0.5822368421052632, 0.5180921052631579, 0.6118421052631579, 0.6167763157894737, 0.5625, 0.5970394736842105, 0.6151315789473685, 0.6036184210526315, 0.6134868421052632, 0.5740131578947368, 0.6151315789473685, 0.5822368421052632, 0.524671052631579] Best val loss: 5.701890468597412


Fold: 3
----- Training resnet18 with sequence: [0.2] -----
Current group: 0.2
Epoch [1/400], Training Loss: 41.0177, Validation Loss Current: 10.0683, Validation Loss AVG: 10.0683, lr: 0.001
Epoch [2/400], Training Loss: 40.8286, Validation Loss Current: 10.1925, Validation Loss AVG: 10.1925, lr: 0.001
Epoch [3/400], Training Loss: 38.4448, Validation Loss Current: 10.3804, Validation Loss AVG: 10.3804, lr: 0.001
Epoch [4/400], Training Loss: 38.3787, Validation Loss Current: 11.1197, Validation Loss AVG: 11.1197, lr: 0.001
Epoch [5/400], Training Loss: 37.1011, Validation Loss Current: 11.2173, Validation Loss AVG: 11.2173, lr: 0.001
Epoch [6/400], Training Loss: 36.0573, Validation Loss Current: 10.3406, Validation Loss AVG: 10.3406, lr: 0.001
Epoch [7/400], Training Loss: 34.7761, Validation Loss Current: 10.3027, Validation Loss AVG: 10.3027, lr: 0.001
Epoch [8/400], Training Loss: 34.4532, Validation Loss Current: 11.1383, Validation Loss AVG: 11.1383, lr: 0.001
Epoch [9/400], Training Loss: 33.1136, Validation Loss Current: 10.7101, Validation Loss AVG: 10.7101, lr: 0.001
Epoch [10/400], Training Loss: 33.0593, Validation Loss Current: 10.7133, Validation Loss AVG: 10.7133, lr: 0.001
Epoch [11/400], Training Loss: 31.6166, Validation Loss Current: 10.1734, Validation Loss AVG: 10.1734, lr: 0.001
Epoch [12/400], Training Loss: 31.6522, Validation Loss Current: 10.5452, Validation Loss AVG: 10.5452, lr: 0.001
Epoch [13/400], Training Loss: 30.4047, Validation Loss Current: 10.1402, Validation Loss AVG: 10.1402, lr: 0.001
Epoch [14/400], Training Loss: 28.9376, Validation Loss Current: 11.5702, Validation Loss AVG: 11.5702, lr: 0.001
Epoch [15/400], Training Loss: 29.6468, Validation Loss Current: 12.3703, Validation Loss AVG: 12.3703, lr: 0.001
Epoch [16/400], Training Loss: 28.4611, Validation Loss Current: 10.5924, Validation Loss AVG: 10.5924, lr: 0.001
Epoch [17/400], Training Loss: 27.0786, Validation Loss Current: 11.6556, Validation Loss AVG: 11.6556, lr: 0.001
Epoch [18/400], Training Loss: 25.1861, Validation Loss Current: 10.6458, Validation Loss AVG: 10.6458, lr: 0.001
Epoch [19/400], Training Loss: 25.2836, Validation Loss Current: 11.2856, Validation Loss AVG: 11.2856, lr: 0.001
Epoch [20/400], Training Loss: 24.9880, Validation Loss Current: 12.1767, Validation Loss AVG: 12.1767, lr: 0.001
Epoch [21/400], Training Loss: 24.5440, Validation Loss Current: 10.8329, Validation Loss AVG: 10.8329, lr: 0.001
Epoch [22/400], Training Loss: 23.5173, Validation Loss Current: 14.6348, Validation Loss AVG: 14.6348, lr: 0.001
Epoch [23/400], Training Loss: 22.8172, Validation Loss Current: 14.5669, Validation Loss AVG: 14.5669, lr: 0.001
Epoch [24/400], Training Loss: 24.0279, Validation Loss Current: 12.7194, Validation Loss AVG: 12.7194, lr: 0.001
Epoch [25/400], Training Loss: 21.1180, Validation Loss Current: 13.9960, Validation Loss AVG: 13.9960, lr: 0.001
Epoch [26/400], Training Loss: 19.9436, Validation Loss Current: 9.6859, Validation Loss AVG: 9.6859, lr: 0.001
Epoch [27/400], Training Loss: 17.9739, Validation Loss Current: 12.9434, Validation Loss AVG: 12.9434, lr: 0.001
Epoch [28/400], Training Loss: 16.3622, Validation Loss Current: 12.9601, Validation Loss AVG: 12.9601, lr: 0.001
Epoch [29/400], Training Loss: 15.5175, Validation Loss Current: 13.4306, Validation Loss AVG: 13.4306, lr: 0.001
Epoch [30/400], Training Loss: 14.8520, Validation Loss Current: 12.5655, Validation Loss AVG: 12.5655, lr: 0.001
Epoch [31/400], Training Loss: 16.3211, Validation Loss Current: 20.4902, Validation Loss AVG: 20.4902, lr: 0.001
Epoch [32/400], Training Loss: 18.1892, Validation Loss Current: 13.0153, Validation Loss AVG: 13.0153, lr: 0.001
Epoch [33/400], Training Loss: 16.2080, Validation Loss Current: 13.7086, Validation Loss AVG: 13.7086, lr: 0.001
Epoch [34/400], Training Loss: 15.4209, Validation Loss Current: 14.6471, Validation Loss AVG: 14.6471, lr: 0.001
Epoch [35/400], Training Loss: 14.1981, Validation Loss Current: 17.9002, Validation Loss AVG: 17.9002, lr: 0.001
Epoch [36/400], Training Loss: 12.6637, Validation Loss Current: 15.5216, Validation Loss AVG: 15.5216, lr: 0.001
Epoch [37/400], Training Loss: 11.3637, Validation Loss Current: 14.3713, Validation Loss AVG: 14.3713, lr: 0.001
Epoch [38/400], Training Loss: 9.7264, Validation Loss Current: 16.1907, Validation Loss AVG: 16.1907, lr: 0.001
Epoch [39/400], Training Loss: 9.7310, Validation Loss Current: 14.1489, Validation Loss AVG: 14.1489, lr: 0.001
Epoch [40/400], Training Loss: 11.6508, Validation Loss Current: 17.1079, Validation Loss AVG: 17.1079, lr: 0.001
Epoch [41/400], Training Loss: 11.5280, Validation Loss Current: 20.1618, Validation Loss AVG: 20.1618, lr: 0.001
Epoch [42/400], Training Loss: 12.0166, Validation Loss Current: 20.2923, Validation Loss AVG: 20.2923, lr: 0.001
Epoch [43/400], Training Loss: 19.3852, Validation Loss Current: 33.7092, Validation Loss AVG: 33.7092, lr: 0.001
Epoch [44/400], Training Loss: 15.5131, Validation Loss Current: 15.6688, Validation Loss AVG: 15.6688, lr: 0.001
Epoch [45/400], Training Loss: 17.0778, Validation Loss Current: 22.1948, Validation Loss AVG: 22.1948, lr: 0.001
Epoch [46/400], Training Loss: 15.7851, Validation Loss Current: 23.3925, Validation Loss AVG: 23.3925, lr: 0.001
Epoch [47/400], Training Loss: 12.1307, Validation Loss Current: 17.2702, Validation Loss AVG: 17.2702, lr: 0.001
Epoch [48/400], Training Loss: 9.7652, Validation Loss Current: 14.9914, Validation Loss AVG: 14.9914, lr: 0.001
Epoch [49/400], Training Loss: 7.2623, Validation Loss Current: 17.8755, Validation Loss AVG: 17.8755, lr: 0.001
Epoch [50/400], Training Loss: 11.6182, Validation Loss Current: 21.0304, Validation Loss AVG: 21.0304, lr: 0.001
Epoch [51/400], Training Loss: 8.7244, Validation Loss Current: 18.4985, Validation Loss AVG: 18.4985, lr: 0.001
Epoch [52/400], Training Loss: 7.3822, Validation Loss Current: 19.6205, Validation Loss AVG: 19.6205, lr: 0.001
Epoch [53/400], Training Loss: 8.9877, Validation Loss Current: 16.0764, Validation Loss AVG: 16.0764, lr: 0.001
Epoch [54/400], Training Loss: 5.8708, Validation Loss Current: 19.4619, Validation Loss AVG: 19.4619, lr: 0.001
Epoch [55/400], Training Loss: 4.0003, Validation Loss Current: 16.5385, Validation Loss AVG: 16.5385, lr: 0.001
Epoch [56/400], Training Loss: 5.1540, Validation Loss Current: 18.0889, Validation Loss AVG: 18.0889, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 26 Best val accuracy: [0.23717105263157895, 0.22828947368421054, 0.21151315789473682, 0.2013157894736842, 0.19111842105263158, 0.2542763157894737, 0.26118421052631585, 0.2588815789473684, 0.24769736842105267, 0.2756578947368421, 0.31546052631578947, 0.2740131578947368, 0.3026315789473685, 0.2802631578947369, 0.22269736842105264, 0.3026315789473684, 0.26348684210526313, 0.3111842105263158, 0.2911184210526316, 0.2842105263157895, 0.33453947368421055, 0.31381578947368427, 0.31480263157894733, 0.28059210526315786, 0.27861842105263157, 0.3799342105263158, 0.3194078947368421, 0.3023026315789474, 0.29407894736842105, 0.3819078947368421, 0.2388157894736842, 0.34046052631578944, 0.2621710526315789, 0.3631578947368421, 0.2555921052631579, 0.34144736842105267, 0.3384868421052632, 0.29407894736842105, 0.32763157894736844, 0.3388157894736842, 0.2766447368421053, 0.2375, 0.22138157894736846, 0.29309210526315793, 0.19375, 0.27401315789473685, 0.30526315789473685, 0.3134868421052631, 0.26710526315789473, 0.2730263157894737, 0.3434210526315789, 0.28848684210526315, 0.32335526315789476, 0.34111842105263157, 0.3305921052631579, 0.3069078947368421] Best val loss: 9.685877633094787


----- Training resnet18 with sequence: [0.8] -----
Current group: 0.8
Epoch [1/400], Training Loss: 41.0218, Validation Loss Current: 10.0266, Validation Loss AVG: 10.0266, lr: 0.001
Epoch [2/400], Training Loss: 39.0264, Validation Loss Current: 9.8119, Validation Loss AVG: 9.8119, lr: 0.001
Epoch [3/400], Training Loss: 38.4180, Validation Loss Current: 9.7620, Validation Loss AVG: 9.7620, lr: 0.001
Epoch [4/400], Training Loss: 36.2464, Validation Loss Current: 9.7167, Validation Loss AVG: 9.7167, lr: 0.001
Epoch [5/400], Training Loss: 35.2210, Validation Loss Current: 9.2352, Validation Loss AVG: 9.2352, lr: 0.001
Epoch [6/400], Training Loss: 33.9386, Validation Loss Current: 9.1312, Validation Loss AVG: 9.1312, lr: 0.001
Epoch [7/400], Training Loss: 32.8241, Validation Loss Current: 8.9399, Validation Loss AVG: 8.9399, lr: 0.001
Epoch [8/400], Training Loss: 31.1686, Validation Loss Current: 9.5342, Validation Loss AVG: 9.5342, lr: 0.001
Epoch [9/400], Training Loss: 29.8252, Validation Loss Current: 9.0190, Validation Loss AVG: 9.0190, lr: 0.001
Epoch [10/400], Training Loss: 29.6666, Validation Loss Current: 9.0808, Validation Loss AVG: 9.0808, lr: 0.001
Epoch [11/400], Training Loss: 29.9633, Validation Loss Current: 8.6939, Validation Loss AVG: 8.6939, lr: 0.001
Epoch [12/400], Training Loss: 28.0212, Validation Loss Current: 9.1654, Validation Loss AVG: 9.1654, lr: 0.001
Epoch [13/400], Training Loss: 26.6343, Validation Loss Current: 12.6175, Validation Loss AVG: 12.6175, lr: 0.001
Epoch [14/400], Training Loss: 26.1139, Validation Loss Current: 8.7022, Validation Loss AVG: 8.7022, lr: 0.001
Epoch [15/400], Training Loss: 26.6189, Validation Loss Current: 8.2756, Validation Loss AVG: 8.2756, lr: 0.001
Epoch [16/400], Training Loss: 24.5119, Validation Loss Current: 11.4561, Validation Loss AVG: 11.4561, lr: 0.001
Epoch [17/400], Training Loss: 23.6829, Validation Loss Current: 8.6337, Validation Loss AVG: 8.6337, lr: 0.001
Epoch [18/400], Training Loss: 23.6544, Validation Loss Current: 14.1406, Validation Loss AVG: 14.1406, lr: 0.001
Epoch [19/400], Training Loss: 23.0328, Validation Loss Current: 8.2340, Validation Loss AVG: 8.2340, lr: 0.001
Epoch [20/400], Training Loss: 21.7606, Validation Loss Current: 11.3453, Validation Loss AVG: 11.3453, lr: 0.001
Epoch [21/400], Training Loss: 20.4248, Validation Loss Current: 8.3007, Validation Loss AVG: 8.3007, lr: 0.001
Epoch [22/400], Training Loss: 19.6167, Validation Loss Current: 8.0297, Validation Loss AVG: 8.0297, lr: 0.001
Epoch [23/400], Training Loss: 18.9460, Validation Loss Current: 9.2857, Validation Loss AVG: 9.2857, lr: 0.001
Epoch [24/400], Training Loss: 18.6662, Validation Loss Current: 9.7584, Validation Loss AVG: 9.7584, lr: 0.001
Epoch [25/400], Training Loss: 18.3844, Validation Loss Current: 15.0134, Validation Loss AVG: 15.0134, lr: 0.001
Epoch [26/400], Training Loss: 17.4294, Validation Loss Current: 11.0459, Validation Loss AVG: 11.0459, lr: 0.001
Epoch [27/400], Training Loss: 16.6923, Validation Loss Current: 10.0653, Validation Loss AVG: 10.0653, lr: 0.001
Epoch [28/400], Training Loss: 16.2007, Validation Loss Current: 9.8287, Validation Loss AVG: 9.8287, lr: 0.001
Epoch [29/400], Training Loss: 15.4266, Validation Loss Current: 15.4219, Validation Loss AVG: 15.4219, lr: 0.001
Epoch [30/400], Training Loss: 14.1683, Validation Loss Current: 8.0922, Validation Loss AVG: 8.0922, lr: 0.001
Epoch [31/400], Training Loss: 13.5506, Validation Loss Current: 8.5118, Validation Loss AVG: 8.5118, lr: 0.001
Epoch [32/400], Training Loss: 13.9102, Validation Loss Current: 10.3587, Validation Loss AVG: 10.3587, lr: 0.001
Epoch [33/400], Training Loss: 13.1720, Validation Loss Current: 8.6274, Validation Loss AVG: 8.6274, lr: 0.001
Epoch [34/400], Training Loss: 11.3815, Validation Loss Current: 9.9922, Validation Loss AVG: 9.9922, lr: 0.001
Epoch [35/400], Training Loss: 12.2208, Validation Loss Current: 9.1163, Validation Loss AVG: 9.1163, lr: 0.001
Epoch [36/400], Training Loss: 13.6548, Validation Loss Current: 10.5500, Validation Loss AVG: 10.5500, lr: 0.001
Epoch [37/400], Training Loss: 11.0410, Validation Loss Current: 8.3074, Validation Loss AVG: 8.3074, lr: 0.001
Epoch [38/400], Training Loss: 9.9308, Validation Loss Current: 9.2361, Validation Loss AVG: 9.2361, lr: 0.001
Epoch [39/400], Training Loss: 9.7704, Validation Loss Current: 8.8537, Validation Loss AVG: 8.8537, lr: 0.001
Epoch [40/400], Training Loss: 8.3938, Validation Loss Current: 11.5271, Validation Loss AVG: 11.5271, lr: 0.001
Epoch [41/400], Training Loss: 11.7355, Validation Loss Current: 8.9528, Validation Loss AVG: 8.9528, lr: 0.001
Epoch [42/400], Training Loss: 9.1333, Validation Loss Current: 10.5619, Validation Loss AVG: 10.5619, lr: 0.001
Epoch [43/400], Training Loss: 8.1653, Validation Loss Current: 9.3210, Validation Loss AVG: 9.3210, lr: 0.001
Epoch [44/400], Training Loss: 7.4271, Validation Loss Current: 9.8146, Validation Loss AVG: 9.8146, lr: 0.001
Epoch [45/400], Training Loss: 6.1959, Validation Loss Current: 12.2467, Validation Loss AVG: 12.2467, lr: 0.001
Epoch [46/400], Training Loss: 7.3075, Validation Loss Current: 11.1635, Validation Loss AVG: 11.1635, lr: 0.001
Epoch [47/400], Training Loss: 6.4946, Validation Loss Current: 10.6040, Validation Loss AVG: 10.6040, lr: 0.001
Epoch [48/400], Training Loss: 7.2130, Validation Loss Current: 11.5780, Validation Loss AVG: 11.5780, lr: 0.001
Epoch [49/400], Training Loss: 6.6490, Validation Loss Current: 14.1311, Validation Loss AVG: 14.1311, lr: 0.001
Epoch [50/400], Training Loss: 10.0588, Validation Loss Current: 11.9892, Validation Loss AVG: 11.9892, lr: 0.001
Epoch [51/400], Training Loss: 5.8180, Validation Loss Current: 12.8923, Validation Loss AVG: 12.8923, lr: 0.001
Epoch [52/400], Training Loss: 3.5896, Validation Loss Current: 10.6579, Validation Loss AVG: 10.6579, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 22 Best val accuracy: [0.23782894736842106, 0.2690789473684211, 0.2763157894736842, 0.30723684210526314, 0.3223684210526316, 0.34111842105263157, 0.3513157894736842, 0.33453947368421055, 0.34572368421052635, 0.3578947368421053, 0.3875, 0.35460526315789476, 0.3269736842105263, 0.3993421052631579, 0.4319078947368421, 0.37203947368421053, 0.4046052631578947, 0.3236842105263158, 0.4342105263157895, 0.3697368421052632, 0.4322368421052632, 0.47302631578947374, 0.4052631578947368, 0.4220394736842105, 0.3671052631578947, 0.34078947368421053, 0.41875, 0.43717105263157896, 0.3973684210526316, 0.4588815789473684, 0.47105263157894744, 0.4046052631578948, 0.45032894736842105, 0.4447368421052632, 0.4269736842105264, 0.4309210526315789, 0.4743421052631579, 0.44506578947368414, 0.46019736842105263, 0.41381578947368425, 0.4302631578947368, 0.4430921052631579, 0.47302631578947363, 0.45230263157894735, 0.4414473684210526, 0.4197368421052632, 0.4292763157894736, 0.4200657894736842, 0.3950657894736842, 0.4233552631578947, 0.4098684210526316, 0.44868421052631574] Best val loss: 8.029674196243286


----- Training resnet18 with sequence: [0.4] -----
Current group: 0.4
Epoch [1/400], Training Loss: 41.5783, Validation Loss Current: 10.1013, Validation Loss AVG: 10.1013, lr: 0.001
Epoch [2/400], Training Loss: 39.3708, Validation Loss Current: 10.0147, Validation Loss AVG: 10.0147, lr: 0.001
Epoch [3/400], Training Loss: 39.8553, Validation Loss Current: 9.8289, Validation Loss AVG: 9.8289, lr: 0.001
Epoch [4/400], Training Loss: 38.5697, Validation Loss Current: 9.6238, Validation Loss AVG: 9.6238, lr: 0.001
Epoch [5/400], Training Loss: 37.9975, Validation Loss Current: 9.6163, Validation Loss AVG: 9.6163, lr: 0.001
Epoch [6/400], Training Loss: 37.2405, Validation Loss Current: 9.5730, Validation Loss AVG: 9.5730, lr: 0.001
Epoch [7/400], Training Loss: 35.4419, Validation Loss Current: 9.3821, Validation Loss AVG: 9.3821, lr: 0.001
Epoch [8/400], Training Loss: 34.2988, Validation Loss Current: 9.3570, Validation Loss AVG: 9.3570, lr: 0.001
Epoch [9/400], Training Loss: 34.5587, Validation Loss Current: 9.2474, Validation Loss AVG: 9.2474, lr: 0.001
Epoch [10/400], Training Loss: 32.6566, Validation Loss Current: 8.9341, Validation Loss AVG: 8.9341, lr: 0.001
Epoch [11/400], Training Loss: 31.7165, Validation Loss Current: 9.1846, Validation Loss AVG: 9.1846, lr: 0.001
Epoch [12/400], Training Loss: 31.3577, Validation Loss Current: 9.1423, Validation Loss AVG: 9.1423, lr: 0.001
Epoch [13/400], Training Loss: 30.0445, Validation Loss Current: 8.9404, Validation Loss AVG: 8.9404, lr: 0.001
Epoch [14/400], Training Loss: 28.8291, Validation Loss Current: 8.7055, Validation Loss AVG: 8.7055, lr: 0.001
Epoch [15/400], Training Loss: 28.8163, Validation Loss Current: 8.6303, Validation Loss AVG: 8.6303, lr: 0.001
Epoch [16/400], Training Loss: 26.9170, Validation Loss Current: 8.7719, Validation Loss AVG: 8.7719, lr: 0.001
Epoch [17/400], Training Loss: 27.0039, Validation Loss Current: 9.2667, Validation Loss AVG: 9.2667, lr: 0.001
Epoch [18/400], Training Loss: 25.3148, Validation Loss Current: 10.6365, Validation Loss AVG: 10.6365, lr: 0.001
Epoch [19/400], Training Loss: 24.7515, Validation Loss Current: 8.2586, Validation Loss AVG: 8.2586, lr: 0.001
Epoch [20/400], Training Loss: 24.5003, Validation Loss Current: 8.5898, Validation Loss AVG: 8.5898, lr: 0.001
Epoch [21/400], Training Loss: 23.1072, Validation Loss Current: 12.6747, Validation Loss AVG: 12.6747, lr: 0.001
Epoch [22/400], Training Loss: 22.3878, Validation Loss Current: 9.9663, Validation Loss AVG: 9.9663, lr: 0.001
Epoch [23/400], Training Loss: 22.2071, Validation Loss Current: 8.3092, Validation Loss AVG: 8.3092, lr: 0.001
Epoch [24/400], Training Loss: 22.3384, Validation Loss Current: 11.7682, Validation Loss AVG: 11.7682, lr: 0.001
Epoch [25/400], Training Loss: 22.4982, Validation Loss Current: 8.7843, Validation Loss AVG: 8.7843, lr: 0.001
Epoch [26/400], Training Loss: 20.1450, Validation Loss Current: 10.7026, Validation Loss AVG: 10.7026, lr: 0.001
Epoch [27/400], Training Loss: 19.7806, Validation Loss Current: 8.1740, Validation Loss AVG: 8.1740, lr: 0.001
Epoch [28/400], Training Loss: 19.8841, Validation Loss Current: 13.7264, Validation Loss AVG: 13.7264, lr: 0.001
Epoch [29/400], Training Loss: 22.1002, Validation Loss Current: 11.3934, Validation Loss AVG: 11.3934, lr: 0.001
Epoch [30/400], Training Loss: 18.7820, Validation Loss Current: 8.2596, Validation Loss AVG: 8.2596, lr: 0.001
Epoch [31/400], Training Loss: 17.8883, Validation Loss Current: 8.8370, Validation Loss AVG: 8.8370, lr: 0.001
Epoch [32/400], Training Loss: 16.7274, Validation Loss Current: 8.8742, Validation Loss AVG: 8.8742, lr: 0.001
Epoch [33/400], Training Loss: 16.9355, Validation Loss Current: 11.2550, Validation Loss AVG: 11.2550, lr: 0.001
Epoch [34/400], Training Loss: 16.1032, Validation Loss Current: 8.3347, Validation Loss AVG: 8.3347, lr: 0.001
Epoch [35/400], Training Loss: 14.0913, Validation Loss Current: 10.1052, Validation Loss AVG: 10.1052, lr: 0.001
Epoch [36/400], Training Loss: 15.0276, Validation Loss Current: 15.6822, Validation Loss AVG: 15.6822, lr: 0.001
Epoch [37/400], Training Loss: 13.2244, Validation Loss Current: 9.1324, Validation Loss AVG: 9.1324, lr: 0.001
Epoch [38/400], Training Loss: 11.7191, Validation Loss Current: 10.2618, Validation Loss AVG: 10.2618, lr: 0.001
Epoch [39/400], Training Loss: 10.6715, Validation Loss Current: 9.6644, Validation Loss AVG: 9.6644, lr: 0.001
Epoch [40/400], Training Loss: 10.2380, Validation Loss Current: 9.8847, Validation Loss AVG: 9.8847, lr: 0.001
Epoch [41/400], Training Loss: 12.3971, Validation Loss Current: 11.1553, Validation Loss AVG: 11.1553, lr: 0.001
Epoch [42/400], Training Loss: 11.8983, Validation Loss Current: 9.5390, Validation Loss AVG: 9.5390, lr: 0.001
Epoch [43/400], Training Loss: 8.3821, Validation Loss Current: 9.3762, Validation Loss AVG: 9.3762, lr: 0.001
Epoch [44/400], Training Loss: 9.6354, Validation Loss Current: 9.9610, Validation Loss AVG: 9.9610, lr: 0.001
Epoch [45/400], Training Loss: 8.5072, Validation Loss Current: 9.3155, Validation Loss AVG: 9.3155, lr: 0.001
Epoch [46/400], Training Loss: 9.0659, Validation Loss Current: 12.8342, Validation Loss AVG: 12.8342, lr: 0.001
Epoch [47/400], Training Loss: 10.0640, Validation Loss Current: 14.7091, Validation Loss AVG: 14.7091, lr: 0.001
Epoch [48/400], Training Loss: 8.4291, Validation Loss Current: 9.6816, Validation Loss AVG: 9.6816, lr: 0.001
Epoch [49/400], Training Loss: 6.2554, Validation Loss Current: 10.6277, Validation Loss AVG: 10.6277, lr: 0.001
Epoch [50/400], Training Loss: 6.6377, Validation Loss Current: 11.3513, Validation Loss AVG: 11.3513, lr: 0.001
Epoch [51/400], Training Loss: 8.8331, Validation Loss Current: 10.3873, Validation Loss AVG: 10.3873, lr: 0.001
Epoch [52/400], Training Loss: 5.6241, Validation Loss Current: 12.4895, Validation Loss AVG: 12.4895, lr: 0.001
Epoch [53/400], Training Loss: 6.0452, Validation Loss Current: 10.9334, Validation Loss AVG: 10.9334, lr: 0.001
Epoch [54/400], Training Loss: 5.7687, Validation Loss Current: 10.8012, Validation Loss AVG: 10.8012, lr: 0.001
Epoch [55/400], Training Loss: 6.7023, Validation Loss Current: 11.1280, Validation Loss AVG: 11.1280, lr: 0.001
Epoch [56/400], Training Loss: 4.6548, Validation Loss Current: 11.5662, Validation Loss AVG: 11.5662, lr: 0.001
Epoch [57/400], Training Loss: 3.9090, Validation Loss Current: 10.8687, Validation Loss AVG: 10.8687, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 27 Best val accuracy: [0.16907894736842105, 0.23552631578947367, 0.24868421052631579, 0.2523026315789474, 0.26052631578947366, 0.28157894736842104, 0.31480263157894733, 0.3026315789473684, 0.30625, 0.36217105263157895, 0.3223684210526316, 0.3115131578947369, 0.3628289473684211, 0.37565789473684214, 0.3904605263157895, 0.3832236842105263, 0.38552631578947366, 0.33092105263157895, 0.4269736842105264, 0.4131578947368421, 0.34769736842105264, 0.33651315789473685, 0.4322368421052632, 0.34539473684210525, 0.3661184210526316, 0.3736842105263158, 0.43717105263157896, 0.3269736842105263, 0.38256578947368425, 0.4180921052631579, 0.43355263157894736, 0.4440789473684211, 0.39276315789473687, 0.4552631578947368, 0.3582236842105263, 0.34440789473684214, 0.43157894736842095, 0.4421052631578948, 0.3828947368421053, 0.40756578947368427, 0.4213815789473684, 0.40690789473684214, 0.39934210526315794, 0.4342105263157895, 0.45855263157894743, 0.3078947368421052, 0.30986842105263157, 0.44769736842105257, 0.4319078947368421, 0.38782894736842105, 0.44868421052631574, 0.4151315789473684, 0.3996710526315789, 0.41381578947368425, 0.4029605263157895, 0.4197368421052632, 0.4667763157894737] Best val loss: 8.173976635932922


----- Training resnet18 with sequence: [0.6] -----
Current group: 0.6
Epoch [1/400], Training Loss: 40.4569, Validation Loss Current: 10.0428, Validation Loss AVG: 10.0428, lr: 0.001
Epoch [2/400], Training Loss: 39.3699, Validation Loss Current: 9.8449, Validation Loss AVG: 9.8449, lr: 0.001
Epoch [3/400], Training Loss: 38.7319, Validation Loss Current: 9.8016, Validation Loss AVG: 9.8016, lr: 0.001
Epoch [4/400], Training Loss: 37.9334, Validation Loss Current: 9.5720, Validation Loss AVG: 9.5720, lr: 0.001
Epoch [5/400], Training Loss: 37.3017, Validation Loss Current: 9.3614, Validation Loss AVG: 9.3614, lr: 0.001
Epoch [6/400], Training Loss: 36.5496, Validation Loss Current: 9.3380, Validation Loss AVG: 9.3380, lr: 0.001
Epoch [7/400], Training Loss: 34.7504, Validation Loss Current: 9.0055, Validation Loss AVG: 9.0055, lr: 0.001
Epoch [8/400], Training Loss: 33.7233, Validation Loss Current: 8.8160, Validation Loss AVG: 8.8160, lr: 0.001
Epoch [9/400], Training Loss: 32.8307, Validation Loss Current: 8.8540, Validation Loss AVG: 8.8540, lr: 0.001
Epoch [10/400], Training Loss: 30.9451, Validation Loss Current: 8.5525, Validation Loss AVG: 8.5525, lr: 0.001
Epoch [11/400], Training Loss: 30.7049, Validation Loss Current: 8.4739, Validation Loss AVG: 8.4739, lr: 0.001
Epoch [12/400], Training Loss: 29.9732, Validation Loss Current: 8.4529, Validation Loss AVG: 8.4529, lr: 0.001
Epoch [13/400], Training Loss: 29.0088, Validation Loss Current: 8.3047, Validation Loss AVG: 8.3047, lr: 0.001
Epoch [14/400], Training Loss: 28.0568, Validation Loss Current: 8.1456, Validation Loss AVG: 8.1456, lr: 0.001
Epoch [15/400], Training Loss: 27.2630, Validation Loss Current: 8.5160, Validation Loss AVG: 8.5160, lr: 0.001
Epoch [16/400], Training Loss: 25.8557, Validation Loss Current: 8.0140, Validation Loss AVG: 8.0140, lr: 0.001
Epoch [17/400], Training Loss: 26.4742, Validation Loss Current: 8.3436, Validation Loss AVG: 8.3436, lr: 0.001
Epoch [18/400], Training Loss: 25.9601, Validation Loss Current: 8.3372, Validation Loss AVG: 8.3372, lr: 0.001
Epoch [19/400], Training Loss: 25.0679, Validation Loss Current: 8.1948, Validation Loss AVG: 8.1948, lr: 0.001
Epoch [20/400], Training Loss: 25.1803, Validation Loss Current: 8.3246, Validation Loss AVG: 8.3246, lr: 0.001
Epoch [21/400], Training Loss: 24.3628, Validation Loss Current: 8.3990, Validation Loss AVG: 8.3990, lr: 0.001
Epoch [22/400], Training Loss: 23.7062, Validation Loss Current: 8.1785, Validation Loss AVG: 8.1785, lr: 0.001
Epoch [23/400], Training Loss: 23.1272, Validation Loss Current: 8.6035, Validation Loss AVG: 8.6035, lr: 0.001
Epoch [24/400], Training Loss: 21.4997, Validation Loss Current: 7.7722, Validation Loss AVG: 7.7722, lr: 0.001
Epoch [25/400], Training Loss: 20.8181, Validation Loss Current: 7.7087, Validation Loss AVG: 7.7087, lr: 0.001
Epoch [26/400], Training Loss: 21.0063, Validation Loss Current: 8.3330, Validation Loss AVG: 8.3330, lr: 0.001
Epoch [27/400], Training Loss: 19.9702, Validation Loss Current: 8.1528, Validation Loss AVG: 8.1528, lr: 0.001
Epoch [28/400], Training Loss: 18.1984, Validation Loss Current: 7.7570, Validation Loss AVG: 7.7570, lr: 0.001
Epoch [29/400], Training Loss: 18.2127, Validation Loss Current: 8.3060, Validation Loss AVG: 8.3060, lr: 0.001
Epoch [30/400], Training Loss: 16.6795, Validation Loss Current: 7.9062, Validation Loss AVG: 7.9062, lr: 0.001
Epoch [31/400], Training Loss: 17.4324, Validation Loss Current: 8.1069, Validation Loss AVG: 8.1069, lr: 0.001
Epoch [32/400], Training Loss: 16.1224, Validation Loss Current: 9.0725, Validation Loss AVG: 9.0725, lr: 0.001
Epoch [33/400], Training Loss: 14.7753, Validation Loss Current: 8.7334, Validation Loss AVG: 8.7334, lr: 0.001
Epoch [34/400], Training Loss: 13.6206, Validation Loss Current: 8.9488, Validation Loss AVG: 8.9488, lr: 0.001
Epoch [35/400], Training Loss: 13.2925, Validation Loss Current: 8.3289, Validation Loss AVG: 8.3289, lr: 0.001
Epoch [36/400], Training Loss: 11.7428, Validation Loss Current: 9.4806, Validation Loss AVG: 9.4806, lr: 0.001
Epoch [37/400], Training Loss: 10.7778, Validation Loss Current: 9.9110, Validation Loss AVG: 9.9110, lr: 0.001
Epoch [38/400], Training Loss: 12.5617, Validation Loss Current: 12.0691, Validation Loss AVG: 12.0691, lr: 0.001
Epoch [39/400], Training Loss: 11.6255, Validation Loss Current: 10.8466, Validation Loss AVG: 10.8466, lr: 0.001
Epoch [40/400], Training Loss: 9.8631, Validation Loss Current: 9.0362, Validation Loss AVG: 9.0362, lr: 0.001
Epoch [41/400], Training Loss: 9.0810, Validation Loss Current: 8.5439, Validation Loss AVG: 8.5439, lr: 0.001
Epoch [42/400], Training Loss: 8.9575, Validation Loss Current: 9.3863, Validation Loss AVG: 9.3863, lr: 0.001
Epoch [43/400], Training Loss: 8.6034, Validation Loss Current: 9.3626, Validation Loss AVG: 9.3626, lr: 0.001
Epoch [44/400], Training Loss: 11.6752, Validation Loss Current: 10.7266, Validation Loss AVG: 10.7266, lr: 0.001
Epoch [45/400], Training Loss: 11.3200, Validation Loss Current: 10.3677, Validation Loss AVG: 10.3677, lr: 0.001
Epoch [46/400], Training Loss: 9.9306, Validation Loss Current: 9.4484, Validation Loss AVG: 9.4484, lr: 0.001
Epoch [47/400], Training Loss: 8.0199, Validation Loss Current: 9.6330, Validation Loss AVG: 9.6330, lr: 0.001
Epoch [48/400], Training Loss: 8.0980, Validation Loss Current: 9.2871, Validation Loss AVG: 9.2871, lr: 0.001
Epoch [49/400], Training Loss: 11.2611, Validation Loss Current: 12.9883, Validation Loss AVG: 12.9883, lr: 0.001
Epoch [50/400], Training Loss: 8.7533, Validation Loss Current: 10.1184, Validation Loss AVG: 10.1184, lr: 0.001
Epoch [51/400], Training Loss: 7.6134, Validation Loss Current: 9.3880, Validation Loss AVG: 9.3880, lr: 0.001
Epoch [52/400], Training Loss: 7.2897, Validation Loss Current: 10.2115, Validation Loss AVG: 10.2115, lr: 0.001
Epoch [53/400], Training Loss: 4.5105, Validation Loss Current: 10.4627, Validation Loss AVG: 10.4627, lr: 0.001
Epoch [54/400], Training Loss: 4.2893, Validation Loss Current: 9.6565, Validation Loss AVG: 9.6565, lr: 0.001
Epoch [55/400], Training Loss: 6.5283, Validation Loss Current: 10.3502, Validation Loss AVG: 10.3502, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 25 Best val accuracy: [0.24243421052631584, 0.2578947368421053, 0.2447368421052632, 0.2710526315789473, 0.3338815789473685, 0.33421052631578946, 0.3539473684210526, 0.3766447368421052, 0.3898026315789474, 0.3921052631578947, 0.3875, 0.3963815789473685, 0.42796052631578946, 0.40921052631578947, 0.4082236842105263, 0.43157894736842106, 0.40559210526315786, 0.42796052631578946, 0.4101973684210526, 0.43717105263157896, 0.42730263157894743, 0.41875, 0.4118421052631579, 0.4569078947368421, 0.46414473684210533, 0.44539473684210523, 0.44868421052631585, 0.4552631578947368, 0.4375, 0.46282894736842106, 0.43947368421052635, 0.45625, 0.4414473684210526, 0.4414473684210526, 0.46842105263157896, 0.43815789473684214, 0.42302631578947364, 0.3111842105263158, 0.43157894736842106, 0.4447368421052632, 0.4638157894736842, 0.4615131578947368, 0.46578947368421053, 0.41447368421052627, 0.40328947368421053, 0.4493421052631579, 0.4601973684210526, 0.41578947368421054, 0.3641447368421053, 0.4217105263157895, 0.44703947368421054, 0.44375, 0.4516447368421052, 0.46578947368421053, 0.46414473684210533] Best val loss: 7.70874674320221


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.1461, Validation Loss Current: 9.9790, Validation Loss AVG: 10.0326, lr: 0.001
Epoch [2/400], Training Loss: 39.2577, Validation Loss Current: 9.5835, Validation Loss AVG: 9.8426, lr: 0.001
Epoch [3/400], Training Loss: 36.2883, Validation Loss Current: 8.9969, Validation Loss AVG: 9.6385, lr: 0.001
Epoch [4/400], Training Loss: 35.2598, Validation Loss Current: 8.5777, Validation Loss AVG: 9.5050, lr: 0.001
Epoch [5/400], Training Loss: 35.1522, Validation Loss Current: 8.2901, Validation Loss AVG: 9.3692, lr: 0.001
Epoch [6/400], Training Loss: 33.9018, Validation Loss Current: 8.5162, Validation Loss AVG: 9.9006, lr: 0.001
Epoch [7/400], Training Loss: 32.0629, Validation Loss Current: 8.1388, Validation Loss AVG: 9.1968, lr: 0.001
Epoch [8/400], Training Loss: 31.3052, Validation Loss Current: 7.6331, Validation Loss AVG: 9.2750, lr: 0.001
Epoch [9/400], Training Loss: 28.9774, Validation Loss Current: 7.2429, Validation Loss AVG: 9.9191, lr: 0.001
Epoch [10/400], Training Loss: 28.3993, Validation Loss Current: 7.2024, Validation Loss AVG: 8.5130, lr: 0.001
Epoch [11/400], Training Loss: 27.5274, Validation Loss Current: 8.0852, Validation Loss AVG: 11.6710, lr: 0.001
Epoch [12/400], Training Loss: 27.6108, Validation Loss Current: 6.9969, Validation Loss AVG: 9.9707, lr: 0.001
Epoch [13/400], Training Loss: 27.0127, Validation Loss Current: 8.2755, Validation Loss AVG: 10.1400, lr: 0.001
Epoch [14/400], Training Loss: 27.0313, Validation Loss Current: 7.0954, Validation Loss AVG: 9.8328, lr: 0.001
Epoch [15/400], Training Loss: 25.8642, Validation Loss Current: 6.6045, Validation Loss AVG: 9.0642, lr: 0.001
Epoch [16/400], Training Loss: 24.0784, Validation Loss Current: 6.3166, Validation Loss AVG: 8.1330, lr: 0.001
Epoch [17/400], Training Loss: 24.3280, Validation Loss Current: 6.5739, Validation Loss AVG: 9.1766, lr: 0.001
Epoch [18/400], Training Loss: 23.9473, Validation Loss Current: 6.6920, Validation Loss AVG: 8.4568, lr: 0.001
Epoch [19/400], Training Loss: 22.5132, Validation Loss Current: 6.3330, Validation Loss AVG: 8.0966, lr: 0.001
Epoch [20/400], Training Loss: 22.4909, Validation Loss Current: 6.2987, Validation Loss AVG: 8.5210, lr: 0.001
Epoch [21/400], Training Loss: 21.1713, Validation Loss Current: 5.7418, Validation Loss AVG: 9.8142, lr: 0.001
Epoch [22/400], Training Loss: 19.5194, Validation Loss Current: 5.6461, Validation Loss AVG: 8.4642, lr: 0.001
Epoch [23/400], Training Loss: 18.8409, Validation Loss Current: 5.8156, Validation Loss AVG: 8.7358, lr: 0.001
Epoch [24/400], Training Loss: 17.5145, Validation Loss Current: 5.9215, Validation Loss AVG: 10.3373, lr: 0.001
Epoch [25/400], Training Loss: 16.9806, Validation Loss Current: 6.1634, Validation Loss AVG: 9.3676, lr: 0.001
Epoch [26/400], Training Loss: 16.7289, Validation Loss Current: 5.6809, Validation Loss AVG: 8.0893, lr: 0.001
Epoch [27/400], Training Loss: 16.5038, Validation Loss Current: 5.6327, Validation Loss AVG: 9.9006, lr: 0.001
Epoch [28/400], Training Loss: 18.2873, Validation Loss Current: 5.8655, Validation Loss AVG: 9.5152, lr: 0.001
Epoch [29/400], Training Loss: 14.7160, Validation Loss Current: 5.9260, Validation Loss AVG: 8.6398, lr: 0.001
Epoch [30/400], Training Loss: 12.9597, Validation Loss Current: 6.3679, Validation Loss AVG: 10.9796, lr: 0.001
Epoch [31/400], Training Loss: 12.4794, Validation Loss Current: 5.2678, Validation Loss AVG: 10.5752, lr: 0.001
Epoch [32/400], Training Loss: 11.1351, Validation Loss Current: 5.5316, Validation Loss AVG: 9.3397, lr: 0.001
Epoch [33/400], Training Loss: 10.8614, Validation Loss Current: 5.5229, Validation Loss AVG: 9.9699, lr: 0.001
Epoch [34/400], Training Loss: 11.3837, Validation Loss Current: 5.7471, Validation Loss AVG: 8.0621, lr: 0.001
Epoch [35/400], Training Loss: 10.4601, Validation Loss Current: 5.4278, Validation Loss AVG: 9.6391, lr: 0.001
Epoch [36/400], Training Loss: 9.0687, Validation Loss Current: 5.4853, Validation Loss AVG: 8.3048, lr: 0.001
Epoch [37/400], Training Loss: 9.6732, Validation Loss Current: 6.5139, Validation Loss AVG: 9.4198, lr: 0.001
Epoch [38/400], Training Loss: 10.8727, Validation Loss Current: 5.4578, Validation Loss AVG: 9.8656, lr: 0.001
Epoch [39/400], Training Loss: 7.7639, Validation Loss Current: 5.4547, Validation Loss AVG: 9.5007, lr: 0.001
Epoch [40/400], Training Loss: 8.5905, Validation Loss Current: 5.8613, Validation Loss AVG: 13.1495, lr: 0.001
Epoch [41/400], Training Loss: 7.4842, Validation Loss Current: 7.9131, Validation Loss AVG: 11.0330, lr: 0.001
Epoch [42/400], Training Loss: 8.4099, Validation Loss Current: 6.0350, Validation Loss AVG: 9.5592, lr: 0.001
Epoch [43/400], Training Loss: 8.5399, Validation Loss Current: 7.3942, Validation Loss AVG: 9.7885, lr: 0.001
Epoch [44/400], Training Loss: 9.0174, Validation Loss Current: 7.6803, Validation Loss AVG: 9.9112, lr: 0.001
Epoch [45/400], Training Loss: 8.1166, Validation Loss Current: 6.3838, Validation Loss AVG: 12.0926, lr: 0.001
Epoch [46/400], Training Loss: 7.3764, Validation Loss Current: 5.5181, Validation Loss AVG: 11.4443, lr: 0.001
Epoch [47/400], Training Loss: 5.1333, Validation Loss Current: 5.6051, Validation Loss AVG: 9.9185, lr: 0.001
Epoch [48/400], Training Loss: 6.6213, Validation Loss Current: 6.7237, Validation Loss AVG: 9.2452, lr: 0.001
Epoch [49/400], Training Loss: 6.5554, Validation Loss Current: 6.4499, Validation Loss AVG: 9.8180, lr: 0.001
Epoch [50/400], Training Loss: 7.0755, Validation Loss Current: 6.4733, Validation Loss AVG: 9.1833, lr: 0.001
Epoch [51/400], Training Loss: 7.5041, Validation Loss Current: 7.2781, Validation Loss AVG: 16.0057, lr: 0.001
Epoch [52/400], Training Loss: 9.5403, Validation Loss Current: 7.2125, Validation Loss AVG: 12.1931, lr: 0.001
Epoch [53/400], Training Loss: 6.3152, Validation Loss Current: 6.3283, Validation Loss AVG: 10.8759, lr: 0.001
Epoch [54/400], Training Loss: 5.2878, Validation Loss Current: 6.1927, Validation Loss AVG: 15.0805, lr: 0.001
Epoch [55/400], Training Loss: 7.1007, Validation Loss Current: 6.4173, Validation Loss AVG: 13.6512, lr: 0.001
Epoch [56/400], Training Loss: 9.7574, Validation Loss Current: 7.3426, Validation Loss AVG: 14.8088, lr: 0.001
Epoch [57/400], Training Loss: 5.8406, Validation Loss Current: 8.1997, Validation Loss AVG: 12.9442, lr: 0.001
Epoch [58/400], Training Loss: 4.1627, Validation Loss Current: 5.9664, Validation Loss AVG: 10.3415, lr: 0.001
Epoch [59/400], Training Loss: 5.8272, Validation Loss Current: 6.9385, Validation Loss AVG: 11.4611, lr: 0.001
Epoch [60/400], Training Loss: 5.0766, Validation Loss Current: 5.7884, Validation Loss AVG: 14.9491, lr: 0.001
Epoch [61/400], Training Loss: 5.2327, Validation Loss Current: 7.0235, Validation Loss AVG: 17.1000, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 31 Best val accuracy: [0.24013157894736842, 0.3404605263157895, 0.36348684210526316, 0.3815789473684211, 0.42269736842105265, 0.4029605263157895, 0.40625, 0.4621710526315789, 0.4934210526315789, 0.48519736842105265, 0.4440789473684211, 0.5, 0.42598684210526316, 0.47039473684210525, 0.524671052631579, 0.5789473684210527, 0.53125, 0.5361842105263158, 0.5608552631578947, 0.5592105263157895, 0.6282894736842105, 0.6085526315789473, 0.5970394736842105, 0.569078947368421, 0.59375, 0.6151315789473685, 0.6151315789473685, 0.6085526315789473, 0.6217105263157895, 0.5773026315789473, 0.6546052631578947, 0.631578947368421, 0.6282894736842105, 0.6167763157894737, 0.6480263157894737, 0.6398026315789473, 0.5953947368421053, 0.6365131578947368, 0.6398026315789473, 0.6217105263157895, 0.5427631578947368, 0.6299342105263158, 0.5493421052631579, 0.5707236842105263, 0.5888157894736842, 0.6430921052631579, 0.6381578947368421, 0.618421052631579, 0.6217105263157895, 0.6233552631578947, 0.5575657894736842, 0.6019736842105263, 0.6233552631578947, 0.6381578947368421, 0.6200657894736842, 0.587171052631579, 0.5279605263157895, 0.649671052631579, 0.6299342105263158, 0.6463815789473685, 0.59375] Best val loss: 5.26779568195343


Fold: 4
----- Training resnet18 with sequence: [0.2] -----
Current group: 0.2
Epoch [1/400], Training Loss: 40.8549, Validation Loss Current: 10.0949, Validation Loss AVG: 10.0949, lr: 0.001
Epoch [2/400], Training Loss: 39.7685, Validation Loss Current: 10.5221, Validation Loss AVG: 10.5221, lr: 0.001
Epoch [3/400], Training Loss: 39.3108, Validation Loss Current: 10.7805, Validation Loss AVG: 10.7805, lr: 0.001
Epoch [4/400], Training Loss: 38.2542, Validation Loss Current: 11.2210, Validation Loss AVG: 11.2210, lr: 0.001
Epoch [5/400], Training Loss: 37.4091, Validation Loss Current: 11.7007, Validation Loss AVG: 11.7007, lr: 0.001
Epoch [6/400], Training Loss: 36.1415, Validation Loss Current: 10.6442, Validation Loss AVG: 10.6442, lr: 0.001
Epoch [7/400], Training Loss: 35.8150, Validation Loss Current: 11.5408, Validation Loss AVG: 11.5408, lr: 0.001
Epoch [8/400], Training Loss: 35.1040, Validation Loss Current: 11.1900, Validation Loss AVG: 11.1900, lr: 0.001
Epoch [9/400], Training Loss: 33.9112, Validation Loss Current: 11.3916, Validation Loss AVG: 11.3916, lr: 0.001
Epoch [10/400], Training Loss: 33.2570, Validation Loss Current: 10.9506, Validation Loss AVG: 10.9506, lr: 0.001
Epoch [11/400], Training Loss: 31.9759, Validation Loss Current: 11.0538, Validation Loss AVG: 11.0538, lr: 0.001
Epoch [12/400], Training Loss: 31.8283, Validation Loss Current: 11.8478, Validation Loss AVG: 11.8478, lr: 0.001
Epoch [13/400], Training Loss: 30.8880, Validation Loss Current: 11.5819, Validation Loss AVG: 11.5819, lr: 0.001
Epoch [14/400], Training Loss: 31.1943, Validation Loss Current: 12.1461, Validation Loss AVG: 12.1461, lr: 0.001
Epoch [15/400], Training Loss: 31.4149, Validation Loss Current: 11.4421, Validation Loss AVG: 11.4421, lr: 0.001
Epoch [16/400], Training Loss: 29.1434, Validation Loss Current: 12.1763, Validation Loss AVG: 12.1763, lr: 0.001
Epoch [17/400], Training Loss: 28.4546, Validation Loss Current: 12.1253, Validation Loss AVG: 12.1253, lr: 0.001
Epoch [18/400], Training Loss: 27.8635, Validation Loss Current: 12.8514, Validation Loss AVG: 12.8514, lr: 0.001
Epoch [19/400], Training Loss: 27.1662, Validation Loss Current: 11.3830, Validation Loss AVG: 11.3830, lr: 0.001
Epoch [20/400], Training Loss: 26.4643, Validation Loss Current: 12.3824, Validation Loss AVG: 12.3824, lr: 0.001
Epoch [21/400], Training Loss: 24.3810, Validation Loss Current: 12.4641, Validation Loss AVG: 12.4641, lr: 0.001
Epoch [22/400], Training Loss: 23.9942, Validation Loss Current: 11.0328, Validation Loss AVG: 11.0328, lr: 0.001
Epoch [23/400], Training Loss: 23.4451, Validation Loss Current: 11.3503, Validation Loss AVG: 11.3503, lr: 0.001
Epoch [24/400], Training Loss: 22.7826, Validation Loss Current: 11.7157, Validation Loss AVG: 11.7157, lr: 0.001
Epoch [25/400], Training Loss: 20.5256, Validation Loss Current: 16.3692, Validation Loss AVG: 16.3692, lr: 0.001
Epoch [26/400], Training Loss: 21.0944, Validation Loss Current: 11.2930, Validation Loss AVG: 11.2930, lr: 0.001
Epoch [27/400], Training Loss: 19.5670, Validation Loss Current: 12.6992, Validation Loss AVG: 12.6992, lr: 0.001
Epoch [28/400], Training Loss: 18.0289, Validation Loss Current: 13.6211, Validation Loss AVG: 13.6211, lr: 0.001
Epoch [29/400], Training Loss: 17.7755, Validation Loss Current: 11.1706, Validation Loss AVG: 11.1706, lr: 0.001
Epoch [30/400], Training Loss: 19.6229, Validation Loss Current: 23.9076, Validation Loss AVG: 23.9076, lr: 0.001
Epoch [31/400], Training Loss: 20.4169, Validation Loss Current: 12.8800, Validation Loss AVG: 12.8800, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 1 Best val accuracy: [0.24967105263157893, 0.21282894736842106, 0.18651315789473683, 0.18486842105263157, 0.17664473684210527, 0.2049342105263158, 0.18026315789473685, 0.21315789473684213, 0.20427631578947372, 0.2240131578947368, 0.24013157894736842, 0.219078947368421, 0.23125, 0.2075657894736842, 0.22269736842105264, 0.2210526315789474, 0.256578947368421, 0.244078947368421, 0.27861842105263157, 0.24013157894736845, 0.2618421052631579, 0.3052631578947368, 0.29078947368421054, 0.2723684210526316, 0.19506578947368422, 0.32499999999999996, 0.28059210526315786, 0.26743421052631583, 0.2934210526315789, 0.2986842105263158, 0.24703947368421053] Best val loss: 10.094918346405029


----- Training resnet18 with sequence: [0.8] -----
Current group: 0.8
Epoch [1/400], Training Loss: 40.8313, Validation Loss Current: 10.0129, Validation Loss AVG: 10.0129, lr: 0.001
Epoch [2/400], Training Loss: 39.8199, Validation Loss Current: 9.8777, Validation Loss AVG: 9.8777, lr: 0.001
Epoch [3/400], Training Loss: 39.0916, Validation Loss Current: 9.6254, Validation Loss AVG: 9.6254, lr: 0.001
Epoch [4/400], Training Loss: 37.0660, Validation Loss Current: 9.4903, Validation Loss AVG: 9.4903, lr: 0.001
Epoch [5/400], Training Loss: 35.8538, Validation Loss Current: 9.2109, Validation Loss AVG: 9.2109, lr: 0.001
Epoch [6/400], Training Loss: 34.4753, Validation Loss Current: 8.9394, Validation Loss AVG: 8.9394, lr: 0.001
Epoch [7/400], Training Loss: 32.2617, Validation Loss Current: 9.5312, Validation Loss AVG: 9.5312, lr: 0.001
Epoch [8/400], Training Loss: 31.5998, Validation Loss Current: 9.5993, Validation Loss AVG: 9.5993, lr: 0.001
Epoch [9/400], Training Loss: 30.5883, Validation Loss Current: 8.8431, Validation Loss AVG: 8.8431, lr: 0.001
Epoch [10/400], Training Loss: 28.8144, Validation Loss Current: 9.5369, Validation Loss AVG: 9.5369, lr: 0.001
Epoch [11/400], Training Loss: 28.6243, Validation Loss Current: 10.2199, Validation Loss AVG: 10.2199, lr: 0.001
Epoch [12/400], Training Loss: 27.4051, Validation Loss Current: 9.2554, Validation Loss AVG: 9.2554, lr: 0.001
Epoch [13/400], Training Loss: 25.8663, Validation Loss Current: 8.9332, Validation Loss AVG: 8.9332, lr: 0.001
Epoch [14/400], Training Loss: 26.2808, Validation Loss Current: 8.7854, Validation Loss AVG: 8.7854, lr: 0.001
Epoch [15/400], Training Loss: 26.1710, Validation Loss Current: 8.4460, Validation Loss AVG: 8.4460, lr: 0.001
Epoch [16/400], Training Loss: 25.0919, Validation Loss Current: 10.6187, Validation Loss AVG: 10.6187, lr: 0.001
Epoch [17/400], Training Loss: 24.0883, Validation Loss Current: 9.2986, Validation Loss AVG: 9.2986, lr: 0.001
Epoch [18/400], Training Loss: 23.2731, Validation Loss Current: 8.2031, Validation Loss AVG: 8.2031, lr: 0.001
Epoch [19/400], Training Loss: 23.1140, Validation Loss Current: 9.1296, Validation Loss AVG: 9.1296, lr: 0.001
Epoch [20/400], Training Loss: 21.5182, Validation Loss Current: 9.0033, Validation Loss AVG: 9.0033, lr: 0.001
Epoch [21/400], Training Loss: 20.4403, Validation Loss Current: 10.1588, Validation Loss AVG: 10.1588, lr: 0.001
Epoch [22/400], Training Loss: 19.4252, Validation Loss Current: 8.7592, Validation Loss AVG: 8.7592, lr: 0.001
Epoch [23/400], Training Loss: 19.2719, Validation Loss Current: 10.0603, Validation Loss AVG: 10.0603, lr: 0.001
Epoch [24/400], Training Loss: 18.9255, Validation Loss Current: 9.4274, Validation Loss AVG: 9.4274, lr: 0.001
Epoch [25/400], Training Loss: 18.4666, Validation Loss Current: 8.6170, Validation Loss AVG: 8.6170, lr: 0.001
Epoch [26/400], Training Loss: 16.8199, Validation Loss Current: 9.4094, Validation Loss AVG: 9.4094, lr: 0.001
Epoch [27/400], Training Loss: 16.2468, Validation Loss Current: 10.4309, Validation Loss AVG: 10.4309, lr: 0.001
Epoch [28/400], Training Loss: 15.0192, Validation Loss Current: 9.3522, Validation Loss AVG: 9.3522, lr: 0.001
Epoch [29/400], Training Loss: 15.3312, Validation Loss Current: 9.2872, Validation Loss AVG: 9.2872, lr: 0.001
Epoch [30/400], Training Loss: 17.7824, Validation Loss Current: 33.0364, Validation Loss AVG: 33.0364, lr: 0.001
Epoch [31/400], Training Loss: 24.0078, Validation Loss Current: 12.1672, Validation Loss AVG: 12.1672, lr: 0.001
Epoch [32/400], Training Loss: 20.1899, Validation Loss Current: 8.0649, Validation Loss AVG: 8.0649, lr: 0.001
Epoch [33/400], Training Loss: 17.2220, Validation Loss Current: 11.6338, Validation Loss AVG: 11.6338, lr: 0.001
Epoch [34/400], Training Loss: 16.9600, Validation Loss Current: 9.6057, Validation Loss AVG: 9.6057, lr: 0.001
Epoch [35/400], Training Loss: 15.1236, Validation Loss Current: 10.0437, Validation Loss AVG: 10.0437, lr: 0.001
Epoch [36/400], Training Loss: 15.6693, Validation Loss Current: 8.8558, Validation Loss AVG: 8.8558, lr: 0.001
Epoch [37/400], Training Loss: 14.6322, Validation Loss Current: 9.8561, Validation Loss AVG: 9.8561, lr: 0.001
Epoch [38/400], Training Loss: 13.6630, Validation Loss Current: 12.2222, Validation Loss AVG: 12.2222, lr: 0.001
Epoch [39/400], Training Loss: 13.3732, Validation Loss Current: 11.0980, Validation Loss AVG: 11.0980, lr: 0.001
Epoch [40/400], Training Loss: 13.7111, Validation Loss Current: 11.3367, Validation Loss AVG: 11.3367, lr: 0.001
Epoch [41/400], Training Loss: 11.9356, Validation Loss Current: 9.1121, Validation Loss AVG: 9.1121, lr: 0.001
Epoch [42/400], Training Loss: 12.0395, Validation Loss Current: 12.0007, Validation Loss AVG: 12.0007, lr: 0.001
Epoch [43/400], Training Loss: 10.2707, Validation Loss Current: 10.4136, Validation Loss AVG: 10.4136, lr: 0.001
Epoch [44/400], Training Loss: 8.3298, Validation Loss Current: 10.3300, Validation Loss AVG: 10.3300, lr: 0.001
Epoch [45/400], Training Loss: 7.4835, Validation Loss Current: 9.8827, Validation Loss AVG: 9.8827, lr: 0.001
Epoch [46/400], Training Loss: 8.1243, Validation Loss Current: 9.0520, Validation Loss AVG: 9.0520, lr: 0.001
Epoch [47/400], Training Loss: 10.1618, Validation Loss Current: 9.5712, Validation Loss AVG: 9.5712, lr: 0.001
Epoch [48/400], Training Loss: 8.0866, Validation Loss Current: 10.6429, Validation Loss AVG: 10.6429, lr: 0.001
Epoch [49/400], Training Loss: 7.5128, Validation Loss Current: 12.2950, Validation Loss AVG: 12.2950, lr: 0.001
Epoch [50/400], Training Loss: 5.4696, Validation Loss Current: 10.0298, Validation Loss AVG: 10.0298, lr: 0.001
Epoch [51/400], Training Loss: 4.1715, Validation Loss Current: 12.5980, Validation Loss AVG: 12.5980, lr: 0.001
Epoch [52/400], Training Loss: 3.1458, Validation Loss Current: 10.6336, Validation Loss AVG: 10.6336, lr: 0.001
Epoch [53/400], Training Loss: 3.5980, Validation Loss Current: 11.5334, Validation Loss AVG: 11.5334, lr: 0.001
Epoch [54/400], Training Loss: 3.6008, Validation Loss Current: 9.6164, Validation Loss AVG: 9.6164, lr: 0.001
Epoch [55/400], Training Loss: 4.3842, Validation Loss Current: 13.4788, Validation Loss AVG: 13.4788, lr: 0.001
Epoch [56/400], Training Loss: 6.9150, Validation Loss Current: 12.0886, Validation Loss AVG: 12.0886, lr: 0.001
Epoch [57/400], Training Loss: 5.3495, Validation Loss Current: 11.7042, Validation Loss AVG: 11.7042, lr: 0.001
Epoch [58/400], Training Loss: 5.3356, Validation Loss Current: 13.4522, Validation Loss AVG: 13.4522, lr: 0.001
Epoch [59/400], Training Loss: 4.6159, Validation Loss Current: 11.4750, Validation Loss AVG: 11.4750, lr: 0.001
Epoch [60/400], Training Loss: 5.5548, Validation Loss Current: 15.5837, Validation Loss AVG: 15.5837, lr: 0.001
Epoch [61/400], Training Loss: 4.8880, Validation Loss Current: 12.6478, Validation Loss AVG: 12.6478, lr: 0.001
Epoch [62/400], Training Loss: 3.4566, Validation Loss Current: 11.9150, Validation Loss AVG: 11.9150, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 32 Best val accuracy: [0.25032894736842104, 0.2388157894736842, 0.2921052631578947, 0.32105263157894737, 0.3223684210526316, 0.3592105263157895, 0.3450657894736842, 0.29901315789473687, 0.3881578947368421, 0.34013157894736845, 0.3279605263157895, 0.3694078947368421, 0.38256578947368425, 0.3950657894736842, 0.43322368421052637, 0.3516447368421053, 0.35328947368421054, 0.43322368421052637, 0.3914473684210526, 0.3973684210526316, 0.37368421052631573, 0.4134868421052632, 0.38782894736842105, 0.3786184210526316, 0.41776315789473684, 0.4023026315789474, 0.38289473684210523, 0.4203947368421052, 0.40493421052631584, 0.2388157894736842, 0.3845394736842105, 0.45625, 0.3628289473684211, 0.41052631578947374, 0.4036184210526315, 0.4046052631578948, 0.3950657894736842, 0.3651315789473684, 0.3940789473684211, 0.38585526315789476, 0.40197368421052626, 0.4026315789473684, 0.41447368421052627, 0.4078947368421052, 0.4411184210526316, 0.42269736842105254, 0.44671052631578945, 0.4009868421052631, 0.3805921052631579, 0.4266447368421053, 0.40592105263157896, 0.41776315789473684, 0.4164473684210527, 0.41743421052631574, 0.4167763157894737, 0.3871710526315789, 0.41381578947368425, 0.3707236842105263, 0.4532894736842105, 0.36907894736842106, 0.4151315789473684, 0.4171052631578947] Best val loss: 8.064919471740723


----- Training resnet18 with sequence: [0.4] -----
Current group: 0.4
Epoch [1/400], Training Loss: 39.9678, Validation Loss Current: 9.9674, Validation Loss AVG: 9.9674, lr: 0.001
Epoch [2/400], Training Loss: 39.4355, Validation Loss Current: 10.1436, Validation Loss AVG: 10.1436, lr: 0.001
Epoch [3/400], Training Loss: 38.8263, Validation Loss Current: 9.7326, Validation Loss AVG: 9.7326, lr: 0.001
Epoch [4/400], Training Loss: 37.5493, Validation Loss Current: 9.5617, Validation Loss AVG: 9.5617, lr: 0.001
Epoch [5/400], Training Loss: 37.5291, Validation Loss Current: 9.6862, Validation Loss AVG: 9.6862, lr: 0.001
Epoch [6/400], Training Loss: 35.8462, Validation Loss Current: 9.3965, Validation Loss AVG: 9.3965, lr: 0.001
Epoch [7/400], Training Loss: 35.3659, Validation Loss Current: 9.3086, Validation Loss AVG: 9.3086, lr: 0.001
Epoch [8/400], Training Loss: 33.7079, Validation Loss Current: 9.0900, Validation Loss AVG: 9.0900, lr: 0.001
Epoch [9/400], Training Loss: 33.5452, Validation Loss Current: 9.0881, Validation Loss AVG: 9.0881, lr: 0.001
Epoch [10/400], Training Loss: 32.0085, Validation Loss Current: 8.7064, Validation Loss AVG: 8.7064, lr: 0.001
Epoch [11/400], Training Loss: 31.8057, Validation Loss Current: 8.7294, Validation Loss AVG: 8.7294, lr: 0.001
Epoch [12/400], Training Loss: 30.2988, Validation Loss Current: 8.6709, Validation Loss AVG: 8.6709, lr: 0.001
Epoch [13/400], Training Loss: 29.0537, Validation Loss Current: 8.5024, Validation Loss AVG: 8.5024, lr: 0.001
Epoch [14/400], Training Loss: 29.5585, Validation Loss Current: 8.6552, Validation Loss AVG: 8.6552, lr: 0.001
Epoch [15/400], Training Loss: 28.8744, Validation Loss Current: 8.3712, Validation Loss AVG: 8.3712, lr: 0.001
Epoch [16/400], Training Loss: 28.4919, Validation Loss Current: 10.5950, Validation Loss AVG: 10.5950, lr: 0.001
Epoch [17/400], Training Loss: 26.4685, Validation Loss Current: 9.2487, Validation Loss AVG: 9.2487, lr: 0.001
Epoch [18/400], Training Loss: 26.5451, Validation Loss Current: 8.0592, Validation Loss AVG: 8.0592, lr: 0.001
Epoch [19/400], Training Loss: 25.3276, Validation Loss Current: 8.8307, Validation Loss AVG: 8.8307, lr: 0.001
Epoch [20/400], Training Loss: 23.8499, Validation Loss Current: 8.0338, Validation Loss AVG: 8.0338, lr: 0.001
Epoch [21/400], Training Loss: 23.7177, Validation Loss Current: 10.2853, Validation Loss AVG: 10.2853, lr: 0.001
Epoch [22/400], Training Loss: 26.9677, Validation Loss Current: 9.3241, Validation Loss AVG: 9.3241, lr: 0.001
Epoch [23/400], Training Loss: 24.7113, Validation Loss Current: 8.4678, Validation Loss AVG: 8.4678, lr: 0.001
Epoch [24/400], Training Loss: 24.3223, Validation Loss Current: 7.9634, Validation Loss AVG: 7.9634, lr: 0.001
Epoch [25/400], Training Loss: 22.5853, Validation Loss Current: 9.2193, Validation Loss AVG: 9.2193, lr: 0.001
Epoch [26/400], Training Loss: 21.5006, Validation Loss Current: 8.1657, Validation Loss AVG: 8.1657, lr: 0.001
Epoch [27/400], Training Loss: 20.4984, Validation Loss Current: 8.1773, Validation Loss AVG: 8.1773, lr: 0.001
Epoch [28/400], Training Loss: 20.9281, Validation Loss Current: 8.6237, Validation Loss AVG: 8.6237, lr: 0.001
Epoch [29/400], Training Loss: 19.6366, Validation Loss Current: 7.9910, Validation Loss AVG: 7.9910, lr: 0.001
Epoch [30/400], Training Loss: 17.8380, Validation Loss Current: 7.7817, Validation Loss AVG: 7.7817, lr: 0.001
Epoch [31/400], Training Loss: 16.2072, Validation Loss Current: 7.8807, Validation Loss AVG: 7.8807, lr: 0.001
Epoch [32/400], Training Loss: 16.2635, Validation Loss Current: 9.1455, Validation Loss AVG: 9.1455, lr: 0.001
Epoch [33/400], Training Loss: 16.5086, Validation Loss Current: 8.0570, Validation Loss AVG: 8.0570, lr: 0.001
Epoch [34/400], Training Loss: 15.0441, Validation Loss Current: 8.6413, Validation Loss AVG: 8.6413, lr: 0.001
Epoch [35/400], Training Loss: 13.8860, Validation Loss Current: 8.9351, Validation Loss AVG: 8.9351, lr: 0.001
Epoch [36/400], Training Loss: 13.2674, Validation Loss Current: 8.6170, Validation Loss AVG: 8.6170, lr: 0.001
Epoch [37/400], Training Loss: 12.0376, Validation Loss Current: 9.8842, Validation Loss AVG: 9.8842, lr: 0.001
Epoch [38/400], Training Loss: 13.0960, Validation Loss Current: 8.7034, Validation Loss AVG: 8.7034, lr: 0.001
Epoch [39/400], Training Loss: 12.6923, Validation Loss Current: 11.9477, Validation Loss AVG: 11.9477, lr: 0.001
Epoch [40/400], Training Loss: 9.6134, Validation Loss Current: 9.4803, Validation Loss AVG: 9.4803, lr: 0.001
Epoch [41/400], Training Loss: 11.1026, Validation Loss Current: 9.5673, Validation Loss AVG: 9.5673, lr: 0.001
Epoch [42/400], Training Loss: 10.2064, Validation Loss Current: 8.5122, Validation Loss AVG: 8.5122, lr: 0.001
Epoch [43/400], Training Loss: 10.8675, Validation Loss Current: 10.5345, Validation Loss AVG: 10.5345, lr: 0.001
Epoch [44/400], Training Loss: 11.2532, Validation Loss Current: 12.3097, Validation Loss AVG: 12.3097, lr: 0.001
Epoch [45/400], Training Loss: 13.3600, Validation Loss Current: 10.2213, Validation Loss AVG: 10.2213, lr: 0.001
Epoch [46/400], Training Loss: 10.4256, Validation Loss Current: 9.0801, Validation Loss AVG: 9.0801, lr: 0.001
Epoch [47/400], Training Loss: 7.1749, Validation Loss Current: 8.3939, Validation Loss AVG: 8.3939, lr: 0.001
Epoch [48/400], Training Loss: 7.5821, Validation Loss Current: 9.5175, Validation Loss AVG: 9.5175, lr: 0.001
Epoch [49/400], Training Loss: 5.6110, Validation Loss Current: 10.0700, Validation Loss AVG: 10.0700, lr: 0.001
Epoch [50/400], Training Loss: 5.2110, Validation Loss Current: 9.2808, Validation Loss AVG: 9.2808, lr: 0.001
Epoch [51/400], Training Loss: 5.9258, Validation Loss Current: 10.7216, Validation Loss AVG: 10.7216, lr: 0.001
Epoch [52/400], Training Loss: 6.8445, Validation Loss Current: 10.1712, Validation Loss AVG: 10.1712, lr: 0.001
Epoch [53/400], Training Loss: 6.4483, Validation Loss Current: 11.5441, Validation Loss AVG: 11.5441, lr: 0.001
Epoch [54/400], Training Loss: 11.4548, Validation Loss Current: 12.6869, Validation Loss AVG: 12.6869, lr: 0.001
Epoch [55/400], Training Loss: 10.7945, Validation Loss Current: 10.8107, Validation Loss AVG: 10.8107, lr: 0.001
Epoch [56/400], Training Loss: 8.0333, Validation Loss Current: 10.9031, Validation Loss AVG: 10.9031, lr: 0.001
Epoch [57/400], Training Loss: 7.0498, Validation Loss Current: 10.9135, Validation Loss AVG: 10.9135, lr: 0.001
Epoch [58/400], Training Loss: 7.1524, Validation Loss Current: 11.6266, Validation Loss AVG: 11.6266, lr: 0.001
Epoch [59/400], Training Loss: 4.8345, Validation Loss Current: 10.6971, Validation Loss AVG: 10.6971, lr: 0.001
Epoch [60/400], Training Loss: 5.1013, Validation Loss Current: 11.6954, Validation Loss AVG: 11.6954, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 30 Best val accuracy: [0.2631578947368421, 0.1957236842105263, 0.2799342105263158, 0.30164473684210524, 0.25427631578947374, 0.30789473684210533, 0.29473684210526313, 0.3095394736842105, 0.32730263157894735, 0.35592105263157897, 0.33519736842105263, 0.35427631578947366, 0.37269736842105267, 0.3447368421052632, 0.3917763157894737, 0.36875, 0.3585526315789474, 0.3980263157894737, 0.38585526315789476, 0.4286184210526316, 0.3470394736842105, 0.38980263157894735, 0.38618421052631574, 0.41776315789473684, 0.3197368421052632, 0.4184210526315789, 0.4230263157894737, 0.40361842105263157, 0.44342105263157894, 0.4365131578947368, 0.42927631578947373, 0.393421052631579, 0.4516447368421053, 0.40164473684210533, 0.406907894736842, 0.41940789473684215, 0.40328947368421053, 0.3782894736842105, 0.3759868421052631, 0.4115131578947368, 0.4029605263157895, 0.3963815789473684, 0.3493421052631579, 0.2723684210526316, 0.3907894736842106, 0.41447368421052627, 0.46282894736842106, 0.3832236842105263, 0.4046052631578948, 0.42894736842105263, 0.39539473684210524, 0.41743421052631585, 0.34375, 0.37434210526315786, 0.36578947368421055, 0.3832236842105263, 0.35625, 0.34375, 0.4151315789473684, 0.3493421052631579] Best val loss: 7.781658244132996


----- Training resnet18 with sequence: [0.6] -----
Current group: 0.6
Epoch [1/400], Training Loss: 40.8647, Validation Loss Current: 10.0802, Validation Loss AVG: 10.0802, lr: 0.001
Epoch [2/400], Training Loss: 39.6074, Validation Loss Current: 9.9300, Validation Loss AVG: 9.9300, lr: 0.001
Epoch [3/400], Training Loss: 38.8863, Validation Loss Current: 9.8623, Validation Loss AVG: 9.8623, lr: 0.001
Epoch [4/400], Training Loss: 37.8587, Validation Loss Current: 9.5412, Validation Loss AVG: 9.5412, lr: 0.001
Epoch [5/400], Training Loss: 37.0721, Validation Loss Current: 9.5985, Validation Loss AVG: 9.5985, lr: 0.001
Epoch [6/400], Training Loss: 35.5845, Validation Loss Current: 9.2715, Validation Loss AVG: 9.2715, lr: 0.001
Epoch [7/400], Training Loss: 34.7574, Validation Loss Current: 9.1483, Validation Loss AVG: 9.1483, lr: 0.001
Epoch [8/400], Training Loss: 33.6732, Validation Loss Current: 9.0025, Validation Loss AVG: 9.0025, lr: 0.001
Epoch [9/400], Training Loss: 32.4451, Validation Loss Current: 8.9006, Validation Loss AVG: 8.9006, lr: 0.001
Epoch [10/400], Training Loss: 31.4739, Validation Loss Current: 8.9228, Validation Loss AVG: 8.9228, lr: 0.001
Epoch [11/400], Training Loss: 30.0888, Validation Loss Current: 8.8382, Validation Loss AVG: 8.8382, lr: 0.001
Epoch [12/400], Training Loss: 28.8656, Validation Loss Current: 8.6353, Validation Loss AVG: 8.6353, lr: 0.001
Epoch [13/400], Training Loss: 28.9075, Validation Loss Current: 8.6806, Validation Loss AVG: 8.6806, lr: 0.001
Epoch [14/400], Training Loss: 28.9956, Validation Loss Current: 8.6961, Validation Loss AVG: 8.6961, lr: 0.001
Epoch [15/400], Training Loss: 27.4824, Validation Loss Current: 8.7042, Validation Loss AVG: 8.7042, lr: 0.001
Epoch [16/400], Training Loss: 27.1724, Validation Loss Current: 8.5543, Validation Loss AVG: 8.5543, lr: 0.001
Epoch [17/400], Training Loss: 27.0484, Validation Loss Current: 8.4758, Validation Loss AVG: 8.4758, lr: 0.001
Epoch [18/400], Training Loss: 25.9147, Validation Loss Current: 8.4868, Validation Loss AVG: 8.4868, lr: 0.001
Epoch [19/400], Training Loss: 24.7908, Validation Loss Current: 8.4363, Validation Loss AVG: 8.4363, lr: 0.001
Epoch [20/400], Training Loss: 23.6589, Validation Loss Current: 8.4739, Validation Loss AVG: 8.4739, lr: 0.001
Epoch [21/400], Training Loss: 23.5729, Validation Loss Current: 8.3607, Validation Loss AVG: 8.3607, lr: 0.001
Epoch [22/400], Training Loss: 20.7993, Validation Loss Current: 8.2431, Validation Loss AVG: 8.2431, lr: 0.001
Epoch [23/400], Training Loss: 20.8228, Validation Loss Current: 8.7019, Validation Loss AVG: 8.7019, lr: 0.001
Epoch [24/400], Training Loss: 20.5695, Validation Loss Current: 8.4292, Validation Loss AVG: 8.4292, lr: 0.001
Epoch [25/400], Training Loss: 20.5288, Validation Loss Current: 8.1795, Validation Loss AVG: 8.1795, lr: 0.001
Epoch [26/400], Training Loss: 19.1894, Validation Loss Current: 8.9105, Validation Loss AVG: 8.9105, lr: 0.001
Epoch [27/400], Training Loss: 17.3353, Validation Loss Current: 8.8471, Validation Loss AVG: 8.8471, lr: 0.001
Epoch [28/400], Training Loss: 17.4756, Validation Loss Current: 14.2171, Validation Loss AVG: 14.2171, lr: 0.001
Epoch [29/400], Training Loss: 23.7004, Validation Loss Current: 9.5764, Validation Loss AVG: 9.5764, lr: 0.001
Epoch [30/400], Training Loss: 20.8338, Validation Loss Current: 8.7390, Validation Loss AVG: 8.7390, lr: 0.001
Epoch [31/400], Training Loss: 18.0496, Validation Loss Current: 8.4280, Validation Loss AVG: 8.4280, lr: 0.001
Epoch [32/400], Training Loss: 16.7760, Validation Loss Current: 8.3668, Validation Loss AVG: 8.3668, lr: 0.001
Epoch [33/400], Training Loss: 17.6360, Validation Loss Current: 9.5179, Validation Loss AVG: 9.5179, lr: 0.001
Epoch [34/400], Training Loss: 18.7894, Validation Loss Current: 9.0666, Validation Loss AVG: 9.0666, lr: 0.001
Epoch [35/400], Training Loss: 21.0915, Validation Loss Current: 9.3262, Validation Loss AVG: 9.3262, lr: 0.001
Epoch [36/400], Training Loss: 18.0605, Validation Loss Current: 9.4091, Validation Loss AVG: 9.4091, lr: 0.001
Epoch [37/400], Training Loss: 16.4003, Validation Loss Current: 9.1380, Validation Loss AVG: 9.1380, lr: 0.001
Epoch [38/400], Training Loss: 13.8129, Validation Loss Current: 8.9905, Validation Loss AVG: 8.9905, lr: 0.001
Epoch [39/400], Training Loss: 13.0219, Validation Loss Current: 8.9127, Validation Loss AVG: 8.9127, lr: 0.001
Epoch [40/400], Training Loss: 13.6697, Validation Loss Current: 9.4211, Validation Loss AVG: 9.4211, lr: 0.001
Epoch [41/400], Training Loss: 12.5092, Validation Loss Current: 9.4704, Validation Loss AVG: 9.4704, lr: 0.001
Epoch [42/400], Training Loss: 11.0132, Validation Loss Current: 9.7407, Validation Loss AVG: 9.7407, lr: 0.001
Epoch [43/400], Training Loss: 10.6370, Validation Loss Current: 8.7682, Validation Loss AVG: 8.7682, lr: 0.001
Epoch [44/400], Training Loss: 9.3515, Validation Loss Current: 9.0790, Validation Loss AVG: 9.0790, lr: 0.001
Epoch [45/400], Training Loss: 9.4224, Validation Loss Current: 9.5077, Validation Loss AVG: 9.5077, lr: 0.001
Epoch [46/400], Training Loss: 7.3706, Validation Loss Current: 10.1991, Validation Loss AVG: 10.1991, lr: 0.001
Epoch [47/400], Training Loss: 7.0760, Validation Loss Current: 8.8553, Validation Loss AVG: 8.8553, lr: 0.001
Epoch [48/400], Training Loss: 7.4607, Validation Loss Current: 9.9142, Validation Loss AVG: 9.9142, lr: 0.001
Epoch [49/400], Training Loss: 6.6396, Validation Loss Current: 9.2391, Validation Loss AVG: 9.2391, lr: 0.001
Epoch [50/400], Training Loss: 7.2682, Validation Loss Current: 8.3680, Validation Loss AVG: 8.3680, lr: 0.001
Epoch [51/400], Training Loss: 7.9658, Validation Loss Current: 10.5615, Validation Loss AVG: 10.5615, lr: 0.001
Epoch [52/400], Training Loss: 6.1723, Validation Loss Current: 10.6137, Validation Loss AVG: 10.6137, lr: 0.001
Epoch [53/400], Training Loss: 5.4042, Validation Loss Current: 10.1228, Validation Loss AVG: 10.1228, lr: 0.001
Epoch [54/400], Training Loss: 3.7292, Validation Loss Current: 9.8564, Validation Loss AVG: 9.8564, lr: 0.001
Epoch [55/400], Training Loss: 3.3101, Validation Loss Current: 10.1193, Validation Loss AVG: 10.1193, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 25 Best val accuracy: [0.17960526315789474, 0.2565789473684211, 0.2684210526315789, 0.3138157894736842, 0.25296052631578947, 0.3286184210526316, 0.3131578947368421, 0.3296052631578947, 0.35559210526315793, 0.34769736842105264, 0.32960526315789473, 0.3782894736842105, 0.3644736842105264, 0.35921052631578954, 0.34572368421052635, 0.4078947368421052, 0.40756578947368427, 0.39671052631578946, 0.3888157894736842, 0.4052631578947368, 0.40921052631578947, 0.4098684210526316, 0.38092105263157894, 0.4115131578947368, 0.42828947368421055, 0.4148026315789474, 0.4233552631578947, 0.3134868421052632, 0.3625, 0.4151315789473684, 0.425, 0.4305921052631579, 0.3907894736842105, 0.41217105263157894, 0.37236842105263157, 0.4023026315789474, 0.43157894736842106, 0.41940789473684215, 0.4236842105263158, 0.4276315789473684, 0.4026315789473684, 0.41776315789473684, 0.42730263157894743, 0.4463815789473684, 0.4108552631578948, 0.4134868421052632, 0.4440789473684211, 0.43355263157894736, 0.4391447368421053, 0.4447368421052631, 0.4233552631578947, 0.4309210526315789, 0.43256578947368424, 0.4197368421052632, 0.4384868421052632] Best val loss: 8.179521703720093


----- Training resnet18 with sequence: [1] -----
Current group: 1
Epoch [1/400], Training Loss: 40.1132, Validation Loss Current: 9.8471, Validation Loss AVG: 9.9163, lr: 0.001
Epoch [2/400], Training Loss: 38.4732, Validation Loss Current: 9.4764, Validation Loss AVG: 9.7693, lr: 0.001
Epoch [3/400], Training Loss: 37.2736, Validation Loss Current: 9.3034, Validation Loss AVG: 10.0470, lr: 0.001
Epoch [4/400], Training Loss: 36.3068, Validation Loss Current: 8.9218, Validation Loss AVG: 9.5616, lr: 0.001
Epoch [5/400], Training Loss: 34.4246, Validation Loss Current: 8.4405, Validation Loss AVG: 9.1990, lr: 0.001
Epoch [6/400], Training Loss: 33.6640, Validation Loss Current: 8.5513, Validation Loss AVG: 9.4283, lr: 0.001
Epoch [7/400], Training Loss: 32.5280, Validation Loss Current: 8.4253, Validation Loss AVG: 9.4832, lr: 0.001
Epoch [8/400], Training Loss: 31.3869, Validation Loss Current: 8.1688, Validation Loss AVG: 9.6502, lr: 0.001
Epoch [9/400], Training Loss: 29.1865, Validation Loss Current: 7.7983, Validation Loss AVG: 9.3047, lr: 0.001
Epoch [10/400], Training Loss: 28.4331, Validation Loss Current: 9.1308, Validation Loss AVG: 12.7687, lr: 0.001
Epoch [11/400], Training Loss: 28.0899, Validation Loss Current: 7.3398, Validation Loss AVG: 9.9271, lr: 0.001
Epoch [12/400], Training Loss: 27.5401, Validation Loss Current: 7.7137, Validation Loss AVG: 9.3982, lr: 0.001
Epoch [13/400], Training Loss: 27.0085, Validation Loss Current: 7.0736, Validation Loss AVG: 8.9857, lr: 0.001
Epoch [14/400], Training Loss: 25.3535, Validation Loss Current: 6.6913, Validation Loss AVG: 9.6580, lr: 0.001
Epoch [15/400], Training Loss: 25.1303, Validation Loss Current: 6.7611, Validation Loss AVG: 8.8425, lr: 0.001
Epoch [16/400], Training Loss: 23.8627, Validation Loss Current: 6.4947, Validation Loss AVG: 9.2766, lr: 0.001
Epoch [17/400], Training Loss: 22.3746, Validation Loss Current: 6.6079, Validation Loss AVG: 8.4713, lr: 0.001
Epoch [18/400], Training Loss: 21.2746, Validation Loss Current: 6.5131, Validation Loss AVG: 9.7812, lr: 0.001
Epoch [19/400], Training Loss: 21.7629, Validation Loss Current: 6.3062, Validation Loss AVG: 10.2977, lr: 0.001
Epoch [20/400], Training Loss: 19.4853, Validation Loss Current: 8.8478, Validation Loss AVG: 15.1084, lr: 0.001
Epoch [21/400], Training Loss: 19.9023, Validation Loss Current: 6.8565, Validation Loss AVG: 10.3614, lr: 0.001
Epoch [22/400], Training Loss: 19.7663, Validation Loss Current: 6.7058, Validation Loss AVG: 10.5761, lr: 0.001
Epoch [23/400], Training Loss: 19.3475, Validation Loss Current: 6.3573, Validation Loss AVG: 8.6521, lr: 0.001
Epoch [24/400], Training Loss: 19.0941, Validation Loss Current: 7.1875, Validation Loss AVG: 9.1113, lr: 0.001
Epoch [25/400], Training Loss: 18.3629, Validation Loss Current: 5.8746, Validation Loss AVG: 10.1806, lr: 0.001
Epoch [26/400], Training Loss: 17.6712, Validation Loss Current: 7.5055, Validation Loss AVG: 9.7349, lr: 0.001
Epoch [27/400], Training Loss: 22.2224, Validation Loss Current: 6.8061, Validation Loss AVG: 9.4105, lr: 0.001
Epoch [28/400], Training Loss: 19.2837, Validation Loss Current: 6.2269, Validation Loss AVG: 11.3728, lr: 0.001
Epoch [29/400], Training Loss: 15.7009, Validation Loss Current: 5.8570, Validation Loss AVG: 9.0967, lr: 0.001
Epoch [30/400], Training Loss: 16.0854, Validation Loss Current: 6.0651, Validation Loss AVG: 8.9035, lr: 0.001
Epoch [31/400], Training Loss: 16.3137, Validation Loss Current: 6.7215, Validation Loss AVG: 13.0404, lr: 0.001
Epoch [32/400], Training Loss: 13.3327, Validation Loss Current: 5.4936, Validation Loss AVG: 9.5839, lr: 0.001
Epoch [33/400], Training Loss: 14.2277, Validation Loss Current: 7.6116, Validation Loss AVG: 10.2601, lr: 0.001
Epoch [34/400], Training Loss: 15.1263, Validation Loss Current: 5.9641, Validation Loss AVG: 8.8312, lr: 0.001
Epoch [35/400], Training Loss: 13.1713, Validation Loss Current: 6.5255, Validation Loss AVG: 11.7059, lr: 0.001
Epoch [36/400], Training Loss: 15.0871, Validation Loss Current: 6.8193, Validation Loss AVG: 10.9590, lr: 0.001
Epoch [37/400], Training Loss: 11.7924, Validation Loss Current: 6.0357, Validation Loss AVG: 12.5195, lr: 0.001
Epoch [38/400], Training Loss: 9.0540, Validation Loss Current: 5.7496, Validation Loss AVG: 11.8202, lr: 0.001
Epoch [39/400], Training Loss: 10.4091, Validation Loss Current: 5.6393, Validation Loss AVG: 10.1007, lr: 0.001
Epoch [40/400], Training Loss: 11.0756, Validation Loss Current: 6.4411, Validation Loss AVG: 10.8989, lr: 0.001
Epoch [41/400], Training Loss: 9.8060, Validation Loss Current: 7.0768, Validation Loss AVG: 12.3807, lr: 0.001
Epoch [42/400], Training Loss: 9.2327, Validation Loss Current: 5.7310, Validation Loss AVG: 9.5712, lr: 0.001
Epoch [43/400], Training Loss: 9.6200, Validation Loss Current: 6.4125, Validation Loss AVG: 13.6797, lr: 0.001
Epoch [44/400], Training Loss: 11.6856, Validation Loss Current: 6.7640, Validation Loss AVG: 12.2307, lr: 0.001
Epoch [45/400], Training Loss: 9.5494, Validation Loss Current: 6.2794, Validation Loss AVG: 11.0962, lr: 0.001
Epoch [46/400], Training Loss: 8.7992, Validation Loss Current: 6.3725, Validation Loss AVG: 14.1472, lr: 0.001
Epoch [47/400], Training Loss: 7.5286, Validation Loss Current: 8.0787, Validation Loss AVG: 12.5555, lr: 0.001
Epoch [48/400], Training Loss: 8.0794, Validation Loss Current: 6.5392, Validation Loss AVG: 13.2751, lr: 0.001
Epoch [49/400], Training Loss: 7.9682, Validation Loss Current: 5.6215, Validation Loss AVG: 9.8348, lr: 0.001
Epoch [50/400], Training Loss: 5.7543, Validation Loss Current: 5.8725, Validation Loss AVG: 10.0247, lr: 0.001
Epoch [51/400], Training Loss: 6.3025, Validation Loss Current: 5.7760, Validation Loss AVG: 11.2594, lr: 0.001
Epoch [52/400], Training Loss: 6.2176, Validation Loss Current: 6.7669, Validation Loss AVG: 11.7928, lr: 0.001
Epoch [53/400], Training Loss: 5.1472, Validation Loss Current: 7.0425, Validation Loss AVG: 11.5833, lr: 0.001
Epoch [54/400], Training Loss: 4.9752, Validation Loss Current: 6.1212, Validation Loss AVG: 11.6167, lr: 0.001
Epoch [55/400], Training Loss: 5.2579, Validation Loss Current: 6.6347, Validation Loss AVG: 14.8592, lr: 0.001
Epoch [56/400], Training Loss: 4.0739, Validation Loss Current: 5.9954, Validation Loss AVG: 12.6567, lr: 0.001
Epoch [57/400], Training Loss: 3.6555, Validation Loss Current: 6.6941, Validation Loss AVG: 12.2780, lr: 0.001
Epoch [58/400], Training Loss: 3.8258, Validation Loss Current: 5.9703, Validation Loss AVG: 11.8663, lr: 0.001
Epoch [59/400], Training Loss: 3.8851, Validation Loss Current: 7.0247, Validation Loss AVG: 10.7243, lr: 0.001
Epoch [60/400], Training Loss: 5.5530, Validation Loss Current: 9.4427, Validation Loss AVG: 14.1173, lr: 0.001
Epoch [61/400], Training Loss: 5.3322, Validation Loss Current: 7.8867, Validation Loss AVG: 12.6842, lr: 0.001
Epoch [62/400], Training Loss: 4.6607, Validation Loss Current: 8.1721, Validation Loss AVG: 12.4055, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 32 Best val accuracy: [0.2631578947368421, 0.29605263157894735, 0.31085526315789475, 0.3519736842105263, 0.36348684210526316, 0.37335526315789475, 0.3848684210526316, 0.4407894736842105, 0.42598684210526316, 0.3717105263157895, 0.49506578947368424, 0.43256578947368424, 0.48519736842105265, 0.5427631578947368, 0.5279605263157895, 0.5361842105263158, 0.5411184210526315, 0.5361842105263158, 0.5674342105263158, 0.48519736842105265, 0.5213815789473685, 0.5509868421052632, 0.5822368421052632, 0.5542763157894737, 0.5970394736842105, 0.5328947368421053, 0.5361842105263158, 0.5657894736842105, 0.5904605263157895, 0.5904605263157895, 0.5526315789473685, 0.6052631578947368, 0.5213815789473685, 0.6217105263157895, 0.569078947368421, 0.5345394736842105, 0.587171052631579, 0.59375, 0.631578947368421, 0.5822368421052632, 0.5444078947368421, 0.6348684210526315, 0.5986842105263158, 0.5641447368421053, 0.618421052631579, 0.5921052631578947, 0.5641447368421053, 0.5904605263157895, 0.6430921052631579, 0.6282894736842105, 0.6414473684210527, 0.5789473684210527, 0.6151315789473685, 0.6381578947368421, 0.6118421052631579, 0.625, 0.6134868421052632, 0.6463815789473685, 0.6200657894736842, 0.49835526315789475, 0.5756578947368421, 0.5970394736842105] Best val loss: 5.493595123291016


-------------------- All training done --------------------


 --- Evaluating ---
Fold: 0
---- Testing model trained on sequence: [0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.5003819709702063
Test set distance: 0.8 Top 1 Accuracy: 0.27960275019098546
Test set distance: 0.4 Top 1 Accuracy: 0.3605805958747135
Test set distance: 0.6 Top 1 Accuracy: 0.32161955691367455
Test set distance: 1 Top 1 Accuracy: 0.2757830404889228
---- Testing model trained on sequence: [0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.17952635599694422
Test set distance: 0.8 Top 1 Accuracy: 0.5836516424751719
Test set distance: 0.4 Top 1 Accuracy: 0.3116883116883117
Test set distance: 0.6 Top 1 Accuracy: 0.4957983193277311
Test set distance: 1 Top 1 Accuracy: 0.5469824293353706
---- Testing model trained on sequence: [0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.32314744079449964
Test set distance: 0.8 Top 1 Accuracy: 0.3919022154316272
Test set distance: 0.4 Top 1 Accuracy: 0.5164247517188694
Test set distance: 0.6 Top 1 Accuracy: 0.3919022154316272
Test set distance: 1 Top 1 Accuracy: 0.37203972498090143
---- Testing model trained on sequence: [0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.19327731092436976
Test set distance: 0.8 Top 1 Accuracy: 0.5286478227654698
Test set distance: 0.4 Top 1 Accuracy: 0.440794499618029
Test set distance: 0.6 Top 1 Accuracy: 0.5508021390374331
Test set distance: 1 Top 1 Accuracy: 0.48586707410236823
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18181818181818182
Test set distance: 0.8 Top 1 Accuracy: 0.5553857906799083
Test set distance: 0.4 Top 1 Accuracy: 0.26585179526355995
Test set distance: 0.6 Top 1 Accuracy: 0.42780748663101603
Test set distance: 1 Top 1 Accuracy: 0.6042780748663101
Fold: 1
---- Testing model trained on sequence: [0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3300229182582124
Test set distance: 0.8 Top 1 Accuracy: 0.24216959511077157
Test set distance: 0.4 Top 1 Accuracy: 0.2605042016806723
Test set distance: 0.6 Top 1 Accuracy: 0.2582123758594347
Test set distance: 1 Top 1 Accuracy: 0.25362872421695953
---- Testing model trained on sequence: [0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.21008403361344538
Test set distance: 0.8 Top 1 Accuracy: 0.5255920550038197
Test set distance: 0.4 Top 1 Accuracy: 0.25210084033613445
Test set distance: 0.6 Top 1 Accuracy: 0.4163483575248281
Test set distance: 1 Top 1 Accuracy: 0.5439266615737204
---- Testing model trained on sequence: [0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.28953399541634833
Test set distance: 0.8 Top 1 Accuracy: 0.37203972498090143
Test set distance: 0.4 Top 1 Accuracy: 0.4102368220015279
Test set distance: 0.6 Top 1 Accuracy: 0.3705118411000764
Test set distance: 1 Top 1 Accuracy: 0.35294117647058826
---- Testing model trained on sequence: [0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.26508785332314744
Test set distance: 0.8 Top 1 Accuracy: 0.47135217723453016
Test set distance: 0.4 Top 1 Accuracy: 0.4079449961802903
Test set distance: 0.6 Top 1 Accuracy: 0.5110771581359816
Test set distance: 1 Top 1 Accuracy: 0.44385026737967914
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.16424751718869365
Test set distance: 0.8 Top 1 Accuracy: 0.5164247517188694
Test set distance: 0.4 Top 1 Accuracy: 0.24446142093200918
Test set distance: 0.6 Top 1 Accuracy: 0.42780748663101603
Test set distance: 1 Top 1 Accuracy: 0.5760122230710466
Fold: 2
---- Testing model trained on sequence: [0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.44690603514132926
Test set distance: 0.8 Top 1 Accuracy: 0.2322383498854087
Test set distance: 0.4 Top 1 Accuracy: 0.2505729564553094
Test set distance: 0.6 Top 1 Accuracy: 0.23911382734912145
Test set distance: 1 Top 1 Accuracy: 0.21772345301757068
---- Testing model trained on sequence: [0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1917494270435447
Test set distance: 0.8 Top 1 Accuracy: 0.5821237585943468
Test set distance: 0.4 Top 1 Accuracy: 0.3391902215431627
Test set distance: 0.6 Top 1 Accuracy: 0.5011459129106188
Test set distance: 1 Top 1 Accuracy: 0.5622612681436211
---- Testing model trained on sequence: [0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.35141329258976317
Test set distance: 0.8 Top 1 Accuracy: 0.4102368220015279
Test set distance: 0.4 Top 1 Accuracy: 0.5317035905271199
Test set distance: 0.6 Top 1 Accuracy: 0.43391902215431627
Test set distance: 1 Top 1 Accuracy: 0.37967914438502676
---- Testing model trained on sequence: [0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.20702826585179526
Test set distance: 0.8 Top 1 Accuracy: 0.5431627196333079
Test set distance: 0.4 Top 1 Accuracy: 0.45760122230710465
Test set distance: 0.6 Top 1 Accuracy: 0.5500381970970206
Test set distance: 1 Top 1 Accuracy: 0.5118411000763942
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.054239877769289534
Test set distance: 0.8 Top 1 Accuracy: 0.44919786096256686
Test set distance: 0.4 Top 1 Accuracy: 0.1489686783804431
Test set distance: 0.6 Top 1 Accuracy: 0.3292589763177998
Test set distance: 1 Top 1 Accuracy: 0.5095492742551566
Fold: 3
---- Testing model trained on sequence: [0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.47135217723453016
Test set distance: 0.8 Top 1 Accuracy: 0.2192513368983957
Test set distance: 0.4 Top 1 Accuracy: 0.2452253628724217
Test set distance: 0.6 Top 1 Accuracy: 0.24675324675324675
Test set distance: 1 Top 1 Accuracy: 0.21619556913674562
---- Testing model trained on sequence: [0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.18029029793735676
Test set distance: 0.8 Top 1 Accuracy: 0.6035141329258976
Test set distance: 0.4 Top 1 Accuracy: 0.3246753246753247
Test set distance: 0.6 Top 1 Accuracy: 0.49961802902979374
Test set distance: 1 Top 1 Accuracy: 0.5752482811306341
---- Testing model trained on sequence: [0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.30786860198624905
Test set distance: 0.8 Top 1 Accuracy: 0.4698242933537051
Test set distance: 0.4 Top 1 Accuracy: 0.5278838808250573
Test set distance: 0.6 Top 1 Accuracy: 0.4637127578304049
Test set distance: 1 Top 1 Accuracy: 0.4514896867838044
---- Testing model trained on sequence: [0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.21543162719633308
Test set distance: 0.8 Top 1 Accuracy: 0.5233002291825821
Test set distance: 0.4 Top 1 Accuracy: 0.44155844155844154
Test set distance: 0.6 Top 1 Accuracy: 0.5721925133689839
Test set distance: 1 Top 1 Accuracy: 0.5095492742551566
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1520244461420932
Test set distance: 0.8 Top 1 Accuracy: 0.5026737967914439
Test set distance: 0.4 Top 1 Accuracy: 0.22459893048128343
Test set distance: 0.6 Top 1 Accuracy: 0.35141329258976317
Test set distance: 1 Top 1 Accuracy: 0.5966386554621849
Fold: 4
---- Testing model trained on sequence: [0.2] ----
Test set distance: 0.2 Top 1 Accuracy: 0.44919786096256686
Test set distance: 0.8 Top 1 Accuracy: 0.18869365928189458
Test set distance: 0.4 Top 1 Accuracy: 0.25668449197860965
Test set distance: 0.6 Top 1 Accuracy: 0.22536287242169595
Test set distance: 1 Top 1 Accuracy: 0.15813598166539344
---- Testing model trained on sequence: [0.8] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1711229946524064
Test set distance: 0.8 Top 1 Accuracy: 0.5744843391902216
Test set distance: 0.4 Top 1 Accuracy: 0.3307868601986249
Test set distance: 0.6 Top 1 Accuracy: 0.494270435446906
Test set distance: 1 Top 1 Accuracy: 0.5309396485867074
---- Testing model trained on sequence: [0.4] ----
Test set distance: 0.2 Top 1 Accuracy: 0.27043544690603516
Test set distance: 0.8 Top 1 Accuracy: 0.34530175706646293
Test set distance: 0.4 Top 1 Accuracy: 0.5263559969442322
Test set distance: 0.6 Top 1 Accuracy: 0.42016806722689076
Test set distance: 1 Top 1 Accuracy: 0.31092436974789917
---- Testing model trained on sequence: [0.6] ----
Test set distance: 0.2 Top 1 Accuracy: 0.20168067226890757
Test set distance: 0.8 Top 1 Accuracy: 0.49961802902979374
Test set distance: 0.4 Top 1 Accuracy: 0.4675324675324675
Test set distance: 0.6 Top 1 Accuracy: 0.5454545454545454
Test set distance: 1 Top 1 Accuracy: 0.47593582887700536
---- Testing model trained on sequence: [1] ----
Test set distance: 0.2 Top 1 Accuracy: 0.1779984721161192
Test set distance: 0.8 Top 1 Accuracy: 0.5416348357524828
Test set distance: 0.4 Top 1 Accuracy: 0.2887700534759358
Test set distance: 0.6 Top 1 Accuracy: 0.4362108479755539
Test set distance: 1 Top 1 Accuracy: 0.6080977845683728
------------------------------ End ------------------------------


 # ------------------ Running pipeline on random color run_0 -------------------- #
cuda:0
 ------ Pipeline with following parameters ------
training_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/train
val_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/val
test_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/test
dataset_name :  VOC
target_distances :  [0.2, 0.8, 0.4, 0.6, 1]
training_mode :  random
n_distances :  None
training_size :  None
background :  color
size :  (150, 150)
cls_to_use :  ['aeroplane', 'bicycle', 'bird', 'boat', 'car', 'cat', 'train', 'tvmonitor']
batch_size :  128
val_size :  1
epochs :  400
resize_method :  long
n_folds :  5
num_workers :  16
model_name :  resnet18
device :  cuda:0
random_seed :  40
result_dirpath :  /u/erdos/students/xcui32/cnslab/results/VOC8R18BlackCUR
save_checkpoints :  False
save_progress_checkpoints :  False
verbose :  0
 ---  Loading datasets ---
 ---  Running  ---
Parameters: --------------------
{'scheduler_kwargs': {'mode': 'min', 'factor': 0.1, 'patience': 5}, 'optim_kwargs': {'lr': 0.001, 'momentum': 0.9}, 'max_norm': None, 'val_target': 'current', 'patience': 30, 'early_stopping': True, 'scheduler_object': None, 'optimizer_object': <class 'torch.optim.sgd.SGD'>, 'criterion_object': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'self': <pipelineCV2.RunModel object at 0x2aaab264dcc0>}
--------------------
Fold: 0
----- Training resnet18 with sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] -----
Current group: random0
Epoch [1/80], Training Loss: 40.9002, Validation Loss Current: 10.0546, Validation Loss AVG: 10.0546, lr: 0.001
Epoch [2/80], Training Loss: 39.7780, Validation Loss Current: 9.9223, Validation Loss AVG: 9.9223, lr: 0.001
Epoch [3/80], Training Loss: 39.1281, Validation Loss Current: 9.8282, Validation Loss AVG: 9.8282, lr: 0.001
Epoch [4/80], Training Loss: 38.6382, Validation Loss Current: 9.6172, Validation Loss AVG: 9.6172, lr: 0.001
Epoch [5/80], Training Loss: 37.7099, Validation Loss Current: 9.4774, Validation Loss AVG: 9.4774, lr: 0.001
Epoch [6/80], Training Loss: 36.7797, Validation Loss Current: 9.1951, Validation Loss AVG: 9.1951, lr: 0.001
Epoch [7/80], Training Loss: 35.9033, Validation Loss Current: 9.0456, Validation Loss AVG: 9.0456, lr: 0.001
Epoch [8/80], Training Loss: 35.8135, Validation Loss Current: 8.9361, Validation Loss AVG: 8.9361, lr: 0.001
Epoch [9/80], Training Loss: 34.4755, Validation Loss Current: 8.8298, Validation Loss AVG: 8.8298, lr: 0.001
Epoch [10/80], Training Loss: 33.4328, Validation Loss Current: 8.7513, Validation Loss AVG: 8.7513, lr: 0.001
Epoch [11/80], Training Loss: 33.0031, Validation Loss Current: 8.4136, Validation Loss AVG: 8.4136, lr: 0.001
Epoch [12/80], Training Loss: 32.4938, Validation Loss Current: 8.6483, Validation Loss AVG: 8.6483, lr: 0.001
Epoch [13/80], Training Loss: 32.0793, Validation Loss Current: 8.4031, Validation Loss AVG: 8.4031, lr: 0.001
Epoch [14/80], Training Loss: 31.2386, Validation Loss Current: 8.1147, Validation Loss AVG: 8.1147, lr: 0.001
Epoch [15/80], Training Loss: 29.8740, Validation Loss Current: 8.4714, Validation Loss AVG: 8.4714, lr: 0.001
Epoch [16/80], Training Loss: 29.7684, Validation Loss Current: 7.9467, Validation Loss AVG: 7.9467, lr: 0.001
Epoch [17/80], Training Loss: 29.1355, Validation Loss Current: 7.5868, Validation Loss AVG: 7.5868, lr: 0.001
Epoch [18/80], Training Loss: 28.7588, Validation Loss Current: 7.7792, Validation Loss AVG: 7.7792, lr: 0.001
Epoch [19/80], Training Loss: 27.7067, Validation Loss Current: 8.1677, Validation Loss AVG: 8.1677, lr: 0.001
Epoch [20/80], Training Loss: 27.1245, Validation Loss Current: 7.8339, Validation Loss AVG: 7.8339, lr: 0.001
Epoch [21/80], Training Loss: 26.6400, Validation Loss Current: 7.6772, Validation Loss AVG: 7.6772, lr: 0.001
Epoch [22/80], Training Loss: 27.7364, Validation Loss Current: 8.3923, Validation Loss AVG: 8.3923, lr: 0.001
Epoch [23/80], Training Loss: 26.5981, Validation Loss Current: 7.5345, Validation Loss AVG: 7.5345, lr: 0.001
Epoch [24/80], Training Loss: 25.1683, Validation Loss Current: 7.2182, Validation Loss AVG: 7.2182, lr: 0.001
Epoch [25/80], Training Loss: 25.5298, Validation Loss Current: 8.1689, Validation Loss AVG: 8.1689, lr: 0.001
Epoch [26/80], Training Loss: 25.1881, Validation Loss Current: 7.7128, Validation Loss AVG: 7.7128, lr: 0.001
Epoch [27/80], Training Loss: 25.1309, Validation Loss Current: 7.0447, Validation Loss AVG: 7.0447, lr: 0.001
Epoch [28/80], Training Loss: 23.7872, Validation Loss Current: 7.1779, Validation Loss AVG: 7.1779, lr: 0.001
Epoch [29/80], Training Loss: 22.2431, Validation Loss Current: 7.7010, Validation Loss AVG: 7.7010, lr: 0.001
Epoch [30/80], Training Loss: 21.9048, Validation Loss Current: 6.8281, Validation Loss AVG: 6.8281, lr: 0.001
Epoch [31/80], Training Loss: 20.4436, Validation Loss Current: 6.5815, Validation Loss AVG: 6.5815, lr: 0.001
Epoch [32/80], Training Loss: 19.6264, Validation Loss Current: 6.6290, Validation Loss AVG: 6.6290, lr: 0.001
Epoch [33/80], Training Loss: 19.0409, Validation Loss Current: 7.0815, Validation Loss AVG: 7.0815, lr: 0.001
Epoch [34/80], Training Loss: 18.7552, Validation Loss Current: 6.8073, Validation Loss AVG: 6.8073, lr: 0.001
Epoch [35/80], Training Loss: 18.9071, Validation Loss Current: 6.9155, Validation Loss AVG: 6.9155, lr: 0.001
Epoch [36/80], Training Loss: 17.0367, Validation Loss Current: 6.7029, Validation Loss AVG: 6.7029, lr: 0.001
Epoch [37/80], Training Loss: 15.6056, Validation Loss Current: 7.9226, Validation Loss AVG: 7.9226, lr: 0.001
Epoch [38/80], Training Loss: 16.9749, Validation Loss Current: 6.7608, Validation Loss AVG: 6.7608, lr: 0.001
Epoch [39/80], Training Loss: 14.5524, Validation Loss Current: 6.1151, Validation Loss AVG: 6.1151, lr: 0.001
Epoch [40/80], Training Loss: 14.6038, Validation Loss Current: 6.5431, Validation Loss AVG: 6.5431, lr: 0.001
Epoch [41/80], Training Loss: 15.4438, Validation Loss Current: 6.7045, Validation Loss AVG: 6.7045, lr: 0.001
Epoch [42/80], Training Loss: 14.1263, Validation Loss Current: 6.5416, Validation Loss AVG: 6.5416, lr: 0.001
Epoch [43/80], Training Loss: 12.1458, Validation Loss Current: 6.4232, Validation Loss AVG: 6.4232, lr: 0.001
Epoch [44/80], Training Loss: 14.8707, Validation Loss Current: 8.1238, Validation Loss AVG: 8.1238, lr: 0.001
Epoch [45/80], Training Loss: 12.6438, Validation Loss Current: 6.8732, Validation Loss AVG: 6.8732, lr: 0.001
Epoch [46/80], Training Loss: 10.7153, Validation Loss Current: 6.5614, Validation Loss AVG: 6.5614, lr: 0.001
Epoch [47/80], Training Loss: 12.2904, Validation Loss Current: 6.8172, Validation Loss AVG: 6.8172, lr: 0.001
Epoch [48/80], Training Loss: 10.3629, Validation Loss Current: 6.4982, Validation Loss AVG: 6.4982, lr: 0.001
Epoch [49/80], Training Loss: 10.2191, Validation Loss Current: 6.6576, Validation Loss AVG: 6.6576, lr: 0.001
Epoch [50/80], Training Loss: 9.5135, Validation Loss Current: 7.5424, Validation Loss AVG: 7.5424, lr: 0.001
Epoch [51/80], Training Loss: 8.5310, Validation Loss Current: 8.1232, Validation Loss AVG: 8.1232, lr: 0.001
Epoch [52/80], Training Loss: 6.8188, Validation Loss Current: 7.7201, Validation Loss AVG: 7.7201, lr: 0.001
Epoch [53/80], Training Loss: 5.2399, Validation Loss Current: 6.6067, Validation Loss AVG: 6.6067, lr: 0.001
Epoch [54/80], Training Loss: 6.9696, Validation Loss Current: 7.1363, Validation Loss AVG: 7.1363, lr: 0.001
Epoch [55/80], Training Loss: 8.5862, Validation Loss Current: 7.1997, Validation Loss AVG: 7.1997, lr: 0.001
Epoch [56/80], Training Loss: 7.4600, Validation Loss Current: 7.3313, Validation Loss AVG: 7.3313, lr: 0.001
Epoch [57/80], Training Loss: 7.2345, Validation Loss Current: 7.4672, Validation Loss AVG: 7.4672, lr: 0.001
Epoch [58/80], Training Loss: 8.8627, Validation Loss Current: 7.9873, Validation Loss AVG: 7.9873, lr: 0.001
Epoch [59/80], Training Loss: 7.0278, Validation Loss Current: 7.4112, Validation Loss AVG: 7.4112, lr: 0.001
Epoch [60/80], Training Loss: 8.7461, Validation Loss Current: 7.8341, Validation Loss AVG: 7.8341, lr: 0.001
Epoch [61/80], Training Loss: 9.2613, Validation Loss Current: 7.9931, Validation Loss AVG: 7.9931, lr: 0.001
Epoch [62/80], Training Loss: 13.2047, Validation Loss Current: 9.8786, Validation Loss AVG: 9.8786, lr: 0.001
Epoch [63/80], Training Loss: 11.9357, Validation Loss Current: 8.2708, Validation Loss AVG: 8.2708, lr: 0.001
Epoch [64/80], Training Loss: 7.6685, Validation Loss Current: 7.9962, Validation Loss AVG: 7.9962, lr: 0.001
Epoch [65/80], Training Loss: 5.2504, Validation Loss Current: 6.8720, Validation Loss AVG: 6.8720, lr: 0.001
Epoch [66/80], Training Loss: 5.3089, Validation Loss Current: 7.9754, Validation Loss AVG: 7.9754, lr: 0.001
Epoch [67/80], Training Loss: 5.3630, Validation Loss Current: 8.0745, Validation Loss AVG: 8.0745, lr: 0.001
Epoch [68/80], Training Loss: 5.9291, Validation Loss Current: 8.1160, Validation Loss AVG: 8.1160, lr: 0.001
Epoch [69/80], Training Loss: 9.5739, Validation Loss Current: 8.1868, Validation Loss AVG: 8.1868, lr: 0.001
 --- Early Stopped ---
Patch distance: random0 finished training. Best epoch: 39 Best val accuracy: [0.20197368421052633, 0.2430921052631579, 0.24671052631578946, 0.2901315789473684, 0.2957236842105263, 0.31447368421052635, 0.3486842105263158, 0.3417763157894737, 0.34407894736842104, 0.37138157894736845, 0.3881578947368421, 0.3717105263157895, 0.4125, 0.41381578947368414, 0.39013157894736844, 0.4358552631578948, 0.46480263157894736, 0.43782894736842104, 0.4220394736842105, 0.44243421052631576, 0.43881578947368427, 0.4240131578947368, 0.4513157894736842, 0.49210526315789477, 0.425, 0.45328947368421046, 0.4934210526315789, 0.4822368421052632, 0.47105263157894733, 0.5305921052631579, 0.5421052631578946, 0.5368421052631579, 0.5296052631578947, 0.5289473684210526, 0.5302631578947368, 0.5365131578947369, 0.49210526315789477, 0.5200657894736842, 0.5819078947368421, 0.562828947368421, 0.5473684210526316, 0.5723684210526316, 0.58125, 0.4967105263157895, 0.5496710526315789, 0.5736842105263158, 0.5641447368421052, 0.5792763157894737, 0.5782894736842106, 0.5335526315789474, 0.5519736842105264, 0.5335526315789474, 0.6075657894736841, 0.5582236842105264, 0.5473684210526315, 0.5726973684210527, 0.5506578947368421, 0.5516447368421054, 0.5470394736842106, 0.5259868421052631, 0.5328947368421052, 0.4809210526315789, 0.49407894736842106, 0.5542763157894737, 0.6042763157894736, 0.5657894736842105, 0.5453947368421053, 0.5746710526315789, 0.55625] Best val loss: 6.115131592750549


Current group: random1
Epoch [1/80], Training Loss: 32.1293, Validation Loss Current: 8.2205, Validation Loss AVG: 8.2205, lr: 0.001
Epoch [2/80], Training Loss: 24.4649, Validation Loss Current: 6.8950, Validation Loss AVG: 6.8950, lr: 0.001
Epoch [3/80], Training Loss: 19.7850, Validation Loss Current: 6.5124, Validation Loss AVG: 6.5124, lr: 0.001
Epoch [4/80], Training Loss: 18.6250, Validation Loss Current: 7.4032, Validation Loss AVG: 7.4032, lr: 0.001
Epoch [5/80], Training Loss: 16.6891, Validation Loss Current: 6.0406, Validation Loss AVG: 6.0406, lr: 0.001
Epoch [6/80], Training Loss: 15.7889, Validation Loss Current: 7.3489, Validation Loss AVG: 7.3489, lr: 0.001
Epoch [7/80], Training Loss: 15.1795, Validation Loss Current: 6.3326, Validation Loss AVG: 6.3326, lr: 0.001
Epoch [8/80], Training Loss: 11.3815, Validation Loss Current: 6.2385, Validation Loss AVG: 6.2385, lr: 0.001
Epoch [9/80], Training Loss: 9.5115, Validation Loss Current: 6.4748, Validation Loss AVG: 6.4748, lr: 0.001
Epoch [10/80], Training Loss: 7.7847, Validation Loss Current: 6.4975, Validation Loss AVG: 6.4975, lr: 0.001
Epoch [11/80], Training Loss: 7.0964, Validation Loss Current: 6.1568, Validation Loss AVG: 6.1568, lr: 0.001
Epoch [12/80], Training Loss: 7.2033, Validation Loss Current: 6.0394, Validation Loss AVG: 6.0394, lr: 0.001
Epoch [13/80], Training Loss: 5.4121, Validation Loss Current: 6.4933, Validation Loss AVG: 6.4933, lr: 0.001
Epoch [14/80], Training Loss: 5.6081, Validation Loss Current: 7.0636, Validation Loss AVG: 7.0636, lr: 0.001
Epoch [15/80], Training Loss: 7.2105, Validation Loss Current: 8.9901, Validation Loss AVG: 8.9901, lr: 0.001
Epoch [16/80], Training Loss: 7.7222, Validation Loss Current: 6.9118, Validation Loss AVG: 6.9118, lr: 0.001
Epoch [17/80], Training Loss: 5.2460, Validation Loss Current: 7.7327, Validation Loss AVG: 7.7327, lr: 0.001
Epoch [18/80], Training Loss: 5.3717, Validation Loss Current: 8.0733, Validation Loss AVG: 8.0733, lr: 0.001
Epoch [19/80], Training Loss: 7.1166, Validation Loss Current: 7.5394, Validation Loss AVG: 7.5394, lr: 0.001
Epoch [20/80], Training Loss: 4.7198, Validation Loss Current: 6.7817, Validation Loss AVG: 6.7817, lr: 0.001
Epoch [21/80], Training Loss: 6.8817, Validation Loss Current: 7.7941, Validation Loss AVG: 7.7941, lr: 0.001
Epoch [22/80], Training Loss: 10.1891, Validation Loss Current: 9.2497, Validation Loss AVG: 9.2497, lr: 0.001
Epoch [23/80], Training Loss: 11.1684, Validation Loss Current: 7.8553, Validation Loss AVG: 7.8553, lr: 0.001
Epoch [24/80], Training Loss: 6.3861, Validation Loss Current: 7.4694, Validation Loss AVG: 7.4694, lr: 0.001
Epoch [25/80], Training Loss: 5.9590, Validation Loss Current: 6.6847, Validation Loss AVG: 6.6847, lr: 0.001
Epoch [26/80], Training Loss: 6.4334, Validation Loss Current: 6.3448, Validation Loss AVG: 6.3448, lr: 0.001
Epoch [27/80], Training Loss: 4.6736, Validation Loss Current: 6.8889, Validation Loss AVG: 6.8889, lr: 0.001
Epoch [28/80], Training Loss: 3.5875, Validation Loss Current: 7.7576, Validation Loss AVG: 7.7576, lr: 0.001
Epoch [29/80], Training Loss: 3.5825, Validation Loss Current: 7.1128, Validation Loss AVG: 7.1128, lr: 0.001
Epoch [30/80], Training Loss: 3.7304, Validation Loss Current: 6.7002, Validation Loss AVG: 6.7002, lr: 0.001
Epoch [31/80], Training Loss: 7.4590, Validation Loss Current: 8.3349, Validation Loss AVG: 8.3349, lr: 0.001
Epoch [32/80], Training Loss: 8.7670, Validation Loss Current: 8.6409, Validation Loss AVG: 8.6409, lr: 0.001
Epoch [33/80], Training Loss: 5.6581, Validation Loss Current: 7.1514, Validation Loss AVG: 7.1514, lr: 0.001
Epoch [34/80], Training Loss: 8.9329, Validation Loss Current: 7.1151, Validation Loss AVG: 7.1151, lr: 0.001
Epoch [35/80], Training Loss: 5.2678, Validation Loss Current: 8.2623, Validation Loss AVG: 8.2623, lr: 0.001
Epoch [36/80], Training Loss: 4.8280, Validation Loss Current: 6.8190, Validation Loss AVG: 6.8190, lr: 0.001
Epoch [37/80], Training Loss: 8.9971, Validation Loss Current: 8.1884, Validation Loss AVG: 8.1884, lr: 0.001
Epoch [38/80], Training Loss: 7.7006, Validation Loss Current: 7.5527, Validation Loss AVG: 7.5527, lr: 0.001
Epoch [39/80], Training Loss: 3.1567, Validation Loss Current: 7.3045, Validation Loss AVG: 7.3045, lr: 0.001
Epoch [40/80], Training Loss: 5.2002, Validation Loss Current: 8.2769, Validation Loss AVG: 8.2769, lr: 0.001
Epoch [41/80], Training Loss: 9.5073, Validation Loss Current: 8.9456, Validation Loss AVG: 8.9456, lr: 0.001
Epoch [42/80], Training Loss: 4.5238, Validation Loss Current: 8.7476, Validation Loss AVG: 8.7476, lr: 0.001
 --- Early Stopped ---
Patch distance: random1 finished training. Best epoch: 12 Best val accuracy: [0.5036184210526317, 0.5509868421052632, 0.5842105263157895, 0.550986842105263, 0.6098684210526316, 0.5611842105263157, 0.5819078947368421, 0.6194078947368421, 0.6065789473684211, 0.5924342105263157, 0.6190789473684211, 0.6269736842105263, 0.6309210526315789, 0.6009868421052632, 0.5578947368421053, 0.5822368421052632, 0.5667763157894737, 0.587171052631579, 0.5782894736842106, 0.6243421052631579, 0.5671052631578948, 0.5279605263157894, 0.5601973684210526, 0.6144736842105263, 0.6266447368421053, 0.6322368421052632, 0.5990131578947369, 0.6013157894736842, 0.624671052631579, 0.6276315789473684, 0.524671052631579, 0.5125, 0.5967105263157896, 0.5792763157894736, 0.5786184210526316, 0.625328947368421, 0.5868421052631578, 0.5891447368421052, 0.6039473684210526, 0.5769736842105264, 0.5506578947368421, 0.5914473684210527] Best val loss: 6.039424848556519


Current group: random2
Epoch [1/80], Training Loss: 35.2000, Validation Loss Current: 6.9799, Validation Loss AVG: 6.9799, lr: 0.001
Epoch [2/80], Training Loss: 19.9747, Validation Loss Current: 5.9484, Validation Loss AVG: 5.9484, lr: 0.001
Epoch [3/80], Training Loss: 13.0059, Validation Loss Current: 4.8527, Validation Loss AVG: 4.8527, lr: 0.001
Epoch [4/80], Training Loss: 11.3242, Validation Loss Current: 4.9142, Validation Loss AVG: 4.9142, lr: 0.001
Epoch [5/80], Training Loss: 9.6020, Validation Loss Current: 6.5287, Validation Loss AVG: 6.5287, lr: 0.001
Epoch [6/80], Training Loss: 15.0729, Validation Loss Current: 6.9413, Validation Loss AVG: 6.9413, lr: 0.001
Epoch [7/80], Training Loss: 17.9317, Validation Loss Current: 6.0263, Validation Loss AVG: 6.0263, lr: 0.001
Epoch [8/80], Training Loss: 14.6212, Validation Loss Current: 6.4981, Validation Loss AVG: 6.4981, lr: 0.001
Epoch [9/80], Training Loss: 10.6656, Validation Loss Current: 6.7133, Validation Loss AVG: 6.7133, lr: 0.001
Epoch [10/80], Training Loss: 8.1809, Validation Loss Current: 6.0406, Validation Loss AVG: 6.0406, lr: 0.001
Epoch [11/80], Training Loss: 7.9820, Validation Loss Current: 6.2111, Validation Loss AVG: 6.2111, lr: 0.001
Epoch [12/80], Training Loss: 6.9624, Validation Loss Current: 5.8001, Validation Loss AVG: 5.8001, lr: 0.001
Epoch [13/80], Training Loss: 12.0235, Validation Loss Current: 6.4854, Validation Loss AVG: 6.4854, lr: 0.001
Epoch [14/80], Training Loss: 8.3838, Validation Loss Current: 6.3650, Validation Loss AVG: 6.3650, lr: 0.001
Epoch [15/80], Training Loss: 8.4969, Validation Loss Current: 6.6476, Validation Loss AVG: 6.6476, lr: 0.001
Epoch [16/80], Training Loss: 7.8896, Validation Loss Current: 5.8711, Validation Loss AVG: 5.8711, lr: 0.001
Epoch [17/80], Training Loss: 4.6098, Validation Loss Current: 5.3084, Validation Loss AVG: 5.3084, lr: 0.001
Epoch [18/80], Training Loss: 4.5423, Validation Loss Current: 5.6677, Validation Loss AVG: 5.6677, lr: 0.001
Epoch [19/80], Training Loss: 7.8846, Validation Loss Current: 6.8127, Validation Loss AVG: 6.8127, lr: 0.001
Epoch [20/80], Training Loss: 8.5624, Validation Loss Current: 6.7434, Validation Loss AVG: 6.7434, lr: 0.001
Epoch [21/80], Training Loss: 4.0402, Validation Loss Current: 6.5063, Validation Loss AVG: 6.5063, lr: 0.001
Epoch [22/80], Training Loss: 6.6551, Validation Loss Current: 6.6213, Validation Loss AVG: 6.6213, lr: 0.001
Epoch [23/80], Training Loss: 6.2951, Validation Loss Current: 7.2839, Validation Loss AVG: 7.2839, lr: 0.001
Epoch [24/80], Training Loss: 4.4816, Validation Loss Current: 6.6013, Validation Loss AVG: 6.6013, lr: 0.001
Epoch [25/80], Training Loss: 2.8974, Validation Loss Current: 6.4796, Validation Loss AVG: 6.4796, lr: 0.001
Epoch [26/80], Training Loss: 2.9400, Validation Loss Current: 6.7204, Validation Loss AVG: 6.7204, lr: 0.001
Epoch [27/80], Training Loss: 4.8066, Validation Loss Current: 6.9341, Validation Loss AVG: 6.9341, lr: 0.001
Epoch [28/80], Training Loss: 3.8204, Validation Loss Current: 6.3794, Validation Loss AVG: 6.3794, lr: 0.001
Epoch [29/80], Training Loss: 3.2267, Validation Loss Current: 7.0614, Validation Loss AVG: 7.0614, lr: 0.001
Epoch [30/80], Training Loss: 10.5660, Validation Loss Current: 8.3403, Validation Loss AVG: 8.3403, lr: 0.001
Epoch [31/80], Training Loss: 5.8846, Validation Loss Current: 6.5222, Validation Loss AVG: 6.5222, lr: 0.001
Epoch [32/80], Training Loss: 5.1346, Validation Loss Current: 6.7049, Validation Loss AVG: 6.7049, lr: 0.001
Epoch [33/80], Training Loss: 3.1352, Validation Loss Current: 6.9271, Validation Loss AVG: 6.9271, lr: 0.001
 --- Early Stopped ---
Patch distance: random2 finished training. Best epoch: 3 Best val accuracy: [0.618421052631579, 0.6371710526315789, 0.687171052631579, 0.6970394736842105, 0.6197368421052631, 0.5976973684210526, 0.6276315789473684, 0.5911184210526316, 0.5976973684210527, 0.6325657894736842, 0.6453947368421054, 0.6444078947368421, 0.6276315789473685, 0.6273026315789474, 0.6305921052631579, 0.6476973684210525, 0.6700657894736842, 0.6634868421052632, 0.6351973684210527, 0.6345394736842105, 0.6542763157894738, 0.6375, 0.6032894736842105, 0.6592105263157896, 0.65625, 0.674342105263158, 0.6243421052631579, 0.6615131578947369, 0.6148026315789473, 0.6009868421052632, 0.6391447368421053, 0.6516447368421052, 0.6532894736842105] Best val loss: 4.852721035480499


Current group: random3
Epoch [1/80], Training Loss: 34.0990, Validation Loss Current: 6.6441, Validation Loss AVG: 6.6441, lr: 0.001
Epoch [2/80], Training Loss: 19.8647, Validation Loss Current: 5.1083, Validation Loss AVG: 5.1083, lr: 0.001
Epoch [3/80], Training Loss: 14.7090, Validation Loss Current: 4.9056, Validation Loss AVG: 4.9056, lr: 0.001
Epoch [4/80], Training Loss: 11.9611, Validation Loss Current: 5.8271, Validation Loss AVG: 5.8271, lr: 0.001
Epoch [5/80], Training Loss: 12.0459, Validation Loss Current: 5.1922, Validation Loss AVG: 5.1922, lr: 0.001
Epoch [6/80], Training Loss: 7.8394, Validation Loss Current: 4.9502, Validation Loss AVG: 4.9502, lr: 0.001
Epoch [7/80], Training Loss: 6.4482, Validation Loss Current: 9.1800, Validation Loss AVG: 9.1800, lr: 0.001
Epoch [8/80], Training Loss: 8.0020, Validation Loss Current: 8.2828, Validation Loss AVG: 8.2828, lr: 0.001
Epoch [9/80], Training Loss: 7.4461, Validation Loss Current: 4.9361, Validation Loss AVG: 4.9361, lr: 0.001
Epoch [10/80], Training Loss: 4.2192, Validation Loss Current: 4.6343, Validation Loss AVG: 4.6343, lr: 0.001
Epoch [11/80], Training Loss: 4.2446, Validation Loss Current: 4.9559, Validation Loss AVG: 4.9559, lr: 0.001
Epoch [12/80], Training Loss: 6.5203, Validation Loss Current: 6.2081, Validation Loss AVG: 6.2081, lr: 0.001
Epoch [13/80], Training Loss: 6.4739, Validation Loss Current: 7.0229, Validation Loss AVG: 7.0229, lr: 0.001
Epoch [14/80], Training Loss: 7.1995, Validation Loss Current: 5.8491, Validation Loss AVG: 5.8491, lr: 0.001
Epoch [15/80], Training Loss: 8.6463, Validation Loss Current: 7.6794, Validation Loss AVG: 7.6794, lr: 0.001
Epoch [16/80], Training Loss: 12.6337, Validation Loss Current: 7.7506, Validation Loss AVG: 7.7506, lr: 0.001
Epoch [17/80], Training Loss: 5.0153, Validation Loss Current: 5.4085, Validation Loss AVG: 5.4085, lr: 0.001
Epoch [18/80], Training Loss: 4.8395, Validation Loss Current: 5.0200, Validation Loss AVG: 5.0200, lr: 0.001
Epoch [19/80], Training Loss: 5.9890, Validation Loss Current: 5.7537, Validation Loss AVG: 5.7537, lr: 0.001
Epoch [20/80], Training Loss: 5.5342, Validation Loss Current: 6.1391, Validation Loss AVG: 6.1391, lr: 0.001
Epoch [21/80], Training Loss: 4.2245, Validation Loss Current: 6.4319, Validation Loss AVG: 6.4319, lr: 0.001
Epoch [22/80], Training Loss: 4.0294, Validation Loss Current: 5.4776, Validation Loss AVG: 5.4776, lr: 0.001
Epoch [23/80], Training Loss: 4.4884, Validation Loss Current: 5.7362, Validation Loss AVG: 5.7362, lr: 0.001
Epoch [24/80], Training Loss: 3.2789, Validation Loss Current: 6.6707, Validation Loss AVG: 6.6707, lr: 0.001
Epoch [25/80], Training Loss: 3.1926, Validation Loss Current: 5.8969, Validation Loss AVG: 5.8969, lr: 0.001
Epoch [26/80], Training Loss: 2.9815, Validation Loss Current: 6.0344, Validation Loss AVG: 6.0344, lr: 0.001
Epoch [27/80], Training Loss: 5.2240, Validation Loss Current: 7.3480, Validation Loss AVG: 7.3480, lr: 0.001
Epoch [28/80], Training Loss: 7.1333, Validation Loss Current: 5.9042, Validation Loss AVG: 5.9042, lr: 0.001
Epoch [29/80], Training Loss: 3.0506, Validation Loss Current: 7.8040, Validation Loss AVG: 7.8040, lr: 0.001
Epoch [30/80], Training Loss: 1.5377, Validation Loss Current: 5.6615, Validation Loss AVG: 5.6615, lr: 0.001
Epoch [31/80], Training Loss: 1.4662, Validation Loss Current: 5.7941, Validation Loss AVG: 5.7941, lr: 0.001
Epoch [32/80], Training Loss: 1.3643, Validation Loss Current: 5.5115, Validation Loss AVG: 5.5115, lr: 0.001
Epoch [33/80], Training Loss: 3.9919, Validation Loss Current: 6.6273, Validation Loss AVG: 6.6273, lr: 0.001
Epoch [34/80], Training Loss: 9.9419, Validation Loss Current: 7.3168, Validation Loss AVG: 7.3168, lr: 0.001
Epoch [35/80], Training Loss: 5.1866, Validation Loss Current: 6.8808, Validation Loss AVG: 6.8808, lr: 0.001
Epoch [36/80], Training Loss: 2.7141, Validation Loss Current: 5.7750, Validation Loss AVG: 5.7750, lr: 0.001
Epoch [37/80], Training Loss: 4.1012, Validation Loss Current: 6.2679, Validation Loss AVG: 6.2679, lr: 0.001
Epoch [38/80], Training Loss: 5.1631, Validation Loss Current: 8.8558, Validation Loss AVG: 8.8558, lr: 0.001
Epoch [39/80], Training Loss: 6.5033, Validation Loss Current: 6.7479, Validation Loss AVG: 6.7479, lr: 0.001
Epoch [40/80], Training Loss: 2.6850, Validation Loss Current: 5.9801, Validation Loss AVG: 5.9801, lr: 0.001
 --- Early Stopped ---
Patch distance: random3 finished training. Best epoch: 10 Best val accuracy: [0.6503289473684211, 0.6888157894736843, 0.6963815789473683, 0.65625, 0.6963815789473684, 0.7029605263157894, 0.5733552631578946, 0.5763157894736842, 0.7088815789473684, 0.71875, 0.706907894736842, 0.65, 0.6292763157894739, 0.6664473684210527, 0.6194078947368421, 0.5865131578947368, 0.6983552631578946, 0.7042763157894737, 0.6710526315789475, 0.6723684210526315, 0.6726973684210527, 0.6980263157894737, 0.6894736842105263, 0.6440789473684211, 0.6720394736842106, 0.675, 0.6486842105263158, 0.699342105263158, 0.6305921052631579, 0.6967105263157894, 0.7046052631578947, 0.7108552631578947, 0.6684210526315789, 0.6164473684210527, 0.6667763157894736, 0.6891447368421052, 0.6838815789473685, 0.5460526315789475, 0.6549342105263157, 0.6875] Best val loss: 4.634250700473785


Current group: random4
Epoch [1/80], Training Loss: 35.6506, Validation Loss Current: 5.7245, Validation Loss AVG: 5.7245, lr: 0.001
Epoch [2/80], Training Loss: 20.6012, Validation Loss Current: 5.6608, Validation Loss AVG: 5.6608, lr: 0.001
Epoch [3/80], Training Loss: 15.4471, Validation Loss Current: 5.3496, Validation Loss AVG: 5.3496, lr: 0.001
Epoch [4/80], Training Loss: 11.3507, Validation Loss Current: 7.7392, Validation Loss AVG: 7.7392, lr: 0.001
Epoch [5/80], Training Loss: 13.9571, Validation Loss Current: 6.6789, Validation Loss AVG: 6.6789, lr: 0.001
Epoch [6/80], Training Loss: 13.3638, Validation Loss Current: 7.3070, Validation Loss AVG: 7.3070, lr: 0.001
Epoch [7/80], Training Loss: 10.1441, Validation Loss Current: 9.7272, Validation Loss AVG: 9.7272, lr: 0.001
Epoch [8/80], Training Loss: 8.3344, Validation Loss Current: 5.4544, Validation Loss AVG: 5.4544, lr: 0.001
Epoch [9/80], Training Loss: 5.6398, Validation Loss Current: 5.6584, Validation Loss AVG: 5.6584, lr: 0.001
Epoch [10/80], Training Loss: 7.8810, Validation Loss Current: 5.4410, Validation Loss AVG: 5.4410, lr: 0.001
Epoch [11/80], Training Loss: 6.8071, Validation Loss Current: 5.3759, Validation Loss AVG: 5.3759, lr: 0.001
Epoch [12/80], Training Loss: 4.1929, Validation Loss Current: 5.1844, Validation Loss AVG: 5.1844, lr: 0.001
Epoch [13/80], Training Loss: 5.6698, Validation Loss Current: 5.1456, Validation Loss AVG: 5.1456, lr: 0.001
Epoch [14/80], Training Loss: 3.9785, Validation Loss Current: 4.8734, Validation Loss AVG: 4.8734, lr: 0.001
Epoch [15/80], Training Loss: 3.9605, Validation Loss Current: 5.0376, Validation Loss AVG: 5.0376, lr: 0.001
Epoch [16/80], Training Loss: 2.9004, Validation Loss Current: 5.5182, Validation Loss AVG: 5.5182, lr: 0.001
Epoch [17/80], Training Loss: 1.8159, Validation Loss Current: 4.7363, Validation Loss AVG: 4.7363, lr: 0.001
Epoch [18/80], Training Loss: 5.3807, Validation Loss Current: 4.9495, Validation Loss AVG: 4.9495, lr: 0.001
Epoch [19/80], Training Loss: 3.8479, Validation Loss Current: 4.9062, Validation Loss AVG: 4.9062, lr: 0.001
Epoch [20/80], Training Loss: 4.0623, Validation Loss Current: 5.4668, Validation Loss AVG: 5.4668, lr: 0.001
Epoch [21/80], Training Loss: 4.4818, Validation Loss Current: 6.0204, Validation Loss AVG: 6.0204, lr: 0.001
Epoch [22/80], Training Loss: 5.4234, Validation Loss Current: 7.6279, Validation Loss AVG: 7.6279, lr: 0.001
Epoch [23/80], Training Loss: 5.6393, Validation Loss Current: 6.6849, Validation Loss AVG: 6.6849, lr: 0.001
Epoch [24/80], Training Loss: 5.8053, Validation Loss Current: 6.1053, Validation Loss AVG: 6.1053, lr: 0.001
Epoch [25/80], Training Loss: 3.1706, Validation Loss Current: 5.9291, Validation Loss AVG: 5.9291, lr: 0.001
Epoch [26/80], Training Loss: 2.5129, Validation Loss Current: 5.7457, Validation Loss AVG: 5.7457, lr: 0.001
Epoch [27/80], Training Loss: 2.8162, Validation Loss Current: 6.4526, Validation Loss AVG: 6.4526, lr: 0.001
Epoch [28/80], Training Loss: 1.0154, Validation Loss Current: 5.3756, Validation Loss AVG: 5.3756, lr: 0.001
Epoch [29/80], Training Loss: 3.6663, Validation Loss Current: 6.3349, Validation Loss AVG: 6.3349, lr: 0.001
Epoch [30/80], Training Loss: 5.6080, Validation Loss Current: 8.3983, Validation Loss AVG: 8.3983, lr: 0.001
Epoch [31/80], Training Loss: 3.9391, Validation Loss Current: 8.0857, Validation Loss AVG: 8.0857, lr: 0.001
Epoch [32/80], Training Loss: 6.0232, Validation Loss Current: 7.6150, Validation Loss AVG: 7.6150, lr: 0.001
Epoch [33/80], Training Loss: 3.6612, Validation Loss Current: 7.2899, Validation Loss AVG: 7.2899, lr: 0.001
Epoch [34/80], Training Loss: 5.3080, Validation Loss Current: 8.3549, Validation Loss AVG: 8.3549, lr: 0.001
Epoch [35/80], Training Loss: 5.6889, Validation Loss Current: 6.2650, Validation Loss AVG: 6.2650, lr: 0.001
Epoch [36/80], Training Loss: 5.0577, Validation Loss Current: 6.1863, Validation Loss AVG: 6.1863, lr: 0.001
Epoch [37/80], Training Loss: 4.8326, Validation Loss Current: 6.3558, Validation Loss AVG: 6.3558, lr: 0.001
Epoch [38/80], Training Loss: 6.4602, Validation Loss Current: 7.8998, Validation Loss AVG: 7.8998, lr: 0.001
Epoch [39/80], Training Loss: 4.0522, Validation Loss Current: 7.5220, Validation Loss AVG: 7.5220, lr: 0.001
Epoch [40/80], Training Loss: 1.9835, Validation Loss Current: 6.2687, Validation Loss AVG: 6.2687, lr: 0.001
Epoch [41/80], Training Loss: 3.5554, Validation Loss Current: 6.2381, Validation Loss AVG: 6.2381, lr: 0.001
Epoch [42/80], Training Loss: 2.2448, Validation Loss Current: 6.0846, Validation Loss AVG: 6.0846, lr: 0.001
Epoch [43/80], Training Loss: 1.8665, Validation Loss Current: 6.1736, Validation Loss AVG: 6.1736, lr: 0.001
Epoch [44/80], Training Loss: 7.3145, Validation Loss Current: 6.2783, Validation Loss AVG: 6.2783, lr: 0.001
Epoch [45/80], Training Loss: 4.1449, Validation Loss Current: 7.1689, Validation Loss AVG: 7.1689, lr: 0.001
Epoch [46/80], Training Loss: 4.3502, Validation Loss Current: 6.5318, Validation Loss AVG: 6.5318, lr: 0.001
Epoch [47/80], Training Loss: 4.7355, Validation Loss Current: 7.3804, Validation Loss AVG: 7.3804, lr: 0.001
 --- Early Stopped ---
Patch distance: random4 finished training. Best epoch: 17 Best val accuracy: [0.6858552631578947, 0.6332236842105263, 0.6605263157894736, 0.6190789473684211, 0.6049342105263158, 0.562171052631579, 0.5371710526315789, 0.6654605263157893, 0.6506578947368421, 0.6595394736842105, 0.6763157894736842, 0.681578947368421, 0.7013157894736843, 0.7101973684210526, 0.7118421052631578, 0.6865131578947368, 0.7243421052631579, 0.7174342105263158, 0.7233552631578948, 0.6944078947368422, 0.6904605263157894, 0.6210526315789473, 0.6506578947368421, 0.6786184210526316, 0.6917763157894736, 0.7029605263157895, 0.6898026315789474, 0.7098684210526315, 0.6815789473684211, 0.61875, 0.6434210526315789, 0.6457236842105262, 0.6444078947368421, 0.6095394736842106, 0.6825657894736843, 0.6779605263157895, 0.6690789473684211, 0.6233552631578948, 0.65, 0.6865131578947368, 0.6792763157894737, 0.6753289473684211, 0.6901315789473684, 0.6904605263157895, 0.6355263157894736, 0.6753289473684211, 0.6351973684210527] Best val loss: 4.736306238174438


Fold: 1
----- Training resnet18 with sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] -----
Current group: random0
Epoch [1/80], Training Loss: 40.6671, Validation Loss Current: 9.9529, Validation Loss AVG: 9.9529, lr: 0.001
Epoch [2/80], Training Loss: 39.3106, Validation Loss Current: 9.9065, Validation Loss AVG: 9.9065, lr: 0.001
Epoch [3/80], Training Loss: 39.5954, Validation Loss Current: 9.6389, Validation Loss AVG: 9.6389, lr: 0.001
Epoch [4/80], Training Loss: 38.1020, Validation Loss Current: 9.4857, Validation Loss AVG: 9.4857, lr: 0.001
Epoch [5/80], Training Loss: 37.5398, Validation Loss Current: 9.3124, Validation Loss AVG: 9.3124, lr: 0.001
Epoch [6/80], Training Loss: 36.4242, Validation Loss Current: 9.4165, Validation Loss AVG: 9.4165, lr: 0.001
Epoch [7/80], Training Loss: 35.5791, Validation Loss Current: 9.1748, Validation Loss AVG: 9.1748, lr: 0.001
Epoch [8/80], Training Loss: 34.8094, Validation Loss Current: 8.9246, Validation Loss AVG: 8.9246, lr: 0.001
Epoch [9/80], Training Loss: 34.0758, Validation Loss Current: 8.7761, Validation Loss AVG: 8.7761, lr: 0.001
Epoch [10/80], Training Loss: 33.0066, Validation Loss Current: 8.4380, Validation Loss AVG: 8.4380, lr: 0.001
Epoch [11/80], Training Loss: 31.7573, Validation Loss Current: 8.2636, Validation Loss AVG: 8.2636, lr: 0.001
Epoch [12/80], Training Loss: 31.7869, Validation Loss Current: 8.1779, Validation Loss AVG: 8.1779, lr: 0.001
Epoch [13/80], Training Loss: 31.5536, Validation Loss Current: 8.0189, Validation Loss AVG: 8.0189, lr: 0.001
Epoch [14/80], Training Loss: 30.2270, Validation Loss Current: 8.1945, Validation Loss AVG: 8.1945, lr: 0.001
Epoch [15/80], Training Loss: 30.2117, Validation Loss Current: 7.9183, Validation Loss AVG: 7.9183, lr: 0.001
Epoch [16/80], Training Loss: 28.7814, Validation Loss Current: 7.6203, Validation Loss AVG: 7.6203, lr: 0.001
Epoch [17/80], Training Loss: 27.7395, Validation Loss Current: 7.4704, Validation Loss AVG: 7.4704, lr: 0.001
Epoch [18/80], Training Loss: 26.4638, Validation Loss Current: 7.4393, Validation Loss AVG: 7.4393, lr: 0.001
Epoch [19/80], Training Loss: 26.5887, Validation Loss Current: 8.0967, Validation Loss AVG: 8.0967, lr: 0.001
Epoch [20/80], Training Loss: 26.1880, Validation Loss Current: 7.4673, Validation Loss AVG: 7.4673, lr: 0.001
Epoch [21/80], Training Loss: 25.1998, Validation Loss Current: 7.3116, Validation Loss AVG: 7.3116, lr: 0.001
Epoch [22/80], Training Loss: 24.0671, Validation Loss Current: 8.5738, Validation Loss AVG: 8.5738, lr: 0.001
Epoch [23/80], Training Loss: 24.1121, Validation Loss Current: 8.2208, Validation Loss AVG: 8.2208, lr: 0.001
Epoch [24/80], Training Loss: 23.7094, Validation Loss Current: 7.2089, Validation Loss AVG: 7.2089, lr: 0.001
Epoch [25/80], Training Loss: 22.7602, Validation Loss Current: 7.5445, Validation Loss AVG: 7.5445, lr: 0.001
Epoch [26/80], Training Loss: 22.3367, Validation Loss Current: 6.9332, Validation Loss AVG: 6.9332, lr: 0.001
Epoch [27/80], Training Loss: 20.5481, Validation Loss Current: 7.1204, Validation Loss AVG: 7.1204, lr: 0.001
Epoch [28/80], Training Loss: 20.0807, Validation Loss Current: 7.5825, Validation Loss AVG: 7.5825, lr: 0.001
Epoch [29/80], Training Loss: 19.9641, Validation Loss Current: 7.7637, Validation Loss AVG: 7.7637, lr: 0.001
Epoch [30/80], Training Loss: 19.3510, Validation Loss Current: 7.4391, Validation Loss AVG: 7.4391, lr: 0.001
Epoch [31/80], Training Loss: 19.2012, Validation Loss Current: 7.2194, Validation Loss AVG: 7.2194, lr: 0.001
Epoch [32/80], Training Loss: 21.5909, Validation Loss Current: 7.5631, Validation Loss AVG: 7.5631, lr: 0.001
Epoch [33/80], Training Loss: 17.2544, Validation Loss Current: 7.2781, Validation Loss AVG: 7.2781, lr: 0.001
Epoch [34/80], Training Loss: 15.2906, Validation Loss Current: 6.9324, Validation Loss AVG: 6.9324, lr: 0.001
Epoch [35/80], Training Loss: 15.6599, Validation Loss Current: 6.5938, Validation Loss AVG: 6.5938, lr: 0.001
Epoch [36/80], Training Loss: 14.1134, Validation Loss Current: 7.4621, Validation Loss AVG: 7.4621, lr: 0.001
Epoch [37/80], Training Loss: 15.5946, Validation Loss Current: 8.5708, Validation Loss AVG: 8.5708, lr: 0.001
Epoch [38/80], Training Loss: 14.4223, Validation Loss Current: 6.7021, Validation Loss AVG: 6.7021, lr: 0.001
Epoch [39/80], Training Loss: 14.3697, Validation Loss Current: 7.2370, Validation Loss AVG: 7.2370, lr: 0.001
Epoch [40/80], Training Loss: 14.5111, Validation Loss Current: 8.4147, Validation Loss AVG: 8.4147, lr: 0.001
Epoch [41/80], Training Loss: 18.9360, Validation Loss Current: 8.0608, Validation Loss AVG: 8.0608, lr: 0.001
Epoch [42/80], Training Loss: 15.5363, Validation Loss Current: 8.3716, Validation Loss AVG: 8.3716, lr: 0.001
Epoch [43/80], Training Loss: 11.5481, Validation Loss Current: 7.8131, Validation Loss AVG: 7.8131, lr: 0.001
Epoch [44/80], Training Loss: 12.2690, Validation Loss Current: 6.9009, Validation Loss AVG: 6.9009, lr: 0.001
Epoch [45/80], Training Loss: 8.7289, Validation Loss Current: 6.9041, Validation Loss AVG: 6.9041, lr: 0.001
Epoch [46/80], Training Loss: 9.8343, Validation Loss Current: 7.5600, Validation Loss AVG: 7.5600, lr: 0.001
Epoch [47/80], Training Loss: 13.2457, Validation Loss Current: 9.1151, Validation Loss AVG: 9.1151, lr: 0.001
Epoch [48/80], Training Loss: 11.9961, Validation Loss Current: 8.2238, Validation Loss AVG: 8.2238, lr: 0.001
Epoch [49/80], Training Loss: 10.7161, Validation Loss Current: 9.0943, Validation Loss AVG: 9.0943, lr: 0.001
Epoch [50/80], Training Loss: 11.3418, Validation Loss Current: 7.7890, Validation Loss AVG: 7.7890, lr: 0.001
Epoch [51/80], Training Loss: 9.3328, Validation Loss Current: 7.2338, Validation Loss AVG: 7.2338, lr: 0.001
Epoch [52/80], Training Loss: 6.2648, Validation Loss Current: 6.6002, Validation Loss AVG: 6.6002, lr: 0.001
Epoch [53/80], Training Loss: 4.6613, Validation Loss Current: 7.2725, Validation Loss AVG: 7.2725, lr: 0.001
Epoch [54/80], Training Loss: 4.5196, Validation Loss Current: 7.0850, Validation Loss AVG: 7.0850, lr: 0.001
Epoch [55/80], Training Loss: 5.6483, Validation Loss Current: 7.1635, Validation Loss AVG: 7.1635, lr: 0.001
Epoch [56/80], Training Loss: 5.7771, Validation Loss Current: 7.2955, Validation Loss AVG: 7.2955, lr: 0.001
Epoch [57/80], Training Loss: 5.5628, Validation Loss Current: 7.3942, Validation Loss AVG: 7.3942, lr: 0.001
Epoch [58/80], Training Loss: 3.8178, Validation Loss Current: 7.5569, Validation Loss AVG: 7.5569, lr: 0.001
Epoch [59/80], Training Loss: 4.7002, Validation Loss Current: 7.4201, Validation Loss AVG: 7.4201, lr: 0.001
Epoch [60/80], Training Loss: 4.6360, Validation Loss Current: 9.2193, Validation Loss AVG: 9.2193, lr: 0.001
Epoch [61/80], Training Loss: 8.3702, Validation Loss Current: 8.8569, Validation Loss AVG: 8.8569, lr: 0.001
Epoch [62/80], Training Loss: 6.7175, Validation Loss Current: 8.4479, Validation Loss AVG: 8.4479, lr: 0.001
Epoch [63/80], Training Loss: 5.4725, Validation Loss Current: 8.0550, Validation Loss AVG: 8.0550, lr: 0.001
Epoch [64/80], Training Loss: 4.2051, Validation Loss Current: 7.6185, Validation Loss AVG: 7.6185, lr: 0.001
Epoch [65/80], Training Loss: 3.2606, Validation Loss Current: 8.0488, Validation Loss AVG: 8.0488, lr: 0.001
 --- Early Stopped ---
Patch distance: random0 finished training. Best epoch: 35 Best val accuracy: [0.25032894736842104, 0.2565789473684211, 0.2970394736842105, 0.2973684210526316, 0.30657894736842106, 0.31118421052631584, 0.3319078947368421, 0.3832236842105263, 0.3516447368421053, 0.4131578947368421, 0.41019736842105264, 0.44210526315789467, 0.4365131578947368, 0.4115131578947368, 0.4526315789473684, 0.4631578947368421, 0.4828947368421053, 0.48717105263157895, 0.4457236842105264, 0.4756578947368421, 0.4944078947368421, 0.43815789473684214, 0.43256578947368424, 0.4901315789473684, 0.48190789473684215, 0.5082236842105263, 0.49967105263157896, 0.49506578947368424, 0.49046052631578946, 0.47894736842105257, 0.5125, 0.4921052631578947, 0.5013157894736842, 0.5273026315789474, 0.5407894736842106, 0.5052631578947369, 0.4546052631578948, 0.5453947368421053, 0.5351973684210526, 0.46480263157894736, 0.4927631578947368, 0.4769736842105264, 0.5052631578947369, 0.5332236842105262, 0.5519736842105264, 0.5328947368421053, 0.46842105263157896, 0.5055921052631579, 0.49375, 0.500328947368421, 0.5375, 0.5782894736842105, 0.5490131578947368, 0.5601973684210526, 0.5519736842105263, 0.550328947368421, 0.562828947368421, 0.5595394736842105, 0.5608552631578947, 0.4776315789473683, 0.5273026315789474, 0.5332236842105262, 0.5592105263157894, 0.5723684210526316, 0.5605263157894737] Best val loss: 6.593838763237


Current group: random1
Epoch [1/80], Training Loss: 33.3685, Validation Loss Current: 9.4510, Validation Loss AVG: 9.4510, lr: 0.001
Epoch [2/80], Training Loss: 25.6307, Validation Loss Current: 6.6782, Validation Loss AVG: 6.6782, lr: 0.001
Epoch [3/80], Training Loss: 21.1039, Validation Loss Current: 7.3061, Validation Loss AVG: 7.3061, lr: 0.001
Epoch [4/80], Training Loss: 18.4915, Validation Loss Current: 6.3328, Validation Loss AVG: 6.3328, lr: 0.001
Epoch [5/80], Training Loss: 14.7126, Validation Loss Current: 7.1516, Validation Loss AVG: 7.1516, lr: 0.001
Epoch [6/80], Training Loss: 11.8737, Validation Loss Current: 6.2820, Validation Loss AVG: 6.2820, lr: 0.001
Epoch [7/80], Training Loss: 12.4306, Validation Loss Current: 7.5925, Validation Loss AVG: 7.5925, lr: 0.001
Epoch [8/80], Training Loss: 11.8409, Validation Loss Current: 6.1103, Validation Loss AVG: 6.1103, lr: 0.001
Epoch [9/80], Training Loss: 8.6507, Validation Loss Current: 6.4563, Validation Loss AVG: 6.4563, lr: 0.001
Epoch [10/80], Training Loss: 8.7052, Validation Loss Current: 6.7861, Validation Loss AVG: 6.7861, lr: 0.001
Epoch [11/80], Training Loss: 6.2953, Validation Loss Current: 6.9121, Validation Loss AVG: 6.9121, lr: 0.001
Epoch [12/80], Training Loss: 5.7745, Validation Loss Current: 7.1900, Validation Loss AVG: 7.1900, lr: 0.001
Epoch [13/80], Training Loss: 9.4528, Validation Loss Current: 6.7464, Validation Loss AVG: 6.7464, lr: 0.001
Epoch [14/80], Training Loss: 6.5706, Validation Loss Current: 8.8605, Validation Loss AVG: 8.8605, lr: 0.001
Epoch [15/80], Training Loss: 9.0903, Validation Loss Current: 7.3299, Validation Loss AVG: 7.3299, lr: 0.001
Epoch [16/80], Training Loss: 9.6772, Validation Loss Current: 6.8498, Validation Loss AVG: 6.8498, lr: 0.001
Epoch [17/80], Training Loss: 7.1539, Validation Loss Current: 6.9143, Validation Loss AVG: 6.9143, lr: 0.001
Epoch [18/80], Training Loss: 4.8318, Validation Loss Current: 7.4052, Validation Loss AVG: 7.4052, lr: 0.001
Epoch [19/80], Training Loss: 6.6222, Validation Loss Current: 7.3681, Validation Loss AVG: 7.3681, lr: 0.001
Epoch [20/80], Training Loss: 7.3771, Validation Loss Current: 7.1723, Validation Loss AVG: 7.1723, lr: 0.001
Epoch [21/80], Training Loss: 6.6019, Validation Loss Current: 7.4203, Validation Loss AVG: 7.4203, lr: 0.001
Epoch [22/80], Training Loss: 7.9035, Validation Loss Current: 9.2499, Validation Loss AVG: 9.2499, lr: 0.001
Epoch [23/80], Training Loss: 7.8748, Validation Loss Current: 9.2338, Validation Loss AVG: 9.2338, lr: 0.001
Epoch [24/80], Training Loss: 9.9273, Validation Loss Current: 8.1487, Validation Loss AVG: 8.1487, lr: 0.001
Epoch [25/80], Training Loss: 6.2462, Validation Loss Current: 7.1665, Validation Loss AVG: 7.1665, lr: 0.001
Epoch [26/80], Training Loss: 5.8030, Validation Loss Current: 7.3809, Validation Loss AVG: 7.3809, lr: 0.001
Epoch [27/80], Training Loss: 4.6308, Validation Loss Current: 8.1855, Validation Loss AVG: 8.1855, lr: 0.001
Epoch [28/80], Training Loss: 6.2902, Validation Loss Current: 10.6230, Validation Loss AVG: 10.6230, lr: 0.001
Epoch [29/80], Training Loss: 9.1655, Validation Loss Current: 9.1170, Validation Loss AVG: 9.1170, lr: 0.001
Epoch [30/80], Training Loss: 7.8724, Validation Loss Current: 7.8040, Validation Loss AVG: 7.8040, lr: 0.001
Epoch [31/80], Training Loss: 9.4191, Validation Loss Current: 8.9918, Validation Loss AVG: 8.9918, lr: 0.001
Epoch [32/80], Training Loss: 4.5216, Validation Loss Current: 7.4510, Validation Loss AVG: 7.4510, lr: 0.001
Epoch [33/80], Training Loss: 9.3145, Validation Loss Current: 8.6862, Validation Loss AVG: 8.6862, lr: 0.001
Epoch [34/80], Training Loss: 6.8283, Validation Loss Current: 8.3622, Validation Loss AVG: 8.3622, lr: 0.001
Epoch [35/80], Training Loss: 7.3720, Validation Loss Current: 8.4345, Validation Loss AVG: 8.4345, lr: 0.001
Epoch [36/80], Training Loss: 3.1469, Validation Loss Current: 7.2498, Validation Loss AVG: 7.2498, lr: 0.001
Epoch [37/80], Training Loss: 4.1378, Validation Loss Current: 8.3813, Validation Loss AVG: 8.3813, lr: 0.001
Epoch [38/80], Training Loss: 13.2714, Validation Loss Current: 13.2197, Validation Loss AVG: 13.2197, lr: 0.001
 --- Early Stopped ---
Patch distance: random1 finished training. Best epoch: 8 Best val accuracy: [0.49046052631578946, 0.5608552631578949, 0.5292763157894737, 0.5927631578947368, 0.5476973684210525, 0.6029605263157894, 0.5365131578947369, 0.6144736842105264, 0.6148026315789472, 0.5901315789473685, 0.5865131578947368, 0.5888157894736843, 0.5881578947368421, 0.5421052631578948, 0.5605263157894737, 0.5878289473684211, 0.5881578947368421, 0.5973684210526317, 0.5914473684210526, 0.6, 0.5861842105263158, 0.5407894736842105, 0.5641447368421052, 0.5417763157894736, 0.6177631578947368, 0.5792763157894736, 0.6164473684210526, 0.50625, 0.5325657894736843, 0.5763157894736841, 0.5717105263157894, 0.6009868421052631, 0.5713815789473685, 0.5713815789473685, 0.5773026315789473, 0.6279605263157894, 0.5888157894736843, 0.4944078947368421] Best val loss: 6.110260593891144


Current group: random2
Epoch [1/80], Training Loss: 39.3872, Validation Loss Current: 7.6901, Validation Loss AVG: 7.6901, lr: 0.001
Epoch [2/80], Training Loss: 23.4079, Validation Loss Current: 6.4634, Validation Loss AVG: 6.4634, lr: 0.001
Epoch [3/80], Training Loss: 19.9346, Validation Loss Current: 6.0166, Validation Loss AVG: 6.0166, lr: 0.001
Epoch [4/80], Training Loss: 14.0021, Validation Loss Current: 5.5039, Validation Loss AVG: 5.5039, lr: 0.001
Epoch [5/80], Training Loss: 9.9163, Validation Loss Current: 5.3595, Validation Loss AVG: 5.3595, lr: 0.001
Epoch [6/80], Training Loss: 7.4363, Validation Loss Current: 5.2033, Validation Loss AVG: 5.2033, lr: 0.001
Epoch [7/80], Training Loss: 7.0270, Validation Loss Current: 5.5728, Validation Loss AVG: 5.5728, lr: 0.001
Epoch [8/80], Training Loss: 5.1247, Validation Loss Current: 5.5211, Validation Loss AVG: 5.5211, lr: 0.001
Epoch [9/80], Training Loss: 3.2830, Validation Loss Current: 5.0092, Validation Loss AVG: 5.0092, lr: 0.001
Epoch [10/80], Training Loss: 2.8791, Validation Loss Current: 5.5176, Validation Loss AVG: 5.5176, lr: 0.001
Epoch [11/80], Training Loss: 3.8187, Validation Loss Current: 5.5277, Validation Loss AVG: 5.5277, lr: 0.001
Epoch [12/80], Training Loss: 3.4752, Validation Loss Current: 6.1554, Validation Loss AVG: 6.1554, lr: 0.001
Epoch [13/80], Training Loss: 7.3055, Validation Loss Current: 6.9504, Validation Loss AVG: 6.9504, lr: 0.001
Epoch [14/80], Training Loss: 4.7941, Validation Loss Current: 9.1911, Validation Loss AVG: 9.1911, lr: 0.001
Epoch [15/80], Training Loss: 8.7544, Validation Loss Current: 8.7262, Validation Loss AVG: 8.7262, lr: 0.001
Epoch [16/80], Training Loss: 9.5256, Validation Loss Current: 8.1283, Validation Loss AVG: 8.1283, lr: 0.001
Epoch [17/80], Training Loss: 10.6729, Validation Loss Current: 10.9666, Validation Loss AVG: 10.9666, lr: 0.001
Epoch [18/80], Training Loss: 10.9123, Validation Loss Current: 8.0741, Validation Loss AVG: 8.0741, lr: 0.001
Epoch [19/80], Training Loss: 6.9204, Validation Loss Current: 6.8433, Validation Loss AVG: 6.8433, lr: 0.001
Epoch [20/80], Training Loss: 5.9979, Validation Loss Current: 6.7513, Validation Loss AVG: 6.7513, lr: 0.001
Epoch [21/80], Training Loss: 6.2941, Validation Loss Current: 6.7264, Validation Loss AVG: 6.7264, lr: 0.001
Epoch [22/80], Training Loss: 4.2562, Validation Loss Current: 7.4554, Validation Loss AVG: 7.4554, lr: 0.001
Epoch [23/80], Training Loss: 5.4658, Validation Loss Current: 6.9016, Validation Loss AVG: 6.9016, lr: 0.001
Epoch [24/80], Training Loss: 6.3856, Validation Loss Current: 7.3361, Validation Loss AVG: 7.3361, lr: 0.001
Epoch [25/80], Training Loss: 5.6454, Validation Loss Current: 8.3225, Validation Loss AVG: 8.3225, lr: 0.001
Epoch [26/80], Training Loss: 6.8277, Validation Loss Current: 7.0966, Validation Loss AVG: 7.0966, lr: 0.001
Epoch [27/80], Training Loss: 4.0393, Validation Loss Current: 7.6773, Validation Loss AVG: 7.6773, lr: 0.001
Epoch [28/80], Training Loss: 6.2531, Validation Loss Current: 7.8113, Validation Loss AVG: 7.8113, lr: 0.001
Epoch [29/80], Training Loss: 3.8551, Validation Loss Current: 8.7728, Validation Loss AVG: 8.7728, lr: 0.001
Epoch [30/80], Training Loss: 3.5794, Validation Loss Current: 7.9063, Validation Loss AVG: 7.9063, lr: 0.001
Epoch [31/80], Training Loss: 3.0948, Validation Loss Current: 7.4016, Validation Loss AVG: 7.4016, lr: 0.001
Epoch [32/80], Training Loss: 2.2839, Validation Loss Current: 6.7868, Validation Loss AVG: 6.7868, lr: 0.001
Epoch [33/80], Training Loss: 3.2983, Validation Loss Current: 8.5426, Validation Loss AVG: 8.5426, lr: 0.001
Epoch [34/80], Training Loss: 5.5100, Validation Loss Current: 8.8186, Validation Loss AVG: 8.8186, lr: 0.001
Epoch [35/80], Training Loss: 8.3014, Validation Loss Current: 12.0455, Validation Loss AVG: 12.0455, lr: 0.001
Epoch [36/80], Training Loss: 9.5289, Validation Loss Current: 7.6109, Validation Loss AVG: 7.6109, lr: 0.001
Epoch [37/80], Training Loss: 5.9938, Validation Loss Current: 7.0952, Validation Loss AVG: 7.0952, lr: 0.001
Epoch [38/80], Training Loss: 4.3765, Validation Loss Current: 7.8752, Validation Loss AVG: 7.8752, lr: 0.001
Epoch [39/80], Training Loss: 4.1592, Validation Loss Current: 7.8799, Validation Loss AVG: 7.8799, lr: 0.001
 --- Early Stopped ---
Patch distance: random2 finished training. Best epoch: 9 Best val accuracy: [0.5467105263157895, 0.6013157894736842, 0.6164473684210526, 0.6394736842105264, 0.6526315789473685, 0.6786184210526316, 0.6605263157894736, 0.6736842105263158, 0.6976973684210527, 0.6865131578947369, 0.68125, 0.6671052631578948, 0.6398026315789475, 0.5858552631578947, 0.5641447368421053, 0.6065789473684211, 0.5095394736842105, 0.5694078947368421, 0.6279605263157894, 0.6200657894736843, 0.6302631578947369, 0.6154605263157895, 0.6519736842105264, 0.6016447368421052, 0.6006578947368422, 0.6088815789473684, 0.6220394736842106, 0.6049342105263158, 0.5726973684210526, 0.5907894736842105, 0.6121710526315789, 0.6476973684210525, 0.5855263157894737, 0.6088815789473684, 0.5039473684210527, 0.61875, 0.6243421052631579, 0.5881578947368421, 0.6098684210526316] Best val loss: 5.009225618839264


Current group: random3
Epoch [1/80], Training Loss: 36.0779, Validation Loss Current: 7.4121, Validation Loss AVG: 7.4121, lr: 0.001
Epoch [2/80], Training Loss: 23.0245, Validation Loss Current: 5.7463, Validation Loss AVG: 5.7463, lr: 0.001
Epoch [3/80], Training Loss: 18.2433, Validation Loss Current: 7.3908, Validation Loss AVG: 7.3908, lr: 0.001
Epoch [4/80], Training Loss: 19.9405, Validation Loss Current: 6.6021, Validation Loss AVG: 6.6021, lr: 0.001
Epoch [5/80], Training Loss: 12.8738, Validation Loss Current: 5.6808, Validation Loss AVG: 5.6808, lr: 0.001
Epoch [6/80], Training Loss: 11.2485, Validation Loss Current: 6.1946, Validation Loss AVG: 6.1946, lr: 0.001
Epoch [7/80], Training Loss: 10.9327, Validation Loss Current: 6.7529, Validation Loss AVG: 6.7529, lr: 0.001
Epoch [8/80], Training Loss: 7.5749, Validation Loss Current: 5.4076, Validation Loss AVG: 5.4076, lr: 0.001
Epoch [9/80], Training Loss: 4.6193, Validation Loss Current: 4.8921, Validation Loss AVG: 4.8921, lr: 0.001
Epoch [10/80], Training Loss: 3.5039, Validation Loss Current: 5.1335, Validation Loss AVG: 5.1335, lr: 0.001
Epoch [11/80], Training Loss: 4.5183, Validation Loss Current: 5.0292, Validation Loss AVG: 5.0292, lr: 0.001
Epoch [12/80], Training Loss: 6.7809, Validation Loss Current: 6.5469, Validation Loss AVG: 6.5469, lr: 0.001
Epoch [13/80], Training Loss: 11.1321, Validation Loss Current: 8.1897, Validation Loss AVG: 8.1897, lr: 0.001
Epoch [14/80], Training Loss: 7.8144, Validation Loss Current: 5.6854, Validation Loss AVG: 5.6854, lr: 0.001
Epoch [15/80], Training Loss: 7.2348, Validation Loss Current: 6.3273, Validation Loss AVG: 6.3273, lr: 0.001
Epoch [16/80], Training Loss: 10.6635, Validation Loss Current: 6.3990, Validation Loss AVG: 6.3990, lr: 0.001
Epoch [17/80], Training Loss: 11.2339, Validation Loss Current: 7.3697, Validation Loss AVG: 7.3697, lr: 0.001
Epoch [18/80], Training Loss: 10.2394, Validation Loss Current: 8.1625, Validation Loss AVG: 8.1625, lr: 0.001
Epoch [19/80], Training Loss: 8.8090, Validation Loss Current: 6.5331, Validation Loss AVG: 6.5331, lr: 0.001
Epoch [20/80], Training Loss: 9.6145, Validation Loss Current: 8.5281, Validation Loss AVG: 8.5281, lr: 0.001
Epoch [21/80], Training Loss: 6.7906, Validation Loss Current: 7.0160, Validation Loss AVG: 7.0160, lr: 0.001
Epoch [22/80], Training Loss: 4.0654, Validation Loss Current: 5.7206, Validation Loss AVG: 5.7206, lr: 0.001
Epoch [23/80], Training Loss: 3.1454, Validation Loss Current: 6.8176, Validation Loss AVG: 6.8176, lr: 0.001
Epoch [24/80], Training Loss: 4.3273, Validation Loss Current: 6.6628, Validation Loss AVG: 6.6628, lr: 0.001
Epoch [25/80], Training Loss: 6.8625, Validation Loss Current: 7.6331, Validation Loss AVG: 7.6331, lr: 0.001
Epoch [26/80], Training Loss: 4.9580, Validation Loss Current: 7.4648, Validation Loss AVG: 7.4648, lr: 0.001
Epoch [27/80], Training Loss: 5.6357, Validation Loss Current: 7.1855, Validation Loss AVG: 7.1855, lr: 0.001
Epoch [28/80], Training Loss: 5.0560, Validation Loss Current: 8.1556, Validation Loss AVG: 8.1556, lr: 0.001
Epoch [29/80], Training Loss: 9.0791, Validation Loss Current: 8.3891, Validation Loss AVG: 8.3891, lr: 0.001
Epoch [30/80], Training Loss: 6.2122, Validation Loss Current: 6.8915, Validation Loss AVG: 6.8915, lr: 0.001
Epoch [31/80], Training Loss: 1.8502, Validation Loss Current: 6.3834, Validation Loss AVG: 6.3834, lr: 0.001
Epoch [32/80], Training Loss: 1.4616, Validation Loss Current: 5.8727, Validation Loss AVG: 5.8727, lr: 0.001
Epoch [33/80], Training Loss: 2.4449, Validation Loss Current: 6.4926, Validation Loss AVG: 6.4926, lr: 0.001
Epoch [34/80], Training Loss: 3.4830, Validation Loss Current: 6.7697, Validation Loss AVG: 6.7697, lr: 0.001
Epoch [35/80], Training Loss: 4.7715, Validation Loss Current: 6.5074, Validation Loss AVG: 6.5074, lr: 0.001
Epoch [36/80], Training Loss: 6.1444, Validation Loss Current: 6.2943, Validation Loss AVG: 6.2943, lr: 0.001
Epoch [37/80], Training Loss: 4.5860, Validation Loss Current: 7.3700, Validation Loss AVG: 7.3700, lr: 0.001
Epoch [38/80], Training Loss: 8.3239, Validation Loss Current: 7.4801, Validation Loss AVG: 7.4801, lr: 0.001
Epoch [39/80], Training Loss: 5.1423, Validation Loss Current: 7.2225, Validation Loss AVG: 7.2225, lr: 0.001
 --- Early Stopped ---
Patch distance: random3 finished training. Best epoch: 9 Best val accuracy: [0.5973684210526315, 0.6654605263157894, 0.5789473684210527, 0.6391447368421053, 0.6391447368421053, 0.6319078947368421, 0.59375, 0.6769736842105264, 0.7042763157894736, 0.7082236842105263, 0.7029605263157895, 0.6470394736842106, 0.5907894736842104, 0.6756578947368421, 0.655921052631579, 0.6328947368421052, 0.6046052631578948, 0.6052631578947368, 0.643092105263158, 0.5529605263157894, 0.6361842105263158, 0.6779605263157895, 0.6348684210526316, 0.6480263157894737, 0.6144736842105264, 0.630921052631579, 0.6375, 0.6032894736842105, 0.6029605263157894, 0.6486842105263158, 0.6700657894736841, 0.6845394736842106, 0.6776315789473685, 0.6483552631578947, 0.6667763157894737, 0.6648026315789474, 0.6348684210526316, 0.6371710526315789, 0.63125] Best val loss: 4.892082667350769


Current group: random4
Epoch [1/80], Training Loss: 41.3227, Validation Loss Current: 6.7888, Validation Loss AVG: 6.7888, lr: 0.001
Epoch [2/80], Training Loss: 26.4898, Validation Loss Current: 7.3213, Validation Loss AVG: 7.3213, lr: 0.001
Epoch [3/80], Training Loss: 20.8904, Validation Loss Current: 7.6404, Validation Loss AVG: 7.6404, lr: 0.001
Epoch [4/80], Training Loss: 14.5221, Validation Loss Current: 6.0769, Validation Loss AVG: 6.0769, lr: 0.001
Epoch [5/80], Training Loss: 12.6092, Validation Loss Current: 5.8755, Validation Loss AVG: 5.8755, lr: 0.001
Epoch [6/80], Training Loss: 14.3515, Validation Loss Current: 6.2019, Validation Loss AVG: 6.2019, lr: 0.001
Epoch [7/80], Training Loss: 11.0591, Validation Loss Current: 4.9546, Validation Loss AVG: 4.9546, lr: 0.001
Epoch [8/80], Training Loss: 7.6978, Validation Loss Current: 5.2016, Validation Loss AVG: 5.2016, lr: 0.001
Epoch [9/80], Training Loss: 5.6720, Validation Loss Current: 4.9724, Validation Loss AVG: 4.9724, lr: 0.001
Epoch [10/80], Training Loss: 4.8433, Validation Loss Current: 5.3792, Validation Loss AVG: 5.3792, lr: 0.001
Epoch [11/80], Training Loss: 5.2099, Validation Loss Current: 5.5005, Validation Loss AVG: 5.5005, lr: 0.001
Epoch [12/80], Training Loss: 5.9588, Validation Loss Current: 6.1629, Validation Loss AVG: 6.1629, lr: 0.001
Epoch [13/80], Training Loss: 7.8518, Validation Loss Current: 7.7289, Validation Loss AVG: 7.7289, lr: 0.001
Epoch [14/80], Training Loss: 8.2198, Validation Loss Current: 5.8794, Validation Loss AVG: 5.8794, lr: 0.001
Epoch [15/80], Training Loss: 8.6595, Validation Loss Current: 6.7399, Validation Loss AVG: 6.7399, lr: 0.001
Epoch [16/80], Training Loss: 7.0243, Validation Loss Current: 7.1659, Validation Loss AVG: 7.1659, lr: 0.001
Epoch [17/80], Training Loss: 5.6937, Validation Loss Current: 5.7672, Validation Loss AVG: 5.7672, lr: 0.001
Epoch [18/80], Training Loss: 4.5643, Validation Loss Current: 6.5836, Validation Loss AVG: 6.5836, lr: 0.001
Epoch [19/80], Training Loss: 3.4062, Validation Loss Current: 6.2873, Validation Loss AVG: 6.2873, lr: 0.001
Epoch [20/80], Training Loss: 5.1688, Validation Loss Current: 5.9891, Validation Loss AVG: 5.9891, lr: 0.001
Epoch [21/80], Training Loss: 3.1034, Validation Loss Current: 5.8267, Validation Loss AVG: 5.8267, lr: 0.001
Epoch [22/80], Training Loss: 4.8409, Validation Loss Current: 6.2405, Validation Loss AVG: 6.2405, lr: 0.001
Epoch [23/80], Training Loss: 8.4615, Validation Loss Current: 7.1400, Validation Loss AVG: 7.1400, lr: 0.001
Epoch [24/80], Training Loss: 4.8861, Validation Loss Current: 6.0626, Validation Loss AVG: 6.0626, lr: 0.001
Epoch [25/80], Training Loss: 7.2279, Validation Loss Current: 6.6587, Validation Loss AVG: 6.6587, lr: 0.001
Epoch [26/80], Training Loss: 4.1143, Validation Loss Current: 6.8858, Validation Loss AVG: 6.8858, lr: 0.001
Epoch [27/80], Training Loss: 5.1860, Validation Loss Current: 6.5864, Validation Loss AVG: 6.5864, lr: 0.001
Epoch [28/80], Training Loss: 2.6899, Validation Loss Current: 6.0791, Validation Loss AVG: 6.0791, lr: 0.001
Epoch [29/80], Training Loss: 1.3156, Validation Loss Current: 5.9911, Validation Loss AVG: 5.9911, lr: 0.001
Epoch [30/80], Training Loss: 2.9753, Validation Loss Current: 6.1726, Validation Loss AVG: 6.1726, lr: 0.001
Epoch [31/80], Training Loss: 4.5946, Validation Loss Current: 8.7063, Validation Loss AVG: 8.7063, lr: 0.001
Epoch [32/80], Training Loss: 4.8120, Validation Loss Current: 6.8268, Validation Loss AVG: 6.8268, lr: 0.001
Epoch [33/80], Training Loss: 3.5890, Validation Loss Current: 7.2062, Validation Loss AVG: 7.2062, lr: 0.001
Epoch [34/80], Training Loss: 5.7748, Validation Loss Current: 7.1176, Validation Loss AVG: 7.1176, lr: 0.001
Epoch [35/80], Training Loss: 6.2265, Validation Loss Current: 7.4174, Validation Loss AVG: 7.4174, lr: 0.001
Epoch [36/80], Training Loss: 6.3166, Validation Loss Current: 8.2549, Validation Loss AVG: 8.2549, lr: 0.001
Epoch [37/80], Training Loss: 3.8388, Validation Loss Current: 7.1217, Validation Loss AVG: 7.1217, lr: 0.001
 --- Early Stopped ---
Patch distance: random4 finished training. Best epoch: 7 Best val accuracy: [0.6167763157894737, 0.6039473684210526, 0.5539473684210525, 0.6118421052631579, 0.6575657894736842, 0.6125, 0.6832236842105264, 0.6690789473684211, 0.6828947368421052, 0.6832236842105264, 0.6782894736842107, 0.6473684210526316, 0.5700657894736842, 0.6661184210526315, 0.6266447368421053, 0.6138157894736842, 0.6799342105263159, 0.6486842105263159, 0.6384868421052631, 0.6875, 0.6799342105263158, 0.6598684210526315, 0.6358552631578948, 0.6651315789473684, 0.6667763157894736, 0.6375, 0.6565789473684212, 0.6667763157894737, 0.6858552631578947, 0.6759868421052632, 0.5661184210526315, 0.6296052631578947, 0.6440789473684211, 0.6434210526315789, 0.6088815789473685, 0.6078947368421053, 0.6588815789473685] Best val loss: 4.954608964920044


Fold: 2
----- Training resnet18 with sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] -----
Current group: random0
Epoch [1/80], Training Loss: 41.3551, Validation Loss Current: 10.0874, Validation Loss AVG: 10.0874, lr: 0.001
Epoch [2/80], Training Loss: 39.0936, Validation Loss Current: 10.0730, Validation Loss AVG: 10.0730, lr: 0.001
Epoch [3/80], Training Loss: 39.1924, Validation Loss Current: 9.7889, Validation Loss AVG: 9.7889, lr: 0.001
Epoch [4/80], Training Loss: 37.5882, Validation Loss Current: 9.8777, Validation Loss AVG: 9.8777, lr: 0.001
Epoch [5/80], Training Loss: 37.4632, Validation Loss Current: 9.6069, Validation Loss AVG: 9.6069, lr: 0.001
Epoch [6/80], Training Loss: 36.7047, Validation Loss Current: 9.2852, Validation Loss AVG: 9.2852, lr: 0.001
Epoch [7/80], Training Loss: 35.7790, Validation Loss Current: 9.1810, Validation Loss AVG: 9.1810, lr: 0.001
Epoch [8/80], Training Loss: 34.7710, Validation Loss Current: 8.8914, Validation Loss AVG: 8.8914, lr: 0.001
Epoch [9/80], Training Loss: 33.8945, Validation Loss Current: 8.8111, Validation Loss AVG: 8.8111, lr: 0.001
Epoch [10/80], Training Loss: 32.6088, Validation Loss Current: 8.7035, Validation Loss AVG: 8.7035, lr: 0.001
Epoch [11/80], Training Loss: 33.0682, Validation Loss Current: 8.4307, Validation Loss AVG: 8.4307, lr: 0.001
Epoch [12/80], Training Loss: 31.4451, Validation Loss Current: 8.3444, Validation Loss AVG: 8.3444, lr: 0.001
Epoch [13/80], Training Loss: 29.6024, Validation Loss Current: 8.3162, Validation Loss AVG: 8.3162, lr: 0.001
Epoch [14/80], Training Loss: 29.5412, Validation Loss Current: 8.7296, Validation Loss AVG: 8.7296, lr: 0.001
Epoch [15/80], Training Loss: 29.2755, Validation Loss Current: 8.0559, Validation Loss AVG: 8.0559, lr: 0.001
Epoch [16/80], Training Loss: 29.2732, Validation Loss Current: 8.0558, Validation Loss AVG: 8.0558, lr: 0.001
Epoch [17/80], Training Loss: 27.9645, Validation Loss Current: 8.1672, Validation Loss AVG: 8.1672, lr: 0.001
Epoch [18/80], Training Loss: 27.6397, Validation Loss Current: 7.5293, Validation Loss AVG: 7.5293, lr: 0.001
Epoch [19/80], Training Loss: 26.7370, Validation Loss Current: 7.7368, Validation Loss AVG: 7.7368, lr: 0.001
Epoch [20/80], Training Loss: 26.1565, Validation Loss Current: 8.9124, Validation Loss AVG: 8.9124, lr: 0.001
Epoch [21/80], Training Loss: 26.7068, Validation Loss Current: 9.1124, Validation Loss AVG: 9.1124, lr: 0.001
Epoch [22/80], Training Loss: 25.7307, Validation Loss Current: 7.5461, Validation Loss AVG: 7.5461, lr: 0.001
Epoch [23/80], Training Loss: 25.6667, Validation Loss Current: 7.8540, Validation Loss AVG: 7.8540, lr: 0.001
Epoch [24/80], Training Loss: 24.9448, Validation Loss Current: 7.6030, Validation Loss AVG: 7.6030, lr: 0.001
Epoch [25/80], Training Loss: 25.1390, Validation Loss Current: 7.7469, Validation Loss AVG: 7.7469, lr: 0.001
Epoch [26/80], Training Loss: 23.4191, Validation Loss Current: 7.6120, Validation Loss AVG: 7.6120, lr: 0.001
Epoch [27/80], Training Loss: 22.9314, Validation Loss Current: 7.0143, Validation Loss AVG: 7.0143, lr: 0.001
Epoch [28/80], Training Loss: 22.6313, Validation Loss Current: 7.7548, Validation Loss AVG: 7.7548, lr: 0.001
Epoch [29/80], Training Loss: 22.0620, Validation Loss Current: 8.0962, Validation Loss AVG: 8.0962, lr: 0.001
Epoch [30/80], Training Loss: 20.8080, Validation Loss Current: 7.2348, Validation Loss AVG: 7.2348, lr: 0.001
Epoch [31/80], Training Loss: 19.5342, Validation Loss Current: 7.6490, Validation Loss AVG: 7.6490, lr: 0.001
Epoch [32/80], Training Loss: 19.8856, Validation Loss Current: 6.8834, Validation Loss AVG: 6.8834, lr: 0.001
Epoch [33/80], Training Loss: 17.9964, Validation Loss Current: 6.8812, Validation Loss AVG: 6.8812, lr: 0.001
Epoch [34/80], Training Loss: 17.9227, Validation Loss Current: 6.7461, Validation Loss AVG: 6.7461, lr: 0.001
Epoch [35/80], Training Loss: 16.7626, Validation Loss Current: 6.9709, Validation Loss AVG: 6.9709, lr: 0.001
Epoch [36/80], Training Loss: 17.5414, Validation Loss Current: 8.3626, Validation Loss AVG: 8.3626, lr: 0.001
Epoch [37/80], Training Loss: 16.8760, Validation Loss Current: 9.2264, Validation Loss AVG: 9.2264, lr: 0.001
Epoch [38/80], Training Loss: 14.1811, Validation Loss Current: 6.9810, Validation Loss AVG: 6.9810, lr: 0.001
Epoch [39/80], Training Loss: 12.7850, Validation Loss Current: 6.7049, Validation Loss AVG: 6.7049, lr: 0.001
Epoch [40/80], Training Loss: 12.8120, Validation Loss Current: 7.4516, Validation Loss AVG: 7.4516, lr: 0.001
Epoch [41/80], Training Loss: 10.3295, Validation Loss Current: 6.3024, Validation Loss AVG: 6.3024, lr: 0.001
Epoch [42/80], Training Loss: 10.0584, Validation Loss Current: 14.3111, Validation Loss AVG: 14.3111, lr: 0.001
Epoch [43/80], Training Loss: 13.8672, Validation Loss Current: 15.3231, Validation Loss AVG: 15.3231, lr: 0.001
Epoch [44/80], Training Loss: 18.2579, Validation Loss Current: 10.5863, Validation Loss AVG: 10.5863, lr: 0.001
Epoch [45/80], Training Loss: 13.5270, Validation Loss Current: 7.1621, Validation Loss AVG: 7.1621, lr: 0.001
Epoch [46/80], Training Loss: 12.2856, Validation Loss Current: 8.8678, Validation Loss AVG: 8.8678, lr: 0.001
Epoch [47/80], Training Loss: 13.9111, Validation Loss Current: 8.9118, Validation Loss AVG: 8.9118, lr: 0.001
Epoch [48/80], Training Loss: 14.3032, Validation Loss Current: 8.3543, Validation Loss AVG: 8.3543, lr: 0.001
Epoch [49/80], Training Loss: 13.7851, Validation Loss Current: 7.7529, Validation Loss AVG: 7.7529, lr: 0.001
Epoch [50/80], Training Loss: 13.1552, Validation Loss Current: 7.6724, Validation Loss AVG: 7.6724, lr: 0.001
Epoch [51/80], Training Loss: 12.4129, Validation Loss Current: 8.1453, Validation Loss AVG: 8.1453, lr: 0.001
Epoch [52/80], Training Loss: 15.7015, Validation Loss Current: 11.9383, Validation Loss AVG: 11.9383, lr: 0.001
Epoch [53/80], Training Loss: 13.4591, Validation Loss Current: 7.3854, Validation Loss AVG: 7.3854, lr: 0.001
Epoch [54/80], Training Loss: 10.5049, Validation Loss Current: 7.3043, Validation Loss AVG: 7.3043, lr: 0.001
Epoch [55/80], Training Loss: 10.9836, Validation Loss Current: 9.2308, Validation Loss AVG: 9.2308, lr: 0.001
Epoch [56/80], Training Loss: 8.4105, Validation Loss Current: 7.7259, Validation Loss AVG: 7.7259, lr: 0.001
Epoch [57/80], Training Loss: 6.5223, Validation Loss Current: 6.7046, Validation Loss AVG: 6.7046, lr: 0.001
Epoch [58/80], Training Loss: 5.2927, Validation Loss Current: 7.0959, Validation Loss AVG: 7.0959, lr: 0.001
Epoch [59/80], Training Loss: 4.9630, Validation Loss Current: 7.2277, Validation Loss AVG: 7.2277, lr: 0.001
Epoch [60/80], Training Loss: 4.9398, Validation Loss Current: 7.1691, Validation Loss AVG: 7.1691, lr: 0.001
Epoch [61/80], Training Loss: 4.3800, Validation Loss Current: 9.4218, Validation Loss AVG: 9.4218, lr: 0.001
Epoch [62/80], Training Loss: 7.2697, Validation Loss Current: 8.7232, Validation Loss AVG: 8.7232, lr: 0.001
Epoch [63/80], Training Loss: 12.9655, Validation Loss Current: 10.0861, Validation Loss AVG: 10.0861, lr: 0.001
Epoch [64/80], Training Loss: 7.5837, Validation Loss Current: 7.5856, Validation Loss AVG: 7.5856, lr: 0.001
Epoch [65/80], Training Loss: 4.7934, Validation Loss Current: 7.9328, Validation Loss AVG: 7.9328, lr: 0.001
Epoch [66/80], Training Loss: 4.8261, Validation Loss Current: 7.1240, Validation Loss AVG: 7.1240, lr: 0.001
Epoch [67/80], Training Loss: 7.7635, Validation Loss Current: 7.9837, Validation Loss AVG: 7.9837, lr: 0.001
Epoch [68/80], Training Loss: 5.6618, Validation Loss Current: 8.8902, Validation Loss AVG: 8.8902, lr: 0.001
Epoch [69/80], Training Loss: 5.4684, Validation Loss Current: 7.8250, Validation Loss AVG: 7.8250, lr: 0.001
Epoch [70/80], Training Loss: 5.2639, Validation Loss Current: 8.3670, Validation Loss AVG: 8.3670, lr: 0.001
Epoch [71/80], Training Loss: 4.9973, Validation Loss Current: 8.7139, Validation Loss AVG: 8.7139, lr: 0.001
 --- Early Stopped ---
Patch distance: random0 finished training. Best epoch: 41 Best val accuracy: [0.2325657894736842, 0.2424342105263158, 0.25625, 0.25263157894736843, 0.2980263157894737, 0.330921052631579, 0.3384868421052632, 0.3536184210526315, 0.37763157894736843, 0.37927631578947374, 0.3960526315789473, 0.40197368421052637, 0.4134868421052632, 0.41578947368421054, 0.4223684210526315, 0.4269736842105264, 0.45032894736842105, 0.47368421052631576, 0.44671052631578945, 0.41217105263157894, 0.3796052631578947, 0.46282894736842106, 0.47138157894736843, 0.48355263157894735, 0.46677631578947365, 0.48190789473684215, 0.5164473684210525, 0.46743421052631573, 0.4651315789473684, 0.4963815789473684, 0.48717105263157895, 0.5210526315789473, 0.5282894736842105, 0.5338815789473684, 0.5141447368421053, 0.45, 0.4391447368421053, 0.5460526315789475, 0.5555921052631578, 0.5190789473684211, 0.5822368421052632, 0.3361842105263158, 0.3444078947368421, 0.4128289473684211, 0.5226973684210525, 0.42269736842105265, 0.4707236842105263, 0.49703947368421053, 0.5154605263157894, 0.4944078947368421, 0.4983552631578947, 0.41907894736842105, 0.5292763157894737, 0.5368421052631579, 0.5108552631578946, 0.5549342105263158, 0.5851973684210525, 0.5532894736842106, 0.575328947368421, 0.5631578947368421, 0.5273026315789473, 0.5309210526315791, 0.4493421052631579, 0.5598684210526315, 0.5677631578947369, 0.5891447368421053, 0.5434210526315789, 0.5414473684210526, 0.5687499999999999, 0.5638157894736843, 0.5463815789473685] Best val loss: 6.302387082576752


Current group: random1
Epoch [1/80], Training Loss: 33.6386, Validation Loss Current: 9.3305, Validation Loss AVG: 9.3305, lr: 0.001
Epoch [2/80], Training Loss: 26.2048, Validation Loss Current: 6.6391, Validation Loss AVG: 6.6391, lr: 0.001
Epoch [3/80], Training Loss: 19.0432, Validation Loss Current: 7.8429, Validation Loss AVG: 7.8429, lr: 0.001
Epoch [4/80], Training Loss: 18.3074, Validation Loss Current: 8.4534, Validation Loss AVG: 8.4534, lr: 0.001
Epoch [5/80], Training Loss: 13.5114, Validation Loss Current: 6.3452, Validation Loss AVG: 6.3452, lr: 0.001
Epoch [6/80], Training Loss: 11.7036, Validation Loss Current: 5.7775, Validation Loss AVG: 5.7775, lr: 0.001
Epoch [7/80], Training Loss: 11.9045, Validation Loss Current: 6.8601, Validation Loss AVG: 6.8601, lr: 0.001
Epoch [8/80], Training Loss: 15.3552, Validation Loss Current: 13.2786, Validation Loss AVG: 13.2786, lr: 0.001
Epoch [9/80], Training Loss: 16.8578, Validation Loss Current: 8.1310, Validation Loss AVG: 8.1310, lr: 0.001
Epoch [10/80], Training Loss: 16.1604, Validation Loss Current: 6.7280, Validation Loss AVG: 6.7280, lr: 0.001
Epoch [11/80], Training Loss: 14.2830, Validation Loss Current: 9.0044, Validation Loss AVG: 9.0044, lr: 0.001
Epoch [12/80], Training Loss: 9.1909, Validation Loss Current: 6.8304, Validation Loss AVG: 6.8304, lr: 0.001
Epoch [13/80], Training Loss: 8.7800, Validation Loss Current: 7.1034, Validation Loss AVG: 7.1034, lr: 0.001
Epoch [14/80], Training Loss: 9.0041, Validation Loss Current: 6.3786, Validation Loss AVG: 6.3786, lr: 0.001
Epoch [15/80], Training Loss: 6.8375, Validation Loss Current: 5.9452, Validation Loss AVG: 5.9452, lr: 0.001
Epoch [16/80], Training Loss: 5.8216, Validation Loss Current: 6.3374, Validation Loss AVG: 6.3374, lr: 0.001
Epoch [17/80], Training Loss: 10.8467, Validation Loss Current: 8.9262, Validation Loss AVG: 8.9262, lr: 0.001
Epoch [18/80], Training Loss: 7.1302, Validation Loss Current: 6.9667, Validation Loss AVG: 6.9667, lr: 0.001
Epoch [19/80], Training Loss: 8.2240, Validation Loss Current: 7.6697, Validation Loss AVG: 7.6697, lr: 0.001
Epoch [20/80], Training Loss: 6.3986, Validation Loss Current: 6.8295, Validation Loss AVG: 6.8295, lr: 0.001
Epoch [21/80], Training Loss: 5.3206, Validation Loss Current: 7.8106, Validation Loss AVG: 7.8106, lr: 0.001
Epoch [22/80], Training Loss: 7.4905, Validation Loss Current: 7.7663, Validation Loss AVG: 7.7663, lr: 0.001
Epoch [23/80], Training Loss: 9.0520, Validation Loss Current: 6.6725, Validation Loss AVG: 6.6725, lr: 0.001
Epoch [24/80], Training Loss: 9.7339, Validation Loss Current: 6.8169, Validation Loss AVG: 6.8169, lr: 0.001
Epoch [25/80], Training Loss: 6.3413, Validation Loss Current: 6.9446, Validation Loss AVG: 6.9446, lr: 0.001
Epoch [26/80], Training Loss: 7.8436, Validation Loss Current: 9.4636, Validation Loss AVG: 9.4636, lr: 0.001
Epoch [27/80], Training Loss: 7.1967, Validation Loss Current: 8.1581, Validation Loss AVG: 8.1581, lr: 0.001
Epoch [28/80], Training Loss: 3.9770, Validation Loss Current: 7.0907, Validation Loss AVG: 7.0907, lr: 0.001
Epoch [29/80], Training Loss: 4.4226, Validation Loss Current: 7.4613, Validation Loss AVG: 7.4613, lr: 0.001
Epoch [30/80], Training Loss: 4.1344, Validation Loss Current: 7.5640, Validation Loss AVG: 7.5640, lr: 0.001
Epoch [31/80], Training Loss: 4.1798, Validation Loss Current: 7.9186, Validation Loss AVG: 7.9186, lr: 0.001
Epoch [32/80], Training Loss: 4.4441, Validation Loss Current: 8.0703, Validation Loss AVG: 8.0703, lr: 0.001
Epoch [33/80], Training Loss: 3.4623, Validation Loss Current: 7.3731, Validation Loss AVG: 7.3731, lr: 0.001
Epoch [34/80], Training Loss: 4.5644, Validation Loss Current: 7.2384, Validation Loss AVG: 7.2384, lr: 0.001
Epoch [35/80], Training Loss: 4.1098, Validation Loss Current: 7.7483, Validation Loss AVG: 7.7483, lr: 0.001
Epoch [36/80], Training Loss: 4.3096, Validation Loss Current: 8.2308, Validation Loss AVG: 8.2308, lr: 0.001
 --- Early Stopped ---
Patch distance: random1 finished training. Best epoch: 6 Best val accuracy: [0.4891447368421053, 0.5720394736842105, 0.4930921052631579, 0.500328947368421, 0.5914473684210526, 0.6325657894736842, 0.5611842105263157, 0.4309210526315789, 0.5220394736842106, 0.5713815789473684, 0.48618421052631583, 0.5769736842105264, 0.5815789473684211, 0.599342105263158, 0.6355263157894737, 0.6259868421052632, 0.5240131578947368, 0.6055921052631579, 0.5838815789473684, 0.5835526315789474, 0.6148026315789474, 0.5759868421052632, 0.6148026315789473, 0.619407894736842, 0.6085526315789473, 0.5523026315789473, 0.5671052631578948, 0.6095394736842105, 0.6111842105263158, 0.6006578947368422, 0.59375, 0.605263157894737, 0.6253289473684209, 0.6276315789473684, 0.6134868421052633, 0.5901315789473685] Best val loss: 5.777508974075317


Current group: random2
Epoch [1/80], Training Loss: 33.8848, Validation Loss Current: 6.3230, Validation Loss AVG: 6.3230, lr: 0.001
Epoch [2/80], Training Loss: 24.0168, Validation Loss Current: 6.2585, Validation Loss AVG: 6.2585, lr: 0.001
Epoch [3/80], Training Loss: 17.6693, Validation Loss Current: 6.0219, Validation Loss AVG: 6.0219, lr: 0.001
Epoch [4/80], Training Loss: 14.1774, Validation Loss Current: 5.7722, Validation Loss AVG: 5.7722, lr: 0.001
Epoch [5/80], Training Loss: 13.5597, Validation Loss Current: 6.5415, Validation Loss AVG: 6.5415, lr: 0.001
Epoch [6/80], Training Loss: 9.5181, Validation Loss Current: 5.2928, Validation Loss AVG: 5.2928, lr: 0.001
Epoch [7/80], Training Loss: 9.1345, Validation Loss Current: 5.7055, Validation Loss AVG: 5.7055, lr: 0.001
Epoch [8/80], Training Loss: 9.0601, Validation Loss Current: 5.6506, Validation Loss AVG: 5.6506, lr: 0.001
Epoch [9/80], Training Loss: 9.1826, Validation Loss Current: 5.3036, Validation Loss AVG: 5.3036, lr: 0.001
Epoch [10/80], Training Loss: 9.0057, Validation Loss Current: 7.9340, Validation Loss AVG: 7.9340, lr: 0.001
Epoch [11/80], Training Loss: 7.0051, Validation Loss Current: 5.8793, Validation Loss AVG: 5.8793, lr: 0.001
Epoch [12/80], Training Loss: 8.2466, Validation Loss Current: 7.2476, Validation Loss AVG: 7.2476, lr: 0.001
Epoch [13/80], Training Loss: 8.8934, Validation Loss Current: 7.9125, Validation Loss AVG: 7.9125, lr: 0.001
Epoch [14/80], Training Loss: 11.2737, Validation Loss Current: 7.4943, Validation Loss AVG: 7.4943, lr: 0.001
Epoch [15/80], Training Loss: 8.8501, Validation Loss Current: 7.2872, Validation Loss AVG: 7.2872, lr: 0.001
Epoch [16/80], Training Loss: 3.8039, Validation Loss Current: 5.7694, Validation Loss AVG: 5.7694, lr: 0.001
Epoch [17/80], Training Loss: 2.5824, Validation Loss Current: 5.7431, Validation Loss AVG: 5.7431, lr: 0.001
Epoch [18/80], Training Loss: 3.7386, Validation Loss Current: 6.5964, Validation Loss AVG: 6.5964, lr: 0.001
Epoch [19/80], Training Loss: 8.1257, Validation Loss Current: 6.8854, Validation Loss AVG: 6.8854, lr: 0.001
Epoch [20/80], Training Loss: 7.4133, Validation Loss Current: 9.1421, Validation Loss AVG: 9.1421, lr: 0.001
Epoch [21/80], Training Loss: 6.6335, Validation Loss Current: 7.0465, Validation Loss AVG: 7.0465, lr: 0.001
Epoch [22/80], Training Loss: 5.8605, Validation Loss Current: 7.0388, Validation Loss AVG: 7.0388, lr: 0.001
Epoch [23/80], Training Loss: 7.2557, Validation Loss Current: 7.1531, Validation Loss AVG: 7.1531, lr: 0.001
Epoch [24/80], Training Loss: 4.6001, Validation Loss Current: 7.4671, Validation Loss AVG: 7.4671, lr: 0.001
Epoch [25/80], Training Loss: 6.3335, Validation Loss Current: 9.3771, Validation Loss AVG: 9.3771, lr: 0.001
Epoch [26/80], Training Loss: 6.9630, Validation Loss Current: 7.3678, Validation Loss AVG: 7.3678, lr: 0.001
Epoch [27/80], Training Loss: 4.0752, Validation Loss Current: 7.2543, Validation Loss AVG: 7.2543, lr: 0.001
Epoch [28/80], Training Loss: 1.9583, Validation Loss Current: 6.2124, Validation Loss AVG: 6.2124, lr: 0.001
Epoch [29/80], Training Loss: 3.6341, Validation Loss Current: 6.7542, Validation Loss AVG: 6.7542, lr: 0.001
Epoch [30/80], Training Loss: 3.5187, Validation Loss Current: 7.6435, Validation Loss AVG: 7.6435, lr: 0.001
Epoch [31/80], Training Loss: 1.9770, Validation Loss Current: 6.2028, Validation Loss AVG: 6.2028, lr: 0.001
Epoch [32/80], Training Loss: 3.2209, Validation Loss Current: 7.0443, Validation Loss AVG: 7.0443, lr: 0.001
Epoch [33/80], Training Loss: 7.4918, Validation Loss Current: 9.0475, Validation Loss AVG: 9.0475, lr: 0.001
Epoch [34/80], Training Loss: 6.9040, Validation Loss Current: 8.1344, Validation Loss AVG: 8.1344, lr: 0.001
Epoch [35/80], Training Loss: 7.6325, Validation Loss Current: 8.5043, Validation Loss AVG: 8.5043, lr: 0.001
Epoch [36/80], Training Loss: 4.7684, Validation Loss Current: 9.1485, Validation Loss AVG: 9.1485, lr: 0.001
 --- Early Stopped ---
Patch distance: random2 finished training. Best epoch: 6 Best val accuracy: [0.6322368421052632, 0.6273026315789474, 0.618421052631579, 0.65625, 0.6105263157894737, 0.6842105263157895, 0.6549342105263157, 0.6723684210526315, 0.687828947368421, 0.5648026315789474, 0.6476973684210526, 0.6055921052631579, 0.569078947368421, 0.6000000000000001, 0.5960526315789474, 0.66875, 0.6805921052631578, 0.6470394736842106, 0.6282894736842104, 0.5805921052631581, 0.6243421052631579, 0.6302631578947369, 0.6388157894736841, 0.6157894736842107, 0.5911184210526316, 0.618421052631579, 0.6190789473684211, 0.6536184210526315, 0.6460526315789472, 0.64375, 0.6608552631578947, 0.6243421052631579, 0.6200657894736843, 0.600328947368421, 0.5763157894736842, 0.5763157894736842] Best val loss: 5.292783498764038


Current group: random3
Epoch [1/80], Training Loss: 36.9809, Validation Loss Current: 8.1313, Validation Loss AVG: 8.1313, lr: 0.001
Epoch [2/80], Training Loss: 20.8407, Validation Loss Current: 5.4900, Validation Loss AVG: 5.4900, lr: 0.001
Epoch [3/80], Training Loss: 17.1954, Validation Loss Current: 6.6729, Validation Loss AVG: 6.6729, lr: 0.001
Epoch [4/80], Training Loss: 13.2980, Validation Loss Current: 5.4873, Validation Loss AVG: 5.4873, lr: 0.001
Epoch [5/80], Training Loss: 10.6434, Validation Loss Current: 6.3499, Validation Loss AVG: 6.3499, lr: 0.001
Epoch [6/80], Training Loss: 11.6010, Validation Loss Current: 8.6436, Validation Loss AVG: 8.6436, lr: 0.001
Epoch [7/80], Training Loss: 15.1905, Validation Loss Current: 6.6438, Validation Loss AVG: 6.6438, lr: 0.001
Epoch [8/80], Training Loss: 8.4835, Validation Loss Current: 6.4648, Validation Loss AVG: 6.4648, lr: 0.001
Epoch [9/80], Training Loss: 8.3321, Validation Loss Current: 7.2726, Validation Loss AVG: 7.2726, lr: 0.001
Epoch [10/80], Training Loss: 7.3956, Validation Loss Current: 6.4231, Validation Loss AVG: 6.4231, lr: 0.001
Epoch [11/80], Training Loss: 8.6535, Validation Loss Current: 6.8988, Validation Loss AVG: 6.8988, lr: 0.001
Epoch [12/80], Training Loss: 4.6879, Validation Loss Current: 5.4953, Validation Loss AVG: 5.4953, lr: 0.001
Epoch [13/80], Training Loss: 5.1155, Validation Loss Current: 6.5880, Validation Loss AVG: 6.5880, lr: 0.001
Epoch [14/80], Training Loss: 6.1287, Validation Loss Current: 7.9595, Validation Loss AVG: 7.9595, lr: 0.001
Epoch [15/80], Training Loss: 4.0549, Validation Loss Current: 5.3898, Validation Loss AVG: 5.3898, lr: 0.001
Epoch [16/80], Training Loss: 4.8088, Validation Loss Current: 5.8229, Validation Loss AVG: 5.8229, lr: 0.001
Epoch [17/80], Training Loss: 5.3769, Validation Loss Current: 5.8538, Validation Loss AVG: 5.8538, lr: 0.001
Epoch [18/80], Training Loss: 3.9489, Validation Loss Current: 5.5687, Validation Loss AVG: 5.5687, lr: 0.001
Epoch [19/80], Training Loss: 5.4321, Validation Loss Current: 5.7398, Validation Loss AVG: 5.7398, lr: 0.001
Epoch [20/80], Training Loss: 3.0166, Validation Loss Current: 6.7078, Validation Loss AVG: 6.7078, lr: 0.001
Epoch [21/80], Training Loss: 6.7101, Validation Loss Current: 5.2883, Validation Loss AVG: 5.2883, lr: 0.001
Epoch [22/80], Training Loss: 3.6640, Validation Loss Current: 5.4112, Validation Loss AVG: 5.4112, lr: 0.001
Epoch [23/80], Training Loss: 6.5270, Validation Loss Current: 5.4103, Validation Loss AVG: 5.4103, lr: 0.001
Epoch [24/80], Training Loss: 3.3670, Validation Loss Current: 6.2412, Validation Loss AVG: 6.2412, lr: 0.001
Epoch [25/80], Training Loss: 6.1590, Validation Loss Current: 5.7021, Validation Loss AVG: 5.7021, lr: 0.001
Epoch [26/80], Training Loss: 3.6571, Validation Loss Current: 6.6226, Validation Loss AVG: 6.6226, lr: 0.001
Epoch [27/80], Training Loss: 6.5848, Validation Loss Current: 6.2144, Validation Loss AVG: 6.2144, lr: 0.001
Epoch [28/80], Training Loss: 4.4492, Validation Loss Current: 7.6566, Validation Loss AVG: 7.6566, lr: 0.001
Epoch [29/80], Training Loss: 3.3325, Validation Loss Current: 5.9857, Validation Loss AVG: 5.9857, lr: 0.001
Epoch [30/80], Training Loss: 5.6679, Validation Loss Current: 6.0806, Validation Loss AVG: 6.0806, lr: 0.001
Epoch [31/80], Training Loss: 1.8831, Validation Loss Current: 6.2859, Validation Loss AVG: 6.2859, lr: 0.001
Epoch [32/80], Training Loss: 3.8216, Validation Loss Current: 7.9942, Validation Loss AVG: 7.9942, lr: 0.001
Epoch [33/80], Training Loss: 7.3747, Validation Loss Current: 7.9722, Validation Loss AVG: 7.9722, lr: 0.001
Epoch [34/80], Training Loss: 10.1447, Validation Loss Current: 7.3147, Validation Loss AVG: 7.3147, lr: 0.001
Epoch [35/80], Training Loss: 4.5197, Validation Loss Current: 6.6847, Validation Loss AVG: 6.6847, lr: 0.001
Epoch [36/80], Training Loss: 2.5787, Validation Loss Current: 6.2965, Validation Loss AVG: 6.2965, lr: 0.001
Epoch [37/80], Training Loss: 4.3658, Validation Loss Current: 6.8016, Validation Loss AVG: 6.8016, lr: 0.001
Epoch [38/80], Training Loss: 8.3409, Validation Loss Current: 9.0025, Validation Loss AVG: 9.0025, lr: 0.001
Epoch [39/80], Training Loss: 8.3442, Validation Loss Current: 8.0957, Validation Loss AVG: 8.0957, lr: 0.001
Epoch [40/80], Training Loss: 6.8311, Validation Loss Current: 6.7575, Validation Loss AVG: 6.7575, lr: 0.001
Epoch [41/80], Training Loss: 3.2557, Validation Loss Current: 6.3518, Validation Loss AVG: 6.3518, lr: 0.001
Epoch [42/80], Training Loss: 1.6920, Validation Loss Current: 6.0300, Validation Loss AVG: 6.0300, lr: 0.001
Epoch [43/80], Training Loss: 1.7526, Validation Loss Current: 7.1251, Validation Loss AVG: 7.1251, lr: 0.001
Epoch [44/80], Training Loss: 2.8453, Validation Loss Current: 6.1762, Validation Loss AVG: 6.1762, lr: 0.001
Epoch [45/80], Training Loss: 3.4294, Validation Loss Current: 7.4235, Validation Loss AVG: 7.4235, lr: 0.001
Epoch [46/80], Training Loss: 2.1995, Validation Loss Current: 7.0874, Validation Loss AVG: 7.0874, lr: 0.001
Epoch [47/80], Training Loss: 2.8068, Validation Loss Current: 6.3858, Validation Loss AVG: 6.3858, lr: 0.001
Epoch [48/80], Training Loss: 1.7066, Validation Loss Current: 6.7390, Validation Loss AVG: 6.7390, lr: 0.001
Epoch [49/80], Training Loss: 1.5204, Validation Loss Current: 6.2800, Validation Loss AVG: 6.2800, lr: 0.001
Epoch [50/80], Training Loss: 1.3970, Validation Loss Current: 7.5010, Validation Loss AVG: 7.5010, lr: 0.001
Epoch [51/80], Training Loss: 1.5099, Validation Loss Current: 6.6467, Validation Loss AVG: 6.6467, lr: 0.001
 --- Early Stopped ---
Patch distance: random3 finished training. Best epoch: 21 Best val accuracy: [0.562828947368421, 0.6546052631578947, 0.6111842105263158, 0.6648026315789474, 0.6207236842105264, 0.53125, 0.6023026315789475, 0.6378289473684211, 0.5983552631578947, 0.6309210526315789, 0.6177631578947368, 0.6805921052631578, 0.6286184210526315, 0.6174342105263158, 0.6832236842105264, 0.6779605263157895, 0.6690789473684211, 0.6914473684210527, 0.6842105263157896, 0.6457236842105263, 0.7036184210526315, 0.707236842105263, 0.6960526315789474, 0.6690789473684211, 0.69375, 0.6542763157894738, 0.6802631578947368, 0.6180921052631578, 0.6901315789473684, 0.69375, 0.6773026315789473, 0.656578947368421, 0.6223684210526317, 0.6388157894736841, 0.6575657894736842, 0.6796052631578947, 0.6664473684210527, 0.6210526315789473, 0.6049342105263158, 0.6404605263157894, 0.6703947368421053, 0.6898026315789474, 0.6654605263157894, 0.6838815789473685, 0.6325657894736841, 0.6717105263157894, 0.6786184210526316, 0.6523026315789474, 0.6690789473684211, 0.6453947368421054, 0.6766447368421054] Best val loss: 5.288330161571503


Current group: random4
Epoch [1/80], Training Loss: 36.1977, Validation Loss Current: 7.8983, Validation Loss AVG: 7.8983, lr: 0.001
Epoch [2/80], Training Loss: 21.7532, Validation Loss Current: 5.9331, Validation Loss AVG: 5.9331, lr: 0.001
Epoch [3/80], Training Loss: 17.6985, Validation Loss Current: 6.1525, Validation Loss AVG: 6.1525, lr: 0.001
Epoch [4/80], Training Loss: 12.1236, Validation Loss Current: 5.1677, Validation Loss AVG: 5.1677, lr: 0.001
Epoch [5/80], Training Loss: 10.3904, Validation Loss Current: 5.0260, Validation Loss AVG: 5.0260, lr: 0.001
Epoch [6/80], Training Loss: 7.9195, Validation Loss Current: 4.4689, Validation Loss AVG: 4.4689, lr: 0.001
Epoch [7/80], Training Loss: 8.4732, Validation Loss Current: 5.4079, Validation Loss AVG: 5.4079, lr: 0.001
Epoch [8/80], Training Loss: 6.0133, Validation Loss Current: 4.7922, Validation Loss AVG: 4.7922, lr: 0.001
Epoch [9/80], Training Loss: 7.8531, Validation Loss Current: 6.2573, Validation Loss AVG: 6.2573, lr: 0.001
Epoch [10/80], Training Loss: 11.4311, Validation Loss Current: 6.0785, Validation Loss AVG: 6.0785, lr: 0.001
Epoch [11/80], Training Loss: 7.8774, Validation Loss Current: 5.0419, Validation Loss AVG: 5.0419, lr: 0.001
Epoch [12/80], Training Loss: 9.6625, Validation Loss Current: 6.4128, Validation Loss AVG: 6.4128, lr: 0.001
Epoch [13/80], Training Loss: 11.5366, Validation Loss Current: 5.7205, Validation Loss AVG: 5.7205, lr: 0.001
Epoch [14/80], Training Loss: 5.1321, Validation Loss Current: 5.0036, Validation Loss AVG: 5.0036, lr: 0.001
Epoch [15/80], Training Loss: 5.7067, Validation Loss Current: 5.6222, Validation Loss AVG: 5.6222, lr: 0.001
Epoch [16/80], Training Loss: 4.0097, Validation Loss Current: 4.8896, Validation Loss AVG: 4.8896, lr: 0.001
Epoch [17/80], Training Loss: 3.8670, Validation Loss Current: 5.0014, Validation Loss AVG: 5.0014, lr: 0.001
Epoch [18/80], Training Loss: 4.2070, Validation Loss Current: 5.8735, Validation Loss AVG: 5.8735, lr: 0.001
Epoch [19/80], Training Loss: 5.8671, Validation Loss Current: 6.1999, Validation Loss AVG: 6.1999, lr: 0.001
Epoch [20/80], Training Loss: 8.5348, Validation Loss Current: 8.7177, Validation Loss AVG: 8.7177, lr: 0.001
Epoch [21/80], Training Loss: 3.3815, Validation Loss Current: 5.1270, Validation Loss AVG: 5.1270, lr: 0.001
Epoch [22/80], Training Loss: 2.4756, Validation Loss Current: 5.0970, Validation Loss AVG: 5.0970, lr: 0.001
Epoch [23/80], Training Loss: 2.9973, Validation Loss Current: 5.0579, Validation Loss AVG: 5.0579, lr: 0.001
Epoch [24/80], Training Loss: 5.7378, Validation Loss Current: 6.0943, Validation Loss AVG: 6.0943, lr: 0.001
Epoch [25/80], Training Loss: 4.2534, Validation Loss Current: 5.6872, Validation Loss AVG: 5.6872, lr: 0.001
Epoch [26/80], Training Loss: 4.2340, Validation Loss Current: 6.3895, Validation Loss AVG: 6.3895, lr: 0.001
Epoch [27/80], Training Loss: 7.5724, Validation Loss Current: 7.3501, Validation Loss AVG: 7.3501, lr: 0.001
Epoch [28/80], Training Loss: 3.2601, Validation Loss Current: 5.4410, Validation Loss AVG: 5.4410, lr: 0.001
Epoch [29/80], Training Loss: 3.6123, Validation Loss Current: 6.0977, Validation Loss AVG: 6.0977, lr: 0.001
Epoch [30/80], Training Loss: 6.8289, Validation Loss Current: 7.6148, Validation Loss AVG: 7.6148, lr: 0.001
Epoch [31/80], Training Loss: 8.3584, Validation Loss Current: 8.2605, Validation Loss AVG: 8.2605, lr: 0.001
Epoch [32/80], Training Loss: 9.7385, Validation Loss Current: 9.0309, Validation Loss AVG: 9.0309, lr: 0.001
Epoch [33/80], Training Loss: 3.7315, Validation Loss Current: 5.9879, Validation Loss AVG: 5.9879, lr: 0.001
Epoch [34/80], Training Loss: 4.9258, Validation Loss Current: 7.2311, Validation Loss AVG: 7.2311, lr: 0.001
Epoch [35/80], Training Loss: 3.9399, Validation Loss Current: 6.7018, Validation Loss AVG: 6.7018, lr: 0.001
Epoch [36/80], Training Loss: 4.0955, Validation Loss Current: 5.6082, Validation Loss AVG: 5.6082, lr: 0.001
 --- Early Stopped ---
Patch distance: random4 finished training. Best epoch: 6 Best val accuracy: [0.6108552631578947, 0.6549342105263157, 0.637171052631579, 0.6898026315789474, 0.6819078947368421, 0.7332236842105263, 0.6930921052631579, 0.718421052631579, 0.6671052631578946, 0.6585526315789474, 0.6904605263157896, 0.6578947368421053, 0.6707236842105264, 0.7095394736842106, 0.6848684210526316, 0.7342105263157894, 0.719078947368421, 0.7082236842105263, 0.6733552631578947, 0.5848684210526316, 0.7095394736842104, 0.7200657894736843, 0.7210526315789474, 0.69375, 0.6957236842105263, 0.6690789473684211, 0.6345394736842105, 0.7118421052631578, 0.6769736842105263, 0.6200657894736842, 0.5990131578947369, 0.5924342105263157, 0.6851973684210526, 0.649671052631579, 0.6532894736842104, 0.6927631578947369] Best val loss: 4.468947392702103


Fold: 3
----- Training resnet18 with sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] -----
Current group: random0
Epoch [1/80], Training Loss: 41.0700, Validation Loss Current: 10.0218, Validation Loss AVG: 10.0218, lr: 0.001
Epoch [2/80], Training Loss: 39.6227, Validation Loss Current: 9.9708, Validation Loss AVG: 9.9708, lr: 0.001
Epoch [3/80], Training Loss: 39.5977, Validation Loss Current: 9.7818, Validation Loss AVG: 9.7818, lr: 0.001
Epoch [4/80], Training Loss: 38.3446, Validation Loss Current: 9.6097, Validation Loss AVG: 9.6097, lr: 0.001
Epoch [5/80], Training Loss: 37.3275, Validation Loss Current: 9.4691, Validation Loss AVG: 9.4691, lr: 0.001
Epoch [6/80], Training Loss: 37.2979, Validation Loss Current: 9.2627, Validation Loss AVG: 9.2627, lr: 0.001
Epoch [7/80], Training Loss: 35.3711, Validation Loss Current: 9.0412, Validation Loss AVG: 9.0412, lr: 0.001
Epoch [8/80], Training Loss: 34.8748, Validation Loss Current: 8.8335, Validation Loss AVG: 8.8335, lr: 0.001
Epoch [9/80], Training Loss: 33.5020, Validation Loss Current: 8.8044, Validation Loss AVG: 8.8044, lr: 0.001
Epoch [10/80], Training Loss: 32.8870, Validation Loss Current: 8.4144, Validation Loss AVG: 8.4144, lr: 0.001
Epoch [11/80], Training Loss: 31.7398, Validation Loss Current: 8.3928, Validation Loss AVG: 8.3928, lr: 0.001
Epoch [12/80], Training Loss: 30.4022, Validation Loss Current: 8.8900, Validation Loss AVG: 8.8900, lr: 0.001
Epoch [13/80], Training Loss: 31.7497, Validation Loss Current: 8.2426, Validation Loss AVG: 8.2426, lr: 0.001
Epoch [14/80], Training Loss: 30.4386, Validation Loss Current: 8.0416, Validation Loss AVG: 8.0416, lr: 0.001
Epoch [15/80], Training Loss: 28.2278, Validation Loss Current: 7.9277, Validation Loss AVG: 7.9277, lr: 0.001
Epoch [16/80], Training Loss: 27.6788, Validation Loss Current: 7.6014, Validation Loss AVG: 7.6014, lr: 0.001
Epoch [17/80], Training Loss: 26.9374, Validation Loss Current: 8.0033, Validation Loss AVG: 8.0033, lr: 0.001
Epoch [18/80], Training Loss: 26.7254, Validation Loss Current: 7.4514, Validation Loss AVG: 7.4514, lr: 0.001
Epoch [19/80], Training Loss: 26.0585, Validation Loss Current: 7.3788, Validation Loss AVG: 7.3788, lr: 0.001
Epoch [20/80], Training Loss: 24.8165, Validation Loss Current: 7.3864, Validation Loss AVG: 7.3864, lr: 0.001
Epoch [21/80], Training Loss: 25.2304, Validation Loss Current: 8.2710, Validation Loss AVG: 8.2710, lr: 0.001
Epoch [22/80], Training Loss: 27.4392, Validation Loss Current: 10.4196, Validation Loss AVG: 10.4196, lr: 0.001
Epoch [23/80], Training Loss: 25.8301, Validation Loss Current: 7.6265, Validation Loss AVG: 7.6265, lr: 0.001
Epoch [24/80], Training Loss: 25.5655, Validation Loss Current: 7.2541, Validation Loss AVG: 7.2541, lr: 0.001
Epoch [25/80], Training Loss: 24.1990, Validation Loss Current: 7.2029, Validation Loss AVG: 7.2029, lr: 0.001
Epoch [26/80], Training Loss: 23.4726, Validation Loss Current: 7.2055, Validation Loss AVG: 7.2055, lr: 0.001
Epoch [27/80], Training Loss: 22.2363, Validation Loss Current: 7.4313, Validation Loss AVG: 7.4313, lr: 0.001
Epoch [28/80], Training Loss: 21.5336, Validation Loss Current: 7.6434, Validation Loss AVG: 7.6434, lr: 0.001
Epoch [29/80], Training Loss: 20.5472, Validation Loss Current: 6.9912, Validation Loss AVG: 6.9912, lr: 0.001
Epoch [30/80], Training Loss: 20.3980, Validation Loss Current: 6.9611, Validation Loss AVG: 6.9611, lr: 0.001
Epoch [31/80], Training Loss: 17.7668, Validation Loss Current: 6.8196, Validation Loss AVG: 6.8196, lr: 0.001
Epoch [32/80], Training Loss: 16.9731, Validation Loss Current: 7.0940, Validation Loss AVG: 7.0940, lr: 0.001
Epoch [33/80], Training Loss: 17.6379, Validation Loss Current: 7.1308, Validation Loss AVG: 7.1308, lr: 0.001
Epoch [34/80], Training Loss: 16.1114, Validation Loss Current: 7.7610, Validation Loss AVG: 7.7610, lr: 0.001
Epoch [35/80], Training Loss: 17.1472, Validation Loss Current: 7.8836, Validation Loss AVG: 7.8836, lr: 0.001
Epoch [36/80], Training Loss: 16.7117, Validation Loss Current: 7.5294, Validation Loss AVG: 7.5294, lr: 0.001
Epoch [37/80], Training Loss: 14.3782, Validation Loss Current: 7.4375, Validation Loss AVG: 7.4375, lr: 0.001
Epoch [38/80], Training Loss: 13.6772, Validation Loss Current: 7.4782, Validation Loss AVG: 7.4782, lr: 0.001
Epoch [39/80], Training Loss: 13.4354, Validation Loss Current: 7.7766, Validation Loss AVG: 7.7766, lr: 0.001
Epoch [40/80], Training Loss: 12.4374, Validation Loss Current: 7.2447, Validation Loss AVG: 7.2447, lr: 0.001
Epoch [41/80], Training Loss: 11.8416, Validation Loss Current: 7.3320, Validation Loss AVG: 7.3320, lr: 0.001
Epoch [42/80], Training Loss: 10.8459, Validation Loss Current: 6.5779, Validation Loss AVG: 6.5779, lr: 0.001
Epoch [43/80], Training Loss: 12.5533, Validation Loss Current: 13.9487, Validation Loss AVG: 13.9487, lr: 0.001
Epoch [44/80], Training Loss: 17.9275, Validation Loss Current: 7.5877, Validation Loss AVG: 7.5877, lr: 0.001
Epoch [45/80], Training Loss: 13.6970, Validation Loss Current: 7.4923, Validation Loss AVG: 7.4923, lr: 0.001
Epoch [46/80], Training Loss: 12.9182, Validation Loss Current: 16.7460, Validation Loss AVG: 16.7460, lr: 0.001
Epoch [47/80], Training Loss: 20.2559, Validation Loss Current: 9.7558, Validation Loss AVG: 9.7558, lr: 0.001
Epoch [48/80], Training Loss: 22.4021, Validation Loss Current: 8.8645, Validation Loss AVG: 8.8645, lr: 0.001
Epoch [49/80], Training Loss: 18.7823, Validation Loss Current: 8.7980, Validation Loss AVG: 8.7980, lr: 0.001
Epoch [50/80], Training Loss: 14.3891, Validation Loss Current: 6.9484, Validation Loss AVG: 6.9484, lr: 0.001
Epoch [51/80], Training Loss: 10.3623, Validation Loss Current: 7.5528, Validation Loss AVG: 7.5528, lr: 0.001
Epoch [52/80], Training Loss: 8.7824, Validation Loss Current: 7.7433, Validation Loss AVG: 7.7433, lr: 0.001
Epoch [53/80], Training Loss: 7.8002, Validation Loss Current: 7.0805, Validation Loss AVG: 7.0805, lr: 0.001
Epoch [54/80], Training Loss: 8.8177, Validation Loss Current: 6.9472, Validation Loss AVG: 6.9472, lr: 0.001
Epoch [55/80], Training Loss: 8.6738, Validation Loss Current: 7.5365, Validation Loss AVG: 7.5365, lr: 0.001
Epoch [56/80], Training Loss: 7.5824, Validation Loss Current: 9.3297, Validation Loss AVG: 9.3297, lr: 0.001
Epoch [57/80], Training Loss: 8.0772, Validation Loss Current: 7.6873, Validation Loss AVG: 7.6873, lr: 0.001
Epoch [58/80], Training Loss: 7.0173, Validation Loss Current: 7.5609, Validation Loss AVG: 7.5609, lr: 0.001
Epoch [59/80], Training Loss: 5.0898, Validation Loss Current: 7.8049, Validation Loss AVG: 7.8049, lr: 0.001
Epoch [60/80], Training Loss: 5.1633, Validation Loss Current: 7.6013, Validation Loss AVG: 7.6013, lr: 0.001
Epoch [61/80], Training Loss: 5.8789, Validation Loss Current: 8.0086, Validation Loss AVG: 8.0086, lr: 0.001
Epoch [62/80], Training Loss: 5.5889, Validation Loss Current: 8.3526, Validation Loss AVG: 8.3526, lr: 0.001
Epoch [63/80], Training Loss: 4.5806, Validation Loss Current: 8.2921, Validation Loss AVG: 8.2921, lr: 0.001
Epoch [64/80], Training Loss: 6.0823, Validation Loss Current: 7.5877, Validation Loss AVG: 7.5877, lr: 0.001
Epoch [65/80], Training Loss: 5.7617, Validation Loss Current: 8.5075, Validation Loss AVG: 8.5075, lr: 0.001
Epoch [66/80], Training Loss: 6.2991, Validation Loss Current: 9.3074, Validation Loss AVG: 9.3074, lr: 0.001
Epoch [67/80], Training Loss: 5.2777, Validation Loss Current: 9.6377, Validation Loss AVG: 9.6377, lr: 0.001
Epoch [68/80], Training Loss: 8.5756, Validation Loss Current: 9.2035, Validation Loss AVG: 9.2035, lr: 0.001
Epoch [69/80], Training Loss: 6.6395, Validation Loss Current: 7.8501, Validation Loss AVG: 7.8501, lr: 0.001
Epoch [70/80], Training Loss: 4.7916, Validation Loss Current: 8.2049, Validation Loss AVG: 8.2049, lr: 0.001
Epoch [71/80], Training Loss: 4.2363, Validation Loss Current: 9.1134, Validation Loss AVG: 9.1134, lr: 0.001
Epoch [72/80], Training Loss: 3.8342, Validation Loss Current: 7.5748, Validation Loss AVG: 7.5748, lr: 0.001
 --- Early Stopped ---
Patch distance: random0 finished training. Best epoch: 42 Best val accuracy: [0.24473684210526314, 0.2388157894736842, 0.2914473684210526, 0.28717105263157894, 0.29934210526315785, 0.3365131578947368, 0.3483552631578948, 0.37138157894736845, 0.3648026315789474, 0.40756578947368427, 0.40592105263157896, 0.3861842105263158, 0.4207236842105263, 0.4473684210526316, 0.45, 0.46019736842105263, 0.4453947368421053, 0.4983552631578948, 0.48684210526315785, 0.48684210526315785, 0.43421052631578955, 0.38914473684210527, 0.46940789473684214, 0.5019736842105262, 0.4898026315789473, 0.5026315789473684, 0.4944078947368421, 0.48486842105263167, 0.5082236842105263, 0.5171052631578947, 0.5457236842105264, 0.5144736842105263, 0.524671052631579, 0.4805921052631579, 0.4657894736842104, 0.5023026315789474, 0.5213815789473684, 0.5342105263157895, 0.5069078947368422, 0.5421052631578948, 0.5375, 0.5776315789473684, 0.39144736842105265, 0.5269736842105264, 0.5358552631578947, 0.42302631578947364, 0.4111842105263158, 0.4305921052631579, 0.4960526315789474, 0.5391447368421052, 0.5203947368421052, 0.5450657894736841, 0.5694078947368422, 0.5700657894736841, 0.5529605263157894, 0.5190789473684211, 0.5641447368421053, 0.5648026315789474, 0.5611842105263157, 0.5496710526315789, 0.5654605263157895, 0.5585526315789473, 0.5694078947368422, 0.5766447368421053, 0.5503289473684211, 0.5151315789473684, 0.5398026315789475, 0.5296052631578948, 0.5736842105263158, 0.5641447368421052, 0.5342105263157894, 0.5927631578947368] Best val loss: 6.577885890007019


Current group: random1
Epoch [1/80], Training Loss: 33.9730, Validation Loss Current: 9.7774, Validation Loss AVG: 9.7774, lr: 0.001
Epoch [2/80], Training Loss: 30.7980, Validation Loss Current: 9.8575, Validation Loss AVG: 9.8575, lr: 0.001
Epoch [3/80], Training Loss: 24.4105, Validation Loss Current: 7.4262, Validation Loss AVG: 7.4262, lr: 0.001
Epoch [4/80], Training Loss: 18.8295, Validation Loss Current: 6.5973, Validation Loss AVG: 6.5973, lr: 0.001
Epoch [5/80], Training Loss: 14.7211, Validation Loss Current: 6.0138, Validation Loss AVG: 6.0138, lr: 0.001
Epoch [6/80], Training Loss: 11.0571, Validation Loss Current: 6.8222, Validation Loss AVG: 6.8222, lr: 0.001
Epoch [7/80], Training Loss: 9.6800, Validation Loss Current: 5.8002, Validation Loss AVG: 5.8002, lr: 0.001
Epoch [8/80], Training Loss: 11.7608, Validation Loss Current: 6.6381, Validation Loss AVG: 6.6381, lr: 0.001
Epoch [9/80], Training Loss: 13.2954, Validation Loss Current: 8.8865, Validation Loss AVG: 8.8865, lr: 0.001
Epoch [10/80], Training Loss: 10.0631, Validation Loss Current: 6.2093, Validation Loss AVG: 6.2093, lr: 0.001
Epoch [11/80], Training Loss: 9.2909, Validation Loss Current: 6.4345, Validation Loss AVG: 6.4345, lr: 0.001
Epoch [12/80], Training Loss: 7.5883, Validation Loss Current: 7.9077, Validation Loss AVG: 7.9077, lr: 0.001
Epoch [13/80], Training Loss: 7.3755, Validation Loss Current: 5.9783, Validation Loss AVG: 5.9783, lr: 0.001
Epoch [14/80], Training Loss: 5.5258, Validation Loss Current: 5.8916, Validation Loss AVG: 5.8916, lr: 0.001
Epoch [15/80], Training Loss: 6.5134, Validation Loss Current: 7.0054, Validation Loss AVG: 7.0054, lr: 0.001
Epoch [16/80], Training Loss: 6.9915, Validation Loss Current: 9.2854, Validation Loss AVG: 9.2854, lr: 0.001
Epoch [17/80], Training Loss: 8.0886, Validation Loss Current: 7.2464, Validation Loss AVG: 7.2464, lr: 0.001
Epoch [18/80], Training Loss: 6.6575, Validation Loss Current: 7.2411, Validation Loss AVG: 7.2411, lr: 0.001
Epoch [19/80], Training Loss: 5.6388, Validation Loss Current: 7.8323, Validation Loss AVG: 7.8323, lr: 0.001
Epoch [20/80], Training Loss: 6.7821, Validation Loss Current: 7.6771, Validation Loss AVG: 7.6771, lr: 0.001
Epoch [21/80], Training Loss: 5.6588, Validation Loss Current: 7.8094, Validation Loss AVG: 7.8094, lr: 0.001
Epoch [22/80], Training Loss: 8.7430, Validation Loss Current: 7.4589, Validation Loss AVG: 7.4589, lr: 0.001
Epoch [23/80], Training Loss: 5.0829, Validation Loss Current: 7.9366, Validation Loss AVG: 7.9366, lr: 0.001
Epoch [24/80], Training Loss: 6.6903, Validation Loss Current: 8.0748, Validation Loss AVG: 8.0748, lr: 0.001
Epoch [25/80], Training Loss: 5.7173, Validation Loss Current: 7.5504, Validation Loss AVG: 7.5504, lr: 0.001
Epoch [26/80], Training Loss: 9.5295, Validation Loss Current: 8.6318, Validation Loss AVG: 8.6318, lr: 0.001
Epoch [27/80], Training Loss: 6.8853, Validation Loss Current: 8.1463, Validation Loss AVG: 8.1463, lr: 0.001
Epoch [28/80], Training Loss: 5.4298, Validation Loss Current: 7.9747, Validation Loss AVG: 7.9747, lr: 0.001
Epoch [29/80], Training Loss: 6.0331, Validation Loss Current: 8.4333, Validation Loss AVG: 8.4333, lr: 0.001
Epoch [30/80], Training Loss: 6.3537, Validation Loss Current: 10.2591, Validation Loss AVG: 10.2591, lr: 0.001
Epoch [31/80], Training Loss: 5.8232, Validation Loss Current: 9.2317, Validation Loss AVG: 9.2317, lr: 0.001
Epoch [32/80], Training Loss: 5.9153, Validation Loss Current: 8.4920, Validation Loss AVG: 8.4920, lr: 0.001
Epoch [33/80], Training Loss: 2.3216, Validation Loss Current: 7.2213, Validation Loss AVG: 7.2213, lr: 0.001
Epoch [34/80], Training Loss: 2.6670, Validation Loss Current: 7.6102, Validation Loss AVG: 7.6102, lr: 0.001
Epoch [35/80], Training Loss: 3.4616, Validation Loss Current: 8.5105, Validation Loss AVG: 8.5105, lr: 0.001
Epoch [36/80], Training Loss: 5.7171, Validation Loss Current: 8.8165, Validation Loss AVG: 8.8165, lr: 0.001
Epoch [37/80], Training Loss: 5.5162, Validation Loss Current: 13.0739, Validation Loss AVG: 13.0739, lr: 0.001
 --- Early Stopped ---
Patch distance: random1 finished training. Best epoch: 7 Best val accuracy: [0.5085526315789474, 0.48026315789473684, 0.5608552631578948, 0.5707236842105263, 0.6282894736842106, 0.5884868421052631, 0.6342105263157894, 0.5917763157894738, 0.5286184210526316, 0.624671052631579, 0.6118421052631577, 0.5450657894736842, 0.6450657894736842, 0.6473684210526316, 0.6013157894736842, 0.5486842105263158, 0.5815789473684211, 0.6154605263157895, 0.6111842105263159, 0.562828947368421, 0.6016447368421053, 0.582236842105263, 0.5914473684210526, 0.6151315789473685, 0.6266447368421052, 0.6016447368421052, 0.5664473684210527, 0.5838815789473684, 0.5634868421052632, 0.5131578947368421, 0.5677631578947369, 0.5865131578947368, 0.6164473684210525, 0.6167763157894737, 0.5733552631578946, 0.60625, 0.46282894736842106] Best val loss: 5.800243699550629


Current group: random2
Epoch [1/80], Training Loss: 35.6665, Validation Loss Current: 8.4230, Validation Loss AVG: 8.4230, lr: 0.001
Epoch [2/80], Training Loss: 22.8656, Validation Loss Current: 7.2561, Validation Loss AVG: 7.2561, lr: 0.001
Epoch [3/80], Training Loss: 17.7569, Validation Loss Current: 6.8082, Validation Loss AVG: 6.8082, lr: 0.001
Epoch [4/80], Training Loss: 14.5727, Validation Loss Current: 5.4688, Validation Loss AVG: 5.4688, lr: 0.001
Epoch [5/80], Training Loss: 10.1467, Validation Loss Current: 5.7607, Validation Loss AVG: 5.7607, lr: 0.001
Epoch [6/80], Training Loss: 7.7661, Validation Loss Current: 5.3453, Validation Loss AVG: 5.3453, lr: 0.001
Epoch [7/80], Training Loss: 7.8430, Validation Loss Current: 6.7762, Validation Loss AVG: 6.7762, lr: 0.001
Epoch [8/80], Training Loss: 8.8177, Validation Loss Current: 6.2245, Validation Loss AVG: 6.2245, lr: 0.001
Epoch [9/80], Training Loss: 8.8615, Validation Loss Current: 6.3513, Validation Loss AVG: 6.3513, lr: 0.001
Epoch [10/80], Training Loss: 4.7555, Validation Loss Current: 5.8085, Validation Loss AVG: 5.8085, lr: 0.001
Epoch [11/80], Training Loss: 4.5047, Validation Loss Current: 8.1107, Validation Loss AVG: 8.1107, lr: 0.001
Epoch [12/80], Training Loss: 9.9644, Validation Loss Current: 8.8570, Validation Loss AVG: 8.8570, lr: 0.001
Epoch [13/80], Training Loss: 7.5300, Validation Loss Current: 6.4157, Validation Loss AVG: 6.4157, lr: 0.001
Epoch [14/80], Training Loss: 5.9027, Validation Loss Current: 7.1109, Validation Loss AVG: 7.1109, lr: 0.001
Epoch [15/80], Training Loss: 8.1704, Validation Loss Current: 7.8578, Validation Loss AVG: 7.8578, lr: 0.001
Epoch [16/80], Training Loss: 10.6817, Validation Loss Current: 10.3488, Validation Loss AVG: 10.3488, lr: 0.001
Epoch [17/80], Training Loss: 12.0730, Validation Loss Current: 9.7005, Validation Loss AVG: 9.7005, lr: 0.001
Epoch [18/80], Training Loss: 10.1721, Validation Loss Current: 7.7138, Validation Loss AVG: 7.7138, lr: 0.001
Epoch [19/80], Training Loss: 7.0396, Validation Loss Current: 7.1583, Validation Loss AVG: 7.1583, lr: 0.001
Epoch [20/80], Training Loss: 3.9694, Validation Loss Current: 6.2335, Validation Loss AVG: 6.2335, lr: 0.001
Epoch [21/80], Training Loss: 3.7095, Validation Loss Current: 6.2883, Validation Loss AVG: 6.2883, lr: 0.001
Epoch [22/80], Training Loss: 4.6867, Validation Loss Current: 6.7835, Validation Loss AVG: 6.7835, lr: 0.001
Epoch [23/80], Training Loss: 3.4087, Validation Loss Current: 6.5017, Validation Loss AVG: 6.5017, lr: 0.001
Epoch [24/80], Training Loss: 2.5301, Validation Loss Current: 6.5460, Validation Loss AVG: 6.5460, lr: 0.001
Epoch [25/80], Training Loss: 2.0156, Validation Loss Current: 6.1320, Validation Loss AVG: 6.1320, lr: 0.001
Epoch [26/80], Training Loss: 2.6953, Validation Loss Current: 6.4183, Validation Loss AVG: 6.4183, lr: 0.001
Epoch [27/80], Training Loss: 5.9054, Validation Loss Current: 11.4180, Validation Loss AVG: 11.4180, lr: 0.001
Epoch [28/80], Training Loss: 14.2349, Validation Loss Current: 8.0691, Validation Loss AVG: 8.0691, lr: 0.001
Epoch [29/80], Training Loss: 6.4873, Validation Loss Current: 7.1961, Validation Loss AVG: 7.1961, lr: 0.001
Epoch [30/80], Training Loss: 6.4381, Validation Loss Current: 6.7781, Validation Loss AVG: 6.7781, lr: 0.001
Epoch [31/80], Training Loss: 2.9273, Validation Loss Current: 6.3725, Validation Loss AVG: 6.3725, lr: 0.001
Epoch [32/80], Training Loss: 4.1611, Validation Loss Current: 7.7409, Validation Loss AVG: 7.7409, lr: 0.001
Epoch [33/80], Training Loss: 8.1131, Validation Loss Current: 7.9696, Validation Loss AVG: 7.9696, lr: 0.001
Epoch [34/80], Training Loss: 4.2355, Validation Loss Current: 6.5134, Validation Loss AVG: 6.5134, lr: 0.001
Epoch [35/80], Training Loss: 6.4279, Validation Loss Current: 9.3765, Validation Loss AVG: 9.3765, lr: 0.001
Epoch [36/80], Training Loss: 3.3446, Validation Loss Current: 9.1970, Validation Loss AVG: 9.1970, lr: 0.001
 --- Early Stopped ---
Patch distance: random2 finished training. Best epoch: 6 Best val accuracy: [0.5391447368421053, 0.5976973684210527, 0.6164473684210525, 0.6700657894736842, 0.6611842105263157, 0.6799342105263158, 0.6381578947368421, 0.6375000000000001, 0.643421052631579, 0.6569078947368421, 0.6072368421052631, 0.5266447368421052, 0.6411184210526316, 0.6200657894736842, 0.6121710526315789, 0.5009868421052632, 0.5273026315789474, 0.5957236842105262, 0.6230263157894738, 0.6509868421052631, 0.6529605263157894, 0.6388157894736842, 0.6480263157894737, 0.6608552631578947, 0.6710526315789475, 0.6644736842105263, 0.5467105263157894, 0.5713815789473684, 0.638157894736842, 0.6411184210526315, 0.6516447368421053, 0.5815789473684211, 0.6213815789473685, 0.6523026315789473, 0.5746710526315789, 0.5677631578947369] Best val loss: 5.345336210727692


Current group: random3
Epoch [1/80], Training Loss: 34.1163, Validation Loss Current: 7.4356, Validation Loss AVG: 7.4356, lr: 0.001
Epoch [2/80], Training Loss: 23.4230, Validation Loss Current: 8.4266, Validation Loss AVG: 8.4266, lr: 0.001
Epoch [3/80], Training Loss: 18.8756, Validation Loss Current: 6.0633, Validation Loss AVG: 6.0633, lr: 0.001
Epoch [4/80], Training Loss: 12.2320, Validation Loss Current: 5.1650, Validation Loss AVG: 5.1650, lr: 0.001
Epoch [5/80], Training Loss: 10.4356, Validation Loss Current: 5.5198, Validation Loss AVG: 5.5198, lr: 0.001
Epoch [6/80], Training Loss: 10.7949, Validation Loss Current: 7.0852, Validation Loss AVG: 7.0852, lr: 0.001
Epoch [7/80], Training Loss: 9.9780, Validation Loss Current: 6.2366, Validation Loss AVG: 6.2366, lr: 0.001
Epoch [8/80], Training Loss: 8.1069, Validation Loss Current: 6.8917, Validation Loss AVG: 6.8917, lr: 0.001
Epoch [9/80], Training Loss: 5.5797, Validation Loss Current: 5.9475, Validation Loss AVG: 5.9475, lr: 0.001
Epoch [10/80], Training Loss: 6.5038, Validation Loss Current: 6.8562, Validation Loss AVG: 6.8562, lr: 0.001
Epoch [11/80], Training Loss: 5.7115, Validation Loss Current: 5.8711, Validation Loss AVG: 5.8711, lr: 0.001
Epoch [12/80], Training Loss: 4.5903, Validation Loss Current: 5.2829, Validation Loss AVG: 5.2829, lr: 0.001
Epoch [13/80], Training Loss: 3.4979, Validation Loss Current: 5.6857, Validation Loss AVG: 5.6857, lr: 0.001
Epoch [14/80], Training Loss: 6.1127, Validation Loss Current: 5.9041, Validation Loss AVG: 5.9041, lr: 0.001
Epoch [15/80], Training Loss: 6.8991, Validation Loss Current: 6.2633, Validation Loss AVG: 6.2633, lr: 0.001
Epoch [16/80], Training Loss: 5.1207, Validation Loss Current: 6.1095, Validation Loss AVG: 6.1095, lr: 0.001
Epoch [17/80], Training Loss: 4.3461, Validation Loss Current: 7.2865, Validation Loss AVG: 7.2865, lr: 0.001
Epoch [18/80], Training Loss: 2.8845, Validation Loss Current: 5.9708, Validation Loss AVG: 5.9708, lr: 0.001
Epoch [19/80], Training Loss: 3.9217, Validation Loss Current: 6.1910, Validation Loss AVG: 6.1910, lr: 0.001
Epoch [20/80], Training Loss: 7.9155, Validation Loss Current: 6.6971, Validation Loss AVG: 6.6971, lr: 0.001
Epoch [21/80], Training Loss: 5.3945, Validation Loss Current: 6.7546, Validation Loss AVG: 6.7546, lr: 0.001
Epoch [22/80], Training Loss: 3.2486, Validation Loss Current: 6.0092, Validation Loss AVG: 6.0092, lr: 0.001
Epoch [23/80], Training Loss: 3.3096, Validation Loss Current: 6.4400, Validation Loss AVG: 6.4400, lr: 0.001
Epoch [24/80], Training Loss: 5.0928, Validation Loss Current: 7.9222, Validation Loss AVG: 7.9222, lr: 0.001
Epoch [25/80], Training Loss: 10.9924, Validation Loss Current: 7.8458, Validation Loss AVG: 7.8458, lr: 0.001
Epoch [26/80], Training Loss: 8.6513, Validation Loss Current: 8.4258, Validation Loss AVG: 8.4258, lr: 0.001
Epoch [27/80], Training Loss: 10.2988, Validation Loss Current: 8.4213, Validation Loss AVG: 8.4213, lr: 0.001
Epoch [28/80], Training Loss: 7.6237, Validation Loss Current: 7.1239, Validation Loss AVG: 7.1239, lr: 0.001
Epoch [29/80], Training Loss: 5.1538, Validation Loss Current: 6.5553, Validation Loss AVG: 6.5553, lr: 0.001
Epoch [30/80], Training Loss: 6.9119, Validation Loss Current: 7.0074, Validation Loss AVG: 7.0074, lr: 0.001
Epoch [31/80], Training Loss: 5.3874, Validation Loss Current: 6.4239, Validation Loss AVG: 6.4239, lr: 0.001
Epoch [32/80], Training Loss: 4.8262, Validation Loss Current: 7.7248, Validation Loss AVG: 7.7248, lr: 0.001
Epoch [33/80], Training Loss: 6.3043, Validation Loss Current: 7.0993, Validation Loss AVG: 7.0993, lr: 0.001
Epoch [34/80], Training Loss: 4.5938, Validation Loss Current: 8.6307, Validation Loss AVG: 8.6307, lr: 0.001
 --- Early Stopped ---
Patch distance: random3 finished training. Best epoch: 4 Best val accuracy: [0.6144736842105263, 0.562828947368421, 0.6210526315789474, 0.6743421052631579, 0.6523026315789473, 0.625328947368421, 0.6332236842105263, 0.6351973684210527, 0.6345394736842105, 0.6460526315789472, 0.675986842105263, 0.6901315789473685, 0.6881578947368421, 0.6799342105263159, 0.6664473684210528, 0.662828947368421, 0.6368421052631579, 0.6851973684210526, 0.6884868421052631, 0.6532894736842104, 0.6529605263157895, 0.6861842105263157, 0.6799342105263159, 0.6305921052631579, 0.5917763157894737, 0.6111842105263158, 0.6078947368421053, 0.6355263157894736, 0.6631578947368422, 0.6578947368421053, 0.661842105263158, 0.6351973684210526, 0.6555921052631579, 0.594078947368421] Best val loss: 5.164995968341827


Current group: random4
Epoch [1/80], Training Loss: 38.6235, Validation Loss Current: 6.2418, Validation Loss AVG: 6.2418, lr: 0.001
Epoch [2/80], Training Loss: 25.7074, Validation Loss Current: 6.5494, Validation Loss AVG: 6.5494, lr: 0.001
Epoch [3/80], Training Loss: 16.0437, Validation Loss Current: 4.6622, Validation Loss AVG: 4.6622, lr: 0.001
Epoch [4/80], Training Loss: 11.6537, Validation Loss Current: 4.7598, Validation Loss AVG: 4.7598, lr: 0.001
Epoch [5/80], Training Loss: 10.2108, Validation Loss Current: 4.5591, Validation Loss AVG: 4.5591, lr: 0.001
Epoch [6/80], Training Loss: 10.4632, Validation Loss Current: 4.3797, Validation Loss AVG: 4.3797, lr: 0.001
Epoch [7/80], Training Loss: 8.1563, Validation Loss Current: 4.8941, Validation Loss AVG: 4.8941, lr: 0.001
Epoch [8/80], Training Loss: 8.6247, Validation Loss Current: 4.7852, Validation Loss AVG: 4.7852, lr: 0.001
Epoch [9/80], Training Loss: 10.3555, Validation Loss Current: 6.0609, Validation Loss AVG: 6.0609, lr: 0.001
Epoch [10/80], Training Loss: 9.4395, Validation Loss Current: 6.1652, Validation Loss AVG: 6.1652, lr: 0.001
Epoch [11/80], Training Loss: 6.4378, Validation Loss Current: 5.0230, Validation Loss AVG: 5.0230, lr: 0.001
Epoch [12/80], Training Loss: 4.5531, Validation Loss Current: 4.6012, Validation Loss AVG: 4.6012, lr: 0.001
Epoch [13/80], Training Loss: 4.5898, Validation Loss Current: 4.8716, Validation Loss AVG: 4.8716, lr: 0.001
Epoch [14/80], Training Loss: 2.4688, Validation Loss Current: 5.0667, Validation Loss AVG: 5.0667, lr: 0.001
Epoch [15/80], Training Loss: 2.1478, Validation Loss Current: 4.6213, Validation Loss AVG: 4.6213, lr: 0.001
Epoch [16/80], Training Loss: 1.7001, Validation Loss Current: 4.5589, Validation Loss AVG: 4.5589, lr: 0.001
Epoch [17/80], Training Loss: 2.2794, Validation Loss Current: 4.8964, Validation Loss AVG: 4.8964, lr: 0.001
Epoch [18/80], Training Loss: 2.7665, Validation Loss Current: 5.2832, Validation Loss AVG: 5.2832, lr: 0.001
Epoch [19/80], Training Loss: 5.4832, Validation Loss Current: 6.0147, Validation Loss AVG: 6.0147, lr: 0.001
Epoch [20/80], Training Loss: 7.1452, Validation Loss Current: 6.5334, Validation Loss AVG: 6.5334, lr: 0.001
Epoch [21/80], Training Loss: 6.8309, Validation Loss Current: 6.9417, Validation Loss AVG: 6.9417, lr: 0.001
Epoch [22/80], Training Loss: 5.8966, Validation Loss Current: 6.0167, Validation Loss AVG: 6.0167, lr: 0.001
Epoch [23/80], Training Loss: 4.7466, Validation Loss Current: 5.8997, Validation Loss AVG: 5.8997, lr: 0.001
Epoch [24/80], Training Loss: 2.5830, Validation Loss Current: 5.0293, Validation Loss AVG: 5.0293, lr: 0.001
Epoch [25/80], Training Loss: 5.8773, Validation Loss Current: 5.3484, Validation Loss AVG: 5.3484, lr: 0.001
Epoch [26/80], Training Loss: 6.8353, Validation Loss Current: 6.0711, Validation Loss AVG: 6.0711, lr: 0.001
Epoch [27/80], Training Loss: 6.8319, Validation Loss Current: 5.8124, Validation Loss AVG: 5.8124, lr: 0.001
Epoch [28/80], Training Loss: 4.3672, Validation Loss Current: 5.4138, Validation Loss AVG: 5.4138, lr: 0.001
Epoch [29/80], Training Loss: 3.4411, Validation Loss Current: 6.1355, Validation Loss AVG: 6.1355, lr: 0.001
Epoch [30/80], Training Loss: 5.6147, Validation Loss Current: 6.1052, Validation Loss AVG: 6.1052, lr: 0.001
Epoch [31/80], Training Loss: 6.7327, Validation Loss Current: 8.0020, Validation Loss AVG: 8.0020, lr: 0.001
Epoch [32/80], Training Loss: 5.6684, Validation Loss Current: 5.9521, Validation Loss AVG: 5.9521, lr: 0.001
Epoch [33/80], Training Loss: 9.8006, Validation Loss Current: 7.7821, Validation Loss AVG: 7.7821, lr: 0.001
Epoch [34/80], Training Loss: 4.2681, Validation Loss Current: 5.9482, Validation Loss AVG: 5.9482, lr: 0.001
Epoch [35/80], Training Loss: 5.7507, Validation Loss Current: 6.8916, Validation Loss AVG: 6.8916, lr: 0.001
Epoch [36/80], Training Loss: 8.3312, Validation Loss Current: 7.7461, Validation Loss AVG: 7.7461, lr: 0.001
 --- Early Stopped ---
Patch distance: random4 finished training. Best epoch: 6 Best val accuracy: [0.6572368421052632, 0.625, 0.7003289473684211, 0.7151315789473685, 0.7230263157894736, 0.7233552631578947, 0.7154605263157895, 0.7062499999999999, 0.6552631578947368, 0.6371710526315789, 0.724671052631579, 0.7236842105263158, 0.7177631578947368, 0.7259868421052631, 0.7404605263157895, 0.7375, 0.7345394736842105, 0.70625, 0.680921052631579, 0.6802631578947368, 0.624671052631579, 0.6671052631578948, 0.6868421052631579, 0.7236842105263157, 0.7177631578947368, 0.6782894736842106, 0.6957236842105264, 0.7098684210526316, 0.6802631578947368, 0.6842105263157894, 0.6243421052631579, 0.6763157894736842, 0.6384868421052632, 0.6726973684210525, 0.6427631578947368, 0.6266447368421053] Best val loss: 4.379714691638947


Fold: 4
----- Training resnet18 with sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] -----
Current group: random0
Epoch [1/80], Training Loss: 41.0697, Validation Loss Current: 9.9720, Validation Loss AVG: 9.9720, lr: 0.001
Epoch [2/80], Training Loss: 39.5906, Validation Loss Current: 9.9378, Validation Loss AVG: 9.9378, lr: 0.001
Epoch [3/80], Training Loss: 39.1200, Validation Loss Current: 9.8499, Validation Loss AVG: 9.8499, lr: 0.001
Epoch [4/80], Training Loss: 39.2266, Validation Loss Current: 9.6899, Validation Loss AVG: 9.6899, lr: 0.001
Epoch [5/80], Training Loss: 38.1652, Validation Loss Current: 9.4411, Validation Loss AVG: 9.4411, lr: 0.001
Epoch [6/80], Training Loss: 37.8547, Validation Loss Current: 9.3970, Validation Loss AVG: 9.3970, lr: 0.001
Epoch [7/80], Training Loss: 36.7585, Validation Loss Current: 9.3281, Validation Loss AVG: 9.3281, lr: 0.001
Epoch [8/80], Training Loss: 35.9427, Validation Loss Current: 8.9164, Validation Loss AVG: 8.9164, lr: 0.001
Epoch [9/80], Training Loss: 34.0053, Validation Loss Current: 8.6618, Validation Loss AVG: 8.6618, lr: 0.001
Epoch [10/80], Training Loss: 33.5150, Validation Loss Current: 8.4355, Validation Loss AVG: 8.4355, lr: 0.001
Epoch [11/80], Training Loss: 32.5149, Validation Loss Current: 8.2770, Validation Loss AVG: 8.2770, lr: 0.001
Epoch [12/80], Training Loss: 32.5577, Validation Loss Current: 8.1648, Validation Loss AVG: 8.1648, lr: 0.001
Epoch [13/80], Training Loss: 30.5779, Validation Loss Current: 8.1303, Validation Loss AVG: 8.1303, lr: 0.001
Epoch [14/80], Training Loss: 30.5662, Validation Loss Current: 7.7861, Validation Loss AVG: 7.7861, lr: 0.001
Epoch [15/80], Training Loss: 29.3231, Validation Loss Current: 7.8405, Validation Loss AVG: 7.8405, lr: 0.001
Epoch [16/80], Training Loss: 29.3910, Validation Loss Current: 7.7934, Validation Loss AVG: 7.7934, lr: 0.001
Epoch [17/80], Training Loss: 27.1803, Validation Loss Current: 8.1799, Validation Loss AVG: 8.1799, lr: 0.001
Epoch [18/80], Training Loss: 28.8995, Validation Loss Current: 8.0461, Validation Loss AVG: 8.0461, lr: 0.001
Epoch [19/80], Training Loss: 27.9766, Validation Loss Current: 7.8616, Validation Loss AVG: 7.8616, lr: 0.001
Epoch [20/80], Training Loss: 26.7863, Validation Loss Current: 7.4396, Validation Loss AVG: 7.4396, lr: 0.001
Epoch [21/80], Training Loss: 26.3986, Validation Loss Current: 8.4128, Validation Loss AVG: 8.4128, lr: 0.001
Epoch [22/80], Training Loss: 25.8869, Validation Loss Current: 7.2108, Validation Loss AVG: 7.2108, lr: 0.001
Epoch [23/80], Training Loss: 25.6687, Validation Loss Current: 6.8825, Validation Loss AVG: 6.8825, lr: 0.001
Epoch [24/80], Training Loss: 24.4012, Validation Loss Current: 12.3518, Validation Loss AVG: 12.3518, lr: 0.001
Epoch [25/80], Training Loss: 24.2864, Validation Loss Current: 8.5327, Validation Loss AVG: 8.5327, lr: 0.001
Epoch [26/80], Training Loss: 26.4039, Validation Loss Current: 8.1792, Validation Loss AVG: 8.1792, lr: 0.001
Epoch [27/80], Training Loss: 22.7430, Validation Loss Current: 6.8397, Validation Loss AVG: 6.8397, lr: 0.001
Epoch [28/80], Training Loss: 22.3646, Validation Loss Current: 6.8543, Validation Loss AVG: 6.8543, lr: 0.001
Epoch [29/80], Training Loss: 21.7175, Validation Loss Current: 6.8004, Validation Loss AVG: 6.8004, lr: 0.001
Epoch [30/80], Training Loss: 22.0586, Validation Loss Current: 7.0027, Validation Loss AVG: 7.0027, lr: 0.001
Epoch [31/80], Training Loss: 20.2414, Validation Loss Current: 6.6434, Validation Loss AVG: 6.6434, lr: 0.001
Epoch [32/80], Training Loss: 19.3965, Validation Loss Current: 6.3578, Validation Loss AVG: 6.3578, lr: 0.001
Epoch [33/80], Training Loss: 18.6271, Validation Loss Current: 7.1494, Validation Loss AVG: 7.1494, lr: 0.001
Epoch [34/80], Training Loss: 18.9566, Validation Loss Current: 6.6956, Validation Loss AVG: 6.6956, lr: 0.001
Epoch [35/80], Training Loss: 17.6772, Validation Loss Current: 6.7035, Validation Loss AVG: 6.7035, lr: 0.001
Epoch [36/80], Training Loss: 15.9421, Validation Loss Current: 7.0864, Validation Loss AVG: 7.0864, lr: 0.001
Epoch [37/80], Training Loss: 16.3456, Validation Loss Current: 6.5866, Validation Loss AVG: 6.5866, lr: 0.001
Epoch [38/80], Training Loss: 15.9143, Validation Loss Current: 6.8569, Validation Loss AVG: 6.8569, lr: 0.001
Epoch [39/80], Training Loss: 17.2650, Validation Loss Current: 6.9930, Validation Loss AVG: 6.9930, lr: 0.001
Epoch [40/80], Training Loss: 14.1328, Validation Loss Current: 6.6185, Validation Loss AVG: 6.6185, lr: 0.001
Epoch [41/80], Training Loss: 13.0622, Validation Loss Current: 6.3273, Validation Loss AVG: 6.3273, lr: 0.001
Epoch [42/80], Training Loss: 12.0450, Validation Loss Current: 6.5619, Validation Loss AVG: 6.5619, lr: 0.001
Epoch [43/80], Training Loss: 10.9794, Validation Loss Current: 6.3280, Validation Loss AVG: 6.3280, lr: 0.001
Epoch [44/80], Training Loss: 11.6399, Validation Loss Current: 6.6981, Validation Loss AVG: 6.6981, lr: 0.001
Epoch [45/80], Training Loss: 11.7087, Validation Loss Current: 6.6817, Validation Loss AVG: 6.6817, lr: 0.001
Epoch [46/80], Training Loss: 9.6642, Validation Loss Current: 7.2433, Validation Loss AVG: 7.2433, lr: 0.001
Epoch [47/80], Training Loss: 10.3935, Validation Loss Current: 6.6555, Validation Loss AVG: 6.6555, lr: 0.001
Epoch [48/80], Training Loss: 8.7566, Validation Loss Current: 7.0285, Validation Loss AVG: 7.0285, lr: 0.001
Epoch [49/80], Training Loss: 7.5127, Validation Loss Current: 6.4597, Validation Loss AVG: 6.4597, lr: 0.001
Epoch [50/80], Training Loss: 6.1445, Validation Loss Current: 6.3482, Validation Loss AVG: 6.3482, lr: 0.001
Epoch [51/80], Training Loss: 6.3162, Validation Loss Current: 7.5039, Validation Loss AVG: 7.5039, lr: 0.001
Epoch [52/80], Training Loss: 7.2155, Validation Loss Current: 7.2677, Validation Loss AVG: 7.2677, lr: 0.001
Epoch [53/80], Training Loss: 6.3384, Validation Loss Current: 6.8074, Validation Loss AVG: 6.8074, lr: 0.001
Epoch [54/80], Training Loss: 7.0922, Validation Loss Current: 8.9619, Validation Loss AVG: 8.9619, lr: 0.001
Epoch [55/80], Training Loss: 11.3872, Validation Loss Current: 19.1829, Validation Loss AVG: 19.1829, lr: 0.001
Epoch [56/80], Training Loss: 16.5099, Validation Loss Current: 13.9394, Validation Loss AVG: 13.9394, lr: 0.001
Epoch [57/80], Training Loss: 13.2603, Validation Loss Current: 9.2252, Validation Loss AVG: 9.2252, lr: 0.001
Epoch [58/80], Training Loss: 10.6002, Validation Loss Current: 7.4949, Validation Loss AVG: 7.4949, lr: 0.001
Epoch [59/80], Training Loss: 9.5427, Validation Loss Current: 6.8330, Validation Loss AVG: 6.8330, lr: 0.001
Epoch [60/80], Training Loss: 6.3132, Validation Loss Current: 7.1787, Validation Loss AVG: 7.1787, lr: 0.001
Epoch [61/80], Training Loss: 8.2405, Validation Loss Current: 7.5604, Validation Loss AVG: 7.5604, lr: 0.001
Epoch [62/80], Training Loss: 6.7643, Validation Loss Current: 7.4005, Validation Loss AVG: 7.4005, lr: 0.001
Epoch [63/80], Training Loss: 5.9386, Validation Loss Current: 6.7128, Validation Loss AVG: 6.7128, lr: 0.001
Epoch [64/80], Training Loss: 6.4326, Validation Loss Current: 6.7512, Validation Loss AVG: 6.7512, lr: 0.001
Epoch [65/80], Training Loss: 4.3026, Validation Loss Current: 7.1445, Validation Loss AVG: 7.1445, lr: 0.001
Epoch [66/80], Training Loss: 3.1309, Validation Loss Current: 6.9009, Validation Loss AVG: 6.9009, lr: 0.001
Epoch [67/80], Training Loss: 3.9194, Validation Loss Current: 7.4359, Validation Loss AVG: 7.4359, lr: 0.001
Epoch [68/80], Training Loss: 6.0924, Validation Loss Current: 7.4332, Validation Loss AVG: 7.4332, lr: 0.001
Epoch [69/80], Training Loss: 5.3361, Validation Loss Current: 8.9069, Validation Loss AVG: 8.9069, lr: 0.001
Epoch [70/80], Training Loss: 6.3670, Validation Loss Current: 8.3963, Validation Loss AVG: 8.3963, lr: 0.001
Epoch [71/80], Training Loss: 4.8202, Validation Loss Current: 9.1599, Validation Loss AVG: 9.1599, lr: 0.001
 --- Early Stopped ---
Patch distance: random0 finished training. Best epoch: 41 Best val accuracy: [0.25756578947368414, 0.2536184210526316, 0.2868421052631579, 0.29539473684210527, 0.2917763157894737, 0.31875, 0.3134868421052631, 0.3680921052631579, 0.3914473684210526, 0.3940789473684211, 0.4197368421052631, 0.42269736842105265, 0.4286184210526316, 0.43881578947368427, 0.4440789473684211, 0.43947368421052635, 0.43881578947368427, 0.41940789473684215, 0.43717105263157896, 0.47796052631578956, 0.4338815789473684, 0.4838815789473684, 0.5157894736842106, 0.3388157894736842, 0.4161184210526316, 0.4453947368421053, 0.5069078947368422, 0.5322368421052631, 0.5161184210526317, 0.5220394736842104, 0.5240131578947368, 0.5483552631578947, 0.5111842105263158, 0.5384868421052632, 0.5368421052631579, 0.5292763157894737, 0.5542763157894737, 0.5457236842105264, 0.5141447368421053, 0.5434210526315789, 0.5654605263157895, 0.5523026315789473, 0.5700657894736841, 0.5470394736842106, 0.5740131578947368, 0.5427631578947368, 0.5746710526315789, 0.5763157894736841, 0.5986842105263157, 0.5993421052631579, 0.5549342105263158, 0.562171052631579, 0.5855263157894737, 0.5266447368421053, 0.3967105263157895, 0.3726973684210526, 0.48355263157894746, 0.575, 0.5898026315789474, 0.5703947368421053, 0.5697368421052632, 0.5726973684210526, 0.5924342105263157, 0.5960526315789474, 0.587171052631579, 0.6026315789473685, 0.5884868421052631, 0.5671052631578948, 0.5460526315789473, 0.5595394736842105, 0.5463815789473684] Best val loss: 6.327267503738403


Current group: random1
Epoch [1/80], Training Loss: 33.3134, Validation Loss Current: 8.5506, Validation Loss AVG: 8.5506, lr: 0.001
Epoch [2/80], Training Loss: 24.2246, Validation Loss Current: 7.4225, Validation Loss AVG: 7.4225, lr: 0.001
Epoch [3/80], Training Loss: 18.4813, Validation Loss Current: 5.5732, Validation Loss AVG: 5.5732, lr: 0.001
Epoch [4/80], Training Loss: 18.4660, Validation Loss Current: 8.3543, Validation Loss AVG: 8.3543, lr: 0.001
Epoch [5/80], Training Loss: 14.0442, Validation Loss Current: 5.4175, Validation Loss AVG: 5.4175, lr: 0.001
Epoch [6/80], Training Loss: 11.6813, Validation Loss Current: 5.6778, Validation Loss AVG: 5.6778, lr: 0.001
Epoch [7/80], Training Loss: 13.3038, Validation Loss Current: 5.7873, Validation Loss AVG: 5.7873, lr: 0.001
Epoch [8/80], Training Loss: 12.8571, Validation Loss Current: 5.9067, Validation Loss AVG: 5.9067, lr: 0.001
Epoch [9/80], Training Loss: 10.3348, Validation Loss Current: 6.1840, Validation Loss AVG: 6.1840, lr: 0.001
Epoch [10/80], Training Loss: 7.3339, Validation Loss Current: 5.2672, Validation Loss AVG: 5.2672, lr: 0.001
Epoch [11/80], Training Loss: 11.0208, Validation Loss Current: 6.9285, Validation Loss AVG: 6.9285, lr: 0.001
Epoch [12/80], Training Loss: 12.1228, Validation Loss Current: 8.8836, Validation Loss AVG: 8.8836, lr: 0.001
Epoch [13/80], Training Loss: 10.0243, Validation Loss Current: 6.9269, Validation Loss AVG: 6.9269, lr: 0.001
Epoch [14/80], Training Loss: 6.0415, Validation Loss Current: 5.7224, Validation Loss AVG: 5.7224, lr: 0.001
Epoch [15/80], Training Loss: 4.0221, Validation Loss Current: 5.4429, Validation Loss AVG: 5.4429, lr: 0.001
Epoch [16/80], Training Loss: 4.1972, Validation Loss Current: 5.6220, Validation Loss AVG: 5.6220, lr: 0.001
Epoch [17/80], Training Loss: 3.3976, Validation Loss Current: 6.1931, Validation Loss AVG: 6.1931, lr: 0.001
Epoch [18/80], Training Loss: 5.0344, Validation Loss Current: 5.9369, Validation Loss AVG: 5.9369, lr: 0.001
Epoch [19/80], Training Loss: 6.8697, Validation Loss Current: 8.0207, Validation Loss AVG: 8.0207, lr: 0.001
Epoch [20/80], Training Loss: 7.8012, Validation Loss Current: 7.5429, Validation Loss AVG: 7.5429, lr: 0.001
Epoch [21/80], Training Loss: 7.5288, Validation Loss Current: 6.1497, Validation Loss AVG: 6.1497, lr: 0.001
Epoch [22/80], Training Loss: 5.7604, Validation Loss Current: 8.5836, Validation Loss AVG: 8.5836, lr: 0.001
Epoch [23/80], Training Loss: 7.2068, Validation Loss Current: 8.5806, Validation Loss AVG: 8.5806, lr: 0.001
Epoch [24/80], Training Loss: 4.5622, Validation Loss Current: 7.8204, Validation Loss AVG: 7.8204, lr: 0.001
Epoch [25/80], Training Loss: 3.5919, Validation Loss Current: 7.5935, Validation Loss AVG: 7.5935, lr: 0.001
Epoch [26/80], Training Loss: 5.5234, Validation Loss Current: 7.3283, Validation Loss AVG: 7.3283, lr: 0.001
Epoch [27/80], Training Loss: 6.6304, Validation Loss Current: 7.7597, Validation Loss AVG: 7.7597, lr: 0.001
Epoch [28/80], Training Loss: 9.6718, Validation Loss Current: 9.7380, Validation Loss AVG: 9.7380, lr: 0.001
Epoch [29/80], Training Loss: 6.9344, Validation Loss Current: 8.7777, Validation Loss AVG: 8.7777, lr: 0.001
Epoch [30/80], Training Loss: 9.9480, Validation Loss Current: 7.7243, Validation Loss AVG: 7.7243, lr: 0.001
Epoch [31/80], Training Loss: 11.7536, Validation Loss Current: 8.9483, Validation Loss AVG: 8.9483, lr: 0.001
Epoch [32/80], Training Loss: 14.2409, Validation Loss Current: 8.7744, Validation Loss AVG: 8.7744, lr: 0.001
Epoch [33/80], Training Loss: 8.2100, Validation Loss Current: 10.2369, Validation Loss AVG: 10.2369, lr: 0.001
Epoch [34/80], Training Loss: 9.0081, Validation Loss Current: 7.7283, Validation Loss AVG: 7.7283, lr: 0.001
Epoch [35/80], Training Loss: 5.8564, Validation Loss Current: 7.2829, Validation Loss AVG: 7.2829, lr: 0.001
Epoch [36/80], Training Loss: 6.8849, Validation Loss Current: 8.2847, Validation Loss AVG: 8.2847, lr: 0.001
Epoch [37/80], Training Loss: 8.3401, Validation Loss Current: 9.5083, Validation Loss AVG: 9.5083, lr: 0.001
Epoch [38/80], Training Loss: 4.2678, Validation Loss Current: 7.3865, Validation Loss AVG: 7.3865, lr: 0.001
Epoch [39/80], Training Loss: 3.4043, Validation Loss Current: 6.8332, Validation Loss AVG: 6.8332, lr: 0.001
Epoch [40/80], Training Loss: 3.1965, Validation Loss Current: 7.8159, Validation Loss AVG: 7.8159, lr: 0.001
 --- Early Stopped ---
Patch distance: random1 finished training. Best epoch: 10 Best val accuracy: [0.5055921052631579, 0.5486842105263158, 0.6414473684210525, 0.5197368421052632, 0.64375, 0.6365131578947368, 0.6319078947368421, 0.6177631578947369, 0.618421052631579, 0.662171052631579, 0.587171052631579, 0.5503289473684211, 0.6029605263157894, 0.6519736842105263, 0.6657894736842105, 0.6641447368421053, 0.631578947368421, 0.6457236842105263, 0.581907894736842, 0.5736842105263158, 0.6394736842105263, 0.5644736842105263, 0.5578947368421053, 0.5901315789473685, 0.5838815789473684, 0.6016447368421052, 0.6128289473684211, 0.5210526315789473, 0.5595394736842104, 0.5631578947368421, 0.5368421052631579, 0.5444078947368421, 0.5105263157894737, 0.5924342105263158, 0.6223684210526316, 0.5825657894736842, 0.537828947368421, 0.6078947368421053, 0.6240131578947368, 0.5904605263157895] Best val loss: 5.267199003696442


Current group: random2
Epoch [1/80], Training Loss: 36.4904, Validation Loss Current: 7.1522, Validation Loss AVG: 7.1522, lr: 0.001
Epoch [2/80], Training Loss: 25.4003, Validation Loss Current: 6.3864, Validation Loss AVG: 6.3864, lr: 0.001
Epoch [3/80], Training Loss: 16.9064, Validation Loss Current: 6.0344, Validation Loss AVG: 6.0344, lr: 0.001
Epoch [4/80], Training Loss: 11.1679, Validation Loss Current: 4.7318, Validation Loss AVG: 4.7318, lr: 0.001
Epoch [5/80], Training Loss: 9.8935, Validation Loss Current: 4.6078, Validation Loss AVG: 4.6078, lr: 0.001
Epoch [6/80], Training Loss: 9.7436, Validation Loss Current: 5.3332, Validation Loss AVG: 5.3332, lr: 0.001
Epoch [7/80], Training Loss: 10.7584, Validation Loss Current: 6.4226, Validation Loss AVG: 6.4226, lr: 0.001
Epoch [8/80], Training Loss: 15.8527, Validation Loss Current: 8.2941, Validation Loss AVG: 8.2941, lr: 0.001
Epoch [9/80], Training Loss: 12.6413, Validation Loss Current: 5.7284, Validation Loss AVG: 5.7284, lr: 0.001
Epoch [10/80], Training Loss: 10.0935, Validation Loss Current: 5.5051, Validation Loss AVG: 5.5051, lr: 0.001
Epoch [11/80], Training Loss: 7.0633, Validation Loss Current: 5.9053, Validation Loss AVG: 5.9053, lr: 0.001
Epoch [12/80], Training Loss: 7.6026, Validation Loss Current: 5.5426, Validation Loss AVG: 5.5426, lr: 0.001
Epoch [13/80], Training Loss: 6.1039, Validation Loss Current: 7.0922, Validation Loss AVG: 7.0922, lr: 0.001
Epoch [14/80], Training Loss: 5.2255, Validation Loss Current: 7.0114, Validation Loss AVG: 7.0114, lr: 0.001
Epoch [15/80], Training Loss: 3.2259, Validation Loss Current: 5.9928, Validation Loss AVG: 5.9928, lr: 0.001
Epoch [16/80], Training Loss: 4.4965, Validation Loss Current: 6.7414, Validation Loss AVG: 6.7414, lr: 0.001
Epoch [17/80], Training Loss: 8.4567, Validation Loss Current: 11.6611, Validation Loss AVG: 11.6611, lr: 0.001
Epoch [18/80], Training Loss: 5.7544, Validation Loss Current: 6.3602, Validation Loss AVG: 6.3602, lr: 0.001
Epoch [19/80], Training Loss: 5.8894, Validation Loss Current: 8.1271, Validation Loss AVG: 8.1271, lr: 0.001
Epoch [20/80], Training Loss: 3.3891, Validation Loss Current: 5.7087, Validation Loss AVG: 5.7087, lr: 0.001
Epoch [21/80], Training Loss: 3.4446, Validation Loss Current: 7.0332, Validation Loss AVG: 7.0332, lr: 0.001
Epoch [22/80], Training Loss: 5.6224, Validation Loss Current: 8.0825, Validation Loss AVG: 8.0825, lr: 0.001
Epoch [23/80], Training Loss: 4.6199, Validation Loss Current: 8.4119, Validation Loss AVG: 8.4119, lr: 0.001
Epoch [24/80], Training Loss: 2.2497, Validation Loss Current: 7.2635, Validation Loss AVG: 7.2635, lr: 0.001
Epoch [25/80], Training Loss: 1.8282, Validation Loss Current: 5.5958, Validation Loss AVG: 5.5958, lr: 0.001
Epoch [26/80], Training Loss: 5.3160, Validation Loss Current: 6.0727, Validation Loss AVG: 6.0727, lr: 0.001
Epoch [27/80], Training Loss: 8.7881, Validation Loss Current: 7.3386, Validation Loss AVG: 7.3386, lr: 0.001
Epoch [28/80], Training Loss: 4.1115, Validation Loss Current: 6.6282, Validation Loss AVG: 6.6282, lr: 0.001
Epoch [29/80], Training Loss: 4.4085, Validation Loss Current: 8.1459, Validation Loss AVG: 8.1459, lr: 0.001
Epoch [30/80], Training Loss: 2.6868, Validation Loss Current: 6.3743, Validation Loss AVG: 6.3743, lr: 0.001
Epoch [31/80], Training Loss: 1.6612, Validation Loss Current: 5.8706, Validation Loss AVG: 5.8706, lr: 0.001
Epoch [32/80], Training Loss: 2.5078, Validation Loss Current: 6.8559, Validation Loss AVG: 6.8559, lr: 0.001
Epoch [33/80], Training Loss: 3.4040, Validation Loss Current: 6.8293, Validation Loss AVG: 6.8293, lr: 0.001
Epoch [34/80], Training Loss: 4.4835, Validation Loss Current: 6.5199, Validation Loss AVG: 6.5199, lr: 0.001
Epoch [35/80], Training Loss: 3.3969, Validation Loss Current: 6.8850, Validation Loss AVG: 6.8850, lr: 0.001
 --- Early Stopped ---
Patch distance: random2 finished training. Best epoch: 5 Best val accuracy: [0.594078947368421, 0.6157894736842104, 0.6371710526315789, 0.7039473684210525, 0.706907894736842, 0.6575657894736843, 0.6299342105263157, 0.5555921052631578, 0.6345394736842105, 0.6578947368421053, 0.6328947368421052, 0.6684210526315789, 0.6138157894736841, 0.6240131578947368, 0.6641447368421052, 0.6509868421052631, 0.4891447368421053, 0.6453947368421054, 0.582236842105263, 0.6595394736842105, 0.6279605263157896, 0.6059210526315789, 0.5605263157894738, 0.6470394736842106, 0.6845394736842105, 0.6605263157894736, 0.5950657894736843, 0.6243421052631579, 0.6180921052631578, 0.6375, 0.6703947368421053, 0.655921052631579, 0.6526315789473685, 0.655921052631579, 0.655921052631579] Best val loss: 4.607793378829956


Current group: random3
Epoch [1/80], Training Loss: 34.2014, Validation Loss Current: 5.9234, Validation Loss AVG: 5.9234, lr: 0.001
Epoch [2/80], Training Loss: 20.2140, Validation Loss Current: 5.6506, Validation Loss AVG: 5.6506, lr: 0.001
Epoch [3/80], Training Loss: 16.6878, Validation Loss Current: 5.4909, Validation Loss AVG: 5.4909, lr: 0.001
Epoch [4/80], Training Loss: 12.4237, Validation Loss Current: 5.7840, Validation Loss AVG: 5.7840, lr: 0.001
Epoch [5/80], Training Loss: 13.2151, Validation Loss Current: 5.6619, Validation Loss AVG: 5.6619, lr: 0.001
Epoch [6/80], Training Loss: 9.0017, Validation Loss Current: 4.9019, Validation Loss AVG: 4.9019, lr: 0.001
Epoch [7/80], Training Loss: 8.2074, Validation Loss Current: 5.0043, Validation Loss AVG: 5.0043, lr: 0.001
Epoch [8/80], Training Loss: 5.3575, Validation Loss Current: 4.5728, Validation Loss AVG: 4.5728, lr: 0.001
Epoch [9/80], Training Loss: 6.6358, Validation Loss Current: 5.1042, Validation Loss AVG: 5.1042, lr: 0.001
Epoch [10/80], Training Loss: 6.6733, Validation Loss Current: 5.5661, Validation Loss AVG: 5.5661, lr: 0.001
Epoch [11/80], Training Loss: 5.0893, Validation Loss Current: 6.0075, Validation Loss AVG: 6.0075, lr: 0.001
Epoch [12/80], Training Loss: 4.5338, Validation Loss Current: 5.9443, Validation Loss AVG: 5.9443, lr: 0.001
Epoch [13/80], Training Loss: 4.5611, Validation Loss Current: 5.0304, Validation Loss AVG: 5.0304, lr: 0.001
Epoch [14/80], Training Loss: 5.7424, Validation Loss Current: 6.0282, Validation Loss AVG: 6.0282, lr: 0.001
Epoch [15/80], Training Loss: 6.2432, Validation Loss Current: 8.0999, Validation Loss AVG: 8.0999, lr: 0.001
Epoch [16/80], Training Loss: 6.7673, Validation Loss Current: 5.5999, Validation Loss AVG: 5.5999, lr: 0.001
Epoch [17/80], Training Loss: 4.8888, Validation Loss Current: 7.4451, Validation Loss AVG: 7.4451, lr: 0.001
Epoch [18/80], Training Loss: 7.0809, Validation Loss Current: 7.0879, Validation Loss AVG: 7.0879, lr: 0.001
Epoch [19/80], Training Loss: 9.2474, Validation Loss Current: 13.3874, Validation Loss AVG: 13.3874, lr: 0.001
Epoch [20/80], Training Loss: 9.2015, Validation Loss Current: 7.7178, Validation Loss AVG: 7.7178, lr: 0.001
Epoch [21/80], Training Loss: 4.5435, Validation Loss Current: 6.0125, Validation Loss AVG: 6.0125, lr: 0.001
Epoch [22/80], Training Loss: 4.2275, Validation Loss Current: 6.6673, Validation Loss AVG: 6.6673, lr: 0.001
Epoch [23/80], Training Loss: 6.8382, Validation Loss Current: 8.2638, Validation Loss AVG: 8.2638, lr: 0.001
Epoch [24/80], Training Loss: 3.8108, Validation Loss Current: 6.2381, Validation Loss AVG: 6.2381, lr: 0.001
Epoch [25/80], Training Loss: 3.1293, Validation Loss Current: 5.9083, Validation Loss AVG: 5.9083, lr: 0.001
Epoch [26/80], Training Loss: 3.0910, Validation Loss Current: 7.6456, Validation Loss AVG: 7.6456, lr: 0.001
Epoch [27/80], Training Loss: 6.2470, Validation Loss Current: 7.4640, Validation Loss AVG: 7.4640, lr: 0.001
Epoch [28/80], Training Loss: 4.1215, Validation Loss Current: 6.5331, Validation Loss AVG: 6.5331, lr: 0.001
Epoch [29/80], Training Loss: 4.5528, Validation Loss Current: 7.5367, Validation Loss AVG: 7.5367, lr: 0.001
Epoch [30/80], Training Loss: 3.0962, Validation Loss Current: 6.6341, Validation Loss AVG: 6.6341, lr: 0.001
Epoch [31/80], Training Loss: 3.4018, Validation Loss Current: 6.3264, Validation Loss AVG: 6.3264, lr: 0.001
Epoch [32/80], Training Loss: 3.5989, Validation Loss Current: 9.1059, Validation Loss AVG: 9.1059, lr: 0.001
Epoch [33/80], Training Loss: 10.1649, Validation Loss Current: 7.3925, Validation Loss AVG: 7.3925, lr: 0.001
Epoch [34/80], Training Loss: 7.3462, Validation Loss Current: 6.4274, Validation Loss AVG: 6.4274, lr: 0.001
Epoch [35/80], Training Loss: 3.5476, Validation Loss Current: 8.2702, Validation Loss AVG: 8.2702, lr: 0.001
Epoch [36/80], Training Loss: 2.0632, Validation Loss Current: 6.4403, Validation Loss AVG: 6.4403, lr: 0.001
Epoch [37/80], Training Loss: 3.2026, Validation Loss Current: 6.2565, Validation Loss AVG: 6.2565, lr: 0.001
Epoch [38/80], Training Loss: 4.6977, Validation Loss Current: 7.4096, Validation Loss AVG: 7.4096, lr: 0.001
 --- Early Stopped ---
Patch distance: random3 finished training. Best epoch: 8 Best val accuracy: [0.6470394736842107, 0.6592105263157894, 0.6657894736842106, 0.6690789473684211, 0.6746710526315789, 0.6855263157894737, 0.7065789473684211, 0.7220394736842104, 0.7082236842105264, 0.69375, 0.6700657894736841, 0.6743421052631579, 0.7082236842105263, 0.6621710526315789, 0.5976973684210527, 0.6822368421052631, 0.631578947368421, 0.6292763157894737, 0.524671052631579, 0.5805921052631579, 0.66875, 0.6460526315789474, 0.6322368421052632, 0.6769736842105263, 0.6786184210526315, 0.6190789473684211, 0.6203947368421053, 0.6726973684210525, 0.6322368421052631, 0.6585526315789474, 0.6934210526315789, 0.58125, 0.6292763157894737, 0.6723684210526316, 0.59375, 0.6671052631578948, 0.6815789473684211, 0.6325657894736842] Best val loss: 4.572800254821777


Current group: random4
Epoch [1/80], Training Loss: 36.9526, Validation Loss Current: 5.7732, Validation Loss AVG: 5.7732, lr: 0.001
Epoch [2/80], Training Loss: 24.5951, Validation Loss Current: 5.0962, Validation Loss AVG: 5.0962, lr: 0.001
Epoch [3/80], Training Loss: 17.0067, Validation Loss Current: 4.7284, Validation Loss AVG: 4.7284, lr: 0.001
Epoch [4/80], Training Loss: 12.6630, Validation Loss Current: 5.1743, Validation Loss AVG: 5.1743, lr: 0.001
Epoch [5/80], Training Loss: 13.2034, Validation Loss Current: 4.8934, Validation Loss AVG: 4.8934, lr: 0.001
Epoch [6/80], Training Loss: 8.3418, Validation Loss Current: 5.0509, Validation Loss AVG: 5.0509, lr: 0.001
Epoch [7/80], Training Loss: 7.1686, Validation Loss Current: 4.0235, Validation Loss AVG: 4.0235, lr: 0.001
Epoch [8/80], Training Loss: 9.2228, Validation Loss Current: 4.2910, Validation Loss AVG: 4.2910, lr: 0.001
Epoch [9/80], Training Loss: 7.3714, Validation Loss Current: 6.1280, Validation Loss AVG: 6.1280, lr: 0.001
Epoch [10/80], Training Loss: 7.8789, Validation Loss Current: 4.5238, Validation Loss AVG: 4.5238, lr: 0.001
Epoch [11/80], Training Loss: 8.2662, Validation Loss Current: 5.1032, Validation Loss AVG: 5.1032, lr: 0.001
Epoch [12/80], Training Loss: 5.5357, Validation Loss Current: 4.8321, Validation Loss AVG: 4.8321, lr: 0.001
Epoch [13/80], Training Loss: 4.5869, Validation Loss Current: 4.8236, Validation Loss AVG: 4.8236, lr: 0.001
Epoch [14/80], Training Loss: 2.8426, Validation Loss Current: 4.3248, Validation Loss AVG: 4.3248, lr: 0.001
Epoch [15/80], Training Loss: 2.7763, Validation Loss Current: 5.5228, Validation Loss AVG: 5.5228, lr: 0.001
Epoch [16/80], Training Loss: 2.6210, Validation Loss Current: 4.7160, Validation Loss AVG: 4.7160, lr: 0.001
Epoch [17/80], Training Loss: 4.4061, Validation Loss Current: 4.9812, Validation Loss AVG: 4.9812, lr: 0.001
Epoch [18/80], Training Loss: 7.5770, Validation Loss Current: 7.1301, Validation Loss AVG: 7.1301, lr: 0.001
Epoch [19/80], Training Loss: 5.4065, Validation Loss Current: 5.9069, Validation Loss AVG: 5.9069, lr: 0.001
Epoch [20/80], Training Loss: 7.4768, Validation Loss Current: 6.0554, Validation Loss AVG: 6.0554, lr: 0.001
Epoch [21/80], Training Loss: 6.4689, Validation Loss Current: 6.2398, Validation Loss AVG: 6.2398, lr: 0.001
Epoch [22/80], Training Loss: 7.8084, Validation Loss Current: 9.5934, Validation Loss AVG: 9.5934, lr: 0.001
Epoch [23/80], Training Loss: 4.7165, Validation Loss Current: 5.4804, Validation Loss AVG: 5.4804, lr: 0.001
Epoch [24/80], Training Loss: 5.6205, Validation Loss Current: 5.0524, Validation Loss AVG: 5.0524, lr: 0.001
Epoch [25/80], Training Loss: 3.3245, Validation Loss Current: 6.2184, Validation Loss AVG: 6.2184, lr: 0.001
Epoch [26/80], Training Loss: 5.6828, Validation Loss Current: 5.9411, Validation Loss AVG: 5.9411, lr: 0.001
Epoch [27/80], Training Loss: 2.9334, Validation Loss Current: 6.0059, Validation Loss AVG: 6.0059, lr: 0.001
Epoch [28/80], Training Loss: 4.9936, Validation Loss Current: 7.6900, Validation Loss AVG: 7.6900, lr: 0.001
Epoch [29/80], Training Loss: 4.5882, Validation Loss Current: 5.8587, Validation Loss AVG: 5.8587, lr: 0.001
Epoch [30/80], Training Loss: 1.5682, Validation Loss Current: 5.4218, Validation Loss AVG: 5.4218, lr: 0.001
Epoch [31/80], Training Loss: 1.5847, Validation Loss Current: 5.1281, Validation Loss AVG: 5.1281, lr: 0.001
Epoch [32/80], Training Loss: 2.4712, Validation Loss Current: 6.0290, Validation Loss AVG: 6.0290, lr: 0.001
Epoch [33/80], Training Loss: 3.7503, Validation Loss Current: 6.5214, Validation Loss AVG: 6.5214, lr: 0.001
Epoch [34/80], Training Loss: 6.1931, Validation Loss Current: 6.3516, Validation Loss AVG: 6.3516, lr: 0.001
Epoch [35/80], Training Loss: 5.1158, Validation Loss Current: 8.5279, Validation Loss AVG: 8.5279, lr: 0.001
Epoch [36/80], Training Loss: 2.9263, Validation Loss Current: 5.9030, Validation Loss AVG: 5.9030, lr: 0.001
Epoch [37/80], Training Loss: 1.8829, Validation Loss Current: 5.7938, Validation Loss AVG: 5.7938, lr: 0.001
 --- Early Stopped ---
Patch distance: random4 finished training. Best epoch: 7 Best val accuracy: [0.6740131578947368, 0.6888157894736842, 0.6934210526315789, 0.6835526315789474, 0.7009868421052631, 0.6996710526315789, 0.7549342105263158, 0.7421052631578947, 0.6493421052631579, 0.7269736842105263, 0.6917763157894736, 0.7223684210526315, 0.7282894736842105, 0.7536184210526315, 0.7092105263157895, 0.7335526315789475, 0.7151315789473685, 0.6654605263157894, 0.6927631578947369, 0.6703947368421053, 0.687171052631579, 0.5496710526315789, 0.7108552631578947, 0.7095394736842104, 0.675657894736842, 0.6957236842105263, 0.7042763157894737, 0.6424342105263159, 0.7138157894736843, 0.7151315789473685, 0.730592105263158, 0.7111842105263158, 0.6947368421052632, 0.6983552631578946, 0.6177631578947368, 0.6953947368421053, 0.7098684210526317] Best val loss: 4.023470318317413


-------------------- All training done --------------------


 --- Evaluating ---
Fold: 0
---- Testing model trained on sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.44461420932009166
Test set distance: 0.8 Top 1 Accuracy: 0.5408708938120703
Test set distance: 0.4 Top 1 Accuracy: 0.4805194805194805
Test set distance: 0.6 Top 1 Accuracy: 0.5278838808250573
Test set distance: 1 Top 1 Accuracy: 0.5301757066462949
Fold: 1
---- Testing model trained on sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4721161191749427
Test set distance: 0.8 Top 1 Accuracy: 0.5607333842627961
Test set distance: 0.4 Top 1 Accuracy: 0.48892284186401835
Test set distance: 0.6 Top 1 Accuracy: 0.5454545454545454
Test set distance: 1 Top 1 Accuracy: 0.5599694423223835
Fold: 2
---- Testing model trained on sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.46524064171123
Test set distance: 0.8 Top 1 Accuracy: 0.6027501909854851
Test set distance: 0.4 Top 1 Accuracy: 0.5126050420168067
Test set distance: 0.6 Top 1 Accuracy: 0.5653170359052712
Test set distance: 1 Top 1 Accuracy: 0.5813598166539343
Fold: 3
---- Testing model trained on sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4079449961802903
Test set distance: 0.8 Top 1 Accuracy: 0.5561497326203209
Test set distance: 0.4 Top 1 Accuracy: 0.47135217723453016
Test set distance: 0.6 Top 1 Accuracy: 0.5255920550038197
Test set distance: 1 Top 1 Accuracy: 0.5592055003819709
Fold: 4
---- Testing model trained on sequence: ['random0', 'random1', 'random2', 'random3', 'random4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4377387318563789
Test set distance: 0.8 Top 1 Accuracy: 0.5928189457601223
Test set distance: 0.4 Top 1 Accuracy: 0.5171886936592819
Test set distance: 0.6 Top 1 Accuracy: 0.5584415584415584
Test set distance: 1 Top 1 Accuracy: 0.5882352941176471
------------------------------ End ------------------------------


 # ------------------ Running pipeline on llo color run_0 -------------------- #
cuda:0
 ------ Pipeline with following parameters ------
training_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/train
val_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/val
test_root_path :  /u/erdos/students/xcui32/cnslab/datasets/VOC2012/VOC2012_filtered/test
dataset_name :  VOC
target_distances :  [0.2, 0.8, 0.4, 0.6, 1]
training_mode :  llo
n_distances :  None
training_size :  None
background :  color
size :  (150, 150)
cls_to_use :  ['aeroplane', 'bicycle', 'bird', 'boat', 'car', 'cat', 'train', 'tvmonitor']
batch_size :  128
val_size :  1
epochs :  400
resize_method :  long
n_folds :  5
num_workers :  16
model_name :  resnet18
device :  cuda:0
random_seed :  40
result_dirpath :  /u/erdos/students/xcui32/cnslab/results/VOC8R18BlackCUR
save_checkpoints :  False
save_progress_checkpoints :  False
verbose :  0
 ---  Loading datasets ---
 ---  Running  ---
Parameters: --------------------
{'scheduler_kwargs': {'mode': 'min', 'factor': 0.1, 'patience': 5}, 'optim_kwargs': {'lr': 0.001, 'momentum': 0.9}, 'max_norm': None, 'val_target': 'current', 'patience': 30, 'early_stopping': True, 'scheduler_object': None, 'optimizer_object': <class 'torch.optim.sgd.SGD'>, 'criterion_object': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'self': <pipelineCV2.RunModel object at 0x2aabfd50dfd0>}
--------------------
Fold: 0
----- Training resnet18 with sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] -----
Current group: llo_0.2_random0
Epoch [1/80], Training Loss: 40.8843, Validation Loss Current: 10.0472, Validation Loss AVG: 10.0472, lr: 0.001
Epoch [2/80], Training Loss: 39.1910, Validation Loss Current: 9.7152, Validation Loss AVG: 9.7152, lr: 0.001
Epoch [3/80], Training Loss: 38.6638, Validation Loss Current: 9.6086, Validation Loss AVG: 9.6086, lr: 0.001
Epoch [4/80], Training Loss: 37.8771, Validation Loss Current: 9.3709, Validation Loss AVG: 9.3709, lr: 0.001
Epoch [5/80], Training Loss: 36.9992, Validation Loss Current: 9.2029, Validation Loss AVG: 9.2029, lr: 0.001
Epoch [6/80], Training Loss: 35.5432, Validation Loss Current: 9.0101, Validation Loss AVG: 9.0101, lr: 0.001
Epoch [7/80], Training Loss: 35.1068, Validation Loss Current: 8.8394, Validation Loss AVG: 8.8394, lr: 0.001
Epoch [8/80], Training Loss: 34.2453, Validation Loss Current: 8.7345, Validation Loss AVG: 8.7345, lr: 0.001
Epoch [9/80], Training Loss: 32.6798, Validation Loss Current: 8.5054, Validation Loss AVG: 8.5054, lr: 0.001
Epoch [10/80], Training Loss: 31.9484, Validation Loss Current: 8.5342, Validation Loss AVG: 8.5342, lr: 0.001
Epoch [11/80], Training Loss: 31.5065, Validation Loss Current: 8.3430, Validation Loss AVG: 8.3430, lr: 0.001
Epoch [12/80], Training Loss: 29.4473, Validation Loss Current: 8.3732, Validation Loss AVG: 8.3732, lr: 0.001
Epoch [13/80], Training Loss: 29.1867, Validation Loss Current: 8.1974, Validation Loss AVG: 8.1974, lr: 0.001
Epoch [14/80], Training Loss: 28.7422, Validation Loss Current: 8.1980, Validation Loss AVG: 8.1980, lr: 0.001
Epoch [15/80], Training Loss: 28.5576, Validation Loss Current: 7.8945, Validation Loss AVG: 7.8945, lr: 0.001
Epoch [16/80], Training Loss: 28.2584, Validation Loss Current: 8.1504, Validation Loss AVG: 8.1504, lr: 0.001
Epoch [17/80], Training Loss: 27.0641, Validation Loss Current: 7.5826, Validation Loss AVG: 7.5826, lr: 0.001
Epoch [18/80], Training Loss: 25.8862, Validation Loss Current: 7.7414, Validation Loss AVG: 7.7414, lr: 0.001
Epoch [19/80], Training Loss: 24.9428, Validation Loss Current: 7.5618, Validation Loss AVG: 7.5618, lr: 0.001
Epoch [20/80], Training Loss: 24.0231, Validation Loss Current: 7.7240, Validation Loss AVG: 7.7240, lr: 0.001
Epoch [21/80], Training Loss: 22.9486, Validation Loss Current: 7.3314, Validation Loss AVG: 7.3314, lr: 0.001
Epoch [22/80], Training Loss: 23.3151, Validation Loss Current: 8.0915, Validation Loss AVG: 8.0915, lr: 0.001
Epoch [23/80], Training Loss: 23.5992, Validation Loss Current: 7.8234, Validation Loss AVG: 7.8234, lr: 0.001
Epoch [24/80], Training Loss: 21.4539, Validation Loss Current: 7.7399, Validation Loss AVG: 7.7399, lr: 0.001
Epoch [25/80], Training Loss: 21.2967, Validation Loss Current: 7.1179, Validation Loss AVG: 7.1179, lr: 0.001
Epoch [26/80], Training Loss: 19.3292, Validation Loss Current: 7.1845, Validation Loss AVG: 7.1845, lr: 0.001
Epoch [27/80], Training Loss: 20.1574, Validation Loss Current: 8.0020, Validation Loss AVG: 8.0020, lr: 0.001
Epoch [28/80], Training Loss: 19.7172, Validation Loss Current: 7.4260, Validation Loss AVG: 7.4260, lr: 0.001
Epoch [29/80], Training Loss: 18.6279, Validation Loss Current: 7.0190, Validation Loss AVG: 7.0190, lr: 0.001
Epoch [30/80], Training Loss: 17.5071, Validation Loss Current: 7.6564, Validation Loss AVG: 7.6564, lr: 0.001
Epoch [31/80], Training Loss: 15.9032, Validation Loss Current: 6.6397, Validation Loss AVG: 6.6397, lr: 0.001
Epoch [32/80], Training Loss: 15.3527, Validation Loss Current: 6.9031, Validation Loss AVG: 6.9031, lr: 0.001
Epoch [33/80], Training Loss: 17.0089, Validation Loss Current: 8.1280, Validation Loss AVG: 8.1280, lr: 0.001
Epoch [34/80], Training Loss: 17.1421, Validation Loss Current: 7.7723, Validation Loss AVG: 7.7723, lr: 0.001
Epoch [35/80], Training Loss: 14.0599, Validation Loss Current: 6.7330, Validation Loss AVG: 6.7330, lr: 0.001
Epoch [36/80], Training Loss: 12.5832, Validation Loss Current: 6.7252, Validation Loss AVG: 6.7252, lr: 0.001
Epoch [37/80], Training Loss: 13.5258, Validation Loss Current: 6.8015, Validation Loss AVG: 6.8015, lr: 0.001
Epoch [38/80], Training Loss: 11.8065, Validation Loss Current: 7.3866, Validation Loss AVG: 7.3866, lr: 0.001
Epoch [39/80], Training Loss: 11.4218, Validation Loss Current: 6.6504, Validation Loss AVG: 6.6504, lr: 0.001
Epoch [40/80], Training Loss: 9.9772, Validation Loss Current: 7.3216, Validation Loss AVG: 7.3216, lr: 0.001
Epoch [41/80], Training Loss: 10.0798, Validation Loss Current: 7.6285, Validation Loss AVG: 7.6285, lr: 0.001
Epoch [42/80], Training Loss: 9.0249, Validation Loss Current: 8.5541, Validation Loss AVG: 8.5541, lr: 0.001
Epoch [43/80], Training Loss: 10.2599, Validation Loss Current: 6.8524, Validation Loss AVG: 6.8524, lr: 0.001
Epoch [44/80], Training Loss: 7.8066, Validation Loss Current: 7.2959, Validation Loss AVG: 7.2959, lr: 0.001
Epoch [45/80], Training Loss: 7.1585, Validation Loss Current: 7.2997, Validation Loss AVG: 7.2997, lr: 0.001
Epoch [46/80], Training Loss: 7.7411, Validation Loss Current: 7.7158, Validation Loss AVG: 7.7158, lr: 0.001
Epoch [47/80], Training Loss: 7.8698, Validation Loss Current: 7.5685, Validation Loss AVG: 7.5685, lr: 0.001
Epoch [48/80], Training Loss: 5.4450, Validation Loss Current: 6.7509, Validation Loss AVG: 6.7509, lr: 0.001
Epoch [49/80], Training Loss: 6.2374, Validation Loss Current: 8.0375, Validation Loss AVG: 8.0375, lr: 0.001
Epoch [50/80], Training Loss: 11.1091, Validation Loss Current: 7.6781, Validation Loss AVG: 7.6781, lr: 0.001
Epoch [51/80], Training Loss: 9.1320, Validation Loss Current: 7.6122, Validation Loss AVG: 7.6122, lr: 0.001
Epoch [52/80], Training Loss: 8.0904, Validation Loss Current: 9.0085, Validation Loss AVG: 9.0085, lr: 0.001
Epoch [53/80], Training Loss: 8.7273, Validation Loss Current: 7.8400, Validation Loss AVG: 7.8400, lr: 0.001
Epoch [54/80], Training Loss: 7.0623, Validation Loss Current: 7.6688, Validation Loss AVG: 7.6688, lr: 0.001
Epoch [55/80], Training Loss: 4.7523, Validation Loss Current: 7.3073, Validation Loss AVG: 7.3073, lr: 0.001
Epoch [56/80], Training Loss: 6.5954, Validation Loss Current: 7.6283, Validation Loss AVG: 7.6283, lr: 0.001
Epoch [57/80], Training Loss: 4.1204, Validation Loss Current: 7.2356, Validation Loss AVG: 7.2356, lr: 0.001
Epoch [58/80], Training Loss: 3.2318, Validation Loss Current: 7.6210, Validation Loss AVG: 7.6210, lr: 0.001
Epoch [59/80], Training Loss: 3.0109, Validation Loss Current: 7.6142, Validation Loss AVG: 7.6142, lr: 0.001
Epoch [60/80], Training Loss: 6.2973, Validation Loss Current: 8.7139, Validation Loss AVG: 8.7139, lr: 0.001
Epoch [61/80], Training Loss: 6.8522, Validation Loss Current: 8.8786, Validation Loss AVG: 8.8786, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random0 finished training. Best epoch: 31 Best val accuracy: [0.23289473684210527, 0.27171052631578946, 0.2763157894736842, 0.29539473684210527, 0.3078947368421053, 0.33092105263157895, 0.34967105263157894, 0.3559210526315789, 0.3851973684210526, 0.3730263157894737, 0.3819078947368421, 0.40592105263157896, 0.4078947368421052, 0.39868421052631575, 0.42927631578947373, 0.40625, 0.4621710526315789, 0.43980263157894733, 0.44506578947368425, 0.4569078947368421, 0.475, 0.44868421052631574, 0.44703947368421054, 0.4582236842105263, 0.4789473684210527, 0.4743421052631579, 0.4286184210526316, 0.4848684210526316, 0.5036184210526315, 0.47467105263157894, 0.5266447368421053, 0.5240131578947368, 0.4736842105263158, 0.46118421052631575, 0.5401315789473684, 0.537828947368421, 0.5328947368421053, 0.5026315789473683, 0.5582236842105263, 0.5398026315789474, 0.5049342105263157, 0.5039473684210527, 0.550328947368421, 0.5490131578947369, 0.5223684210526316, 0.5368421052631579, 0.5302631578947368, 0.5730263157894737, 0.5302631578947369, 0.5319078947368421, 0.5328947368421052, 0.5253289473684211, 0.5411184210526316, 0.5434210526315789, 0.5476973684210527, 0.5585526315789474, 0.5493421052631579, 0.5759868421052632, 0.5503289473684211, 0.5322368421052632, 0.5088815789473684] Best val loss: 6.639747679233551


Current group: llo_0.2_random1
Epoch [1/80], Training Loss: 28.4843, Validation Loss Current: 8.4771, Validation Loss AVG: 8.4771, lr: 0.001
Epoch [2/80], Training Loss: 23.4321, Validation Loss Current: 7.7979, Validation Loss AVG: 7.7979, lr: 0.001
Epoch [3/80], Training Loss: 21.5832, Validation Loss Current: 8.5238, Validation Loss AVG: 8.5238, lr: 0.001
Epoch [4/80], Training Loss: 17.8913, Validation Loss Current: 9.5502, Validation Loss AVG: 9.5502, lr: 0.001
Epoch [5/80], Training Loss: 19.3904, Validation Loss Current: 7.2284, Validation Loss AVG: 7.2284, lr: 0.001
Epoch [6/80], Training Loss: 13.4870, Validation Loss Current: 6.7860, Validation Loss AVG: 6.7860, lr: 0.001
Epoch [7/80], Training Loss: 10.2524, Validation Loss Current: 6.3728, Validation Loss AVG: 6.3728, lr: 0.001
Epoch [8/80], Training Loss: 9.5110, Validation Loss Current: 6.4175, Validation Loss AVG: 6.4175, lr: 0.001
Epoch [9/80], Training Loss: 10.1590, Validation Loss Current: 6.5315, Validation Loss AVG: 6.5315, lr: 0.001
Epoch [10/80], Training Loss: 9.2622, Validation Loss Current: 8.6588, Validation Loss AVG: 8.6588, lr: 0.001
Epoch [11/80], Training Loss: 9.0007, Validation Loss Current: 7.2924, Validation Loss AVG: 7.2924, lr: 0.001
Epoch [12/80], Training Loss: 5.4786, Validation Loss Current: 5.7116, Validation Loss AVG: 5.7116, lr: 0.001
Epoch [13/80], Training Loss: 5.1674, Validation Loss Current: 6.2055, Validation Loss AVG: 6.2055, lr: 0.001
Epoch [14/80], Training Loss: 8.4407, Validation Loss Current: 8.5095, Validation Loss AVG: 8.5095, lr: 0.001
Epoch [15/80], Training Loss: 9.4384, Validation Loss Current: 8.2229, Validation Loss AVG: 8.2229, lr: 0.001
Epoch [16/80], Training Loss: 8.6196, Validation Loss Current: 7.7609, Validation Loss AVG: 7.7609, lr: 0.001
Epoch [17/80], Training Loss: 6.9731, Validation Loss Current: 7.8980, Validation Loss AVG: 7.8980, lr: 0.001
Epoch [18/80], Training Loss: 5.4272, Validation Loss Current: 7.2956, Validation Loss AVG: 7.2956, lr: 0.001
Epoch [19/80], Training Loss: 8.1080, Validation Loss Current: 9.0414, Validation Loss AVG: 9.0414, lr: 0.001
Epoch [20/80], Training Loss: 5.2174, Validation Loss Current: 8.2756, Validation Loss AVG: 8.2756, lr: 0.001
Epoch [21/80], Training Loss: 5.8422, Validation Loss Current: 7.3787, Validation Loss AVG: 7.3787, lr: 0.001
Epoch [22/80], Training Loss: 5.8985, Validation Loss Current: 7.4325, Validation Loss AVG: 7.4325, lr: 0.001
Epoch [23/80], Training Loss: 3.9449, Validation Loss Current: 7.0211, Validation Loss AVG: 7.0211, lr: 0.001
Epoch [24/80], Training Loss: 3.0817, Validation Loss Current: 8.0731, Validation Loss AVG: 8.0731, lr: 0.001
Epoch [25/80], Training Loss: 9.3353, Validation Loss Current: 9.0692, Validation Loss AVG: 9.0692, lr: 0.001
Epoch [26/80], Training Loss: 7.5347, Validation Loss Current: 7.7076, Validation Loss AVG: 7.7076, lr: 0.001
Epoch [27/80], Training Loss: 6.8653, Validation Loss Current: 7.8033, Validation Loss AVG: 7.8033, lr: 0.001
Epoch [28/80], Training Loss: 3.8652, Validation Loss Current: 7.1551, Validation Loss AVG: 7.1551, lr: 0.001
Epoch [29/80], Training Loss: 4.7952, Validation Loss Current: 8.2156, Validation Loss AVG: 8.2156, lr: 0.001
Epoch [30/80], Training Loss: 5.5860, Validation Loss Current: 8.2858, Validation Loss AVG: 8.2858, lr: 0.001
Epoch [31/80], Training Loss: 5.8152, Validation Loss Current: 8.3847, Validation Loss AVG: 8.3847, lr: 0.001
Epoch [32/80], Training Loss: 3.7998, Validation Loss Current: 8.1781, Validation Loss AVG: 8.1781, lr: 0.001
Epoch [33/80], Training Loss: 2.8231, Validation Loss Current: 8.3081, Validation Loss AVG: 8.3081, lr: 0.001
Epoch [34/80], Training Loss: 2.4390, Validation Loss Current: 8.8602, Validation Loss AVG: 8.8602, lr: 0.001
Epoch [35/80], Training Loss: 4.6085, Validation Loss Current: 8.6255, Validation Loss AVG: 8.6255, lr: 0.001
Epoch [36/80], Training Loss: 8.7493, Validation Loss Current: 8.3779, Validation Loss AVG: 8.3779, lr: 0.001
Epoch [37/80], Training Loss: 5.0572, Validation Loss Current: 7.9892, Validation Loss AVG: 7.9892, lr: 0.001
Epoch [38/80], Training Loss: 2.1251, Validation Loss Current: 7.5638, Validation Loss AVG: 7.5638, lr: 0.001
Epoch [39/80], Training Loss: 3.1725, Validation Loss Current: 11.0610, Validation Loss AVG: 11.0610, lr: 0.001
Epoch [40/80], Training Loss: 8.7622, Validation Loss Current: 9.9819, Validation Loss AVG: 9.9819, lr: 0.001
Epoch [41/80], Training Loss: 3.0001, Validation Loss Current: 7.3795, Validation Loss AVG: 7.3795, lr: 0.001
Epoch [42/80], Training Loss: 3.3274, Validation Loss Current: 7.7694, Validation Loss AVG: 7.7694, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random1 finished training. Best epoch: 12 Best val accuracy: [0.46842105263157896, 0.5210526315789473, 0.5078947368421053, 0.4638157894736842, 0.5157894736842106, 0.5523026315789473, 0.5848684210526316, 0.60625, 0.5953947368421052, 0.4953947368421052, 0.5184210526315789, 0.6371710526315789, 0.6171052631578947, 0.5230263157894737, 0.5332236842105263, 0.5828947368421054, 0.5444078947368421, 0.5802631578947368, 0.5332236842105262, 0.5578947368421053, 0.5723684210526316, 0.5842105263157894, 0.600328947368421, 0.5601973684210526, 0.5391447368421053, 0.5763157894736842, 0.569078947368421, 0.5819078947368421, 0.58125, 0.5769736842105264, 0.575657894736842, 0.5667763157894737, 0.5825657894736842, 0.5457236842105264, 0.5815789473684211, 0.5615131578947368, 0.5674342105263157, 0.5822368421052632, 0.5480263157894736, 0.47269736842105264, 0.5891447368421052, 0.5842105263157895] Best val loss: 5.711608862876892


Current group: llo_0.2_random2
Epoch [1/80], Training Loss: 29.9431, Validation Loss Current: 10.8991, Validation Loss AVG: 10.8991, lr: 0.001
Epoch [2/80], Training Loss: 27.1666, Validation Loss Current: 9.6580, Validation Loss AVG: 9.6580, lr: 0.001
Epoch [3/80], Training Loss: 17.1321, Validation Loss Current: 11.5018, Validation Loss AVG: 11.5018, lr: 0.001
Epoch [4/80], Training Loss: 16.9468, Validation Loss Current: 7.3441, Validation Loss AVG: 7.3441, lr: 0.001
Epoch [5/80], Training Loss: 11.1677, Validation Loss Current: 5.9349, Validation Loss AVG: 5.9349, lr: 0.001
Epoch [6/80], Training Loss: 9.0013, Validation Loss Current: 6.3429, Validation Loss AVG: 6.3429, lr: 0.001
Epoch [7/80], Training Loss: 6.8190, Validation Loss Current: 5.9577, Validation Loss AVG: 5.9577, lr: 0.001
Epoch [8/80], Training Loss: 6.4625, Validation Loss Current: 6.1653, Validation Loss AVG: 6.1653, lr: 0.001
Epoch [9/80], Training Loss: 11.7435, Validation Loss Current: 6.2451, Validation Loss AVG: 6.2451, lr: 0.001
Epoch [10/80], Training Loss: 8.8058, Validation Loss Current: 7.8665, Validation Loss AVG: 7.8665, lr: 0.001
Epoch [11/80], Training Loss: 7.6560, Validation Loss Current: 6.4693, Validation Loss AVG: 6.4693, lr: 0.001
Epoch [12/80], Training Loss: 5.4563, Validation Loss Current: 6.6117, Validation Loss AVG: 6.6117, lr: 0.001
Epoch [13/80], Training Loss: 7.4924, Validation Loss Current: 6.9334, Validation Loss AVG: 6.9334, lr: 0.001
Epoch [14/80], Training Loss: 5.0037, Validation Loss Current: 6.0214, Validation Loss AVG: 6.0214, lr: 0.001
Epoch [15/80], Training Loss: 3.3026, Validation Loss Current: 6.2723, Validation Loss AVG: 6.2723, lr: 0.001
Epoch [16/80], Training Loss: 3.4280, Validation Loss Current: 6.4098, Validation Loss AVG: 6.4098, lr: 0.001
Epoch [17/80], Training Loss: 6.9659, Validation Loss Current: 6.8163, Validation Loss AVG: 6.8163, lr: 0.001
Epoch [18/80], Training Loss: 3.3501, Validation Loss Current: 6.7446, Validation Loss AVG: 6.7446, lr: 0.001
Epoch [19/80], Training Loss: 2.5119, Validation Loss Current: 7.0153, Validation Loss AVG: 7.0153, lr: 0.001
Epoch [20/80], Training Loss: 4.8862, Validation Loss Current: 7.6338, Validation Loss AVG: 7.6338, lr: 0.001
Epoch [21/80], Training Loss: 3.8872, Validation Loss Current: 7.6218, Validation Loss AVG: 7.6218, lr: 0.001
Epoch [22/80], Training Loss: 2.9410, Validation Loss Current: 6.4020, Validation Loss AVG: 6.4020, lr: 0.001
Epoch [23/80], Training Loss: 2.7087, Validation Loss Current: 8.0861, Validation Loss AVG: 8.0861, lr: 0.001
Epoch [24/80], Training Loss: 3.1191, Validation Loss Current: 7.2303, Validation Loss AVG: 7.2303, lr: 0.001
Epoch [25/80], Training Loss: 3.6553, Validation Loss Current: 7.1182, Validation Loss AVG: 7.1182, lr: 0.001
Epoch [26/80], Training Loss: 1.4579, Validation Loss Current: 6.5395, Validation Loss AVG: 6.5395, lr: 0.001
Epoch [27/80], Training Loss: 4.6194, Validation Loss Current: 6.1851, Validation Loss AVG: 6.1851, lr: 0.001
Epoch [28/80], Training Loss: 4.7205, Validation Loss Current: 7.3397, Validation Loss AVG: 7.3397, lr: 0.001
Epoch [29/80], Training Loss: 6.0684, Validation Loss Current: 8.3918, Validation Loss AVG: 8.3918, lr: 0.001
Epoch [30/80], Training Loss: 10.3727, Validation Loss Current: 9.2710, Validation Loss AVG: 9.2710, lr: 0.001
Epoch [31/80], Training Loss: 5.1983, Validation Loss Current: 7.2888, Validation Loss AVG: 7.2888, lr: 0.001
Epoch [32/80], Training Loss: 6.8108, Validation Loss Current: 7.4867, Validation Loss AVG: 7.4867, lr: 0.001
Epoch [33/80], Training Loss: 2.4076, Validation Loss Current: 7.0956, Validation Loss AVG: 7.0956, lr: 0.001
Epoch [34/80], Training Loss: 1.3500, Validation Loss Current: 6.6697, Validation Loss AVG: 6.6697, lr: 0.001
Epoch [35/80], Training Loss: 2.2307, Validation Loss Current: 6.4194, Validation Loss AVG: 6.4194, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random2 finished training. Best epoch: 5 Best val accuracy: [0.48717105263157895, 0.4838815789473684, 0.42993421052631575, 0.5598684210526316, 0.6197368421052631, 0.6157894736842106, 0.6180921052631579, 0.6197368421052631, 0.6200657894736843, 0.5394736842105263, 0.6282894736842105, 0.6171052631578947, 0.6157894736842106, 0.6299342105263157, 0.6437499999999999, 0.6266447368421052, 0.6223684210526316, 0.6240131578947368, 0.6375, 0.5980263157894736, 0.6236842105263157, 0.6470394736842104, 0.5842105263157895, 0.6167763157894737, 0.6269736842105262, 0.6506578947368421, 0.6575657894736843, 0.6121710526315789, 0.5960526315789473, 0.5555921052631578, 0.6032894736842105, 0.5930921052631578, 0.6148026315789474, 0.6513157894736843, 0.6404605263157894] Best val loss: 5.934892678260804


Current group: llo_0.2_random3
Epoch [1/80], Training Loss: 30.2805, Validation Loss Current: 7.3036, Validation Loss AVG: 7.3036, lr: 0.001
Epoch [2/80], Training Loss: 17.6560, Validation Loss Current: 6.3789, Validation Loss AVG: 6.3789, lr: 0.001
Epoch [3/80], Training Loss: 13.1447, Validation Loss Current: 6.0380, Validation Loss AVG: 6.0380, lr: 0.001
Epoch [4/80], Training Loss: 13.4218, Validation Loss Current: 7.3164, Validation Loss AVG: 7.3164, lr: 0.001
Epoch [5/80], Training Loss: 8.9494, Validation Loss Current: 6.2488, Validation Loss AVG: 6.2488, lr: 0.001
Epoch [6/80], Training Loss: 7.9309, Validation Loss Current: 5.5161, Validation Loss AVG: 5.5161, lr: 0.001
Epoch [7/80], Training Loss: 7.7440, Validation Loss Current: 6.9354, Validation Loss AVG: 6.9354, lr: 0.001
Epoch [8/80], Training Loss: 6.2203, Validation Loss Current: 6.6482, Validation Loss AVG: 6.6482, lr: 0.001
Epoch [9/80], Training Loss: 4.3659, Validation Loss Current: 5.8633, Validation Loss AVG: 5.8633, lr: 0.001
Epoch [10/80], Training Loss: 7.9988, Validation Loss Current: 5.7329, Validation Loss AVG: 5.7329, lr: 0.001
Epoch [11/80], Training Loss: 5.3825, Validation Loss Current: 5.7831, Validation Loss AVG: 5.7831, lr: 0.001
Epoch [12/80], Training Loss: 4.8293, Validation Loss Current: 5.7277, Validation Loss AVG: 5.7277, lr: 0.001
Epoch [13/80], Training Loss: 4.3426, Validation Loss Current: 6.5980, Validation Loss AVG: 6.5980, lr: 0.001
Epoch [14/80], Training Loss: 4.5481, Validation Loss Current: 5.9732, Validation Loss AVG: 5.9732, lr: 0.001
Epoch [15/80], Training Loss: 5.6865, Validation Loss Current: 7.5032, Validation Loss AVG: 7.5032, lr: 0.001
Epoch [16/80], Training Loss: 5.5178, Validation Loss Current: 6.5136, Validation Loss AVG: 6.5136, lr: 0.001
Epoch [17/80], Training Loss: 4.4287, Validation Loss Current: 8.1169, Validation Loss AVG: 8.1169, lr: 0.001
Epoch [18/80], Training Loss: 6.7225, Validation Loss Current: 8.4415, Validation Loss AVG: 8.4415, lr: 0.001
Epoch [19/80], Training Loss: 7.0498, Validation Loss Current: 7.3488, Validation Loss AVG: 7.3488, lr: 0.001
Epoch [20/80], Training Loss: 4.8359, Validation Loss Current: 6.7397, Validation Loss AVG: 6.7397, lr: 0.001
Epoch [21/80], Training Loss: 4.6404, Validation Loss Current: 6.3685, Validation Loss AVG: 6.3685, lr: 0.001
Epoch [22/80], Training Loss: 3.9849, Validation Loss Current: 7.8228, Validation Loss AVG: 7.8228, lr: 0.001
Epoch [23/80], Training Loss: 4.0595, Validation Loss Current: 6.9738, Validation Loss AVG: 6.9738, lr: 0.001
Epoch [24/80], Training Loss: 7.6355, Validation Loss Current: 7.7107, Validation Loss AVG: 7.7107, lr: 0.001
Epoch [25/80], Training Loss: 4.2699, Validation Loss Current: 7.2751, Validation Loss AVG: 7.2751, lr: 0.001
Epoch [26/80], Training Loss: 4.4316, Validation Loss Current: 7.3354, Validation Loss AVG: 7.3354, lr: 0.001
Epoch [27/80], Training Loss: 3.2392, Validation Loss Current: 7.0259, Validation Loss AVG: 7.0259, lr: 0.001
Epoch [28/80], Training Loss: 4.5534, Validation Loss Current: 6.3096, Validation Loss AVG: 6.3096, lr: 0.001
Epoch [29/80], Training Loss: 2.0909, Validation Loss Current: 6.7271, Validation Loss AVG: 6.7271, lr: 0.001
Epoch [30/80], Training Loss: 4.9189, Validation Loss Current: 7.8476, Validation Loss AVG: 7.8476, lr: 0.001
Epoch [31/80], Training Loss: 4.2438, Validation Loss Current: 9.1970, Validation Loss AVG: 9.1970, lr: 0.001
Epoch [32/80], Training Loss: 3.2046, Validation Loss Current: 7.6798, Validation Loss AVG: 7.6798, lr: 0.001
Epoch [33/80], Training Loss: 2.9210, Validation Loss Current: 7.9922, Validation Loss AVG: 7.9922, lr: 0.001
Epoch [34/80], Training Loss: 3.8168, Validation Loss Current: 7.3323, Validation Loss AVG: 7.3323, lr: 0.001
Epoch [35/80], Training Loss: 2.2730, Validation Loss Current: 7.7283, Validation Loss AVG: 7.7283, lr: 0.001
Epoch [36/80], Training Loss: 2.8721, Validation Loss Current: 7.1660, Validation Loss AVG: 7.1660, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random3 finished training. Best epoch: 6 Best val accuracy: [0.5973684210526315, 0.6200657894736843, 0.6578947368421053, 0.6118421052631579, 0.6480263157894737, 0.6792763157894737, 0.6253289473684212, 0.6447368421052632, 0.66875, 0.6680921052631579, 0.6644736842105263, 0.6638157894736841, 0.6513157894736843, 0.6519736842105263, 0.6154605263157895, 0.6348684210526316, 0.6095394736842106, 0.5671052631578947, 0.6332236842105263, 0.6470394736842107, 0.6457236842105263, 0.6101973684210527, 0.6108552631578947, 0.6095394736842106, 0.6292763157894736, 0.6171052631578948, 0.6269736842105263, 0.65625, 0.6345394736842105, 0.6289473684210526, 0.5552631578947368, 0.6233552631578947, 0.6453947368421054, 0.6401315789473684, 0.6450657894736842, 0.6572368421052632] Best val loss: 5.51612201333046


Current group: 0.2
Epoch [1/80], Training Loss: 46.7798, Validation Loss Current: 20.9063, Validation Loss AVG: 20.9063, lr: 0.001
Epoch [2/80], Training Loss: 29.2277, Validation Loss Current: 11.4697, Validation Loss AVG: 11.4697, lr: 0.001
Epoch [3/80], Training Loss: 21.6641, Validation Loss Current: 12.3074, Validation Loss AVG: 12.3074, lr: 0.001
Epoch [4/80], Training Loss: 18.4831, Validation Loss Current: 16.9143, Validation Loss AVG: 16.9143, lr: 0.001
Epoch [5/80], Training Loss: 16.4453, Validation Loss Current: 12.1124, Validation Loss AVG: 12.1124, lr: 0.001
Epoch [6/80], Training Loss: 13.0755, Validation Loss Current: 13.3406, Validation Loss AVG: 13.3406, lr: 0.001
Epoch [7/80], Training Loss: 13.1026, Validation Loss Current: 13.2094, Validation Loss AVG: 13.2094, lr: 0.001
Epoch [8/80], Training Loss: 13.0793, Validation Loss Current: 15.8652, Validation Loss AVG: 15.8652, lr: 0.001
Epoch [9/80], Training Loss: 11.5290, Validation Loss Current: 13.5853, Validation Loss AVG: 13.5853, lr: 0.001
Epoch [10/80], Training Loss: 7.8914, Validation Loss Current: 15.6827, Validation Loss AVG: 15.6827, lr: 0.001
Epoch [11/80], Training Loss: 8.8410, Validation Loss Current: 13.1182, Validation Loss AVG: 13.1182, lr: 0.001
Epoch [12/80], Training Loss: 6.7372, Validation Loss Current: 14.8197, Validation Loss AVG: 14.8197, lr: 0.001
Epoch [13/80], Training Loss: 7.6515, Validation Loss Current: 14.9711, Validation Loss AVG: 14.9711, lr: 0.001
Epoch [14/80], Training Loss: 8.1487, Validation Loss Current: 22.9343, Validation Loss AVG: 22.9343, lr: 0.001
Epoch [15/80], Training Loss: 4.4231, Validation Loss Current: 14.9699, Validation Loss AVG: 14.9699, lr: 0.001
Epoch [16/80], Training Loss: 4.4646, Validation Loss Current: 17.8179, Validation Loss AVG: 17.8179, lr: 0.001
Epoch [17/80], Training Loss: 7.1252, Validation Loss Current: 17.3525, Validation Loss AVG: 17.3525, lr: 0.001
Epoch [18/80], Training Loss: 12.9727, Validation Loss Current: 19.6284, Validation Loss AVG: 19.6284, lr: 0.001
Epoch [19/80], Training Loss: 9.3536, Validation Loss Current: 28.9615, Validation Loss AVG: 28.9615, lr: 0.001
Epoch [20/80], Training Loss: 4.1235, Validation Loss Current: 15.9211, Validation Loss AVG: 15.9211, lr: 0.001
Epoch [21/80], Training Loss: 3.9850, Validation Loss Current: 16.7407, Validation Loss AVG: 16.7407, lr: 0.001
Epoch [22/80], Training Loss: 9.6333, Validation Loss Current: 20.6870, Validation Loss AVG: 20.6870, lr: 0.001
Epoch [23/80], Training Loss: 5.4986, Validation Loss Current: 16.6393, Validation Loss AVG: 16.6393, lr: 0.001
Epoch [24/80], Training Loss: 7.9086, Validation Loss Current: 23.3712, Validation Loss AVG: 23.3712, lr: 0.001
Epoch [25/80], Training Loss: 19.4379, Validation Loss Current: 18.4710, Validation Loss AVG: 18.4710, lr: 0.001
Epoch [26/80], Training Loss: 11.9215, Validation Loss Current: 19.4362, Validation Loss AVG: 19.4362, lr: 0.001
Epoch [27/80], Training Loss: 6.5901, Validation Loss Current: 18.0046, Validation Loss AVG: 18.0046, lr: 0.001
Epoch [28/80], Training Loss: 3.7333, Validation Loss Current: 19.3638, Validation Loss AVG: 19.3638, lr: 0.001
Epoch [29/80], Training Loss: 3.4454, Validation Loss Current: 17.7665, Validation Loss AVG: 17.7665, lr: 0.001
Epoch [30/80], Training Loss: 4.8749, Validation Loss Current: 21.5407, Validation Loss AVG: 21.5407, lr: 0.001
Epoch [31/80], Training Loss: 6.6189, Validation Loss Current: 18.4254, Validation Loss AVG: 18.4254, lr: 0.001
Epoch [32/80], Training Loss: 3.1344, Validation Loss Current: 18.3075, Validation Loss AVG: 18.3075, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 2 Best val accuracy: [0.28124999999999994, 0.4115131578947368, 0.3980263157894737, 0.28125, 0.4197368421052632, 0.3381578947368421, 0.3542763157894737, 0.3042763157894737, 0.3608552631578947, 0.3483552631578947, 0.37467105263157896, 0.37203947368421053, 0.34506578947368427, 0.25690789473684206, 0.38355263157894737, 0.35328947368421054, 0.31414473684210525, 0.35855263157894735, 0.26381578947368417, 0.41052631578947363, 0.36907894736842106, 0.34671052631578947, 0.36019736842105265, 0.2667763157894737, 0.3555921052631579, 0.2875, 0.3582236842105263, 0.33881578947368424, 0.4115131578947368, 0.34111842105263157, 0.33914473684210533, 0.34605263157894733] Best val loss: 11.469709134101867


----- Training resnet18 with sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] -----
Current group: llo_0.8_random0
Epoch [1/80], Training Loss: 41.2748, Validation Loss Current: 10.1622, Validation Loss AVG: 10.1622, lr: 0.001
Epoch [2/80], Training Loss: 39.2849, Validation Loss Current: 9.9277, Validation Loss AVG: 9.9277, lr: 0.001
Epoch [3/80], Training Loss: 39.3342, Validation Loss Current: 9.7689, Validation Loss AVG: 9.7689, lr: 0.001
Epoch [4/80], Training Loss: 38.2641, Validation Loss Current: 9.5336, Validation Loss AVG: 9.5336, lr: 0.001
Epoch [5/80], Training Loss: 38.0128, Validation Loss Current: 9.4385, Validation Loss AVG: 9.4385, lr: 0.001
Epoch [6/80], Training Loss: 36.8442, Validation Loss Current: 9.3088, Validation Loss AVG: 9.3088, lr: 0.001
Epoch [7/80], Training Loss: 36.1363, Validation Loss Current: 9.0146, Validation Loss AVG: 9.0146, lr: 0.001
Epoch [8/80], Training Loss: 35.8219, Validation Loss Current: 8.7790, Validation Loss AVG: 8.7790, lr: 0.001
Epoch [9/80], Training Loss: 34.1311, Validation Loss Current: 8.6642, Validation Loss AVG: 8.6642, lr: 0.001
Epoch [10/80], Training Loss: 34.3533, Validation Loss Current: 8.4786, Validation Loss AVG: 8.4786, lr: 0.001
Epoch [11/80], Training Loss: 33.4058, Validation Loss Current: 8.3430, Validation Loss AVG: 8.3430, lr: 0.001
Epoch [12/80], Training Loss: 32.1751, Validation Loss Current: 8.0742, Validation Loss AVG: 8.0742, lr: 0.001
Epoch [13/80], Training Loss: 31.8570, Validation Loss Current: 8.0616, Validation Loss AVG: 8.0616, lr: 0.001
Epoch [14/80], Training Loss: 30.6603, Validation Loss Current: 8.1362, Validation Loss AVG: 8.1362, lr: 0.001
Epoch [15/80], Training Loss: 29.8471, Validation Loss Current: 7.8903, Validation Loss AVG: 7.8903, lr: 0.001
Epoch [16/80], Training Loss: 29.2151, Validation Loss Current: 7.8624, Validation Loss AVG: 7.8624, lr: 0.001
Epoch [17/80], Training Loss: 27.8071, Validation Loss Current: 8.0862, Validation Loss AVG: 8.0862, lr: 0.001
Epoch [18/80], Training Loss: 27.2984, Validation Loss Current: 8.3862, Validation Loss AVG: 8.3862, lr: 0.001
Epoch [19/80], Training Loss: 27.3640, Validation Loss Current: 7.3059, Validation Loss AVG: 7.3059, lr: 0.001
Epoch [20/80], Training Loss: 26.3858, Validation Loss Current: 7.5457, Validation Loss AVG: 7.5457, lr: 0.001
Epoch [21/80], Training Loss: 25.6678, Validation Loss Current: 7.6277, Validation Loss AVG: 7.6277, lr: 0.001
Epoch [22/80], Training Loss: 24.7331, Validation Loss Current: 8.0520, Validation Loss AVG: 8.0520, lr: 0.001
Epoch [23/80], Training Loss: 25.4022, Validation Loss Current: 8.0127, Validation Loss AVG: 8.0127, lr: 0.001
Epoch [24/80], Training Loss: 25.1226, Validation Loss Current: 7.8429, Validation Loss AVG: 7.8429, lr: 0.001
Epoch [25/80], Training Loss: 24.0717, Validation Loss Current: 7.1019, Validation Loss AVG: 7.1019, lr: 0.001
Epoch [26/80], Training Loss: 25.3863, Validation Loss Current: 7.6328, Validation Loss AVG: 7.6328, lr: 0.001
Epoch [27/80], Training Loss: 24.7247, Validation Loss Current: 7.3201, Validation Loss AVG: 7.3201, lr: 0.001
Epoch [28/80], Training Loss: 22.8061, Validation Loss Current: 7.2200, Validation Loss AVG: 7.2200, lr: 0.001
Epoch [29/80], Training Loss: 21.4382, Validation Loss Current: 7.7821, Validation Loss AVG: 7.7821, lr: 0.001
Epoch [30/80], Training Loss: 19.8222, Validation Loss Current: 6.9303, Validation Loss AVG: 6.9303, lr: 0.001
Epoch [31/80], Training Loss: 19.6777, Validation Loss Current: 6.9727, Validation Loss AVG: 6.9727, lr: 0.001
Epoch [32/80], Training Loss: 17.7587, Validation Loss Current: 7.0233, Validation Loss AVG: 7.0233, lr: 0.001
Epoch [33/80], Training Loss: 18.2261, Validation Loss Current: 6.9434, Validation Loss AVG: 6.9434, lr: 0.001
Epoch [34/80], Training Loss: 19.3390, Validation Loss Current: 8.9275, Validation Loss AVG: 8.9275, lr: 0.001
Epoch [35/80], Training Loss: 19.4497, Validation Loss Current: 7.2914, Validation Loss AVG: 7.2914, lr: 0.001
Epoch [36/80], Training Loss: 17.7935, Validation Loss Current: 7.8721, Validation Loss AVG: 7.8721, lr: 0.001
Epoch [37/80], Training Loss: 17.5687, Validation Loss Current: 7.0814, Validation Loss AVG: 7.0814, lr: 0.001
Epoch [38/80], Training Loss: 15.8936, Validation Loss Current: 7.6606, Validation Loss AVG: 7.6606, lr: 0.001
Epoch [39/80], Training Loss: 15.9636, Validation Loss Current: 7.9354, Validation Loss AVG: 7.9354, lr: 0.001
Epoch [40/80], Training Loss: 15.5104, Validation Loss Current: 7.0608, Validation Loss AVG: 7.0608, lr: 0.001
Epoch [41/80], Training Loss: 13.4917, Validation Loss Current: 7.2514, Validation Loss AVG: 7.2514, lr: 0.001
Epoch [42/80], Training Loss: 12.4751, Validation Loss Current: 8.0511, Validation Loss AVG: 8.0511, lr: 0.001
Epoch [43/80], Training Loss: 13.1316, Validation Loss Current: 7.3262, Validation Loss AVG: 7.3262, lr: 0.001
Epoch [44/80], Training Loss: 10.5990, Validation Loss Current: 6.7599, Validation Loss AVG: 6.7599, lr: 0.001
Epoch [45/80], Training Loss: 9.0553, Validation Loss Current: 7.5039, Validation Loss AVG: 7.5039, lr: 0.001
Epoch [46/80], Training Loss: 8.4650, Validation Loss Current: 8.0590, Validation Loss AVG: 8.0590, lr: 0.001
Epoch [47/80], Training Loss: 10.3077, Validation Loss Current: 7.4978, Validation Loss AVG: 7.4978, lr: 0.001
Epoch [48/80], Training Loss: 9.2870, Validation Loss Current: 11.4952, Validation Loss AVG: 11.4952, lr: 0.001
Epoch [49/80], Training Loss: 12.4332, Validation Loss Current: 9.0573, Validation Loss AVG: 9.0573, lr: 0.001
Epoch [50/80], Training Loss: 10.6573, Validation Loss Current: 7.8607, Validation Loss AVG: 7.8607, lr: 0.001
Epoch [51/80], Training Loss: 8.4563, Validation Loss Current: 7.6666, Validation Loss AVG: 7.6666, lr: 0.001
Epoch [52/80], Training Loss: 8.6690, Validation Loss Current: 8.0337, Validation Loss AVG: 8.0337, lr: 0.001
Epoch [53/80], Training Loss: 12.3825, Validation Loss Current: 9.9089, Validation Loss AVG: 9.9089, lr: 0.001
Epoch [54/80], Training Loss: 7.5433, Validation Loss Current: 7.5453, Validation Loss AVG: 7.5453, lr: 0.001
Epoch [55/80], Training Loss: 7.4896, Validation Loss Current: 8.2182, Validation Loss AVG: 8.2182, lr: 0.001
Epoch [56/80], Training Loss: 5.9731, Validation Loss Current: 8.8347, Validation Loss AVG: 8.8347, lr: 0.001
Epoch [57/80], Training Loss: 11.5165, Validation Loss Current: 8.4982, Validation Loss AVG: 8.4982, lr: 0.001
Epoch [58/80], Training Loss: 8.7693, Validation Loss Current: 9.7064, Validation Loss AVG: 9.7064, lr: 0.001
Epoch [59/80], Training Loss: 7.6875, Validation Loss Current: 9.9266, Validation Loss AVG: 9.9266, lr: 0.001
Epoch [60/80], Training Loss: 10.2020, Validation Loss Current: 8.8031, Validation Loss AVG: 8.8031, lr: 0.001
Epoch [61/80], Training Loss: 11.2032, Validation Loss Current: 9.5358, Validation Loss AVG: 9.5358, lr: 0.001
Epoch [62/80], Training Loss: 11.3954, Validation Loss Current: 13.7123, Validation Loss AVG: 13.7123, lr: 0.001
Epoch [63/80], Training Loss: 7.8070, Validation Loss Current: 7.4522, Validation Loss AVG: 7.4522, lr: 0.001
Epoch [64/80], Training Loss: 5.0304, Validation Loss Current: 9.3395, Validation Loss AVG: 9.3395, lr: 0.001
Epoch [65/80], Training Loss: 7.9213, Validation Loss Current: 10.4686, Validation Loss AVG: 10.4686, lr: 0.001
Epoch [66/80], Training Loss: 11.4840, Validation Loss Current: 10.2111, Validation Loss AVG: 10.2111, lr: 0.001
Epoch [67/80], Training Loss: 8.7869, Validation Loss Current: 8.7347, Validation Loss AVG: 8.7347, lr: 0.001
Epoch [68/80], Training Loss: 8.3842, Validation Loss Current: 7.7758, Validation Loss AVG: 7.7758, lr: 0.001
Epoch [69/80], Training Loss: 6.0833, Validation Loss Current: 8.3028, Validation Loss AVG: 8.3028, lr: 0.001
Epoch [70/80], Training Loss: 5.4086, Validation Loss Current: 7.8730, Validation Loss AVG: 7.8730, lr: 0.001
Epoch [71/80], Training Loss: 5.4054, Validation Loss Current: 7.9054, Validation Loss AVG: 7.9054, lr: 0.001
Epoch [72/80], Training Loss: 5.7867, Validation Loss Current: 9.4622, Validation Loss AVG: 9.4622, lr: 0.001
Epoch [73/80], Training Loss: 6.1082, Validation Loss Current: 9.1726, Validation Loss AVG: 9.1726, lr: 0.001
Epoch [74/80], Training Loss: 6.9940, Validation Loss Current: 11.5395, Validation Loss AVG: 11.5395, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random0 finished training. Best epoch: 44 Best val accuracy: [0.2276315789473684, 0.23125, 0.2450657894736842, 0.2759868421052632, 0.28125, 0.3111842105263158, 0.31052631578947365, 0.3628289473684211, 0.3805921052631579, 0.36447368421052634, 0.3888157894736842, 0.4223684210526315, 0.42467105263157895, 0.41447368421052627, 0.4233552631578947, 0.4404605263157896, 0.4391447368421053, 0.38782894736842105, 0.48322368421052636, 0.4703947368421052, 0.4625, 0.43453947368421053, 0.44835526315789476, 0.4473684210526316, 0.5085526315789475, 0.45394736842105265, 0.49769736842105267, 0.49243421052631575, 0.4588815789473684, 0.5299342105263157, 0.5180921052631579, 0.5174342105263158, 0.5342105263157895, 0.43453947368421053, 0.5006578947368421, 0.4805921052631579, 0.5259868421052631, 0.49078947368421044, 0.47171052631578947, 0.5381578947368422, 0.5305921052631579, 0.49769736842105256, 0.5365131578947369, 0.5684210526315789, 0.5417763157894736, 0.5194078947368421, 0.5430921052631579, 0.44342105263157894, 0.47006578947368427, 0.5325657894736843, 0.5453947368421053, 0.5328947368421053, 0.46809210526315786, 0.555921052631579, 0.5457236842105263, 0.5463815789473684, 0.5046052631578948, 0.5167763157894737, 0.47993421052631574, 0.5184210526315789, 0.4842105263157895, 0.44177631578947374, 0.5667763157894737, 0.49539473684210533, 0.47335526315789467, 0.49572368421052626, 0.5253289473684211, 0.5657894736842105, 0.5539473684210527, 0.5759868421052632, 0.5838815789473684, 0.5467105263157894, 0.5358552631578948, 0.4266447368421053] Best val loss: 6.75990481376648


Current group: llo_0.8_random1
Epoch [1/80], Training Loss: 34.6780, Validation Loss Current: 10.5388, Validation Loss AVG: 10.5388, lr: 0.001
Epoch [2/80], Training Loss: 25.8180, Validation Loss Current: 10.6835, Validation Loss AVG: 10.6835, lr: 0.001
Epoch [3/80], Training Loss: 21.7004, Validation Loss Current: 7.5455, Validation Loss AVG: 7.5455, lr: 0.001
Epoch [4/80], Training Loss: 22.4965, Validation Loss Current: 6.9437, Validation Loss AVG: 6.9437, lr: 0.001
Epoch [5/80], Training Loss: 16.9346, Validation Loss Current: 6.4752, Validation Loss AVG: 6.4752, lr: 0.001
Epoch [6/80], Training Loss: 13.4013, Validation Loss Current: 6.7178, Validation Loss AVG: 6.7178, lr: 0.001
Epoch [7/80], Training Loss: 12.9113, Validation Loss Current: 6.7583, Validation Loss AVG: 6.7583, lr: 0.001
Epoch [8/80], Training Loss: 11.7102, Validation Loss Current: 7.3547, Validation Loss AVG: 7.3547, lr: 0.001
Epoch [9/80], Training Loss: 11.7599, Validation Loss Current: 6.7667, Validation Loss AVG: 6.7667, lr: 0.001
Epoch [10/80], Training Loss: 11.2125, Validation Loss Current: 6.8426, Validation Loss AVG: 6.8426, lr: 0.001
Epoch [11/80], Training Loss: 9.4372, Validation Loss Current: 7.7503, Validation Loss AVG: 7.7503, lr: 0.001
Epoch [12/80], Training Loss: 12.1052, Validation Loss Current: 7.5916, Validation Loss AVG: 7.5916, lr: 0.001
Epoch [13/80], Training Loss: 9.6293, Validation Loss Current: 6.5119, Validation Loss AVG: 6.5119, lr: 0.001
Epoch [14/80], Training Loss: 10.5122, Validation Loss Current: 7.6951, Validation Loss AVG: 7.6951, lr: 0.001
Epoch [15/80], Training Loss: 10.5847, Validation Loss Current: 8.6514, Validation Loss AVG: 8.6514, lr: 0.001
Epoch [16/80], Training Loss: 9.5355, Validation Loss Current: 7.5935, Validation Loss AVG: 7.5935, lr: 0.001
Epoch [17/80], Training Loss: 8.4375, Validation Loss Current: 6.9552, Validation Loss AVG: 6.9552, lr: 0.001
Epoch [18/80], Training Loss: 7.6053, Validation Loss Current: 7.4028, Validation Loss AVG: 7.4028, lr: 0.001
Epoch [19/80], Training Loss: 7.0586, Validation Loss Current: 6.6552, Validation Loss AVG: 6.6552, lr: 0.001
Epoch [20/80], Training Loss: 9.7555, Validation Loss Current: 7.7256, Validation Loss AVG: 7.7256, lr: 0.001
Epoch [21/80], Training Loss: 9.5906, Validation Loss Current: 7.1654, Validation Loss AVG: 7.1654, lr: 0.001
Epoch [22/80], Training Loss: 8.4750, Validation Loss Current: 7.3078, Validation Loss AVG: 7.3078, lr: 0.001
Epoch [23/80], Training Loss: 6.0426, Validation Loss Current: 6.7376, Validation Loss AVG: 6.7376, lr: 0.001
Epoch [24/80], Training Loss: 3.7061, Validation Loss Current: 6.9449, Validation Loss AVG: 6.9449, lr: 0.001
Epoch [25/80], Training Loss: 3.9371, Validation Loss Current: 7.5474, Validation Loss AVG: 7.5474, lr: 0.001
Epoch [26/80], Training Loss: 5.4566, Validation Loss Current: 8.4376, Validation Loss AVG: 8.4376, lr: 0.001
Epoch [27/80], Training Loss: 4.4386, Validation Loss Current: 7.6443, Validation Loss AVG: 7.6443, lr: 0.001
Epoch [28/80], Training Loss: 6.4145, Validation Loss Current: 9.5819, Validation Loss AVG: 9.5819, lr: 0.001
Epoch [29/80], Training Loss: 7.3168, Validation Loss Current: 8.2844, Validation Loss AVG: 8.2844, lr: 0.001
Epoch [30/80], Training Loss: 4.5705, Validation Loss Current: 8.1302, Validation Loss AVG: 8.1302, lr: 0.001
Epoch [31/80], Training Loss: 5.5517, Validation Loss Current: 8.9308, Validation Loss AVG: 8.9308, lr: 0.001
Epoch [32/80], Training Loss: 4.0070, Validation Loss Current: 8.3224, Validation Loss AVG: 8.3224, lr: 0.001
Epoch [33/80], Training Loss: 5.6209, Validation Loss Current: 8.6265, Validation Loss AVG: 8.6265, lr: 0.001
Epoch [34/80], Training Loss: 8.1500, Validation Loss Current: 8.0099, Validation Loss AVG: 8.0099, lr: 0.001
Epoch [35/80], Training Loss: 6.6459, Validation Loss Current: 8.4398, Validation Loss AVG: 8.4398, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random1 finished training. Best epoch: 5 Best val accuracy: [0.48421052631578937, 0.44703947368421054, 0.5421052631578946, 0.5631578947368421, 0.6088815789473684, 0.5700657894736842, 0.5986842105263157, 0.5651315789473684, 0.6055921052631579, 0.5746710526315789, 0.562171052631579, 0.5460526315789475, 0.6302631578947369, 0.5776315789473684, 0.5552631578947368, 0.5680921052631579, 0.5993421052631579, 0.6016447368421052, 0.5960526315789474, 0.5713815789473685, 0.6032894736842106, 0.5996710526315789, 0.6345394736842105, 0.6203947368421052, 0.5924342105263157, 0.5809210526315789, 0.5947368421052632, 0.5674342105263157, 0.58125, 0.5717105263157894, 0.5819078947368421, 0.5815789473684211, 0.5832236842105264, 0.5891447368421052, 0.5713815789473684] Best val loss: 6.475158166885376


Current group: llo_0.8_random2
Epoch [1/80], Training Loss: 37.4448, Validation Loss Current: 7.9651, Validation Loss AVG: 7.9651, lr: 0.001
Epoch [2/80], Training Loss: 24.4112, Validation Loss Current: 6.2463, Validation Loss AVG: 6.2463, lr: 0.001
Epoch [3/80], Training Loss: 20.5990, Validation Loss Current: 7.4407, Validation Loss AVG: 7.4407, lr: 0.001
Epoch [4/80], Training Loss: 19.1828, Validation Loss Current: 8.1527, Validation Loss AVG: 8.1527, lr: 0.001
Epoch [5/80], Training Loss: 13.0712, Validation Loss Current: 5.4648, Validation Loss AVG: 5.4648, lr: 0.001
Epoch [6/80], Training Loss: 11.1625, Validation Loss Current: 5.8100, Validation Loss AVG: 5.8100, lr: 0.001
Epoch [7/80], Training Loss: 11.0884, Validation Loss Current: 5.9936, Validation Loss AVG: 5.9936, lr: 0.001
Epoch [8/80], Training Loss: 7.6523, Validation Loss Current: 5.1565, Validation Loss AVG: 5.1565, lr: 0.001
Epoch [9/80], Training Loss: 8.0457, Validation Loss Current: 6.3893, Validation Loss AVG: 6.3893, lr: 0.001
Epoch [10/80], Training Loss: 6.7396, Validation Loss Current: 6.1360, Validation Loss AVG: 6.1360, lr: 0.001
Epoch [11/80], Training Loss: 5.8440, Validation Loss Current: 5.3869, Validation Loss AVG: 5.3869, lr: 0.001
Epoch [12/80], Training Loss: 7.0126, Validation Loss Current: 6.4600, Validation Loss AVG: 6.4600, lr: 0.001
Epoch [13/80], Training Loss: 8.8396, Validation Loss Current: 6.0890, Validation Loss AVG: 6.0890, lr: 0.001
Epoch [14/80], Training Loss: 7.2716, Validation Loss Current: 5.7820, Validation Loss AVG: 5.7820, lr: 0.001
Epoch [15/80], Training Loss: 3.7543, Validation Loss Current: 7.0931, Validation Loss AVG: 7.0931, lr: 0.001
Epoch [16/80], Training Loss: 4.4921, Validation Loss Current: 6.2332, Validation Loss AVG: 6.2332, lr: 0.001
Epoch [17/80], Training Loss: 5.2654, Validation Loss Current: 7.9622, Validation Loss AVG: 7.9622, lr: 0.001
Epoch [18/80], Training Loss: 7.1840, Validation Loss Current: 7.3442, Validation Loss AVG: 7.3442, lr: 0.001
Epoch [19/80], Training Loss: 4.6650, Validation Loss Current: 6.2700, Validation Loss AVG: 6.2700, lr: 0.001
Epoch [20/80], Training Loss: 5.7860, Validation Loss Current: 8.0575, Validation Loss AVG: 8.0575, lr: 0.001
Epoch [21/80], Training Loss: 6.4422, Validation Loss Current: 9.1305, Validation Loss AVG: 9.1305, lr: 0.001
Epoch [22/80], Training Loss: 12.7075, Validation Loss Current: 7.3934, Validation Loss AVG: 7.3934, lr: 0.001
Epoch [23/80], Training Loss: 5.9352, Validation Loss Current: 7.1964, Validation Loss AVG: 7.1964, lr: 0.001
Epoch [24/80], Training Loss: 3.2186, Validation Loss Current: 6.1538, Validation Loss AVG: 6.1538, lr: 0.001
Epoch [25/80], Training Loss: 5.9867, Validation Loss Current: 7.5040, Validation Loss AVG: 7.5040, lr: 0.001
Epoch [26/80], Training Loss: 4.4291, Validation Loss Current: 6.6242, Validation Loss AVG: 6.6242, lr: 0.001
Epoch [27/80], Training Loss: 7.2885, Validation Loss Current: 7.1150, Validation Loss AVG: 7.1150, lr: 0.001
Epoch [28/80], Training Loss: 8.1181, Validation Loss Current: 7.8184, Validation Loss AVG: 7.8184, lr: 0.001
Epoch [29/80], Training Loss: 3.5062, Validation Loss Current: 6.6585, Validation Loss AVG: 6.6585, lr: 0.001
Epoch [30/80], Training Loss: 2.6872, Validation Loss Current: 8.3858, Validation Loss AVG: 8.3858, lr: 0.001
Epoch [31/80], Training Loss: 4.3780, Validation Loss Current: 7.4399, Validation Loss AVG: 7.4399, lr: 0.001
Epoch [32/80], Training Loss: 7.0202, Validation Loss Current: 7.7914, Validation Loss AVG: 7.7914, lr: 0.001
Epoch [33/80], Training Loss: 3.3083, Validation Loss Current: 7.4255, Validation Loss AVG: 7.4255, lr: 0.001
Epoch [34/80], Training Loss: 2.5106, Validation Loss Current: 6.9284, Validation Loss AVG: 6.9284, lr: 0.001
Epoch [35/80], Training Loss: 2.2924, Validation Loss Current: 6.8012, Validation Loss AVG: 6.8012, lr: 0.001
Epoch [36/80], Training Loss: 3.5383, Validation Loss Current: 7.7106, Validation Loss AVG: 7.7106, lr: 0.001
Epoch [37/80], Training Loss: 6.8332, Validation Loss Current: 8.0626, Validation Loss AVG: 8.0626, lr: 0.001
Epoch [38/80], Training Loss: 5.5763, Validation Loss Current: 9.5181, Validation Loss AVG: 9.5181, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random2 finished training. Best epoch: 8 Best val accuracy: [0.575, 0.6157894736842104, 0.555921052631579, 0.5427631578947368, 0.6424342105263158, 0.6421052631578947, 0.6569078947368421, 0.6769736842105264, 0.6493421052631579, 0.6325657894736842, 0.6799342105263159, 0.6427631578947368, 0.6398026315789473, 0.6815789473684211, 0.6325657894736841, 0.656578947368421, 0.6164473684210526, 0.5822368421052632, 0.6667763157894737, 0.6075657894736842, 0.5529605263157895, 0.6355263157894737, 0.625, 0.6654605263157894, 0.6111842105263159, 0.6493421052631578, 0.6345394736842106, 0.6078947368421053, 0.64375, 0.5976973684210527, 0.6184210526315789, 0.6197368421052631, 0.6388157894736841, 0.6269736842105262, 0.6618421052631579, 0.6180921052631578, 0.6207236842105263, 0.5733552631578948] Best val loss: 5.156490552425384


Current group: llo_0.8_random3
Epoch [1/80], Training Loss: 36.8378, Validation Loss Current: 6.1578, Validation Loss AVG: 6.1578, lr: 0.001
Epoch [2/80], Training Loss: 23.9434, Validation Loss Current: 6.5671, Validation Loss AVG: 6.5671, lr: 0.001
Epoch [3/80], Training Loss: 18.0827, Validation Loss Current: 5.5637, Validation Loss AVG: 5.5637, lr: 0.001
Epoch [4/80], Training Loss: 14.9347, Validation Loss Current: 6.4924, Validation Loss AVG: 6.4924, lr: 0.001
Epoch [5/80], Training Loss: 10.1519, Validation Loss Current: 6.1694, Validation Loss AVG: 6.1694, lr: 0.001
Epoch [6/80], Training Loss: 12.1091, Validation Loss Current: 6.2379, Validation Loss AVG: 6.2379, lr: 0.001
Epoch [7/80], Training Loss: 8.6049, Validation Loss Current: 5.6083, Validation Loss AVG: 5.6083, lr: 0.001
Epoch [8/80], Training Loss: 7.6876, Validation Loss Current: 5.6937, Validation Loss AVG: 5.6937, lr: 0.001
Epoch [9/80], Training Loss: 6.8172, Validation Loss Current: 6.1283, Validation Loss AVG: 6.1283, lr: 0.001
Epoch [10/80], Training Loss: 5.7244, Validation Loss Current: 5.6636, Validation Loss AVG: 5.6636, lr: 0.001
Epoch [11/80], Training Loss: 5.2065, Validation Loss Current: 5.7656, Validation Loss AVG: 5.7656, lr: 0.001
Epoch [12/80], Training Loss: 4.5103, Validation Loss Current: 5.7709, Validation Loss AVG: 5.7709, lr: 0.001
Epoch [13/80], Training Loss: 6.9552, Validation Loss Current: 7.1852, Validation Loss AVG: 7.1852, lr: 0.001
Epoch [14/80], Training Loss: 10.1323, Validation Loss Current: 7.1900, Validation Loss AVG: 7.1900, lr: 0.001
Epoch [15/80], Training Loss: 6.1076, Validation Loss Current: 6.0299, Validation Loss AVG: 6.0299, lr: 0.001
Epoch [16/80], Training Loss: 3.8210, Validation Loss Current: 7.1376, Validation Loss AVG: 7.1376, lr: 0.001
Epoch [17/80], Training Loss: 4.3497, Validation Loss Current: 5.7690, Validation Loss AVG: 5.7690, lr: 0.001
Epoch [18/80], Training Loss: 3.8536, Validation Loss Current: 6.8999, Validation Loss AVG: 6.8999, lr: 0.001
Epoch [19/80], Training Loss: 4.0950, Validation Loss Current: 6.6489, Validation Loss AVG: 6.6489, lr: 0.001
Epoch [20/80], Training Loss: 3.6629, Validation Loss Current: 6.0090, Validation Loss AVG: 6.0090, lr: 0.001
Epoch [21/80], Training Loss: 3.8174, Validation Loss Current: 7.2227, Validation Loss AVG: 7.2227, lr: 0.001
Epoch [22/80], Training Loss: 2.2072, Validation Loss Current: 6.5340, Validation Loss AVG: 6.5340, lr: 0.001
Epoch [23/80], Training Loss: 4.8653, Validation Loss Current: 6.2637, Validation Loss AVG: 6.2637, lr: 0.001
Epoch [24/80], Training Loss: 4.4446, Validation Loss Current: 6.7001, Validation Loss AVG: 6.7001, lr: 0.001
Epoch [25/80], Training Loss: 4.4093, Validation Loss Current: 7.4349, Validation Loss AVG: 7.4349, lr: 0.001
Epoch [26/80], Training Loss: 5.8643, Validation Loss Current: 6.8179, Validation Loss AVG: 6.8179, lr: 0.001
Epoch [27/80], Training Loss: 5.3431, Validation Loss Current: 7.3061, Validation Loss AVG: 7.3061, lr: 0.001
Epoch [28/80], Training Loss: 5.3188, Validation Loss Current: 7.2420, Validation Loss AVG: 7.2420, lr: 0.001
Epoch [29/80], Training Loss: 4.8154, Validation Loss Current: 7.6198, Validation Loss AVG: 7.6198, lr: 0.001
Epoch [30/80], Training Loss: 4.8470, Validation Loss Current: 7.4393, Validation Loss AVG: 7.4393, lr: 0.001
Epoch [31/80], Training Loss: 5.7923, Validation Loss Current: 8.1150, Validation Loss AVG: 8.1150, lr: 0.001
Epoch [32/80], Training Loss: 6.4415, Validation Loss Current: 7.0428, Validation Loss AVG: 7.0428, lr: 0.001
Epoch [33/80], Training Loss: 2.2141, Validation Loss Current: 6.6806, Validation Loss AVG: 6.6806, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random3 finished training. Best epoch: 3 Best val accuracy: [0.6358552631578948, 0.6269736842105263, 0.662828947368421, 0.6319078947368422, 0.6476973684210525, 0.6536184210526316, 0.6703947368421053, 0.6779605263157895, 0.667763157894737, 0.6651315789473684, 0.680921052631579, 0.66875, 0.6039473684210527, 0.6141447368421052, 0.6631578947368422, 0.6098684210526315, 0.6746710526315789, 0.6483552631578947, 0.6470394736842106, 0.675657894736842, 0.6335526315789474, 0.6648026315789475, 0.6707236842105263, 0.6736842105263159, 0.6302631578947369, 0.6463815789473684, 0.6355263157894737, 0.6434210526315789, 0.6279605263157896, 0.6493421052631578, 0.6378289473684211, 0.6582236842105263, 0.6615131578947369] Best val loss: 5.563667607307434


Current group: 0.8
Epoch [1/80], Training Loss: 30.6355, Validation Loss Current: 9.2181, Validation Loss AVG: 9.2181, lr: 0.001
Epoch [2/80], Training Loss: 13.8794, Validation Loss Current: 7.2946, Validation Loss AVG: 7.2946, lr: 0.001
Epoch [3/80], Training Loss: 9.0138, Validation Loss Current: 6.9117, Validation Loss AVG: 6.9117, lr: 0.001
Epoch [4/80], Training Loss: 6.8060, Validation Loss Current: 7.8571, Validation Loss AVG: 7.8571, lr: 0.001
Epoch [5/80], Training Loss: 6.1178, Validation Loss Current: 7.8970, Validation Loss AVG: 7.8970, lr: 0.001
Epoch [6/80], Training Loss: 5.7160, Validation Loss Current: 9.0066, Validation Loss AVG: 9.0066, lr: 0.001
Epoch [7/80], Training Loss: 5.6856, Validation Loss Current: 7.6300, Validation Loss AVG: 7.6300, lr: 0.001
Epoch [8/80], Training Loss: 5.0813, Validation Loss Current: 8.8931, Validation Loss AVG: 8.8931, lr: 0.001
Epoch [9/80], Training Loss: 5.4001, Validation Loss Current: 9.3061, Validation Loss AVG: 9.3061, lr: 0.001
Epoch [10/80], Training Loss: 6.2958, Validation Loss Current: 8.7211, Validation Loss AVG: 8.7211, lr: 0.001
Epoch [11/80], Training Loss: 4.3327, Validation Loss Current: 8.2760, Validation Loss AVG: 8.2760, lr: 0.001
Epoch [12/80], Training Loss: 2.4296, Validation Loss Current: 7.6305, Validation Loss AVG: 7.6305, lr: 0.001
Epoch [13/80], Training Loss: 2.4195, Validation Loss Current: 8.4331, Validation Loss AVG: 8.4331, lr: 0.001
Epoch [14/80], Training Loss: 1.9715, Validation Loss Current: 7.9608, Validation Loss AVG: 7.9608, lr: 0.001
Epoch [15/80], Training Loss: 1.4953, Validation Loss Current: 8.4090, Validation Loss AVG: 8.4090, lr: 0.001
Epoch [16/80], Training Loss: 3.1752, Validation Loss Current: 8.3927, Validation Loss AVG: 8.3927, lr: 0.001
Epoch [17/80], Training Loss: 4.0357, Validation Loss Current: 10.5225, Validation Loss AVG: 10.5225, lr: 0.001
Epoch [18/80], Training Loss: 4.8649, Validation Loss Current: 9.7556, Validation Loss AVG: 9.7556, lr: 0.001
Epoch [19/80], Training Loss: 3.8314, Validation Loss Current: 10.3103, Validation Loss AVG: 10.3103, lr: 0.001
Epoch [20/80], Training Loss: 6.3215, Validation Loss Current: 9.6353, Validation Loss AVG: 9.6353, lr: 0.001
Epoch [21/80], Training Loss: 4.7601, Validation Loss Current: 10.2051, Validation Loss AVG: 10.2051, lr: 0.001
Epoch [22/80], Training Loss: 5.1125, Validation Loss Current: 10.1723, Validation Loss AVG: 10.1723, lr: 0.001
Epoch [23/80], Training Loss: 9.5133, Validation Loss Current: 11.3000, Validation Loss AVG: 11.3000, lr: 0.001
Epoch [24/80], Training Loss: 5.1864, Validation Loss Current: 11.7272, Validation Loss AVG: 11.7272, lr: 0.001
Epoch [25/80], Training Loss: 2.6231, Validation Loss Current: 9.3136, Validation Loss AVG: 9.3136, lr: 0.001
Epoch [26/80], Training Loss: 1.6399, Validation Loss Current: 8.9439, Validation Loss AVG: 8.9439, lr: 0.001
Epoch [27/80], Training Loss: 2.1159, Validation Loss Current: 9.2890, Validation Loss AVG: 9.2890, lr: 0.001
Epoch [28/80], Training Loss: 3.0944, Validation Loss Current: 9.2475, Validation Loss AVG: 9.2475, lr: 0.001
Epoch [29/80], Training Loss: 6.7704, Validation Loss Current: 10.1034, Validation Loss AVG: 10.1034, lr: 0.001
Epoch [30/80], Training Loss: 3.9368, Validation Loss Current: 9.7961, Validation Loss AVG: 9.7961, lr: 0.001
Epoch [31/80], Training Loss: 2.1649, Validation Loss Current: 8.7116, Validation Loss AVG: 8.7116, lr: 0.001
Epoch [32/80], Training Loss: 4.4821, Validation Loss Current: 10.8328, Validation Loss AVG: 10.8328, lr: 0.001
Epoch [33/80], Training Loss: 5.5230, Validation Loss Current: 9.2794, Validation Loss AVG: 9.2794, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 3 Best val accuracy: [0.5782894736842106, 0.6046052631578946, 0.6217105263157894, 0.6072368421052632, 0.5875, 0.5957236842105262, 0.6141447368421054, 0.5789473684210525, 0.5703947368421053, 0.5786184210526317, 0.5766447368421053, 0.6055921052631579, 0.6, 0.6164473684210525, 0.6059210526315789, 0.6203947368421052, 0.5549342105263159, 0.5848684210526316, 0.5375, 0.5710526315789473, 0.5625, 0.5697368421052632, 0.5414473684210526, 0.47960526315789476, 0.5631578947368421, 0.575, 0.5773026315789473, 0.5634868421052631, 0.5213815789473684, 0.5486842105263159, 0.5796052631578947, 0.5427631578947368, 0.5444078947368421] Best val loss: 6.911657071113586


----- Training resnet18 with sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] -----
Current group: llo_0.4_random0
Epoch [1/80], Training Loss: 40.7036, Validation Loss Current: 10.0395, Validation Loss AVG: 10.0395, lr: 0.001
Epoch [2/80], Training Loss: 39.2976, Validation Loss Current: 9.9079, Validation Loss AVG: 9.9079, lr: 0.001
Epoch [3/80], Training Loss: 38.8339, Validation Loss Current: 9.6603, Validation Loss AVG: 9.6603, lr: 0.001
Epoch [4/80], Training Loss: 38.1665, Validation Loss Current: 9.5802, Validation Loss AVG: 9.5802, lr: 0.001
Epoch [5/80], Training Loss: 37.0199, Validation Loss Current: 9.4032, Validation Loss AVG: 9.4032, lr: 0.001
Epoch [6/80], Training Loss: 36.4963, Validation Loss Current: 9.1139, Validation Loss AVG: 9.1139, lr: 0.001
Epoch [7/80], Training Loss: 36.1703, Validation Loss Current: 8.9446, Validation Loss AVG: 8.9446, lr: 0.001
Epoch [8/80], Training Loss: 34.5266, Validation Loss Current: 8.8253, Validation Loss AVG: 8.8253, lr: 0.001
Epoch [9/80], Training Loss: 34.2838, Validation Loss Current: 8.7007, Validation Loss AVG: 8.7007, lr: 0.001
Epoch [10/80], Training Loss: 33.2224, Validation Loss Current: 8.4579, Validation Loss AVG: 8.4579, lr: 0.001
Epoch [11/80], Training Loss: 31.3253, Validation Loss Current: 8.2245, Validation Loss AVG: 8.2245, lr: 0.001
Epoch [12/80], Training Loss: 31.0110, Validation Loss Current: 7.9678, Validation Loss AVG: 7.9678, lr: 0.001
Epoch [13/80], Training Loss: 29.9149, Validation Loss Current: 7.7889, Validation Loss AVG: 7.7889, lr: 0.001
Epoch [14/80], Training Loss: 28.6925, Validation Loss Current: 8.0356, Validation Loss AVG: 8.0356, lr: 0.001
Epoch [15/80], Training Loss: 29.7394, Validation Loss Current: 8.3322, Validation Loss AVG: 8.3322, lr: 0.001
Epoch [16/80], Training Loss: 28.2216, Validation Loss Current: 7.7746, Validation Loss AVG: 7.7746, lr: 0.001
Epoch [17/80], Training Loss: 27.4891, Validation Loss Current: 8.0157, Validation Loss AVG: 8.0157, lr: 0.001
Epoch [18/80], Training Loss: 26.3502, Validation Loss Current: 7.5865, Validation Loss AVG: 7.5865, lr: 0.001
Epoch [19/80], Training Loss: 27.1268, Validation Loss Current: 7.7787, Validation Loss AVG: 7.7787, lr: 0.001
Epoch [20/80], Training Loss: 26.4944, Validation Loss Current: 7.4078, Validation Loss AVG: 7.4078, lr: 0.001
Epoch [21/80], Training Loss: 25.2886, Validation Loss Current: 7.2193, Validation Loss AVG: 7.2193, lr: 0.001
Epoch [22/80], Training Loss: 23.2732, Validation Loss Current: 7.2238, Validation Loss AVG: 7.2238, lr: 0.001
Epoch [23/80], Training Loss: 23.0612, Validation Loss Current: 6.9322, Validation Loss AVG: 6.9322, lr: 0.001
Epoch [24/80], Training Loss: 22.9138, Validation Loss Current: 7.1348, Validation Loss AVG: 7.1348, lr: 0.001
Epoch [25/80], Training Loss: 23.9113, Validation Loss Current: 7.2833, Validation Loss AVG: 7.2833, lr: 0.001
Epoch [26/80], Training Loss: 24.3637, Validation Loss Current: 7.2323, Validation Loss AVG: 7.2323, lr: 0.001
Epoch [27/80], Training Loss: 24.1108, Validation Loss Current: 7.2095, Validation Loss AVG: 7.2095, lr: 0.001
Epoch [28/80], Training Loss: 21.8305, Validation Loss Current: 6.9931, Validation Loss AVG: 6.9931, lr: 0.001
Epoch [29/80], Training Loss: 21.6890, Validation Loss Current: 6.9400, Validation Loss AVG: 6.9400, lr: 0.001
Epoch [30/80], Training Loss: 19.2058, Validation Loss Current: 6.7304, Validation Loss AVG: 6.7304, lr: 0.001
Epoch [31/80], Training Loss: 19.2995, Validation Loss Current: 6.9063, Validation Loss AVG: 6.9063, lr: 0.001
Epoch [32/80], Training Loss: 17.9609, Validation Loss Current: 7.0185, Validation Loss AVG: 7.0185, lr: 0.001
Epoch [33/80], Training Loss: 19.3953, Validation Loss Current: 8.0731, Validation Loss AVG: 8.0731, lr: 0.001
Epoch [34/80], Training Loss: 17.5898, Validation Loss Current: 6.6082, Validation Loss AVG: 6.6082, lr: 0.001
Epoch [35/80], Training Loss: 17.3287, Validation Loss Current: 6.5927, Validation Loss AVG: 6.5927, lr: 0.001
Epoch [36/80], Training Loss: 16.3116, Validation Loss Current: 6.4400, Validation Loss AVG: 6.4400, lr: 0.001
Epoch [37/80], Training Loss: 16.2486, Validation Loss Current: 7.4687, Validation Loss AVG: 7.4687, lr: 0.001
Epoch [38/80], Training Loss: 16.5935, Validation Loss Current: 6.6213, Validation Loss AVG: 6.6213, lr: 0.001
Epoch [39/80], Training Loss: 15.4301, Validation Loss Current: 6.5883, Validation Loss AVG: 6.5883, lr: 0.001
Epoch [40/80], Training Loss: 13.1845, Validation Loss Current: 6.5990, Validation Loss AVG: 6.5990, lr: 0.001
Epoch [41/80], Training Loss: 11.1992, Validation Loss Current: 6.2749, Validation Loss AVG: 6.2749, lr: 0.001
Epoch [42/80], Training Loss: 9.9356, Validation Loss Current: 6.4299, Validation Loss AVG: 6.4299, lr: 0.001
Epoch [43/80], Training Loss: 11.1470, Validation Loss Current: 6.6729, Validation Loss AVG: 6.6729, lr: 0.001
Epoch [44/80], Training Loss: 11.2668, Validation Loss Current: 6.9507, Validation Loss AVG: 6.9507, lr: 0.001
Epoch [45/80], Training Loss: 9.0577, Validation Loss Current: 6.6665, Validation Loss AVG: 6.6665, lr: 0.001
Epoch [46/80], Training Loss: 7.8242, Validation Loss Current: 6.7858, Validation Loss AVG: 6.7858, lr: 0.001
Epoch [47/80], Training Loss: 8.9833, Validation Loss Current: 6.9403, Validation Loss AVG: 6.9403, lr: 0.001
Epoch [48/80], Training Loss: 8.2112, Validation Loss Current: 8.2172, Validation Loss AVG: 8.2172, lr: 0.001
Epoch [49/80], Training Loss: 9.2318, Validation Loss Current: 8.9917, Validation Loss AVG: 8.9917, lr: 0.001
Epoch [50/80], Training Loss: 10.4979, Validation Loss Current: 8.4147, Validation Loss AVG: 8.4147, lr: 0.001
Epoch [51/80], Training Loss: 9.1332, Validation Loss Current: 9.9672, Validation Loss AVG: 9.9672, lr: 0.001
Epoch [52/80], Training Loss: 10.1921, Validation Loss Current: 7.7457, Validation Loss AVG: 7.7457, lr: 0.001
Epoch [53/80], Training Loss: 6.6836, Validation Loss Current: 7.2603, Validation Loss AVG: 7.2603, lr: 0.001
Epoch [54/80], Training Loss: 4.9702, Validation Loss Current: 6.8883, Validation Loss AVG: 6.8883, lr: 0.001
Epoch [55/80], Training Loss: 4.3698, Validation Loss Current: 6.8965, Validation Loss AVG: 6.8965, lr: 0.001
Epoch [56/80], Training Loss: 6.6624, Validation Loss Current: 9.4739, Validation Loss AVG: 9.4739, lr: 0.001
Epoch [57/80], Training Loss: 10.9446, Validation Loss Current: 9.9998, Validation Loss AVG: 9.9998, lr: 0.001
Epoch [58/80], Training Loss: 14.9850, Validation Loss Current: 12.3101, Validation Loss AVG: 12.3101, lr: 0.001
Epoch [59/80], Training Loss: 13.0379, Validation Loss Current: 9.9388, Validation Loss AVG: 9.9388, lr: 0.001
Epoch [60/80], Training Loss: 17.8981, Validation Loss Current: 11.5978, Validation Loss AVG: 11.5978, lr: 0.001
Epoch [61/80], Training Loss: 11.7110, Validation Loss Current: 7.3202, Validation Loss AVG: 7.3202, lr: 0.001
Epoch [62/80], Training Loss: 8.0899, Validation Loss Current: 7.4762, Validation Loss AVG: 7.4762, lr: 0.001
Epoch [63/80], Training Loss: 9.3409, Validation Loss Current: 7.7083, Validation Loss AVG: 7.7083, lr: 0.001
Epoch [64/80], Training Loss: 9.2692, Validation Loss Current: 8.7909, Validation Loss AVG: 8.7909, lr: 0.001
Epoch [65/80], Training Loss: 9.0071, Validation Loss Current: 8.0749, Validation Loss AVG: 8.0749, lr: 0.001
Epoch [66/80], Training Loss: 8.8489, Validation Loss Current: 9.9397, Validation Loss AVG: 9.9397, lr: 0.001
Epoch [67/80], Training Loss: 5.5170, Validation Loss Current: 8.5066, Validation Loss AVG: 8.5066, lr: 0.001
Epoch [68/80], Training Loss: 3.5452, Validation Loss Current: 7.0921, Validation Loss AVG: 7.0921, lr: 0.001
Epoch [69/80], Training Loss: 2.7960, Validation Loss Current: 6.9216, Validation Loss AVG: 6.9216, lr: 0.001
Epoch [70/80], Training Loss: 2.3617, Validation Loss Current: 6.8398, Validation Loss AVG: 6.8398, lr: 0.001
Epoch [71/80], Training Loss: 3.8288, Validation Loss Current: 7.3496, Validation Loss AVG: 7.3496, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random0 finished training. Best epoch: 41 Best val accuracy: [0.22697368421052627, 0.2388157894736842, 0.2657894736842105, 0.2947368421052632, 0.31546052631578947, 0.3404605263157895, 0.34769736842105264, 0.3539473684210527, 0.36546052631578946, 0.40559210526315786, 0.40493421052631573, 0.4375, 0.4532894736842105, 0.4256578947368421, 0.3855263157894737, 0.43782894736842104, 0.4082236842105263, 0.4585526315789473, 0.44835526315789476, 0.4631578947368421, 0.5032894736842105, 0.4773026315789474, 0.5213815789473684, 0.4927631578947368, 0.4828947368421053, 0.4759868421052632, 0.48026315789473684, 0.5286184210526316, 0.5289473684210526, 0.5322368421052631, 0.5276315789473685, 0.5217105263157895, 0.42269736842105265, 0.5414473684210527, 0.5427631578947368, 0.5611842105263157, 0.4769736842105264, 0.5601973684210526, 0.5473684210526316, 0.5684210526315789, 0.5825657894736842, 0.574013157894737, 0.5519736842105264, 0.5601973684210526, 0.5661184210526315, 0.5598684210526315, 0.5565789473684211, 0.5190789473684211, 0.47993421052631574, 0.4990131578947368, 0.43519736842105256, 0.5476973684210525, 0.5450657894736842, 0.5608552631578948, 0.5769736842105264, 0.45394736842105265, 0.4536184210526316, 0.3875, 0.44868421052631585, 0.39342105263157895, 0.5453947368421053, 0.5480263157894736, 0.5424342105263158, 0.5039473684210527, 0.5388157894736842, 0.5, 0.5351973684210527, 0.5700657894736842, 0.5832236842105263, 0.5901315789473683, 0.5828947368421054] Best val loss: 6.274948489665985


Current group: llo_0.4_random1
Epoch [1/80], Training Loss: 29.1998, Validation Loss Current: 8.1507, Validation Loss AVG: 8.1507, lr: 0.001
Epoch [2/80], Training Loss: 23.3706, Validation Loss Current: 7.8144, Validation Loss AVG: 7.8144, lr: 0.001
Epoch [3/80], Training Loss: 20.0879, Validation Loss Current: 7.6743, Validation Loss AVG: 7.6743, lr: 0.001
Epoch [4/80], Training Loss: 15.7355, Validation Loss Current: 6.5574, Validation Loss AVG: 6.5574, lr: 0.001
Epoch [5/80], Training Loss: 14.9843, Validation Loss Current: 7.5132, Validation Loss AVG: 7.5132, lr: 0.001
Epoch [6/80], Training Loss: 12.8886, Validation Loss Current: 6.6212, Validation Loss AVG: 6.6212, lr: 0.001
Epoch [7/80], Training Loss: 11.5225, Validation Loss Current: 6.2720, Validation Loss AVG: 6.2720, lr: 0.001
Epoch [8/80], Training Loss: 13.5809, Validation Loss Current: 9.3088, Validation Loss AVG: 9.3088, lr: 0.001
Epoch [9/80], Training Loss: 14.4458, Validation Loss Current: 7.5423, Validation Loss AVG: 7.5423, lr: 0.001
Epoch [10/80], Training Loss: 14.1215, Validation Loss Current: 8.8511, Validation Loss AVG: 8.8511, lr: 0.001
Epoch [11/80], Training Loss: 11.8807, Validation Loss Current: 6.2369, Validation Loss AVG: 6.2369, lr: 0.001
Epoch [12/80], Training Loss: 11.5478, Validation Loss Current: 9.2099, Validation Loss AVG: 9.2099, lr: 0.001
Epoch [13/80], Training Loss: 11.1986, Validation Loss Current: 8.9059, Validation Loss AVG: 8.9059, lr: 0.001
Epoch [14/80], Training Loss: 9.9837, Validation Loss Current: 6.7008, Validation Loss AVG: 6.7008, lr: 0.001
Epoch [15/80], Training Loss: 12.4578, Validation Loss Current: 9.0116, Validation Loss AVG: 9.0116, lr: 0.001
Epoch [16/80], Training Loss: 10.4040, Validation Loss Current: 7.4055, Validation Loss AVG: 7.4055, lr: 0.001
Epoch [17/80], Training Loss: 8.2216, Validation Loss Current: 6.4047, Validation Loss AVG: 6.4047, lr: 0.001
Epoch [18/80], Training Loss: 4.9401, Validation Loss Current: 6.7124, Validation Loss AVG: 6.7124, lr: 0.001
Epoch [19/80], Training Loss: 8.1436, Validation Loss Current: 8.3311, Validation Loss AVG: 8.3311, lr: 0.001
Epoch [20/80], Training Loss: 6.8557, Validation Loss Current: 7.5921, Validation Loss AVG: 7.5921, lr: 0.001
Epoch [21/80], Training Loss: 3.8937, Validation Loss Current: 6.4778, Validation Loss AVG: 6.4778, lr: 0.001
Epoch [22/80], Training Loss: 6.0818, Validation Loss Current: 7.7092, Validation Loss AVG: 7.7092, lr: 0.001
Epoch [23/80], Training Loss: 7.2417, Validation Loss Current: 6.7586, Validation Loss AVG: 6.7586, lr: 0.001
Epoch [24/80], Training Loss: 6.5342, Validation Loss Current: 8.3061, Validation Loss AVG: 8.3061, lr: 0.001
Epoch [25/80], Training Loss: 7.5365, Validation Loss Current: 7.1459, Validation Loss AVG: 7.1459, lr: 0.001
Epoch [26/80], Training Loss: 4.1278, Validation Loss Current: 6.9898, Validation Loss AVG: 6.9898, lr: 0.001
Epoch [27/80], Training Loss: 4.2284, Validation Loss Current: 7.0487, Validation Loss AVG: 7.0487, lr: 0.001
Epoch [28/80], Training Loss: 4.8510, Validation Loss Current: 6.8944, Validation Loss AVG: 6.8944, lr: 0.001
Epoch [29/80], Training Loss: 4.3079, Validation Loss Current: 7.0886, Validation Loss AVG: 7.0886, lr: 0.001
Epoch [30/80], Training Loss: 4.9039, Validation Loss Current: 8.3790, Validation Loss AVG: 8.3790, lr: 0.001
Epoch [31/80], Training Loss: 5.7637, Validation Loss Current: 7.6889, Validation Loss AVG: 7.6889, lr: 0.001
Epoch [32/80], Training Loss: 3.2603, Validation Loss Current: 7.8282, Validation Loss AVG: 7.8282, lr: 0.001
Epoch [33/80], Training Loss: 5.1529, Validation Loss Current: 8.1229, Validation Loss AVG: 8.1229, lr: 0.001
Epoch [34/80], Training Loss: 4.8181, Validation Loss Current: 8.9310, Validation Loss AVG: 8.9310, lr: 0.001
Epoch [35/80], Training Loss: 5.6204, Validation Loss Current: 8.2667, Validation Loss AVG: 8.2667, lr: 0.001
Epoch [36/80], Training Loss: 5.0785, Validation Loss Current: 7.8548, Validation Loss AVG: 7.8548, lr: 0.001
Epoch [37/80], Training Loss: 4.9903, Validation Loss Current: 7.5573, Validation Loss AVG: 7.5573, lr: 0.001
Epoch [38/80], Training Loss: 5.8426, Validation Loss Current: 11.4678, Validation Loss AVG: 11.4678, lr: 0.001
Epoch [39/80], Training Loss: 4.1756, Validation Loss Current: 10.0743, Validation Loss AVG: 10.0743, lr: 0.001
Epoch [40/80], Training Loss: 6.1173, Validation Loss Current: 9.9231, Validation Loss AVG: 9.9231, lr: 0.001
Epoch [41/80], Training Loss: 4.7051, Validation Loss Current: 12.1436, Validation Loss AVG: 12.1436, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random1 finished training. Best epoch: 11 Best val accuracy: [0.506578947368421, 0.5453947368421053, 0.5200657894736842, 0.5855263157894737, 0.5381578947368422, 0.5802631578947368, 0.6203947368421052, 0.5078947368421053, 0.524671052631579, 0.5019736842105263, 0.6065789473684211, 0.5164473684210527, 0.5351973684210526, 0.5884868421052631, 0.5233552631578948, 0.5368421052631579, 0.6190789473684211, 0.6039473684210526, 0.5565789473684211, 0.5717105263157894, 0.6296052631578947, 0.5684210526315789, 0.6118421052631579, 0.5601973684210526, 0.6105263157894737, 0.6131578947368421, 0.6088815789473685, 0.6217105263157896, 0.5976973684210527, 0.587171052631579, 0.5990131578947369, 0.600328947368421, 0.5700657894736841, 0.5868421052631578, 0.5904605263157896, 0.5963815789473684, 0.6042763157894736, 0.5082236842105263, 0.550657894736842, 0.5483552631578947, 0.4773026315789474] Best val loss: 6.236901891231537


Current group: llo_0.4_random2
Epoch [1/80], Training Loss: 34.7622, Validation Loss Current: 8.0191, Validation Loss AVG: 8.0191, lr: 0.001
Epoch [2/80], Training Loss: 24.9143, Validation Loss Current: 6.1313, Validation Loss AVG: 6.1313, lr: 0.001
Epoch [3/80], Training Loss: 17.6367, Validation Loss Current: 5.8167, Validation Loss AVG: 5.8167, lr: 0.001
Epoch [4/80], Training Loss: 13.7467, Validation Loss Current: 7.2024, Validation Loss AVG: 7.2024, lr: 0.001
Epoch [5/80], Training Loss: 11.8892, Validation Loss Current: 6.3003, Validation Loss AVG: 6.3003, lr: 0.001
Epoch [6/80], Training Loss: 8.6788, Validation Loss Current: 5.7593, Validation Loss AVG: 5.7593, lr: 0.001
Epoch [7/80], Training Loss: 6.2189, Validation Loss Current: 5.5317, Validation Loss AVG: 5.5317, lr: 0.001
Epoch [8/80], Training Loss: 6.6474, Validation Loss Current: 5.7841, Validation Loss AVG: 5.7841, lr: 0.001
Epoch [9/80], Training Loss: 4.3354, Validation Loss Current: 5.3234, Validation Loss AVG: 5.3234, lr: 0.001
Epoch [10/80], Training Loss: 5.1790, Validation Loss Current: 5.2250, Validation Loss AVG: 5.2250, lr: 0.001
Epoch [11/80], Training Loss: 9.4564, Validation Loss Current: 7.5458, Validation Loss AVG: 7.5458, lr: 0.001
Epoch [12/80], Training Loss: 7.2782, Validation Loss Current: 7.2112, Validation Loss AVG: 7.2112, lr: 0.001
Epoch [13/80], Training Loss: 6.4078, Validation Loss Current: 5.9280, Validation Loss AVG: 5.9280, lr: 0.001
Epoch [14/80], Training Loss: 3.9632, Validation Loss Current: 5.5848, Validation Loss AVG: 5.5848, lr: 0.001
Epoch [15/80], Training Loss: 5.2591, Validation Loss Current: 6.2619, Validation Loss AVG: 6.2619, lr: 0.001
Epoch [16/80], Training Loss: 3.6653, Validation Loss Current: 6.1613, Validation Loss AVG: 6.1613, lr: 0.001
Epoch [17/80], Training Loss: 4.1583, Validation Loss Current: 6.2558, Validation Loss AVG: 6.2558, lr: 0.001
Epoch [18/80], Training Loss: 6.9948, Validation Loss Current: 7.2419, Validation Loss AVG: 7.2419, lr: 0.001
Epoch [19/80], Training Loss: 5.7238, Validation Loss Current: 6.3087, Validation Loss AVG: 6.3087, lr: 0.001
Epoch [20/80], Training Loss: 5.1190, Validation Loss Current: 6.7062, Validation Loss AVG: 6.7062, lr: 0.001
Epoch [21/80], Training Loss: 9.3562, Validation Loss Current: 6.6451, Validation Loss AVG: 6.6451, lr: 0.001
Epoch [22/80], Training Loss: 3.6629, Validation Loss Current: 7.0503, Validation Loss AVG: 7.0503, lr: 0.001
Epoch [23/80], Training Loss: 7.8437, Validation Loss Current: 9.9694, Validation Loss AVG: 9.9694, lr: 0.001
Epoch [24/80], Training Loss: 9.6629, Validation Loss Current: 8.9756, Validation Loss AVG: 8.9756, lr: 0.001
Epoch [25/80], Training Loss: 11.2791, Validation Loss Current: 9.6262, Validation Loss AVG: 9.6262, lr: 0.001
Epoch [26/80], Training Loss: 5.9418, Validation Loss Current: 8.7691, Validation Loss AVG: 8.7691, lr: 0.001
Epoch [27/80], Training Loss: 5.7311, Validation Loss Current: 6.8130, Validation Loss AVG: 6.8130, lr: 0.001
Epoch [28/80], Training Loss: 6.9486, Validation Loss Current: 7.4945, Validation Loss AVG: 7.4945, lr: 0.001
Epoch [29/80], Training Loss: 7.3093, Validation Loss Current: 8.0846, Validation Loss AVG: 8.0846, lr: 0.001
Epoch [30/80], Training Loss: 4.5492, Validation Loss Current: 7.9962, Validation Loss AVG: 7.9962, lr: 0.001
Epoch [31/80], Training Loss: 3.8534, Validation Loss Current: 7.9764, Validation Loss AVG: 7.9764, lr: 0.001
Epoch [32/80], Training Loss: 6.0638, Validation Loss Current: 7.0666, Validation Loss AVG: 7.0666, lr: 0.001
Epoch [33/80], Training Loss: 3.5648, Validation Loss Current: 6.9362, Validation Loss AVG: 6.9362, lr: 0.001
Epoch [34/80], Training Loss: 1.8767, Validation Loss Current: 6.3481, Validation Loss AVG: 6.3481, lr: 0.001
Epoch [35/80], Training Loss: 1.4563, Validation Loss Current: 6.6741, Validation Loss AVG: 6.6741, lr: 0.001
Epoch [36/80], Training Loss: 1.2007, Validation Loss Current: 6.6500, Validation Loss AVG: 6.6500, lr: 0.001
Epoch [37/80], Training Loss: 0.9327, Validation Loss Current: 6.4352, Validation Loss AVG: 6.4352, lr: 0.001
Epoch [38/80], Training Loss: 1.1761, Validation Loss Current: 6.7120, Validation Loss AVG: 6.7120, lr: 0.001
Epoch [39/80], Training Loss: 2.6371, Validation Loss Current: 6.9928, Validation Loss AVG: 6.9928, lr: 0.001
Epoch [40/80], Training Loss: 3.8317, Validation Loss Current: 7.6727, Validation Loss AVG: 7.6727, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random2 finished training. Best epoch: 10 Best val accuracy: [0.593421052631579, 0.6180921052631578, 0.6342105263157894, 0.5888157894736843, 0.631578947368421, 0.6532894736842105, 0.6792763157894737, 0.6671052631578949, 0.6898026315789474, 0.6917763157894736, 0.5648026315789474, 0.6161184210526316, 0.6608552631578947, 0.6782894736842106, 0.6434210526315789, 0.6651315789473685, 0.6667763157894737, 0.6243421052631579, 0.6615131578947369, 0.6592105263157896, 0.6424342105263158, 0.6292763157894739, 0.5588815789473685, 0.5786184210526316, 0.5634868421052632, 0.5717105263157894, 0.6230263157894737, 0.6154605263157895, 0.5868421052631578, 0.6095394736842106, 0.6230263157894738, 0.6483552631578947, 0.6394736842105263, 0.6690789473684211, 0.6753289473684211, 0.6733552631578947, 0.6713815789473684, 0.6680921052631579, 0.6506578947368421, 0.6138157894736842] Best val loss: 5.224983644485474


Current group: llo_0.4_random3
Epoch [1/80], Training Loss: 33.2568, Validation Loss Current: 6.9091, Validation Loss AVG: 6.9091, lr: 0.001
Epoch [2/80], Training Loss: 17.5445, Validation Loss Current: 6.0433, Validation Loss AVG: 6.0433, lr: 0.001
Epoch [3/80], Training Loss: 12.3058, Validation Loss Current: 6.5666, Validation Loss AVG: 6.5666, lr: 0.001
Epoch [4/80], Training Loss: 9.3091, Validation Loss Current: 5.8687, Validation Loss AVG: 5.8687, lr: 0.001
Epoch [5/80], Training Loss: 8.6251, Validation Loss Current: 5.8603, Validation Loss AVG: 5.8603, lr: 0.001
Epoch [6/80], Training Loss: 8.9869, Validation Loss Current: 5.4618, Validation Loss AVG: 5.4618, lr: 0.001
Epoch [7/80], Training Loss: 9.3465, Validation Loss Current: 9.6140, Validation Loss AVG: 9.6140, lr: 0.001
Epoch [8/80], Training Loss: 13.5987, Validation Loss Current: 7.0588, Validation Loss AVG: 7.0588, lr: 0.001
Epoch [9/80], Training Loss: 7.7853, Validation Loss Current: 5.8958, Validation Loss AVG: 5.8958, lr: 0.001
Epoch [10/80], Training Loss: 3.6933, Validation Loss Current: 5.2013, Validation Loss AVG: 5.2013, lr: 0.001
Epoch [11/80], Training Loss: 3.1179, Validation Loss Current: 6.1204, Validation Loss AVG: 6.1204, lr: 0.001
Epoch [12/80], Training Loss: 5.0006, Validation Loss Current: 6.6713, Validation Loss AVG: 6.6713, lr: 0.001
Epoch [13/80], Training Loss: 5.5531, Validation Loss Current: 8.2348, Validation Loss AVG: 8.2348, lr: 0.001
Epoch [14/80], Training Loss: 7.1917, Validation Loss Current: 9.4395, Validation Loss AVG: 9.4395, lr: 0.001
Epoch [15/80], Training Loss: 9.3932, Validation Loss Current: 6.9965, Validation Loss AVG: 6.9965, lr: 0.001
Epoch [16/80], Training Loss: 7.6544, Validation Loss Current: 6.7304, Validation Loss AVG: 6.7304, lr: 0.001
Epoch [17/80], Training Loss: 7.7894, Validation Loss Current: 6.1939, Validation Loss AVG: 6.1939, lr: 0.001
Epoch [18/80], Training Loss: 8.8560, Validation Loss Current: 6.6199, Validation Loss AVG: 6.6199, lr: 0.001
Epoch [19/80], Training Loss: 7.0366, Validation Loss Current: 6.2213, Validation Loss AVG: 6.2213, lr: 0.001
Epoch [20/80], Training Loss: 3.6997, Validation Loss Current: 6.5107, Validation Loss AVG: 6.5107, lr: 0.001
Epoch [21/80], Training Loss: 4.4006, Validation Loss Current: 6.2784, Validation Loss AVG: 6.2784, lr: 0.001
Epoch [22/80], Training Loss: 6.8378, Validation Loss Current: 7.1212, Validation Loss AVG: 7.1212, lr: 0.001
Epoch [23/80], Training Loss: 5.6860, Validation Loss Current: 6.8714, Validation Loss AVG: 6.8714, lr: 0.001
Epoch [24/80], Training Loss: 7.7077, Validation Loss Current: 6.9987, Validation Loss AVG: 6.9987, lr: 0.001
Epoch [25/80], Training Loss: 7.1053, Validation Loss Current: 9.6208, Validation Loss AVG: 9.6208, lr: 0.001
Epoch [26/80], Training Loss: 7.2687, Validation Loss Current: 7.5253, Validation Loss AVG: 7.5253, lr: 0.001
Epoch [27/80], Training Loss: 6.1120, Validation Loss Current: 7.6310, Validation Loss AVG: 7.6310, lr: 0.001
Epoch [28/80], Training Loss: 4.2395, Validation Loss Current: 7.6911, Validation Loss AVG: 7.6911, lr: 0.001
Epoch [29/80], Training Loss: 5.6388, Validation Loss Current: 6.8837, Validation Loss AVG: 6.8837, lr: 0.001
Epoch [30/80], Training Loss: 3.5917, Validation Loss Current: 7.1748, Validation Loss AVG: 7.1748, lr: 0.001
Epoch [31/80], Training Loss: 2.4561, Validation Loss Current: 7.2708, Validation Loss AVG: 7.2708, lr: 0.001
Epoch [32/80], Training Loss: 4.0064, Validation Loss Current: 6.7601, Validation Loss AVG: 6.7601, lr: 0.001
Epoch [33/80], Training Loss: 2.6671, Validation Loss Current: 6.8310, Validation Loss AVG: 6.8310, lr: 0.001
Epoch [34/80], Training Loss: 4.5379, Validation Loss Current: 9.0235, Validation Loss AVG: 9.0235, lr: 0.001
Epoch [35/80], Training Loss: 7.6614, Validation Loss Current: 8.5885, Validation Loss AVG: 8.5885, lr: 0.001
Epoch [36/80], Training Loss: 6.6134, Validation Loss Current: 9.3825, Validation Loss AVG: 9.3825, lr: 0.001
Epoch [37/80], Training Loss: 3.5915, Validation Loss Current: 7.6625, Validation Loss AVG: 7.6625, lr: 0.001
Epoch [38/80], Training Loss: 3.2010, Validation Loss Current: 6.9819, Validation Loss AVG: 6.9819, lr: 0.001
Epoch [39/80], Training Loss: 4.5718, Validation Loss Current: 8.0869, Validation Loss AVG: 8.0869, lr: 0.001
Epoch [40/80], Training Loss: 5.9389, Validation Loss Current: 9.7592, Validation Loss AVG: 9.7592, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random3 finished training. Best epoch: 10 Best val accuracy: [0.6194078947368422, 0.6572368421052631, 0.6134868421052632, 0.6730263157894737, 0.6608552631578948, 0.6759868421052632, 0.5786184210526315, 0.6095394736842106, 0.6769736842105264, 0.7072368421052632, 0.6766447368421052, 0.6434210526315789, 0.5990131578947369, 0.5332236842105263, 0.6345394736842105, 0.6375, 0.6621710526315789, 0.630592105263158, 0.6618421052631579, 0.6569078947368421, 0.6638157894736841, 0.6223684210526316, 0.6493421052631578, 0.6470394736842106, 0.5667763157894737, 0.6029605263157893, 0.6286184210526315, 0.5960526315789474, 0.6328947368421053, 0.6286184210526315, 0.65, 0.6555921052631579, 0.6532894736842106, 0.5911184210526315, 0.6108552631578947, 0.5671052631578947, 0.625, 0.6434210526315789, 0.6098684210526316, 0.5717105263157894] Best val loss: 5.2013277292251585


Current group: 0.4
Epoch [1/80], Training Loss: 43.1094, Validation Loss Current: 8.9253, Validation Loss AVG: 8.9253, lr: 0.001
Epoch [2/80], Training Loss: 20.6866, Validation Loss Current: 6.9281, Validation Loss AVG: 6.9281, lr: 0.001
Epoch [3/80], Training Loss: 13.3156, Validation Loss Current: 7.6247, Validation Loss AVG: 7.6247, lr: 0.001
Epoch [4/80], Training Loss: 11.0934, Validation Loss Current: 8.0581, Validation Loss AVG: 8.0581, lr: 0.001
Epoch [5/80], Training Loss: 8.7438, Validation Loss Current: 7.9006, Validation Loss AVG: 7.9006, lr: 0.001
Epoch [6/80], Training Loss: 7.5429, Validation Loss Current: 8.5705, Validation Loss AVG: 8.5705, lr: 0.001
Epoch [7/80], Training Loss: 5.8046, Validation Loss Current: 6.9031, Validation Loss AVG: 6.9031, lr: 0.001
Epoch [8/80], Training Loss: 4.0521, Validation Loss Current: 7.9591, Validation Loss AVG: 7.9591, lr: 0.001
Epoch [9/80], Training Loss: 3.1299, Validation Loss Current: 8.1919, Validation Loss AVG: 8.1919, lr: 0.001
Epoch [10/80], Training Loss: 2.4940, Validation Loss Current: 7.3615, Validation Loss AVG: 7.3615, lr: 0.001
Epoch [11/80], Training Loss: 2.4820, Validation Loss Current: 8.2874, Validation Loss AVG: 8.2874, lr: 0.001
Epoch [12/80], Training Loss: 2.8282, Validation Loss Current: 8.3940, Validation Loss AVG: 8.3940, lr: 0.001
Epoch [13/80], Training Loss: 5.2790, Validation Loss Current: 11.9247, Validation Loss AVG: 11.9247, lr: 0.001
Epoch [14/80], Training Loss: 6.0326, Validation Loss Current: 10.2028, Validation Loss AVG: 10.2028, lr: 0.001
Epoch [15/80], Training Loss: 10.5874, Validation Loss Current: 10.2535, Validation Loss AVG: 10.2535, lr: 0.001
Epoch [16/80], Training Loss: 5.8895, Validation Loss Current: 9.7060, Validation Loss AVG: 9.7060, lr: 0.001
Epoch [17/80], Training Loss: 5.0315, Validation Loss Current: 9.2048, Validation Loss AVG: 9.2048, lr: 0.001
Epoch [18/80], Training Loss: 5.4679, Validation Loss Current: 11.7272, Validation Loss AVG: 11.7272, lr: 0.001
Epoch [19/80], Training Loss: 2.9589, Validation Loss Current: 8.4168, Validation Loss AVG: 8.4168, lr: 0.001
Epoch [20/80], Training Loss: 1.7549, Validation Loss Current: 8.8646, Validation Loss AVG: 8.8646, lr: 0.001
Epoch [21/80], Training Loss: 0.9168, Validation Loss Current: 8.9995, Validation Loss AVG: 8.9995, lr: 0.001
Epoch [22/80], Training Loss: 2.5477, Validation Loss Current: 8.6226, Validation Loss AVG: 8.6226, lr: 0.001
Epoch [23/80], Training Loss: 5.6159, Validation Loss Current: 10.4637, Validation Loss AVG: 10.4637, lr: 0.001
Epoch [24/80], Training Loss: 6.5634, Validation Loss Current: 10.6276, Validation Loss AVG: 10.6276, lr: 0.001
Epoch [25/80], Training Loss: 5.8356, Validation Loss Current: 10.7136, Validation Loss AVG: 10.7136, lr: 0.001
Epoch [26/80], Training Loss: 10.5459, Validation Loss Current: 10.5269, Validation Loss AVG: 10.5269, lr: 0.001
Epoch [27/80], Training Loss: 4.1332, Validation Loss Current: 9.0286, Validation Loss AVG: 9.0286, lr: 0.001
Epoch [28/80], Training Loss: 2.2143, Validation Loss Current: 9.4071, Validation Loss AVG: 9.4071, lr: 0.001
Epoch [29/80], Training Loss: 4.5200, Validation Loss Current: 9.1604, Validation Loss AVG: 9.1604, lr: 0.001
Epoch [30/80], Training Loss: 6.1531, Validation Loss Current: 10.8057, Validation Loss AVG: 10.8057, lr: 0.001
Epoch [31/80], Training Loss: 4.1343, Validation Loss Current: 10.6589, Validation Loss AVG: 10.6589, lr: 0.001
Epoch [32/80], Training Loss: 2.9864, Validation Loss Current: 8.9868, Validation Loss AVG: 8.9868, lr: 0.001
Epoch [33/80], Training Loss: 2.6170, Validation Loss Current: 9.9428, Validation Loss AVG: 9.9428, lr: 0.001
Epoch [34/80], Training Loss: 1.3683, Validation Loss Current: 9.4849, Validation Loss AVG: 9.4849, lr: 0.001
Epoch [35/80], Training Loss: 1.2886, Validation Loss Current: 8.7110, Validation Loss AVG: 8.7110, lr: 0.001
Epoch [36/80], Training Loss: 1.6391, Validation Loss Current: 10.4409, Validation Loss AVG: 10.4409, lr: 0.001
Epoch [37/80], Training Loss: 3.1375, Validation Loss Current: 9.5598, Validation Loss AVG: 9.5598, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 7 Best val accuracy: [0.556907894736842, 0.5822368421052632, 0.569078947368421, 0.5611842105263158, 0.5684210526315789, 0.5450657894736842, 0.6115131578947368, 0.5884868421052631, 0.5578947368421053, 0.6065789473684211, 0.575, 0.5815789473684211, 0.46907894736842104, 0.5256578947368421, 0.5335526315789474, 0.5631578947368421, 0.5473684210526316, 0.4677631578947368, 0.56875, 0.5664473684210526, 0.5674342105263158, 0.58125, 0.5509868421052632, 0.5098684210526316, 0.5286184210526316, 0.5069078947368422, 0.562171052631579, 0.5555921052631578, 0.5641447368421053, 0.5269736842105264, 0.537828947368421, 0.5582236842105263, 0.5381578947368422, 0.5398026315789474, 0.5611842105263158, 0.525, 0.5460526315789475] Best val loss: 6.903137159347534


----- Training resnet18 with sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] -----
Current group: llo_0.6_random0
Epoch [1/80], Training Loss: 40.9835, Validation Loss Current: 10.0144, Validation Loss AVG: 10.0144, lr: 0.001
Epoch [2/80], Training Loss: 39.2575, Validation Loss Current: 9.7999, Validation Loss AVG: 9.7999, lr: 0.001
Epoch [3/80], Training Loss: 38.9528, Validation Loss Current: 9.6764, Validation Loss AVG: 9.6764, lr: 0.001
Epoch [4/80], Training Loss: 38.2074, Validation Loss Current: 9.4843, Validation Loss AVG: 9.4843, lr: 0.001
Epoch [5/80], Training Loss: 37.5232, Validation Loss Current: 9.2953, Validation Loss AVG: 9.2953, lr: 0.001
Epoch [6/80], Training Loss: 36.5475, Validation Loss Current: 8.9513, Validation Loss AVG: 8.9513, lr: 0.001
Epoch [7/80], Training Loss: 35.3389, Validation Loss Current: 8.9882, Validation Loss AVG: 8.9882, lr: 0.001
Epoch [8/80], Training Loss: 34.7291, Validation Loss Current: 8.8730, Validation Loss AVG: 8.8730, lr: 0.001
Epoch [9/80], Training Loss: 34.1775, Validation Loss Current: 8.5408, Validation Loss AVG: 8.5408, lr: 0.001
Epoch [10/80], Training Loss: 32.5959, Validation Loss Current: 8.3988, Validation Loss AVG: 8.3988, lr: 0.001
Epoch [11/80], Training Loss: 32.0078, Validation Loss Current: 8.2843, Validation Loss AVG: 8.2843, lr: 0.001
Epoch [12/80], Training Loss: 32.1379, Validation Loss Current: 8.2160, Validation Loss AVG: 8.2160, lr: 0.001
Epoch [13/80], Training Loss: 31.0776, Validation Loss Current: 8.0553, Validation Loss AVG: 8.0553, lr: 0.001
Epoch [14/80], Training Loss: 30.8631, Validation Loss Current: 7.8472, Validation Loss AVG: 7.8472, lr: 0.001
Epoch [15/80], Training Loss: 29.0290, Validation Loss Current: 7.8869, Validation Loss AVG: 7.8869, lr: 0.001
Epoch [16/80], Training Loss: 28.1539, Validation Loss Current: 8.2829, Validation Loss AVG: 8.2829, lr: 0.001
Epoch [17/80], Training Loss: 28.1244, Validation Loss Current: 7.7020, Validation Loss AVG: 7.7020, lr: 0.001
Epoch [18/80], Training Loss: 27.4349, Validation Loss Current: 7.7775, Validation Loss AVG: 7.7775, lr: 0.001
Epoch [19/80], Training Loss: 26.2134, Validation Loss Current: 7.5117, Validation Loss AVG: 7.5117, lr: 0.001
Epoch [20/80], Training Loss: 26.0330, Validation Loss Current: 7.8964, Validation Loss AVG: 7.8964, lr: 0.001
Epoch [21/80], Training Loss: 25.7930, Validation Loss Current: 7.7973, Validation Loss AVG: 7.7973, lr: 0.001
Epoch [22/80], Training Loss: 24.6740, Validation Loss Current: 7.8453, Validation Loss AVG: 7.8453, lr: 0.001
Epoch [23/80], Training Loss: 24.7789, Validation Loss Current: 8.8462, Validation Loss AVG: 8.8462, lr: 0.001
Epoch [24/80], Training Loss: 26.0124, Validation Loss Current: 7.8894, Validation Loss AVG: 7.8894, lr: 0.001
Epoch [25/80], Training Loss: 23.7626, Validation Loss Current: 7.3226, Validation Loss AVG: 7.3226, lr: 0.001
Epoch [26/80], Training Loss: 23.0186, Validation Loss Current: 7.0576, Validation Loss AVG: 7.0576, lr: 0.001
Epoch [27/80], Training Loss: 22.0854, Validation Loss Current: 7.0075, Validation Loss AVG: 7.0075, lr: 0.001
Epoch [28/80], Training Loss: 20.7845, Validation Loss Current: 7.6492, Validation Loss AVG: 7.6492, lr: 0.001
Epoch [29/80], Training Loss: 19.4952, Validation Loss Current: 6.8747, Validation Loss AVG: 6.8747, lr: 0.001
Epoch [30/80], Training Loss: 18.4661, Validation Loss Current: 7.9979, Validation Loss AVG: 7.9979, lr: 0.001
Epoch [31/80], Training Loss: 18.5348, Validation Loss Current: 7.1600, Validation Loss AVG: 7.1600, lr: 0.001
Epoch [32/80], Training Loss: 18.0409, Validation Loss Current: 7.0213, Validation Loss AVG: 7.0213, lr: 0.001
Epoch [33/80], Training Loss: 17.2343, Validation Loss Current: 6.8882, Validation Loss AVG: 6.8882, lr: 0.001
Epoch [34/80], Training Loss: 16.1551, Validation Loss Current: 6.6055, Validation Loss AVG: 6.6055, lr: 0.001
Epoch [35/80], Training Loss: 12.9056, Validation Loss Current: 6.7796, Validation Loss AVG: 6.7796, lr: 0.001
Epoch [36/80], Training Loss: 11.8159, Validation Loss Current: 6.9158, Validation Loss AVG: 6.9158, lr: 0.001
Epoch [37/80], Training Loss: 14.0223, Validation Loss Current: 7.0311, Validation Loss AVG: 7.0311, lr: 0.001
Epoch [38/80], Training Loss: 14.3828, Validation Loss Current: 7.5215, Validation Loss AVG: 7.5215, lr: 0.001
Epoch [39/80], Training Loss: 13.2454, Validation Loss Current: 7.3492, Validation Loss AVG: 7.3492, lr: 0.001
Epoch [40/80], Training Loss: 13.8225, Validation Loss Current: 7.2082, Validation Loss AVG: 7.2082, lr: 0.001
Epoch [41/80], Training Loss: 10.9137, Validation Loss Current: 7.7147, Validation Loss AVG: 7.7147, lr: 0.001
Epoch [42/80], Training Loss: 14.6017, Validation Loss Current: 7.5268, Validation Loss AVG: 7.5268, lr: 0.001
Epoch [43/80], Training Loss: 12.6011, Validation Loss Current: 8.1018, Validation Loss AVG: 8.1018, lr: 0.001
Epoch [44/80], Training Loss: 12.2633, Validation Loss Current: 7.6037, Validation Loss AVG: 7.6037, lr: 0.001
Epoch [45/80], Training Loss: 13.4062, Validation Loss Current: 7.6124, Validation Loss AVG: 7.6124, lr: 0.001
Epoch [46/80], Training Loss: 12.4245, Validation Loss Current: 7.1961, Validation Loss AVG: 7.1961, lr: 0.001
Epoch [47/80], Training Loss: 9.5111, Validation Loss Current: 7.0582, Validation Loss AVG: 7.0582, lr: 0.001
Epoch [48/80], Training Loss: 9.5345, Validation Loss Current: 7.9317, Validation Loss AVG: 7.9317, lr: 0.001
Epoch [49/80], Training Loss: 8.4725, Validation Loss Current: 7.7076, Validation Loss AVG: 7.7076, lr: 0.001
Epoch [50/80], Training Loss: 10.6470, Validation Loss Current: 8.0594, Validation Loss AVG: 8.0594, lr: 0.001
Epoch [51/80], Training Loss: 13.5644, Validation Loss Current: 9.1599, Validation Loss AVG: 9.1599, lr: 0.001
Epoch [52/80], Training Loss: 11.1384, Validation Loss Current: 8.2051, Validation Loss AVG: 8.2051, lr: 0.001
Epoch [53/80], Training Loss: 8.4276, Validation Loss Current: 8.0859, Validation Loss AVG: 8.0859, lr: 0.001
Epoch [54/80], Training Loss: 7.5245, Validation Loss Current: 7.5123, Validation Loss AVG: 7.5123, lr: 0.001
Epoch [55/80], Training Loss: 6.3466, Validation Loss Current: 7.1087, Validation Loss AVG: 7.1087, lr: 0.001
Epoch [56/80], Training Loss: 6.1840, Validation Loss Current: 7.2154, Validation Loss AVG: 7.2154, lr: 0.001
Epoch [57/80], Training Loss: 5.8631, Validation Loss Current: 9.5229, Validation Loss AVG: 9.5229, lr: 0.001
Epoch [58/80], Training Loss: 13.9590, Validation Loss Current: 9.0571, Validation Loss AVG: 9.0571, lr: 0.001
Epoch [59/80], Training Loss: 10.3250, Validation Loss Current: 8.4173, Validation Loss AVG: 8.4173, lr: 0.001
Epoch [60/80], Training Loss: 8.6298, Validation Loss Current: 7.7813, Validation Loss AVG: 7.7813, lr: 0.001
Epoch [61/80], Training Loss: 7.4271, Validation Loss Current: 8.2875, Validation Loss AVG: 8.2875, lr: 0.001
Epoch [62/80], Training Loss: 12.2850, Validation Loss Current: 10.0300, Validation Loss AVG: 10.0300, lr: 0.001
Epoch [63/80], Training Loss: 13.0868, Validation Loss Current: 8.7204, Validation Loss AVG: 8.7204, lr: 0.001
Epoch [64/80], Training Loss: 9.3645, Validation Loss Current: 9.7254, Validation Loss AVG: 9.7254, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random0 finished training. Best epoch: 34 Best val accuracy: [0.23322368421052633, 0.2552631578947368, 0.2740131578947368, 0.2875, 0.3111842105263158, 0.350328947368421, 0.32894736842105265, 0.3559210526315789, 0.3625, 0.380921052631579, 0.4164473684210527, 0.4118421052631579, 0.41875, 0.4552631578947368, 0.4391447368421052, 0.42828947368421055, 0.4513157894736842, 0.4384868421052632, 0.46085526315789477, 0.4444078947368421, 0.4473684210526316, 0.4549342105263158, 0.37993421052631576, 0.44506578947368425, 0.4894736842105263, 0.4934210526315789, 0.5121710526315789, 0.46677631578947365, 0.5256578947368421, 0.45789473684210524, 0.5118421052631579, 0.5144736842105263, 0.5296052631578948, 0.5532894736842106, 0.5542763157894737, 0.5342105263157895, 0.5486842105263158, 0.5151315789473684, 0.5108552631578948, 0.5358552631578947, 0.50625, 0.53125, 0.48848684210526316, 0.5286184210526317, 0.5118421052631579, 0.5542763157894737, 0.5523026315789473, 0.5302631578947369, 0.5174342105263158, 0.5230263157894737, 0.4618421052631579, 0.5226973684210525, 0.5388157894736842, 0.5552631578947368, 0.5776315789473684, 0.58125, 0.5095394736842105, 0.4733552631578948, 0.5351973684210527, 0.544078947368421, 0.5417763157894737, 0.5019736842105263, 0.5167763157894737, 0.47269736842105264] Best val loss: 6.605500411987305


Current group: llo_0.6_random1
Epoch [1/80], Training Loss: 31.7717, Validation Loss Current: 9.4456, Validation Loss AVG: 9.4456, lr: 0.001
Epoch [2/80], Training Loss: 25.6650, Validation Loss Current: 7.4012, Validation Loss AVG: 7.4012, lr: 0.001
Epoch [3/80], Training Loss: 17.9615, Validation Loss Current: 5.9573, Validation Loss AVG: 5.9573, lr: 0.001
Epoch [4/80], Training Loss: 14.2209, Validation Loss Current: 6.1944, Validation Loss AVG: 6.1944, lr: 0.001
Epoch [5/80], Training Loss: 11.8331, Validation Loss Current: 6.5321, Validation Loss AVG: 6.5321, lr: 0.001
Epoch [6/80], Training Loss: 12.9415, Validation Loss Current: 8.1456, Validation Loss AVG: 8.1456, lr: 0.001
Epoch [7/80], Training Loss: 14.1763, Validation Loss Current: 7.7961, Validation Loss AVG: 7.7961, lr: 0.001
Epoch [8/80], Training Loss: 18.9177, Validation Loss Current: 9.2496, Validation Loss AVG: 9.2496, lr: 0.001
Epoch [9/80], Training Loss: 11.6231, Validation Loss Current: 6.2114, Validation Loss AVG: 6.2114, lr: 0.001
Epoch [10/80], Training Loss: 10.6989, Validation Loss Current: 6.4399, Validation Loss AVG: 6.4399, lr: 0.001
Epoch [11/80], Training Loss: 8.2299, Validation Loss Current: 6.9089, Validation Loss AVG: 6.9089, lr: 0.001
Epoch [12/80], Training Loss: 6.0137, Validation Loss Current: 6.4964, Validation Loss AVG: 6.4964, lr: 0.001
Epoch [13/80], Training Loss: 4.2358, Validation Loss Current: 5.9190, Validation Loss AVG: 5.9190, lr: 0.001
Epoch [14/80], Training Loss: 5.5480, Validation Loss Current: 7.2433, Validation Loss AVG: 7.2433, lr: 0.001
Epoch [15/80], Training Loss: 9.2562, Validation Loss Current: 6.7490, Validation Loss AVG: 6.7490, lr: 0.001
Epoch [16/80], Training Loss: 5.5607, Validation Loss Current: 7.3616, Validation Loss AVG: 7.3616, lr: 0.001
Epoch [17/80], Training Loss: 6.8410, Validation Loss Current: 7.5277, Validation Loss AVG: 7.5277, lr: 0.001
Epoch [18/80], Training Loss: 4.9710, Validation Loss Current: 6.8750, Validation Loss AVG: 6.8750, lr: 0.001
Epoch [19/80], Training Loss: 4.1907, Validation Loss Current: 8.2844, Validation Loss AVG: 8.2844, lr: 0.001
Epoch [20/80], Training Loss: 5.6560, Validation Loss Current: 8.6483, Validation Loss AVG: 8.6483, lr: 0.001
Epoch [21/80], Training Loss: 7.8086, Validation Loss Current: 8.0614, Validation Loss AVG: 8.0614, lr: 0.001
Epoch [22/80], Training Loss: 7.2216, Validation Loss Current: 8.0853, Validation Loss AVG: 8.0853, lr: 0.001
Epoch [23/80], Training Loss: 6.6969, Validation Loss Current: 8.3940, Validation Loss AVG: 8.3940, lr: 0.001
Epoch [24/80], Training Loss: 7.7044, Validation Loss Current: 8.2042, Validation Loss AVG: 8.2042, lr: 0.001
Epoch [25/80], Training Loss: 5.7137, Validation Loss Current: 7.8627, Validation Loss AVG: 7.8627, lr: 0.001
Epoch [26/80], Training Loss: 5.2211, Validation Loss Current: 7.9701, Validation Loss AVG: 7.9701, lr: 0.001
Epoch [27/80], Training Loss: 6.6852, Validation Loss Current: 9.8822, Validation Loss AVG: 9.8822, lr: 0.001
Epoch [28/80], Training Loss: 6.3419, Validation Loss Current: 8.6211, Validation Loss AVG: 8.6211, lr: 0.001
Epoch [29/80], Training Loss: 4.9745, Validation Loss Current: 8.8666, Validation Loss AVG: 8.8666, lr: 0.001
Epoch [30/80], Training Loss: 5.2851, Validation Loss Current: 8.6853, Validation Loss AVG: 8.6853, lr: 0.001
Epoch [31/80], Training Loss: 3.7187, Validation Loss Current: 8.7069, Validation Loss AVG: 8.7069, lr: 0.001
Epoch [32/80], Training Loss: 2.4632, Validation Loss Current: 7.3815, Validation Loss AVG: 7.3815, lr: 0.001
Epoch [33/80], Training Loss: 2.4973, Validation Loss Current: 8.0166, Validation Loss AVG: 8.0166, lr: 0.001
Epoch [34/80], Training Loss: 3.5349, Validation Loss Current: 13.0573, Validation Loss AVG: 13.0573, lr: 0.001
Epoch [35/80], Training Loss: 6.4995, Validation Loss Current: 9.6806, Validation Loss AVG: 9.6806, lr: 0.001
Epoch [36/80], Training Loss: 10.6062, Validation Loss Current: 10.1550, Validation Loss AVG: 10.1550, lr: 0.001
Epoch [37/80], Training Loss: 6.1351, Validation Loss Current: 7.9093, Validation Loss AVG: 7.9093, lr: 0.001
Epoch [38/80], Training Loss: 4.7958, Validation Loss Current: 9.4571, Validation Loss AVG: 9.4571, lr: 0.001
Epoch [39/80], Training Loss: 6.4023, Validation Loss Current: 9.5703, Validation Loss AVG: 9.5703, lr: 0.001
Epoch [40/80], Training Loss: 12.6542, Validation Loss Current: 10.8810, Validation Loss AVG: 10.8810, lr: 0.001
Epoch [41/80], Training Loss: 8.9732, Validation Loss Current: 13.3705, Validation Loss AVG: 13.3705, lr: 0.001
Epoch [42/80], Training Loss: 6.3097, Validation Loss Current: 7.7826, Validation Loss AVG: 7.7826, lr: 0.001
Epoch [43/80], Training Loss: 3.4356, Validation Loss Current: 7.6255, Validation Loss AVG: 7.6255, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random1 finished training. Best epoch: 13 Best val accuracy: [0.4516447368421053, 0.5286184210526316, 0.5993421052631579, 0.6009868421052632, 0.5789473684210528, 0.5263157894736842, 0.5430921052631579, 0.5, 0.600328947368421, 0.6111842105263158, 0.5970394736842105, 0.6049342105263158, 0.6486842105263158, 0.5842105263157895, 0.5868421052631579, 0.6006578947368421, 0.5835526315789473, 0.5983552631578947, 0.5796052631578947, 0.5855263157894737, 0.5937500000000001, 0.5848684210526316, 0.5904605263157894, 0.5819078947368421, 0.5953947368421053, 0.5970394736842105, 0.5513157894736842, 0.550657894736842, 0.5457236842105264, 0.5506578947368421, 0.5855263157894737, 0.6049342105263158, 0.6016447368421052, 0.46546052631578955, 0.5555921052631578, 0.5217105263157895, 0.5861842105263158, 0.5490131578947368, 0.5447368421052632, 0.4677631578947368, 0.45065789473684215, 0.582236842105263, 0.6059210526315789] Best val loss: 5.919034075737


Current group: llo_0.6_random2
Epoch [1/80], Training Loss: 34.7524, Validation Loss Current: 7.2640, Validation Loss AVG: 7.2640, lr: 0.001
Epoch [2/80], Training Loss: 22.5021, Validation Loss Current: 8.2201, Validation Loss AVG: 8.2201, lr: 0.001
Epoch [3/80], Training Loss: 20.9763, Validation Loss Current: 8.9994, Validation Loss AVG: 8.9994, lr: 0.001
Epoch [4/80], Training Loss: 14.3444, Validation Loss Current: 5.8092, Validation Loss AVG: 5.8092, lr: 0.001
Epoch [5/80], Training Loss: 10.7204, Validation Loss Current: 5.7865, Validation Loss AVG: 5.7865, lr: 0.001
Epoch [6/80], Training Loss: 9.7959, Validation Loss Current: 6.0818, Validation Loss AVG: 6.0818, lr: 0.001
Epoch [7/80], Training Loss: 8.5740, Validation Loss Current: 5.6441, Validation Loss AVG: 5.6441, lr: 0.001
Epoch [8/80], Training Loss: 7.6981, Validation Loss Current: 6.0463, Validation Loss AVG: 6.0463, lr: 0.001
Epoch [9/80], Training Loss: 10.4141, Validation Loss Current: 6.6063, Validation Loss AVG: 6.6063, lr: 0.001
Epoch [10/80], Training Loss: 9.5271, Validation Loss Current: 6.9687, Validation Loss AVG: 6.9687, lr: 0.001
Epoch [11/80], Training Loss: 7.5397, Validation Loss Current: 6.6120, Validation Loss AVG: 6.6120, lr: 0.001
Epoch [12/80], Training Loss: 6.7852, Validation Loss Current: 6.6936, Validation Loss AVG: 6.6936, lr: 0.001
Epoch [13/80], Training Loss: 5.2801, Validation Loss Current: 7.1109, Validation Loss AVG: 7.1109, lr: 0.001
Epoch [14/80], Training Loss: 8.5207, Validation Loss Current: 6.7735, Validation Loss AVG: 6.7735, lr: 0.001
Epoch [15/80], Training Loss: 6.4132, Validation Loss Current: 6.3338, Validation Loss AVG: 6.3338, lr: 0.001
Epoch [16/80], Training Loss: 5.4252, Validation Loss Current: 6.5581, Validation Loss AVG: 6.5581, lr: 0.001
Epoch [17/80], Training Loss: 6.6861, Validation Loss Current: 7.7133, Validation Loss AVG: 7.7133, lr: 0.001
Epoch [18/80], Training Loss: 4.8045, Validation Loss Current: 6.1264, Validation Loss AVG: 6.1264, lr: 0.001
Epoch [19/80], Training Loss: 4.7610, Validation Loss Current: 6.5153, Validation Loss AVG: 6.5153, lr: 0.001
Epoch [20/80], Training Loss: 7.6689, Validation Loss Current: 7.3713, Validation Loss AVG: 7.3713, lr: 0.001
Epoch [21/80], Training Loss: 7.9176, Validation Loss Current: 7.6950, Validation Loss AVG: 7.6950, lr: 0.001
Epoch [22/80], Training Loss: 3.6110, Validation Loss Current: 7.6008, Validation Loss AVG: 7.6008, lr: 0.001
Epoch [23/80], Training Loss: 4.0199, Validation Loss Current: 7.4739, Validation Loss AVG: 7.4739, lr: 0.001
Epoch [24/80], Training Loss: 5.7970, Validation Loss Current: 7.2784, Validation Loss AVG: 7.2784, lr: 0.001
Epoch [25/80], Training Loss: 7.4598, Validation Loss Current: 8.1047, Validation Loss AVG: 8.1047, lr: 0.001
Epoch [26/80], Training Loss: 4.8304, Validation Loss Current: 7.8743, Validation Loss AVG: 7.8743, lr: 0.001
Epoch [27/80], Training Loss: 5.1676, Validation Loss Current: 7.0188, Validation Loss AVG: 7.0188, lr: 0.001
Epoch [28/80], Training Loss: 2.3014, Validation Loss Current: 6.9678, Validation Loss AVG: 6.9678, lr: 0.001
Epoch [29/80], Training Loss: 3.3222, Validation Loss Current: 6.3198, Validation Loss AVG: 6.3198, lr: 0.001
Epoch [30/80], Training Loss: 4.4200, Validation Loss Current: 6.8597, Validation Loss AVG: 6.8597, lr: 0.001
Epoch [31/80], Training Loss: 6.0694, Validation Loss Current: 7.8296, Validation Loss AVG: 7.8296, lr: 0.001
Epoch [32/80], Training Loss: 4.5254, Validation Loss Current: 7.5410, Validation Loss AVG: 7.5410, lr: 0.001
Epoch [33/80], Training Loss: 5.3473, Validation Loss Current: 7.6806, Validation Loss AVG: 7.6806, lr: 0.001
Epoch [34/80], Training Loss: 5.1039, Validation Loss Current: 11.1136, Validation Loss AVG: 11.1136, lr: 0.001
Epoch [35/80], Training Loss: 8.6942, Validation Loss Current: 7.9503, Validation Loss AVG: 7.9503, lr: 0.001
Epoch [36/80], Training Loss: 5.4295, Validation Loss Current: 8.4619, Validation Loss AVG: 8.4619, lr: 0.001
Epoch [37/80], Training Loss: 3.3780, Validation Loss Current: 7.5163, Validation Loss AVG: 7.5163, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random2 finished training. Best epoch: 7 Best val accuracy: [0.5657894736842105, 0.5608552631578947, 0.5523026315789474, 0.6401315789473685, 0.6398026315789472, 0.6440789473684211, 0.6585526315789474, 0.6322368421052632, 0.6355263157894737, 0.59375, 0.6414473684210527, 0.6233552631578948, 0.6375, 0.6289473684210527, 0.6398026315789473, 0.6598684210526317, 0.6230263157894738, 0.655921052631579, 0.6440789473684211, 0.605263157894737, 0.6259868421052632, 0.618421052631579, 0.6095394736842105, 0.6256578947368421, 0.5993421052631579, 0.6144736842105264, 0.6299342105263157, 0.6368421052631579, 0.6529605263157894, 0.6453947368421052, 0.6180921052631578, 0.5983552631578947, 0.6124999999999999, 0.5549342105263158, 0.6039473684210527, 0.5766447368421053, 0.6276315789473685] Best val loss: 5.644093692302704


Current group: llo_0.6_random3
Epoch [1/80], Training Loss: 37.6491, Validation Loss Current: 8.1216, Validation Loss AVG: 8.1216, lr: 0.001
Epoch [2/80], Training Loss: 23.4713, Validation Loss Current: 7.9363, Validation Loss AVG: 7.9363, lr: 0.001
Epoch [3/80], Training Loss: 17.8521, Validation Loss Current: 6.4378, Validation Loss AVG: 6.4378, lr: 0.001
Epoch [4/80], Training Loss: 13.9577, Validation Loss Current: 5.8467, Validation Loss AVG: 5.8467, lr: 0.001
Epoch [5/80], Training Loss: 12.4020, Validation Loss Current: 5.6807, Validation Loss AVG: 5.6807, lr: 0.001
Epoch [6/80], Training Loss: 7.9122, Validation Loss Current: 5.2616, Validation Loss AVG: 5.2616, lr: 0.001
Epoch [7/80], Training Loss: 5.2040, Validation Loss Current: 4.8062, Validation Loss AVG: 4.8062, lr: 0.001
Epoch [8/80], Training Loss: 5.1923, Validation Loss Current: 5.5552, Validation Loss AVG: 5.5552, lr: 0.001
Epoch [9/80], Training Loss: 4.5806, Validation Loss Current: 5.4577, Validation Loss AVG: 5.4577, lr: 0.001
Epoch [10/80], Training Loss: 3.8866, Validation Loss Current: 5.6407, Validation Loss AVG: 5.6407, lr: 0.001
Epoch [11/80], Training Loss: 5.1642, Validation Loss Current: 5.7317, Validation Loss AVG: 5.7317, lr: 0.001
Epoch [12/80], Training Loss: 6.9161, Validation Loss Current: 6.8186, Validation Loss AVG: 6.8186, lr: 0.001
Epoch [13/80], Training Loss: 7.2527, Validation Loss Current: 6.1373, Validation Loss AVG: 6.1373, lr: 0.001
Epoch [14/80], Training Loss: 3.8886, Validation Loss Current: 5.7966, Validation Loss AVG: 5.7966, lr: 0.001
Epoch [15/80], Training Loss: 5.3522, Validation Loss Current: 9.4993, Validation Loss AVG: 9.4993, lr: 0.001
Epoch [16/80], Training Loss: 12.1140, Validation Loss Current: 13.2360, Validation Loss AVG: 13.2360, lr: 0.001
Epoch [17/80], Training Loss: 4.0736, Validation Loss Current: 6.3816, Validation Loss AVG: 6.3816, lr: 0.001
Epoch [18/80], Training Loss: 4.9796, Validation Loss Current: 5.9359, Validation Loss AVG: 5.9359, lr: 0.001
Epoch [19/80], Training Loss: 3.7565, Validation Loss Current: 6.3924, Validation Loss AVG: 6.3924, lr: 0.001
Epoch [20/80], Training Loss: 6.1521, Validation Loss Current: 6.1908, Validation Loss AVG: 6.1908, lr: 0.001
Epoch [21/80], Training Loss: 3.6257, Validation Loss Current: 7.1803, Validation Loss AVG: 7.1803, lr: 0.001
Epoch [22/80], Training Loss: 2.4025, Validation Loss Current: 6.2207, Validation Loss AVG: 6.2207, lr: 0.001
Epoch [23/80], Training Loss: 5.9201, Validation Loss Current: 6.8941, Validation Loss AVG: 6.8941, lr: 0.001
Epoch [24/80], Training Loss: 6.6042, Validation Loss Current: 7.7798, Validation Loss AVG: 7.7798, lr: 0.001
Epoch [25/80], Training Loss: 9.0335, Validation Loss Current: 8.6988, Validation Loss AVG: 8.6988, lr: 0.001
Epoch [26/80], Training Loss: 7.4044, Validation Loss Current: 7.0359, Validation Loss AVG: 7.0359, lr: 0.001
Epoch [27/80], Training Loss: 7.4518, Validation Loss Current: 8.8962, Validation Loss AVG: 8.8962, lr: 0.001
Epoch [28/80], Training Loss: 3.1802, Validation Loss Current: 6.9948, Validation Loss AVG: 6.9948, lr: 0.001
Epoch [29/80], Training Loss: 2.7176, Validation Loss Current: 6.3343, Validation Loss AVG: 6.3343, lr: 0.001
Epoch [30/80], Training Loss: 4.6144, Validation Loss Current: 8.9298, Validation Loss AVG: 8.9298, lr: 0.001
Epoch [31/80], Training Loss: 3.9210, Validation Loss Current: 7.7863, Validation Loss AVG: 7.7863, lr: 0.001
Epoch [32/80], Training Loss: 1.4942, Validation Loss Current: 6.5387, Validation Loss AVG: 6.5387, lr: 0.001
Epoch [33/80], Training Loss: 5.0493, Validation Loss Current: 6.6496, Validation Loss AVG: 6.6496, lr: 0.001
Epoch [34/80], Training Loss: 7.0949, Validation Loss Current: 7.0153, Validation Loss AVG: 7.0153, lr: 0.001
Epoch [35/80], Training Loss: 5.5733, Validation Loss Current: 7.9335, Validation Loss AVG: 7.9335, lr: 0.001
Epoch [36/80], Training Loss: 5.3940, Validation Loss Current: 9.4125, Validation Loss AVG: 9.4125, lr: 0.001
Epoch [37/80], Training Loss: 13.2504, Validation Loss Current: 9.9204, Validation Loss AVG: 9.9204, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random3 finished training. Best epoch: 7 Best val accuracy: [0.5457236842105264, 0.5167763157894736, 0.6055921052631579, 0.6355263157894737, 0.6605263157894737, 0.6848684210526315, 0.7092105263157895, 0.6848684210526316, 0.6842105263157894, 0.6733552631578947, 0.6664473684210527, 0.6407894736842106, 0.6638157894736842, 0.6842105263157895, 0.5799342105263158, 0.43717105263157896, 0.655921052631579, 0.6605263157894736, 0.6430921052631579, 0.6648026315789475, 0.644736842105263, 0.656578947368421, 0.6440789473684211, 0.5993421052631579, 0.5976973684210527, 0.6125, 0.5947368421052631, 0.6463815789473684, 0.6549342105263158, 0.5684210526315789, 0.6273026315789474, 0.6654605263157894, 0.6595394736842105, 0.6348684210526315, 0.6296052631578947, 0.5253289473684211, 0.5125] Best val loss: 4.806186056137085


Current group: 0.6
Epoch [1/80], Training Loss: 35.9107, Validation Loss Current: 7.1329, Validation Loss AVG: 7.1329, lr: 0.001
Epoch [2/80], Training Loss: 22.6139, Validation Loss Current: 7.9369, Validation Loss AVG: 7.9369, lr: 0.001
Epoch [3/80], Training Loss: 17.2587, Validation Loss Current: 8.1677, Validation Loss AVG: 8.1677, lr: 0.001
Epoch [4/80], Training Loss: 10.9794, Validation Loss Current: 6.9170, Validation Loss AVG: 6.9170, lr: 0.001
Epoch [5/80], Training Loss: 7.4005, Validation Loss Current: 6.4250, Validation Loss AVG: 6.4250, lr: 0.001
Epoch [6/80], Training Loss: 7.6933, Validation Loss Current: 7.0585, Validation Loss AVG: 7.0585, lr: 0.001
Epoch [7/80], Training Loss: 8.1193, Validation Loss Current: 7.8858, Validation Loss AVG: 7.8858, lr: 0.001
Epoch [8/80], Training Loss: 5.3038, Validation Loss Current: 6.5324, Validation Loss AVG: 6.5324, lr: 0.001
Epoch [9/80], Training Loss: 5.3620, Validation Loss Current: 6.9992, Validation Loss AVG: 6.9992, lr: 0.001
Epoch [10/80], Training Loss: 3.0761, Validation Loss Current: 6.9141, Validation Loss AVG: 6.9141, lr: 0.001
Epoch [11/80], Training Loss: 2.5369, Validation Loss Current: 7.0509, Validation Loss AVG: 7.0509, lr: 0.001
Epoch [12/80], Training Loss: 2.5262, Validation Loss Current: 7.6007, Validation Loss AVG: 7.6007, lr: 0.001
Epoch [13/80], Training Loss: 1.7891, Validation Loss Current: 7.3456, Validation Loss AVG: 7.3456, lr: 0.001
Epoch [14/80], Training Loss: 2.7956, Validation Loss Current: 7.9922, Validation Loss AVG: 7.9922, lr: 0.001
Epoch [15/80], Training Loss: 5.0621, Validation Loss Current: 8.3921, Validation Loss AVG: 8.3921, lr: 0.001
Epoch [16/80], Training Loss: 2.5613, Validation Loss Current: 7.7081, Validation Loss AVG: 7.7081, lr: 0.001
Epoch [17/80], Training Loss: 5.6746, Validation Loss Current: 7.9853, Validation Loss AVG: 7.9853, lr: 0.001
Epoch [18/80], Training Loss: 5.9478, Validation Loss Current: 8.7426, Validation Loss AVG: 8.7426, lr: 0.001
Epoch [19/80], Training Loss: 7.9607, Validation Loss Current: 9.6941, Validation Loss AVG: 9.6941, lr: 0.001
Epoch [20/80], Training Loss: 6.4064, Validation Loss Current: 8.3995, Validation Loss AVG: 8.3995, lr: 0.001
Epoch [21/80], Training Loss: 7.0792, Validation Loss Current: 8.6778, Validation Loss AVG: 8.6778, lr: 0.001
Epoch [22/80], Training Loss: 2.6222, Validation Loss Current: 7.7477, Validation Loss AVG: 7.7477, lr: 0.001
Epoch [23/80], Training Loss: 3.2052, Validation Loss Current: 7.9915, Validation Loss AVG: 7.9915, lr: 0.001
Epoch [24/80], Training Loss: 9.2055, Validation Loss Current: 8.6006, Validation Loss AVG: 8.6006, lr: 0.001
Epoch [25/80], Training Loss: 3.5176, Validation Loss Current: 8.6917, Validation Loss AVG: 8.6917, lr: 0.001
Epoch [26/80], Training Loss: 4.0879, Validation Loss Current: 8.8823, Validation Loss AVG: 8.8823, lr: 0.001
Epoch [27/80], Training Loss: 5.0940, Validation Loss Current: 8.3070, Validation Loss AVG: 8.3070, lr: 0.001
Epoch [28/80], Training Loss: 8.6505, Validation Loss Current: 9.2884, Validation Loss AVG: 9.2884, lr: 0.001
Epoch [29/80], Training Loss: 5.2619, Validation Loss Current: 9.9620, Validation Loss AVG: 9.9620, lr: 0.001
Epoch [30/80], Training Loss: 7.4761, Validation Loss Current: 8.8937, Validation Loss AVG: 8.8937, lr: 0.001
Epoch [31/80], Training Loss: 4.4733, Validation Loss Current: 9.8986, Validation Loss AVG: 9.8986, lr: 0.001
Epoch [32/80], Training Loss: 6.3051, Validation Loss Current: 9.0132, Validation Loss AVG: 9.0132, lr: 0.001
Epoch [33/80], Training Loss: 2.8593, Validation Loss Current: 9.5561, Validation Loss AVG: 9.5561, lr: 0.001
Epoch [34/80], Training Loss: 1.2530, Validation Loss Current: 8.7932, Validation Loss AVG: 8.7932, lr: 0.001
Epoch [35/80], Training Loss: 5.7994, Validation Loss Current: 8.8273, Validation Loss AVG: 8.8273, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 5 Best val accuracy: [0.6105263157894736, 0.5953947368421052, 0.5674342105263157, 0.6009868421052632, 0.6164473684210526, 0.6065789473684211, 0.5763157894736841, 0.6207236842105264, 0.6115131578947368, 0.6039473684210527, 0.6236842105263157, 0.6078947368421053, 0.6115131578947369, 0.5970394736842105, 0.5746710526315789, 0.5953947368421053, 0.5845394736842106, 0.5384868421052632, 0.5430921052631579, 0.5707236842105263, 0.5654605263157895, 0.575657894736842, 0.5911184210526316, 0.5723684210526315, 0.5697368421052632, 0.549671052631579, 0.5680921052631579, 0.5305921052631579, 0.5325657894736843, 0.5513157894736842, 0.5200657894736842, 0.5417763157894737, 0.5292763157894738, 0.5529605263157895, 0.5532894736842104] Best val loss: 6.424976861476898


----- Training resnet18 with sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] -----
Current group: llo_1_random0
Epoch [1/80], Training Loss: 40.6401, Validation Loss Current: 10.0432, Validation Loss AVG: 10.0432, lr: 0.001
Epoch [2/80], Training Loss: 39.9728, Validation Loss Current: 9.9097, Validation Loss AVG: 9.9097, lr: 0.001
Epoch [3/80], Training Loss: 39.1966, Validation Loss Current: 9.7026, Validation Loss AVG: 9.7026, lr: 0.001
Epoch [4/80], Training Loss: 37.5532, Validation Loss Current: 9.5304, Validation Loss AVG: 9.5304, lr: 0.001
Epoch [5/80], Training Loss: 37.3268, Validation Loss Current: 9.2736, Validation Loss AVG: 9.2736, lr: 0.001
Epoch [6/80], Training Loss: 36.8441, Validation Loss Current: 9.2577, Validation Loss AVG: 9.2577, lr: 0.001
Epoch [7/80], Training Loss: 36.3302, Validation Loss Current: 9.3667, Validation Loss AVG: 9.3667, lr: 0.001
Epoch [8/80], Training Loss: 35.4468, Validation Loss Current: 8.8954, Validation Loss AVG: 8.8954, lr: 0.001
Epoch [9/80], Training Loss: 35.0481, Validation Loss Current: 8.7624, Validation Loss AVG: 8.7624, lr: 0.001
Epoch [10/80], Training Loss: 33.5358, Validation Loss Current: 8.5298, Validation Loss AVG: 8.5298, lr: 0.001
Epoch [11/80], Training Loss: 33.2258, Validation Loss Current: 8.4221, Validation Loss AVG: 8.4221, lr: 0.001
Epoch [12/80], Training Loss: 32.4688, Validation Loss Current: 8.2785, Validation Loss AVG: 8.2785, lr: 0.001
Epoch [13/80], Training Loss: 30.6203, Validation Loss Current: 8.0324, Validation Loss AVG: 8.0324, lr: 0.001
Epoch [14/80], Training Loss: 29.5762, Validation Loss Current: 7.9114, Validation Loss AVG: 7.9114, lr: 0.001
Epoch [15/80], Training Loss: 30.0108, Validation Loss Current: 7.8003, Validation Loss AVG: 7.8003, lr: 0.001
Epoch [16/80], Training Loss: 28.1748, Validation Loss Current: 8.2504, Validation Loss AVG: 8.2504, lr: 0.001
Epoch [17/80], Training Loss: 29.5184, Validation Loss Current: 8.1854, Validation Loss AVG: 8.1854, lr: 0.001
Epoch [18/80], Training Loss: 28.3308, Validation Loss Current: 8.0987, Validation Loss AVG: 8.0987, lr: 0.001
Epoch [19/80], Training Loss: 25.5499, Validation Loss Current: 7.3672, Validation Loss AVG: 7.3672, lr: 0.001
Epoch [20/80], Training Loss: 25.9336, Validation Loss Current: 7.5308, Validation Loss AVG: 7.5308, lr: 0.001
Epoch [21/80], Training Loss: 25.3904, Validation Loss Current: 7.2344, Validation Loss AVG: 7.2344, lr: 0.001
Epoch [22/80], Training Loss: 25.5046, Validation Loss Current: 8.9887, Validation Loss AVG: 8.9887, lr: 0.001
Epoch [23/80], Training Loss: 24.0691, Validation Loss Current: 7.3628, Validation Loss AVG: 7.3628, lr: 0.001
Epoch [24/80], Training Loss: 23.0071, Validation Loss Current: 7.2877, Validation Loss AVG: 7.2877, lr: 0.001
Epoch [25/80], Training Loss: 24.6990, Validation Loss Current: 7.3572, Validation Loss AVG: 7.3572, lr: 0.001
Epoch [26/80], Training Loss: 22.1740, Validation Loss Current: 7.1345, Validation Loss AVG: 7.1345, lr: 0.001
Epoch [27/80], Training Loss: 21.6755, Validation Loss Current: 7.7795, Validation Loss AVG: 7.7795, lr: 0.001
Epoch [28/80], Training Loss: 19.2706, Validation Loss Current: 7.3605, Validation Loss AVG: 7.3605, lr: 0.001
Epoch [29/80], Training Loss: 19.3564, Validation Loss Current: 7.1169, Validation Loss AVG: 7.1169, lr: 0.001
Epoch [30/80], Training Loss: 19.4687, Validation Loss Current: 7.2535, Validation Loss AVG: 7.2535, lr: 0.001
Epoch [31/80], Training Loss: 18.1145, Validation Loss Current: 6.9482, Validation Loss AVG: 6.9482, lr: 0.001
Epoch [32/80], Training Loss: 17.2498, Validation Loss Current: 7.4090, Validation Loss AVG: 7.4090, lr: 0.001
Epoch [33/80], Training Loss: 20.6737, Validation Loss Current: 7.9092, Validation Loss AVG: 7.9092, lr: 0.001
Epoch [34/80], Training Loss: 18.4310, Validation Loss Current: 7.2063, Validation Loss AVG: 7.2063, lr: 0.001
Epoch [35/80], Training Loss: 19.0536, Validation Loss Current: 7.4303, Validation Loss AVG: 7.4303, lr: 0.001
Epoch [36/80], Training Loss: 18.4067, Validation Loss Current: 7.2548, Validation Loss AVG: 7.2548, lr: 0.001
Epoch [37/80], Training Loss: 17.1637, Validation Loss Current: 7.0591, Validation Loss AVG: 7.0591, lr: 0.001
Epoch [38/80], Training Loss: 13.9149, Validation Loss Current: 7.1868, Validation Loss AVG: 7.1868, lr: 0.001
Epoch [39/80], Training Loss: 12.6425, Validation Loss Current: 6.7461, Validation Loss AVG: 6.7461, lr: 0.001
Epoch [40/80], Training Loss: 11.2618, Validation Loss Current: 8.2162, Validation Loss AVG: 8.2162, lr: 0.001
Epoch [41/80], Training Loss: 10.1757, Validation Loss Current: 6.7618, Validation Loss AVG: 6.7618, lr: 0.001
Epoch [42/80], Training Loss: 10.6184, Validation Loss Current: 7.7393, Validation Loss AVG: 7.7393, lr: 0.001
Epoch [43/80], Training Loss: 10.8077, Validation Loss Current: 9.5388, Validation Loss AVG: 9.5388, lr: 0.001
Epoch [44/80], Training Loss: 13.2222, Validation Loss Current: 8.1785, Validation Loss AVG: 8.1785, lr: 0.001
Epoch [45/80], Training Loss: 11.1705, Validation Loss Current: 7.2122, Validation Loss AVG: 7.2122, lr: 0.001
Epoch [46/80], Training Loss: 9.6034, Validation Loss Current: 7.5502, Validation Loss AVG: 7.5502, lr: 0.001
Epoch [47/80], Training Loss: 9.0929, Validation Loss Current: 7.3874, Validation Loss AVG: 7.3874, lr: 0.001
Epoch [48/80], Training Loss: 6.9126, Validation Loss Current: 7.4985, Validation Loss AVG: 7.4985, lr: 0.001
Epoch [49/80], Training Loss: 9.7185, Validation Loss Current: 8.9076, Validation Loss AVG: 8.9076, lr: 0.001
Epoch [50/80], Training Loss: 13.5877, Validation Loss Current: 9.1516, Validation Loss AVG: 9.1516, lr: 0.001
Epoch [51/80], Training Loss: 14.3345, Validation Loss Current: 9.4358, Validation Loss AVG: 9.4358, lr: 0.001
Epoch [52/80], Training Loss: 10.6244, Validation Loss Current: 8.9629, Validation Loss AVG: 8.9629, lr: 0.001
Epoch [53/80], Training Loss: 9.5382, Validation Loss Current: 7.4245, Validation Loss AVG: 7.4245, lr: 0.001
Epoch [54/80], Training Loss: 8.5712, Validation Loss Current: 7.6714, Validation Loss AVG: 7.6714, lr: 0.001
Epoch [55/80], Training Loss: 10.6911, Validation Loss Current: 9.4512, Validation Loss AVG: 9.4512, lr: 0.001
Epoch [56/80], Training Loss: 7.4074, Validation Loss Current: 9.9246, Validation Loss AVG: 9.9246, lr: 0.001
Epoch [57/80], Training Loss: 7.4011, Validation Loss Current: 7.8034, Validation Loss AVG: 7.8034, lr: 0.001
Epoch [58/80], Training Loss: 5.5568, Validation Loss Current: 7.1858, Validation Loss AVG: 7.1858, lr: 0.001
Epoch [59/80], Training Loss: 5.8851, Validation Loss Current: 8.7932, Validation Loss AVG: 8.7932, lr: 0.001
Epoch [60/80], Training Loss: 5.2600, Validation Loss Current: 9.3221, Validation Loss AVG: 9.3221, lr: 0.001
Epoch [61/80], Training Loss: 7.7966, Validation Loss Current: 9.2583, Validation Loss AVG: 9.2583, lr: 0.001
Epoch [62/80], Training Loss: 4.7350, Validation Loss Current: 8.4045, Validation Loss AVG: 8.4045, lr: 0.001
Epoch [63/80], Training Loss: 5.1401, Validation Loss Current: 8.2506, Validation Loss AVG: 8.2506, lr: 0.001
Epoch [64/80], Training Loss: 7.4952, Validation Loss Current: 8.4869, Validation Loss AVG: 8.4869, lr: 0.001
Epoch [65/80], Training Loss: 5.8720, Validation Loss Current: 10.0550, Validation Loss AVG: 10.0550, lr: 0.001
Epoch [66/80], Training Loss: 5.0510, Validation Loss Current: 8.3667, Validation Loss AVG: 8.3667, lr: 0.001
Epoch [67/80], Training Loss: 6.5005, Validation Loss Current: 8.0412, Validation Loss AVG: 8.0412, lr: 0.001
Epoch [68/80], Training Loss: 7.2612, Validation Loss Current: 10.3090, Validation Loss AVG: 10.3090, lr: 0.001
Epoch [69/80], Training Loss: 4.3368, Validation Loss Current: 8.8279, Validation Loss AVG: 8.8279, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random0 finished training. Best epoch: 39 Best val accuracy: [0.2299342105263158, 0.2536184210526316, 0.2447368421052632, 0.27203947368421055, 0.31052631578947365, 0.30296052631578946, 0.2855263157894737, 0.33519736842105263, 0.35657894736842105, 0.37467105263157896, 0.3888157894736842, 0.3980263157894737, 0.4118421052631579, 0.41907894736842105, 0.45197368421052636, 0.4164473684210527, 0.41546052631578945, 0.4240131578947368, 0.47467105263157894, 0.4651315789473684, 0.4881578947368421, 0.3776315789473684, 0.49078947368421055, 0.48519736842105254, 0.47631578947368425, 0.49605263157894736, 0.4786184210526316, 0.47697368421052627, 0.506578947368421, 0.513157894736842, 0.53125, 0.5266447368421053, 0.4707236842105263, 0.49605263157894736, 0.49967105263157896, 0.5036184210526315, 0.5286184210526316, 0.5180921052631579, 0.5345394736842105, 0.5213815789473684, 0.5585526315789473, 0.5351973684210526, 0.4098684210526316, 0.5263157894736842, 0.5345394736842104, 0.5424342105263158, 0.5470394736842106, 0.530921052631579, 0.48684210526315785, 0.4703947368421052, 0.48157894736842105, 0.4894736842105263, 0.550657894736842, 0.5125, 0.4756578947368421, 0.4921052631578947, 0.5549342105263158, 0.5746710526315789, 0.5105263157894737, 0.5299342105263157, 0.5203947368421052, 0.51875, 0.5539473684210526, 0.5598684210526317, 0.4733552631578948, 0.5388157894736842, 0.5736842105263158, 0.5036184210526315, 0.5378289473684211] Best val loss: 6.746117210388183


Current group: llo_1_random1
Epoch [1/80], Training Loss: 33.3025, Validation Loss Current: 8.4827, Validation Loss AVG: 8.4827, lr: 0.001
Epoch [2/80], Training Loss: 23.9554, Validation Loss Current: 8.1857, Validation Loss AVG: 8.1857, lr: 0.001
Epoch [3/80], Training Loss: 22.3442, Validation Loss Current: 7.2665, Validation Loss AVG: 7.2665, lr: 0.001
Epoch [4/80], Training Loss: 18.2547, Validation Loss Current: 6.2068, Validation Loss AVG: 6.2068, lr: 0.001
Epoch [5/80], Training Loss: 15.5855, Validation Loss Current: 5.9186, Validation Loss AVG: 5.9186, lr: 0.001
Epoch [6/80], Training Loss: 13.4288, Validation Loss Current: 5.9446, Validation Loss AVG: 5.9446, lr: 0.001
Epoch [7/80], Training Loss: 16.8433, Validation Loss Current: 6.8312, Validation Loss AVG: 6.8312, lr: 0.001
Epoch [8/80], Training Loss: 15.2952, Validation Loss Current: 8.9756, Validation Loss AVG: 8.9756, lr: 0.001
Epoch [9/80], Training Loss: 14.1312, Validation Loss Current: 7.9669, Validation Loss AVG: 7.9669, lr: 0.001
Epoch [10/80], Training Loss: 11.8616, Validation Loss Current: 9.3656, Validation Loss AVG: 9.3656, lr: 0.001
Epoch [11/80], Training Loss: 10.3452, Validation Loss Current: 7.0112, Validation Loss AVG: 7.0112, lr: 0.001
Epoch [12/80], Training Loss: 10.4812, Validation Loss Current: 6.8004, Validation Loss AVG: 6.8004, lr: 0.001
Epoch [13/80], Training Loss: 7.1085, Validation Loss Current: 6.4669, Validation Loss AVG: 6.4669, lr: 0.001
Epoch [14/80], Training Loss: 6.7836, Validation Loss Current: 9.4861, Validation Loss AVG: 9.4861, lr: 0.001
Epoch [15/80], Training Loss: 5.0090, Validation Loss Current: 6.9055, Validation Loss AVG: 6.9055, lr: 0.001
Epoch [16/80], Training Loss: 4.9222, Validation Loss Current: 5.8092, Validation Loss AVG: 5.8092, lr: 0.001
Epoch [17/80], Training Loss: 4.3688, Validation Loss Current: 6.4909, Validation Loss AVG: 6.4909, lr: 0.001
Epoch [18/80], Training Loss: 5.6384, Validation Loss Current: 8.3168, Validation Loss AVG: 8.3168, lr: 0.001
Epoch [19/80], Training Loss: 6.8481, Validation Loss Current: 12.6652, Validation Loss AVG: 12.6652, lr: 0.001
Epoch [20/80], Training Loss: 3.3313, Validation Loss Current: 7.5389, Validation Loss AVG: 7.5389, lr: 0.001
Epoch [21/80], Training Loss: 1.8018, Validation Loss Current: 6.0836, Validation Loss AVG: 6.0836, lr: 0.001
Epoch [22/80], Training Loss: 2.3301, Validation Loss Current: 7.3943, Validation Loss AVG: 7.3943, lr: 0.001
Epoch [23/80], Training Loss: 4.9212, Validation Loss Current: 7.1699, Validation Loss AVG: 7.1699, lr: 0.001
Epoch [24/80], Training Loss: 6.8019, Validation Loss Current: 6.7891, Validation Loss AVG: 6.7891, lr: 0.001
Epoch [25/80], Training Loss: 5.0799, Validation Loss Current: 7.3457, Validation Loss AVG: 7.3457, lr: 0.001
Epoch [26/80], Training Loss: 8.8231, Validation Loss Current: 8.8497, Validation Loss AVG: 8.8497, lr: 0.001
Epoch [27/80], Training Loss: 9.3834, Validation Loss Current: 7.0983, Validation Loss AVG: 7.0983, lr: 0.001
Epoch [28/80], Training Loss: 6.9117, Validation Loss Current: 7.2127, Validation Loss AVG: 7.2127, lr: 0.001
Epoch [29/80], Training Loss: 6.6140, Validation Loss Current: 7.9463, Validation Loss AVG: 7.9463, lr: 0.001
Epoch [30/80], Training Loss: 4.8565, Validation Loss Current: 6.8612, Validation Loss AVG: 6.8612, lr: 0.001
Epoch [31/80], Training Loss: 7.6600, Validation Loss Current: 25.1003, Validation Loss AVG: 25.1003, lr: 0.001
Epoch [32/80], Training Loss: 5.5856, Validation Loss Current: 7.9039, Validation Loss AVG: 7.9039, lr: 0.001
Epoch [33/80], Training Loss: 3.3184, Validation Loss Current: 7.9857, Validation Loss AVG: 7.9857, lr: 0.001
Epoch [34/80], Training Loss: 2.6378, Validation Loss Current: 7.6228, Validation Loss AVG: 7.6228, lr: 0.001
Epoch [35/80], Training Loss: 4.2831, Validation Loss Current: 8.0282, Validation Loss AVG: 8.0282, lr: 0.001
Epoch [36/80], Training Loss: 5.6407, Validation Loss Current: 8.6632, Validation Loss AVG: 8.6632, lr: 0.001
Epoch [37/80], Training Loss: 3.2805, Validation Loss Current: 8.2194, Validation Loss AVG: 8.2194, lr: 0.001
Epoch [38/80], Training Loss: 3.7169, Validation Loss Current: 8.0670, Validation Loss AVG: 8.0670, lr: 0.001
Epoch [39/80], Training Loss: 6.3688, Validation Loss Current: 9.4204, Validation Loss AVG: 9.4204, lr: 0.001
Epoch [40/80], Training Loss: 4.2328, Validation Loss Current: 8.0305, Validation Loss AVG: 8.0305, lr: 0.001
Epoch [41/80], Training Loss: 8.6440, Validation Loss Current: 8.5233, Validation Loss AVG: 8.5233, lr: 0.001
Epoch [42/80], Training Loss: 9.0174, Validation Loss Current: 10.5074, Validation Loss AVG: 10.5074, lr: 0.001
Epoch [43/80], Training Loss: 10.3415, Validation Loss Current: 12.3996, Validation Loss AVG: 12.3996, lr: 0.001
Epoch [44/80], Training Loss: 8.9296, Validation Loss Current: 8.2719, Validation Loss AVG: 8.2719, lr: 0.001
Epoch [45/80], Training Loss: 4.0435, Validation Loss Current: 7.6523, Validation Loss AVG: 7.6523, lr: 0.001
Epoch [46/80], Training Loss: 5.2567, Validation Loss Current: 9.1569, Validation Loss AVG: 9.1569, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random1 finished training. Best epoch: 16 Best val accuracy: [0.5424342105263158, 0.5338815789473685, 0.5858552631578948, 0.6016447368421052, 0.6128289473684211, 0.6345394736842105, 0.5848684210526316, 0.5171052631578947, 0.5171052631578947, 0.5134868421052632, 0.5809210526315789, 0.6082236842105264, 0.5976973684210526, 0.5529605263157895, 0.5907894736842106, 0.6644736842105263, 0.6342105263157896, 0.5947368421052632, 0.46809210526315786, 0.5723684210526315, 0.656578947368421, 0.6256578947368421, 0.6151315789473684, 0.6401315789473684, 0.5894736842105263, 0.5625, 0.6059210526315788, 0.6292763157894736, 0.6101973684210527, 0.6006578947368422, 0.3588815789473684, 0.5845394736842107, 0.6194078947368421, 0.6256578947368421, 0.6032894736842105, 0.5720394736842105, 0.5796052631578947, 0.6263157894736842, 0.5138157894736842, 0.6009868421052632, 0.5957236842105263, 0.5351973684210527, 0.4697368421052632, 0.5700657894736841, 0.6115131578947368, 0.5759868421052633] Best val loss: 5.809176254272461


Current group: llo_1_random2
Epoch [1/80], Training Loss: 34.6521, Validation Loss Current: 7.6181, Validation Loss AVG: 7.6181, lr: 0.001
Epoch [2/80], Training Loss: 24.0912, Validation Loss Current: 6.2178, Validation Loss AVG: 6.2178, lr: 0.001
Epoch [3/80], Training Loss: 18.8022, Validation Loss Current: 6.2676, Validation Loss AVG: 6.2676, lr: 0.001
Epoch [4/80], Training Loss: 14.3559, Validation Loss Current: 7.6049, Validation Loss AVG: 7.6049, lr: 0.001
Epoch [5/80], Training Loss: 12.6945, Validation Loss Current: 5.6732, Validation Loss AVG: 5.6732, lr: 0.001
Epoch [6/80], Training Loss: 7.5172, Validation Loss Current: 5.3306, Validation Loss AVG: 5.3306, lr: 0.001
Epoch [7/80], Training Loss: 5.8214, Validation Loss Current: 6.0225, Validation Loss AVG: 6.0225, lr: 0.001
Epoch [8/80], Training Loss: 8.6609, Validation Loss Current: 6.8788, Validation Loss AVG: 6.8788, lr: 0.001
Epoch [9/80], Training Loss: 10.8666, Validation Loss Current: 7.4160, Validation Loss AVG: 7.4160, lr: 0.001
Epoch [10/80], Training Loss: 8.6652, Validation Loss Current: 7.1929, Validation Loss AVG: 7.1929, lr: 0.001
Epoch [11/80], Training Loss: 8.9563, Validation Loss Current: 6.9473, Validation Loss AVG: 6.9473, lr: 0.001
Epoch [12/80], Training Loss: 7.3948, Validation Loss Current: 7.0654, Validation Loss AVG: 7.0654, lr: 0.001
Epoch [13/80], Training Loss: 6.9890, Validation Loss Current: 7.7932, Validation Loss AVG: 7.7932, lr: 0.001
Epoch [14/80], Training Loss: 6.3884, Validation Loss Current: 6.5746, Validation Loss AVG: 6.5746, lr: 0.001
Epoch [15/80], Training Loss: 5.0071, Validation Loss Current: 7.1415, Validation Loss AVG: 7.1415, lr: 0.001
Epoch [16/80], Training Loss: 6.6512, Validation Loss Current: 8.1821, Validation Loss AVG: 8.1821, lr: 0.001
Epoch [17/80], Training Loss: 9.0704, Validation Loss Current: 12.6190, Validation Loss AVG: 12.6190, lr: 0.001
Epoch [18/80], Training Loss: 9.7265, Validation Loss Current: 8.9668, Validation Loss AVG: 8.9668, lr: 0.001
Epoch [19/80], Training Loss: 6.7419, Validation Loss Current: 6.8573, Validation Loss AVG: 6.8573, lr: 0.001
Epoch [20/80], Training Loss: 6.3724, Validation Loss Current: 7.6236, Validation Loss AVG: 7.6236, lr: 0.001
Epoch [21/80], Training Loss: 7.2247, Validation Loss Current: 9.2638, Validation Loss AVG: 9.2638, lr: 0.001
Epoch [22/80], Training Loss: 6.0055, Validation Loss Current: 7.5406, Validation Loss AVG: 7.5406, lr: 0.001
Epoch [23/80], Training Loss: 4.4284, Validation Loss Current: 6.9534, Validation Loss AVG: 6.9534, lr: 0.001
Epoch [24/80], Training Loss: 9.5718, Validation Loss Current: 7.9671, Validation Loss AVG: 7.9671, lr: 0.001
Epoch [25/80], Training Loss: 6.8160, Validation Loss Current: 7.9859, Validation Loss AVG: 7.9859, lr: 0.001
Epoch [26/80], Training Loss: 6.8669, Validation Loss Current: 9.2921, Validation Loss AVG: 9.2921, lr: 0.001
Epoch [27/80], Training Loss: 7.8909, Validation Loss Current: 7.8101, Validation Loss AVG: 7.8101, lr: 0.001
Epoch [28/80], Training Loss: 4.8032, Validation Loss Current: 7.5419, Validation Loss AVG: 7.5419, lr: 0.001
Epoch [29/80], Training Loss: 4.1232, Validation Loss Current: 8.3210, Validation Loss AVG: 8.3210, lr: 0.001
Epoch [30/80], Training Loss: 4.1621, Validation Loss Current: 7.0402, Validation Loss AVG: 7.0402, lr: 0.001
Epoch [31/80], Training Loss: 5.1315, Validation Loss Current: 7.6144, Validation Loss AVG: 7.6144, lr: 0.001
Epoch [32/80], Training Loss: 3.5013, Validation Loss Current: 6.8826, Validation Loss AVG: 6.8826, lr: 0.001
Epoch [33/80], Training Loss: 5.0232, Validation Loss Current: 7.5641, Validation Loss AVG: 7.5641, lr: 0.001
Epoch [34/80], Training Loss: 8.8274, Validation Loss Current: 9.6132, Validation Loss AVG: 9.6132, lr: 0.001
Epoch [35/80], Training Loss: 4.4508, Validation Loss Current: 7.7162, Validation Loss AVG: 7.7162, lr: 0.001
Epoch [36/80], Training Loss: 2.6162, Validation Loss Current: 7.2232, Validation Loss AVG: 7.2232, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random2 finished training. Best epoch: 6 Best val accuracy: [0.5769736842105263, 0.6177631578947368, 0.6236842105263157, 0.58125, 0.6529605263157895, 0.6796052631578947, 0.6358552631578946, 0.6223684210526316, 0.5894736842105263, 0.6055921052631579, 0.6319078947368422, 0.6059210526315789, 0.605263157894737, 0.63125, 0.64375, 0.6055921052631578, 0.48026315789473684, 0.5549342105263158, 0.6131578947368421, 0.6213815789473685, 0.5447368421052632, 0.625, 0.6407894736842106, 0.5957236842105263, 0.6108552631578947, 0.5707236842105263, 0.593421052631579, 0.6026315789473683, 0.5993421052631579, 0.6345394736842105, 0.6207236842105263, 0.6414473684210527, 0.6302631578947369, 0.5536184210526315, 0.6259868421052632, 0.6368421052631579] Best val loss: 5.330594766139984


Current group: llo_1_random3
Epoch [1/80], Training Loss: 37.6592, Validation Loss Current: 12.2569, Validation Loss AVG: 12.2569, lr: 0.001
Epoch [2/80], Training Loss: 26.4635, Validation Loss Current: 7.6610, Validation Loss AVG: 7.6610, lr: 0.001
Epoch [3/80], Training Loss: 19.0955, Validation Loss Current: 7.5953, Validation Loss AVG: 7.5953, lr: 0.001
Epoch [4/80], Training Loss: 16.8208, Validation Loss Current: 6.7965, Validation Loss AVG: 6.7965, lr: 0.001
Epoch [5/80], Training Loss: 12.6975, Validation Loss Current: 7.2256, Validation Loss AVG: 7.2256, lr: 0.001
Epoch [6/80], Training Loss: 9.9050, Validation Loss Current: 5.4841, Validation Loss AVG: 5.4841, lr: 0.001
Epoch [7/80], Training Loss: 10.9360, Validation Loss Current: 5.8540, Validation Loss AVG: 5.8540, lr: 0.001
Epoch [8/80], Training Loss: 8.3511, Validation Loss Current: 5.5905, Validation Loss AVG: 5.5905, lr: 0.001
Epoch [9/80], Training Loss: 6.2882, Validation Loss Current: 5.9500, Validation Loss AVG: 5.9500, lr: 0.001
Epoch [10/80], Training Loss: 4.7488, Validation Loss Current: 5.6590, Validation Loss AVG: 5.6590, lr: 0.001
Epoch [11/80], Training Loss: 4.6748, Validation Loss Current: 5.3710, Validation Loss AVG: 5.3710, lr: 0.001
Epoch [12/80], Training Loss: 4.8879, Validation Loss Current: 6.1188, Validation Loss AVG: 6.1188, lr: 0.001
Epoch [13/80], Training Loss: 4.2114, Validation Loss Current: 5.8638, Validation Loss AVG: 5.8638, lr: 0.001
Epoch [14/80], Training Loss: 5.8647, Validation Loss Current: 6.6842, Validation Loss AVG: 6.6842, lr: 0.001
Epoch [15/80], Training Loss: 6.7097, Validation Loss Current: 8.9161, Validation Loss AVG: 8.9161, lr: 0.001
Epoch [16/80], Training Loss: 4.8671, Validation Loss Current: 6.3679, Validation Loss AVG: 6.3679, lr: 0.001
Epoch [17/80], Training Loss: 3.4686, Validation Loss Current: 6.2088, Validation Loss AVG: 6.2088, lr: 0.001
Epoch [18/80], Training Loss: 4.0178, Validation Loss Current: 5.9259, Validation Loss AVG: 5.9259, lr: 0.001
Epoch [19/80], Training Loss: 7.2769, Validation Loss Current: 7.2208, Validation Loss AVG: 7.2208, lr: 0.001
Epoch [20/80], Training Loss: 7.5724, Validation Loss Current: 7.8136, Validation Loss AVG: 7.8136, lr: 0.001
Epoch [21/80], Training Loss: 3.5551, Validation Loss Current: 7.0407, Validation Loss AVG: 7.0407, lr: 0.001
Epoch [22/80], Training Loss: 3.4769, Validation Loss Current: 6.5246, Validation Loss AVG: 6.5246, lr: 0.001
Epoch [23/80], Training Loss: 6.7713, Validation Loss Current: 7.3821, Validation Loss AVG: 7.3821, lr: 0.001
Epoch [24/80], Training Loss: 9.8393, Validation Loss Current: 11.0185, Validation Loss AVG: 11.0185, lr: 0.001
Epoch [25/80], Training Loss: 9.1059, Validation Loss Current: 8.2595, Validation Loss AVG: 8.2595, lr: 0.001
Epoch [26/80], Training Loss: 7.5396, Validation Loss Current: 6.7924, Validation Loss AVG: 6.7924, lr: 0.001
Epoch [27/80], Training Loss: 4.2279, Validation Loss Current: 8.4687, Validation Loss AVG: 8.4687, lr: 0.001
Epoch [28/80], Training Loss: 6.3224, Validation Loss Current: 6.3273, Validation Loss AVG: 6.3273, lr: 0.001
Epoch [29/80], Training Loss: 7.7221, Validation Loss Current: 8.3058, Validation Loss AVG: 8.3058, lr: 0.001
Epoch [30/80], Training Loss: 7.8968, Validation Loss Current: 8.0241, Validation Loss AVG: 8.0241, lr: 0.001
Epoch [31/80], Training Loss: 3.3450, Validation Loss Current: 6.7044, Validation Loss AVG: 6.7044, lr: 0.001
Epoch [32/80], Training Loss: 4.0028, Validation Loss Current: 6.4398, Validation Loss AVG: 6.4398, lr: 0.001
Epoch [33/80], Training Loss: 8.1346, Validation Loss Current: 7.8489, Validation Loss AVG: 7.8489, lr: 0.001
Epoch [34/80], Training Loss: 5.4889, Validation Loss Current: 6.9258, Validation Loss AVG: 6.9258, lr: 0.001
Epoch [35/80], Training Loss: 7.3059, Validation Loss Current: 7.9652, Validation Loss AVG: 7.9652, lr: 0.001
Epoch [36/80], Training Loss: 6.6620, Validation Loss Current: 8.1623, Validation Loss AVG: 8.1623, lr: 0.001
Epoch [37/80], Training Loss: 6.8471, Validation Loss Current: 8.1281, Validation Loss AVG: 8.1281, lr: 0.001
Epoch [38/80], Training Loss: 5.1098, Validation Loss Current: 7.5230, Validation Loss AVG: 7.5230, lr: 0.001
Epoch [39/80], Training Loss: 3.0564, Validation Loss Current: 7.1612, Validation Loss AVG: 7.1612, lr: 0.001
Epoch [40/80], Training Loss: 6.8520, Validation Loss Current: 8.0476, Validation Loss AVG: 8.0476, lr: 0.001
Epoch [41/80], Training Loss: 5.8300, Validation Loss Current: 7.6198, Validation Loss AVG: 7.6198, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random3 finished training. Best epoch: 11 Best val accuracy: [0.46842105263157885, 0.6006578947368421, 0.6036184210526315, 0.5983552631578948, 0.6148026315789473, 0.6723684210526316, 0.6559210526315791, 0.6736842105263159, 0.6536184210526316, 0.6921052631578948, 0.6947368421052632, 0.6753289473684211, 0.6733552631578947, 0.6486842105263158, 0.5891447368421053, 0.6447368421052632, 0.6671052631578946, 0.6680921052631579, 0.6210526315789474, 0.5921052631578947, 0.6467105263157895, 0.6661184210526316, 0.6115131578947369, 0.5302631578947369, 0.5631578947368421, 0.6440789473684211, 0.550328947368421, 0.6611842105263157, 0.6059210526315789, 0.6131578947368421, 0.6519736842105263, 0.6608552631578948, 0.5898026315789473, 0.6480263157894737, 0.6131578947368421, 0.5766447368421053, 0.5963815789473684, 0.6075657894736842, 0.6407894736842106, 0.6263157894736843, 0.6299342105263157] Best val loss: 5.371022462844849


Current group: 1
Epoch [1/80], Training Loss: 38.9217, Validation Loss Current: 9.7194, Validation Loss AVG: 9.6428, lr: 0.001
Epoch [2/80], Training Loss: 19.5255, Validation Loss Current: 7.1372, Validation Loss AVG: 7.9308, lr: 0.001
Epoch [3/80], Training Loss: 14.4729, Validation Loss Current: 8.2921, Validation Loss AVG: 10.1078, lr: 0.001
Epoch [4/80], Training Loss: 12.1781, Validation Loss Current: 7.1181, Validation Loss AVG: 8.2210, lr: 0.001
Epoch [5/80], Training Loss: 6.8372, Validation Loss Current: 6.6537, Validation Loss AVG: 8.1639, lr: 0.001
Epoch [6/80], Training Loss: 5.3779, Validation Loss Current: 7.5414, Validation Loss AVG: 9.4221, lr: 0.001
Epoch [7/80], Training Loss: 5.0969, Validation Loss Current: 7.3345, Validation Loss AVG: 10.8858, lr: 0.001
Epoch [8/80], Training Loss: 2.8398, Validation Loss Current: 7.2497, Validation Loss AVG: 9.1267, lr: 0.001
Epoch [9/80], Training Loss: 1.5912, Validation Loss Current: 6.9220, Validation Loss AVG: 8.8697, lr: 0.001
Epoch [10/80], Training Loss: 2.1898, Validation Loss Current: 6.7138, Validation Loss AVG: 9.3521, lr: 0.001
Epoch [11/80], Training Loss: 7.0010, Validation Loss Current: 7.4017, Validation Loss AVG: 8.8270, lr: 0.001
Epoch [12/80], Training Loss: 7.3024, Validation Loss Current: 9.1221, Validation Loss AVG: 10.8181, lr: 0.001
Epoch [13/80], Training Loss: 5.0226, Validation Loss Current: 7.8341, Validation Loss AVG: 11.0822, lr: 0.001
Epoch [14/80], Training Loss: 2.8895, Validation Loss Current: 7.2693, Validation Loss AVG: 9.5935, lr: 0.001
Epoch [15/80], Training Loss: 5.5782, Validation Loss Current: 7.3288, Validation Loss AVG: 9.7475, lr: 0.001
Epoch [16/80], Training Loss: 5.1672, Validation Loss Current: 8.2459, Validation Loss AVG: 10.4713, lr: 0.001
Epoch [17/80], Training Loss: 10.6588, Validation Loss Current: 8.9472, Validation Loss AVG: 11.1795, lr: 0.001
Epoch [18/80], Training Loss: 6.5922, Validation Loss Current: 7.8449, Validation Loss AVG: 10.3686, lr: 0.001
Epoch [19/80], Training Loss: 6.0647, Validation Loss Current: 8.8173, Validation Loss AVG: 13.5974, lr: 0.001
Epoch [20/80], Training Loss: 5.7081, Validation Loss Current: 9.5021, Validation Loss AVG: 10.3915, lr: 0.001
Epoch [21/80], Training Loss: 6.4180, Validation Loss Current: 7.9769, Validation Loss AVG: 10.4496, lr: 0.001
Epoch [22/80], Training Loss: 7.8905, Validation Loss Current: 7.9168, Validation Loss AVG: 11.2101, lr: 0.001
Epoch [23/80], Training Loss: 4.6231, Validation Loss Current: 7.9206, Validation Loss AVG: 10.9178, lr: 0.001
Epoch [24/80], Training Loss: 4.1011, Validation Loss Current: 8.1024, Validation Loss AVG: 10.4849, lr: 0.001
Epoch [25/80], Training Loss: 2.9594, Validation Loss Current: 7.4612, Validation Loss AVG: 10.2220, lr: 0.001
Epoch [26/80], Training Loss: 1.8162, Validation Loss Current: 7.6627, Validation Loss AVG: 10.7424, lr: 0.001
Epoch [27/80], Training Loss: 1.7373, Validation Loss Current: 7.6570, Validation Loss AVG: 10.3156, lr: 0.001
Epoch [28/80], Training Loss: 1.1511, Validation Loss Current: 7.6040, Validation Loss AVG: 9.9228, lr: 0.001
Epoch [29/80], Training Loss: 3.8662, Validation Loss Current: 8.4082, Validation Loss AVG: 10.4912, lr: 0.001
Epoch [30/80], Training Loss: 3.1039, Validation Loss Current: 8.5535, Validation Loss AVG: 12.7497, lr: 0.001
Epoch [31/80], Training Loss: 2.4235, Validation Loss Current: 8.8713, Validation Loss AVG: 12.9855, lr: 0.001
Epoch [32/80], Training Loss: 1.7772, Validation Loss Current: 8.0807, Validation Loss AVG: 11.4912, lr: 0.001
Epoch [33/80], Training Loss: 3.1223, Validation Loss Current: 8.2952, Validation Loss AVG: 10.5284, lr: 0.001
Epoch [34/80], Training Loss: 5.3145, Validation Loss Current: 8.7790, Validation Loss AVG: 12.1281, lr: 0.001
Epoch [35/80], Training Loss: 6.3679, Validation Loss Current: 8.3952, Validation Loss AVG: 13.4206, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 5 Best val accuracy: [0.48519736842105265, 0.5970394736842105, 0.5394736842105263, 0.6101973684210527, 0.631578947368421, 0.5986842105263158, 0.6217105263157895, 0.631578947368421, 0.6381578947368421, 0.6332236842105263, 0.5970394736842105, 0.5805921052631579, 0.5921052631578947, 0.618421052631579, 0.625, 0.5970394736842105, 0.5608552631578947, 0.5773026315789473, 0.5740131578947368, 0.5592105263157895, 0.6118421052631579, 0.6036184210526315, 0.600328947368421, 0.600328947368421, 0.6052631578947368, 0.5921052631578947, 0.6019736842105263, 0.5921052631578947, 0.5822368421052632, 0.5707236842105263, 0.5707236842105263, 0.6134868421052632, 0.6200657894736842, 0.600328947368421, 0.6052631578947368] Best val loss: 6.653679013252258


Fold: 1
----- Training resnet18 with sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] -----
Current group: llo_0.2_random0
Epoch [1/80], Training Loss: 40.1439, Validation Loss Current: 9.9390, Validation Loss AVG: 9.9390, lr: 0.001
Epoch [2/80], Training Loss: 39.4762, Validation Loss Current: 9.8820, Validation Loss AVG: 9.8820, lr: 0.001
Epoch [3/80], Training Loss: 39.3340, Validation Loss Current: 9.8406, Validation Loss AVG: 9.8406, lr: 0.001
Epoch [4/80], Training Loss: 38.5811, Validation Loss Current: 9.5658, Validation Loss AVG: 9.5658, lr: 0.001
Epoch [5/80], Training Loss: 37.8047, Validation Loss Current: 9.4033, Validation Loss AVG: 9.4033, lr: 0.001
Epoch [6/80], Training Loss: 36.1744, Validation Loss Current: 9.1888, Validation Loss AVG: 9.1888, lr: 0.001
Epoch [7/80], Training Loss: 35.5453, Validation Loss Current: 8.9794, Validation Loss AVG: 8.9794, lr: 0.001
Epoch [8/80], Training Loss: 34.2748, Validation Loss Current: 8.6585, Validation Loss AVG: 8.6585, lr: 0.001
Epoch [9/80], Training Loss: 32.7654, Validation Loss Current: 8.5562, Validation Loss AVG: 8.5562, lr: 0.001
Epoch [10/80], Training Loss: 30.5681, Validation Loss Current: 8.2679, Validation Loss AVG: 8.2679, lr: 0.001
Epoch [11/80], Training Loss: 30.3685, Validation Loss Current: 8.2106, Validation Loss AVG: 8.2106, lr: 0.001
Epoch [12/80], Training Loss: 28.8207, Validation Loss Current: 10.3636, Validation Loss AVG: 10.3636, lr: 0.001
Epoch [13/80], Training Loss: 30.2659, Validation Loss Current: 8.0267, Validation Loss AVG: 8.0267, lr: 0.001
Epoch [14/80], Training Loss: 29.2428, Validation Loss Current: 8.1494, Validation Loss AVG: 8.1494, lr: 0.001
Epoch [15/80], Training Loss: 27.2967, Validation Loss Current: 8.3529, Validation Loss AVG: 8.3529, lr: 0.001
Epoch [16/80], Training Loss: 26.9226, Validation Loss Current: 7.8963, Validation Loss AVG: 7.8963, lr: 0.001
Epoch [17/80], Training Loss: 25.5938, Validation Loss Current: 7.8579, Validation Loss AVG: 7.8579, lr: 0.001
Epoch [18/80], Training Loss: 25.0236, Validation Loss Current: 7.8231, Validation Loss AVG: 7.8231, lr: 0.001
Epoch [19/80], Training Loss: 24.9858, Validation Loss Current: 7.7078, Validation Loss AVG: 7.7078, lr: 0.001
Epoch [20/80], Training Loss: 25.8323, Validation Loss Current: 7.4399, Validation Loss AVG: 7.4399, lr: 0.001
Epoch [21/80], Training Loss: 24.8885, Validation Loss Current: 8.3146, Validation Loss AVG: 8.3146, lr: 0.001
Epoch [22/80], Training Loss: 24.0986, Validation Loss Current: 7.2169, Validation Loss AVG: 7.2169, lr: 0.001
Epoch [23/80], Training Loss: 23.6411, Validation Loss Current: 7.5402, Validation Loss AVG: 7.5402, lr: 0.001
Epoch [24/80], Training Loss: 22.7791, Validation Loss Current: 7.7094, Validation Loss AVG: 7.7094, lr: 0.001
Epoch [25/80], Training Loss: 25.8811, Validation Loss Current: 9.7547, Validation Loss AVG: 9.7547, lr: 0.001
Epoch [26/80], Training Loss: 22.8258, Validation Loss Current: 7.3835, Validation Loss AVG: 7.3835, lr: 0.001
Epoch [27/80], Training Loss: 21.1578, Validation Loss Current: 7.3305, Validation Loss AVG: 7.3305, lr: 0.001
Epoch [28/80], Training Loss: 19.7003, Validation Loss Current: 7.2754, Validation Loss AVG: 7.2754, lr: 0.001
Epoch [29/80], Training Loss: 19.0108, Validation Loss Current: 6.9755, Validation Loss AVG: 6.9755, lr: 0.001
Epoch [30/80], Training Loss: 17.3765, Validation Loss Current: 6.6247, Validation Loss AVG: 6.6247, lr: 0.001
Epoch [31/80], Training Loss: 18.4782, Validation Loss Current: 6.5907, Validation Loss AVG: 6.5907, lr: 0.001
Epoch [32/80], Training Loss: 18.7930, Validation Loss Current: 7.9970, Validation Loss AVG: 7.9970, lr: 0.001
Epoch [33/80], Training Loss: 20.1887, Validation Loss Current: 7.1028, Validation Loss AVG: 7.1028, lr: 0.001
Epoch [34/80], Training Loss: 19.0772, Validation Loss Current: 7.1828, Validation Loss AVG: 7.1828, lr: 0.001
Epoch [35/80], Training Loss: 16.9333, Validation Loss Current: 7.1452, Validation Loss AVG: 7.1452, lr: 0.001
Epoch [36/80], Training Loss: 16.5659, Validation Loss Current: 6.5437, Validation Loss AVG: 6.5437, lr: 0.001
Epoch [37/80], Training Loss: 15.8084, Validation Loss Current: 7.1121, Validation Loss AVG: 7.1121, lr: 0.001
Epoch [38/80], Training Loss: 15.6717, Validation Loss Current: 6.3860, Validation Loss AVG: 6.3860, lr: 0.001
Epoch [39/80], Training Loss: 13.7081, Validation Loss Current: 6.6867, Validation Loss AVG: 6.6867, lr: 0.001
Epoch [40/80], Training Loss: 14.1868, Validation Loss Current: 7.1454, Validation Loss AVG: 7.1454, lr: 0.001
Epoch [41/80], Training Loss: 13.6928, Validation Loss Current: 7.3896, Validation Loss AVG: 7.3896, lr: 0.001
Epoch [42/80], Training Loss: 12.0822, Validation Loss Current: 6.5518, Validation Loss AVG: 6.5518, lr: 0.001
Epoch [43/80], Training Loss: 13.2702, Validation Loss Current: 8.3159, Validation Loss AVG: 8.3159, lr: 0.001
Epoch [44/80], Training Loss: 12.7801, Validation Loss Current: 8.2693, Validation Loss AVG: 8.2693, lr: 0.001
Epoch [45/80], Training Loss: 9.7690, Validation Loss Current: 6.2360, Validation Loss AVG: 6.2360, lr: 0.001
Epoch [46/80], Training Loss: 8.8833, Validation Loss Current: 6.3531, Validation Loss AVG: 6.3531, lr: 0.001
Epoch [47/80], Training Loss: 7.8945, Validation Loss Current: 8.3407, Validation Loss AVG: 8.3407, lr: 0.001
Epoch [48/80], Training Loss: 11.3816, Validation Loss Current: 7.2250, Validation Loss AVG: 7.2250, lr: 0.001
Epoch [49/80], Training Loss: 10.2729, Validation Loss Current: 7.8706, Validation Loss AVG: 7.8706, lr: 0.001
Epoch [50/80], Training Loss: 8.1345, Validation Loss Current: 7.1701, Validation Loss AVG: 7.1701, lr: 0.001
Epoch [51/80], Training Loss: 5.8442, Validation Loss Current: 6.5500, Validation Loss AVG: 6.5500, lr: 0.001
Epoch [52/80], Training Loss: 5.2218, Validation Loss Current: 6.8608, Validation Loss AVG: 6.8608, lr: 0.001
Epoch [53/80], Training Loss: 5.2485, Validation Loss Current: 7.6432, Validation Loss AVG: 7.6432, lr: 0.001
Epoch [54/80], Training Loss: 4.1481, Validation Loss Current: 6.7942, Validation Loss AVG: 6.7942, lr: 0.001
Epoch [55/80], Training Loss: 3.7542, Validation Loss Current: 7.4506, Validation Loss AVG: 7.4506, lr: 0.001
Epoch [56/80], Training Loss: 4.9333, Validation Loss Current: 7.5144, Validation Loss AVG: 7.5144, lr: 0.001
Epoch [57/80], Training Loss: 5.2016, Validation Loss Current: 8.2595, Validation Loss AVG: 8.2595, lr: 0.001
Epoch [58/80], Training Loss: 6.3565, Validation Loss Current: 8.5775, Validation Loss AVG: 8.5775, lr: 0.001
Epoch [59/80], Training Loss: 6.1569, Validation Loss Current: 7.3860, Validation Loss AVG: 7.3860, lr: 0.001
Epoch [60/80], Training Loss: 5.3700, Validation Loss Current: 8.0018, Validation Loss AVG: 8.0018, lr: 0.001
Epoch [61/80], Training Loss: 7.0043, Validation Loss Current: 8.0435, Validation Loss AVG: 8.0435, lr: 0.001
Epoch [62/80], Training Loss: 6.1602, Validation Loss Current: 7.8171, Validation Loss AVG: 7.8171, lr: 0.001
Epoch [63/80], Training Loss: 8.4903, Validation Loss Current: 7.5085, Validation Loss AVG: 7.5085, lr: 0.001
Epoch [64/80], Training Loss: 4.8325, Validation Loss Current: 8.1081, Validation Loss AVG: 8.1081, lr: 0.001
Epoch [65/80], Training Loss: 3.2665, Validation Loss Current: 8.0148, Validation Loss AVG: 8.0148, lr: 0.001
Epoch [66/80], Training Loss: 4.2606, Validation Loss Current: 7.5502, Validation Loss AVG: 7.5502, lr: 0.001
Epoch [67/80], Training Loss: 4.9198, Validation Loss Current: 8.4810, Validation Loss AVG: 8.4810, lr: 0.001
Epoch [68/80], Training Loss: 2.7893, Validation Loss Current: 7.4218, Validation Loss AVG: 7.4218, lr: 0.001
Epoch [69/80], Training Loss: 3.1782, Validation Loss Current: 9.4707, Validation Loss AVG: 9.4707, lr: 0.001
Epoch [70/80], Training Loss: 8.4788, Validation Loss Current: 7.7743, Validation Loss AVG: 7.7743, lr: 0.001
Epoch [71/80], Training Loss: 4.6765, Validation Loss Current: 8.2919, Validation Loss AVG: 8.2919, lr: 0.001
Epoch [72/80], Training Loss: 3.4626, Validation Loss Current: 10.5499, Validation Loss AVG: 10.5499, lr: 0.001
Epoch [73/80], Training Loss: 5.7758, Validation Loss Current: 8.7643, Validation Loss AVG: 8.7643, lr: 0.001
Epoch [74/80], Training Loss: 5.5840, Validation Loss Current: 16.2805, Validation Loss AVG: 16.2805, lr: 0.001
Epoch [75/80], Training Loss: 11.4534, Validation Loss Current: 9.7871, Validation Loss AVG: 9.7871, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random0 finished training. Best epoch: 45 Best val accuracy: [0.23782894736842106, 0.2513157894736842, 0.2595394736842105, 0.28092105263157896, 0.3134868421052632, 0.35625, 0.3299342105263158, 0.39769736842105263, 0.3950657894736842, 0.4108552631578948, 0.40394736842105267, 0.30032894736842103, 0.42434210526315785, 0.41052631578947374, 0.4128289473684211, 0.43618421052631573, 0.44177631578947374, 0.46447368421052637, 0.45427631578947364, 0.48190789473684215, 0.42960526315789477, 0.5095394736842105, 0.45921052631578946, 0.47335526315789467, 0.38355263157894737, 0.4753289473684211, 0.4990131578947368, 0.5049342105263157, 0.5075657894736841, 0.55625, 0.5552631578947368, 0.4569078947368421, 0.5121710526315789, 0.49572368421052637, 0.5141447368421053, 0.5578947368421052, 0.5174342105263158, 0.5773026315789473, 0.5381578947368421, 0.5421052631578948, 0.5154605263157894, 0.5700657894736841, 0.44769736842105257, 0.5019736842105262, 0.5789473684210527, 0.5726973684210526, 0.4944078947368421, 0.5259868421052631, 0.5233552631578947, 0.5608552631578947, 0.6032894736842105, 0.5529605263157895, 0.5447368421052631, 0.5789473684210525, 0.5631578947368421, 0.5555921052631578, 0.531578947368421, 0.5401315789473684, 0.5644736842105263, 0.5345394736842105, 0.5388157894736842, 0.5664473684210526, 0.5618421052631579, 0.5615131578947368, 0.562828947368421, 0.5700657894736842, 0.5536184210526316, 0.5769736842105264, 0.49671052631578955, 0.5868421052631578, 0.5490131578947369, 0.5013157894736843, 0.5213815789473685, 0.38355263157894737, 0.5023026315789474] Best val loss: 6.235991144180298


Current group: llo_0.2_random1
Epoch [1/80], Training Loss: 31.3378, Validation Loss Current: 10.2194, Validation Loss AVG: 10.2194, lr: 0.001
Epoch [2/80], Training Loss: 22.0520, Validation Loss Current: 8.4746, Validation Loss AVG: 8.4746, lr: 0.001
Epoch [3/80], Training Loss: 16.7142, Validation Loss Current: 7.0185, Validation Loss AVG: 7.0185, lr: 0.001
Epoch [4/80], Training Loss: 13.9320, Validation Loss Current: 6.9294, Validation Loss AVG: 6.9294, lr: 0.001
Epoch [5/80], Training Loss: 12.9193, Validation Loss Current: 8.5054, Validation Loss AVG: 8.5054, lr: 0.001
Epoch [6/80], Training Loss: 14.2049, Validation Loss Current: 6.3036, Validation Loss AVG: 6.3036, lr: 0.001
Epoch [7/80], Training Loss: 10.5070, Validation Loss Current: 5.9280, Validation Loss AVG: 5.9280, lr: 0.001
Epoch [8/80], Training Loss: 9.3203, Validation Loss Current: 6.6605, Validation Loss AVG: 6.6605, lr: 0.001
Epoch [9/80], Training Loss: 7.9150, Validation Loss Current: 6.4117, Validation Loss AVG: 6.4117, lr: 0.001
Epoch [10/80], Training Loss: 8.6451, Validation Loss Current: 7.3800, Validation Loss AVG: 7.3800, lr: 0.001
Epoch [11/80], Training Loss: 8.8972, Validation Loss Current: 7.5271, Validation Loss AVG: 7.5271, lr: 0.001
Epoch [12/80], Training Loss: 7.7033, Validation Loss Current: 7.2586, Validation Loss AVG: 7.2586, lr: 0.001
Epoch [13/80], Training Loss: 5.9349, Validation Loss Current: 6.1627, Validation Loss AVG: 6.1627, lr: 0.001
Epoch [14/80], Training Loss: 5.7357, Validation Loss Current: 6.7749, Validation Loss AVG: 6.7749, lr: 0.001
Epoch [15/80], Training Loss: 6.0572, Validation Loss Current: 6.6316, Validation Loss AVG: 6.6316, lr: 0.001
Epoch [16/80], Training Loss: 4.8926, Validation Loss Current: 6.4643, Validation Loss AVG: 6.4643, lr: 0.001
Epoch [17/80], Training Loss: 9.8602, Validation Loss Current: 7.6239, Validation Loss AVG: 7.6239, lr: 0.001
Epoch [18/80], Training Loss: 10.5712, Validation Loss Current: 9.1966, Validation Loss AVG: 9.1966, lr: 0.001
Epoch [19/80], Training Loss: 7.3928, Validation Loss Current: 6.8380, Validation Loss AVG: 6.8380, lr: 0.001
Epoch [20/80], Training Loss: 7.1570, Validation Loss Current: 6.5911, Validation Loss AVG: 6.5911, lr: 0.001
Epoch [21/80], Training Loss: 9.9996, Validation Loss Current: 6.5385, Validation Loss AVG: 6.5385, lr: 0.001
Epoch [22/80], Training Loss: 6.2580, Validation Loss Current: 8.4131, Validation Loss AVG: 8.4131, lr: 0.001
Epoch [23/80], Training Loss: 11.8197, Validation Loss Current: 8.1730, Validation Loss AVG: 8.1730, lr: 0.001
Epoch [24/80], Training Loss: 6.9863, Validation Loss Current: 7.2799, Validation Loss AVG: 7.2799, lr: 0.001
Epoch [25/80], Training Loss: 5.8978, Validation Loss Current: 7.7878, Validation Loss AVG: 7.7878, lr: 0.001
Epoch [26/80], Training Loss: 5.1767, Validation Loss Current: 6.8416, Validation Loss AVG: 6.8416, lr: 0.001
Epoch [27/80], Training Loss: 5.3383, Validation Loss Current: 6.6065, Validation Loss AVG: 6.6065, lr: 0.001
Epoch [28/80], Training Loss: 3.1199, Validation Loss Current: 6.6557, Validation Loss AVG: 6.6557, lr: 0.001
Epoch [29/80], Training Loss: 6.1121, Validation Loss Current: 7.4976, Validation Loss AVG: 7.4976, lr: 0.001
Epoch [30/80], Training Loss: 5.1654, Validation Loss Current: 7.2326, Validation Loss AVG: 7.2326, lr: 0.001
Epoch [31/80], Training Loss: 5.4668, Validation Loss Current: 7.9400, Validation Loss AVG: 7.9400, lr: 0.001
Epoch [32/80], Training Loss: 6.1917, Validation Loss Current: 7.2298, Validation Loss AVG: 7.2298, lr: 0.001
Epoch [33/80], Training Loss: 7.0588, Validation Loss Current: 7.7763, Validation Loss AVG: 7.7763, lr: 0.001
Epoch [34/80], Training Loss: 6.7028, Validation Loss Current: 7.4575, Validation Loss AVG: 7.4575, lr: 0.001
Epoch [35/80], Training Loss: 4.6204, Validation Loss Current: 6.9094, Validation Loss AVG: 6.9094, lr: 0.001
Epoch [36/80], Training Loss: 5.6402, Validation Loss Current: 7.0661, Validation Loss AVG: 7.0661, lr: 0.001
Epoch [37/80], Training Loss: 5.2424, Validation Loss Current: 12.9604, Validation Loss AVG: 12.9604, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random1 finished training. Best epoch: 7 Best val accuracy: [0.4796052631578947, 0.5223684210526316, 0.5578947368421052, 0.5549342105263158, 0.4881578947368421, 0.5894736842105264, 0.6194078947368421, 0.5832236842105263, 0.6144736842105264, 0.562828947368421, 0.5815789473684211, 0.5723684210526316, 0.61875, 0.6157894736842106, 0.6023026315789474, 0.618421052631579, 0.5411184210526316, 0.5046052631578947, 0.600328947368421, 0.5960526315789474, 0.5944078947368421, 0.5552631578947369, 0.5743421052631579, 0.5802631578947368, 0.5671052631578947, 0.6171052631578948, 0.6098684210526316, 0.6197368421052631, 0.5898026315789473, 0.6319078947368422, 0.5875, 0.5894736842105264, 0.5875, 0.6009868421052632, 0.6164473684210526, 0.6233552631578947, 0.49703947368421064] Best val loss: 5.928000271320343


Current group: llo_0.2_random2
Epoch [1/80], Training Loss: 27.1963, Validation Loss Current: 9.7864, Validation Loss AVG: 9.7864, lr: 0.001
Epoch [2/80], Training Loss: 21.3002, Validation Loss Current: 6.3747, Validation Loss AVG: 6.3747, lr: 0.001
Epoch [3/80], Training Loss: 13.2108, Validation Loss Current: 6.0883, Validation Loss AVG: 6.0883, lr: 0.001
Epoch [4/80], Training Loss: 11.0814, Validation Loss Current: 5.1089, Validation Loss AVG: 5.1089, lr: 0.001
Epoch [5/80], Training Loss: 8.7683, Validation Loss Current: 7.4247, Validation Loss AVG: 7.4247, lr: 0.001
Epoch [6/80], Training Loss: 9.0249, Validation Loss Current: 6.7823, Validation Loss AVG: 6.7823, lr: 0.001
Epoch [7/80], Training Loss: 16.7011, Validation Loss Current: 7.9203, Validation Loss AVG: 7.9203, lr: 0.001
Epoch [8/80], Training Loss: 13.3728, Validation Loss Current: 6.0376, Validation Loss AVG: 6.0376, lr: 0.001
Epoch [9/80], Training Loss: 7.3305, Validation Loss Current: 6.1652, Validation Loss AVG: 6.1652, lr: 0.001
Epoch [10/80], Training Loss: 6.3037, Validation Loss Current: 6.3700, Validation Loss AVG: 6.3700, lr: 0.001
Epoch [11/80], Training Loss: 5.4085, Validation Loss Current: 5.7773, Validation Loss AVG: 5.7773, lr: 0.001
Epoch [12/80], Training Loss: 4.3193, Validation Loss Current: 5.4257, Validation Loss AVG: 5.4257, lr: 0.001
Epoch [13/80], Training Loss: 4.3355, Validation Loss Current: 5.7888, Validation Loss AVG: 5.7888, lr: 0.001
Epoch [14/80], Training Loss: 4.9320, Validation Loss Current: 7.4482, Validation Loss AVG: 7.4482, lr: 0.001
Epoch [15/80], Training Loss: 7.9296, Validation Loss Current: 7.5302, Validation Loss AVG: 7.5302, lr: 0.001
Epoch [16/80], Training Loss: 6.8886, Validation Loss Current: 5.9330, Validation Loss AVG: 5.9330, lr: 0.001
Epoch [17/80], Training Loss: 5.7779, Validation Loss Current: 5.8057, Validation Loss AVG: 5.8057, lr: 0.001
Epoch [18/80], Training Loss: 6.6742, Validation Loss Current: 5.7449, Validation Loss AVG: 5.7449, lr: 0.001
Epoch [19/80], Training Loss: 2.5311, Validation Loss Current: 5.7905, Validation Loss AVG: 5.7905, lr: 0.001
Epoch [20/80], Training Loss: 2.7365, Validation Loss Current: 6.0446, Validation Loss AVG: 6.0446, lr: 0.001
Epoch [21/80], Training Loss: 3.2121, Validation Loss Current: 5.8960, Validation Loss AVG: 5.8960, lr: 0.001
Epoch [22/80], Training Loss: 2.7440, Validation Loss Current: 7.5925, Validation Loss AVG: 7.5925, lr: 0.001
Epoch [23/80], Training Loss: 5.0112, Validation Loss Current: 6.7509, Validation Loss AVG: 6.7509, lr: 0.001
Epoch [24/80], Training Loss: 7.0376, Validation Loss Current: 7.8166, Validation Loss AVG: 7.8166, lr: 0.001
Epoch [25/80], Training Loss: 3.7929, Validation Loss Current: 6.2373, Validation Loss AVG: 6.2373, lr: 0.001
Epoch [26/80], Training Loss: 7.1037, Validation Loss Current: 7.4238, Validation Loss AVG: 7.4238, lr: 0.001
Epoch [27/80], Training Loss: 3.8227, Validation Loss Current: 6.4942, Validation Loss AVG: 6.4942, lr: 0.001
Epoch [28/80], Training Loss: 3.9482, Validation Loss Current: 6.4339, Validation Loss AVG: 6.4339, lr: 0.001
Epoch [29/80], Training Loss: 4.6323, Validation Loss Current: 6.9999, Validation Loss AVG: 6.9999, lr: 0.001
Epoch [30/80], Training Loss: 3.4566, Validation Loss Current: 6.8662, Validation Loss AVG: 6.8662, lr: 0.001
Epoch [31/80], Training Loss: 3.7575, Validation Loss Current: 7.3374, Validation Loss AVG: 7.3374, lr: 0.001
Epoch [32/80], Training Loss: 4.2468, Validation Loss Current: 7.8801, Validation Loss AVG: 7.8801, lr: 0.001
Epoch [33/80], Training Loss: 3.4857, Validation Loss Current: 8.8522, Validation Loss AVG: 8.8522, lr: 0.001
Epoch [34/80], Training Loss: 4.9000, Validation Loss Current: 7.7319, Validation Loss AVG: 7.7319, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random2 finished training. Best epoch: 4 Best val accuracy: [0.536842105263158, 0.6253289473684212, 0.6282894736842105, 0.6888157894736843, 0.5490131578947369, 0.5963815789473684, 0.5516447368421052, 0.6319078947368421, 0.6434210526315789, 0.6401315789473684, 0.6539473684210526, 0.6661184210526316, 0.6641447368421052, 0.6223684210526316, 0.5733552631578948, 0.6598684210526317, 0.6536184210526316, 0.6651315789473684, 0.6674342105263158, 0.6536184210526315, 0.6664473684210527, 0.6125, 0.644736842105263, 0.5907894736842105, 0.649671052631579, 0.6259868421052631, 0.6338815789473683, 0.649671052631579, 0.6407894736842106, 0.6440789473684211, 0.6164473684210526, 0.6023026315789474, 0.5486842105263158, 0.6115131578947368] Best val loss: 5.108913850784302


Current group: llo_0.2_random3
Epoch [1/80], Training Loss: 28.4460, Validation Loss Current: 7.2661, Validation Loss AVG: 7.2661, lr: 0.001
Epoch [2/80], Training Loss: 16.1276, Validation Loss Current: 5.4778, Validation Loss AVG: 5.4778, lr: 0.001
Epoch [3/80], Training Loss: 10.3265, Validation Loss Current: 6.0400, Validation Loss AVG: 6.0400, lr: 0.001
Epoch [4/80], Training Loss: 9.1796, Validation Loss Current: 5.6093, Validation Loss AVG: 5.6093, lr: 0.001
Epoch [5/80], Training Loss: 7.1158, Validation Loss Current: 5.3320, Validation Loss AVG: 5.3320, lr: 0.001
Epoch [6/80], Training Loss: 4.5546, Validation Loss Current: 5.7606, Validation Loss AVG: 5.7606, lr: 0.001
Epoch [7/80], Training Loss: 3.4784, Validation Loss Current: 5.2591, Validation Loss AVG: 5.2591, lr: 0.001
Epoch [8/80], Training Loss: 4.3340, Validation Loss Current: 6.3806, Validation Loss AVG: 6.3806, lr: 0.001
Epoch [9/80], Training Loss: 10.5925, Validation Loss Current: 8.7583, Validation Loss AVG: 8.7583, lr: 0.001
Epoch [10/80], Training Loss: 6.2248, Validation Loss Current: 6.9621, Validation Loss AVG: 6.9621, lr: 0.001
Epoch [11/80], Training Loss: 8.1895, Validation Loss Current: 6.3750, Validation Loss AVG: 6.3750, lr: 0.001
Epoch [12/80], Training Loss: 3.1206, Validation Loss Current: 6.0543, Validation Loss AVG: 6.0543, lr: 0.001
Epoch [13/80], Training Loss: 2.0460, Validation Loss Current: 5.5999, Validation Loss AVG: 5.5999, lr: 0.001
Epoch [14/80], Training Loss: 4.7646, Validation Loss Current: 5.8482, Validation Loss AVG: 5.8482, lr: 0.001
Epoch [15/80], Training Loss: 4.8484, Validation Loss Current: 7.3565, Validation Loss AVG: 7.3565, lr: 0.001
Epoch [16/80], Training Loss: 7.0756, Validation Loss Current: 6.6030, Validation Loss AVG: 6.6030, lr: 0.001
Epoch [17/80], Training Loss: 4.3527, Validation Loss Current: 6.5473, Validation Loss AVG: 6.5473, lr: 0.001
Epoch [18/80], Training Loss: 4.4071, Validation Loss Current: 6.9549, Validation Loss AVG: 6.9549, lr: 0.001
Epoch [19/80], Training Loss: 5.2037, Validation Loss Current: 6.7132, Validation Loss AVG: 6.7132, lr: 0.001
Epoch [20/80], Training Loss: 2.9299, Validation Loss Current: 6.5364, Validation Loss AVG: 6.5364, lr: 0.001
Epoch [21/80], Training Loss: 1.7202, Validation Loss Current: 6.1376, Validation Loss AVG: 6.1376, lr: 0.001
Epoch [22/80], Training Loss: 2.6749, Validation Loss Current: 6.7412, Validation Loss AVG: 6.7412, lr: 0.001
Epoch [23/80], Training Loss: 5.0541, Validation Loss Current: 6.8402, Validation Loss AVG: 6.8402, lr: 0.001
Epoch [24/80], Training Loss: 9.0814, Validation Loss Current: 8.1528, Validation Loss AVG: 8.1528, lr: 0.001
Epoch [25/80], Training Loss: 7.0215, Validation Loss Current: 7.3532, Validation Loss AVG: 7.3532, lr: 0.001
Epoch [26/80], Training Loss: 8.2213, Validation Loss Current: 7.3571, Validation Loss AVG: 7.3571, lr: 0.001
Epoch [27/80], Training Loss: 5.7581, Validation Loss Current: 7.6045, Validation Loss AVG: 7.6045, lr: 0.001
Epoch [28/80], Training Loss: 3.9661, Validation Loss Current: 7.1886, Validation Loss AVG: 7.1886, lr: 0.001
Epoch [29/80], Training Loss: 5.2471, Validation Loss Current: 7.3792, Validation Loss AVG: 7.3792, lr: 0.001
Epoch [30/80], Training Loss: 4.3396, Validation Loss Current: 7.0782, Validation Loss AVG: 7.0782, lr: 0.001
Epoch [31/80], Training Loss: 1.5492, Validation Loss Current: 6.4339, Validation Loss AVG: 6.4339, lr: 0.001
Epoch [32/80], Training Loss: 1.1711, Validation Loss Current: 6.0421, Validation Loss AVG: 6.0421, lr: 0.001
Epoch [33/80], Training Loss: 2.0550, Validation Loss Current: 7.1223, Validation Loss AVG: 7.1223, lr: 0.001
Epoch [34/80], Training Loss: 4.5013, Validation Loss Current: 7.9413, Validation Loss AVG: 7.9413, lr: 0.001
Epoch [35/80], Training Loss: 3.2081, Validation Loss Current: 8.0781, Validation Loss AVG: 8.0781, lr: 0.001
Epoch [36/80], Training Loss: 3.3532, Validation Loss Current: 7.4215, Validation Loss AVG: 7.4215, lr: 0.001
Epoch [37/80], Training Loss: 3.5258, Validation Loss Current: 6.9545, Validation Loss AVG: 6.9545, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random3 finished training. Best epoch: 7 Best val accuracy: [0.618421052631579, 0.6615131578947369, 0.6756578947368421, 0.6835526315789473, 0.6828947368421052, 0.6861842105263157, 0.7059210526315789, 0.6611842105263157, 0.6049342105263158, 0.6361842105263158, 0.6763157894736842, 0.6736842105263158, 0.6973684210526315, 0.7000000000000001, 0.64375, 0.6328947368421053, 0.6424342105263158, 0.6611842105263158, 0.6585526315789473, 0.6667763157894737, 0.6861842105263157, 0.6753289473684211, 0.6592105263157895, 0.5944078947368421, 0.625328947368421, 0.6161184210526315, 0.6375, 0.6539473684210526, 0.6266447368421053, 0.6384868421052632, 0.6598684210526315, 0.6786184210526316, 0.6710526315789475, 0.60625, 0.63125, 0.625328947368421, 0.6631578947368422] Best val loss: 5.259109079837799


Current group: 0.2
Epoch [1/80], Training Loss: 46.0381, Validation Loss Current: 16.3484, Validation Loss AVG: 16.3484, lr: 0.001
Epoch [2/80], Training Loss: 26.3561, Validation Loss Current: 12.0002, Validation Loss AVG: 12.0002, lr: 0.001
Epoch [3/80], Training Loss: 21.1672, Validation Loss Current: 13.7355, Validation Loss AVG: 13.7355, lr: 0.001
Epoch [4/80], Training Loss: 17.9618, Validation Loss Current: 15.9635, Validation Loss AVG: 15.9635, lr: 0.001
Epoch [5/80], Training Loss: 15.0242, Validation Loss Current: 10.9872, Validation Loss AVG: 10.9872, lr: 0.001
Epoch [6/80], Training Loss: 12.0343, Validation Loss Current: 13.4643, Validation Loss AVG: 13.4643, lr: 0.001
Epoch [7/80], Training Loss: 12.0469, Validation Loss Current: 14.0420, Validation Loss AVG: 14.0420, lr: 0.001
Epoch [8/80], Training Loss: 8.4595, Validation Loss Current: 14.4423, Validation Loss AVG: 14.4423, lr: 0.001
Epoch [9/80], Training Loss: 8.2443, Validation Loss Current: 20.1192, Validation Loss AVG: 20.1192, lr: 0.001
Epoch [10/80], Training Loss: 12.8980, Validation Loss Current: 16.0036, Validation Loss AVG: 16.0036, lr: 0.001
Epoch [11/80], Training Loss: 10.4963, Validation Loss Current: 16.9501, Validation Loss AVG: 16.9501, lr: 0.001
Epoch [12/80], Training Loss: 5.6617, Validation Loss Current: 14.0873, Validation Loss AVG: 14.0873, lr: 0.001
Epoch [13/80], Training Loss: 7.2737, Validation Loss Current: 16.8468, Validation Loss AVG: 16.8468, lr: 0.001
Epoch [14/80], Training Loss: 9.4378, Validation Loss Current: 26.1152, Validation Loss AVG: 26.1152, lr: 0.001
Epoch [15/80], Training Loss: 9.3595, Validation Loss Current: 13.8808, Validation Loss AVG: 13.8808, lr: 0.001
Epoch [16/80], Training Loss: 9.3396, Validation Loss Current: 17.5762, Validation Loss AVG: 17.5762, lr: 0.001
Epoch [17/80], Training Loss: 8.1291, Validation Loss Current: 28.8745, Validation Loss AVG: 28.8745, lr: 0.001
Epoch [18/80], Training Loss: 8.8003, Validation Loss Current: 19.9879, Validation Loss AVG: 19.9879, lr: 0.001
Epoch [19/80], Training Loss: 8.0199, Validation Loss Current: 17.5114, Validation Loss AVG: 17.5114, lr: 0.001
Epoch [20/80], Training Loss: 10.3607, Validation Loss Current: 21.0155, Validation Loss AVG: 21.0155, lr: 0.001
Epoch [21/80], Training Loss: 5.4496, Validation Loss Current: 13.9698, Validation Loss AVG: 13.9698, lr: 0.001
Epoch [22/80], Training Loss: 6.5905, Validation Loss Current: 18.7479, Validation Loss AVG: 18.7479, lr: 0.001
Epoch [23/80], Training Loss: 5.8996, Validation Loss Current: 23.0861, Validation Loss AVG: 23.0861, lr: 0.001
Epoch [24/80], Training Loss: 7.2420, Validation Loss Current: 19.9841, Validation Loss AVG: 19.9841, lr: 0.001
Epoch [25/80], Training Loss: 3.5124, Validation Loss Current: 15.5395, Validation Loss AVG: 15.5395, lr: 0.001
Epoch [26/80], Training Loss: 4.3510, Validation Loss Current: 22.2323, Validation Loss AVG: 22.2323, lr: 0.001
Epoch [27/80], Training Loss: 10.5220, Validation Loss Current: 18.5789, Validation Loss AVG: 18.5789, lr: 0.001
Epoch [28/80], Training Loss: 10.1533, Validation Loss Current: 18.4036, Validation Loss AVG: 18.4036, lr: 0.001
Epoch [29/80], Training Loss: 5.5906, Validation Loss Current: 17.6100, Validation Loss AVG: 17.6100, lr: 0.001
Epoch [30/80], Training Loss: 3.1182, Validation Loss Current: 17.1426, Validation Loss AVG: 17.1426, lr: 0.001
Epoch [31/80], Training Loss: 5.5760, Validation Loss Current: 28.2815, Validation Loss AVG: 28.2815, lr: 0.001
Epoch [32/80], Training Loss: 10.1314, Validation Loss Current: 22.8162, Validation Loss AVG: 22.8162, lr: 0.001
Epoch [33/80], Training Loss: 8.0596, Validation Loss Current: 25.3049, Validation Loss AVG: 25.3049, lr: 0.001
Epoch [34/80], Training Loss: 9.3318, Validation Loss Current: 18.6748, Validation Loss AVG: 18.6748, lr: 0.001
Epoch [35/80], Training Loss: 5.3377, Validation Loss Current: 20.9504, Validation Loss AVG: 20.9504, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 5 Best val accuracy: [0.38026315789473686, 0.4338815789473684, 0.33782894736842106, 0.3575657894736842, 0.43322368421052637, 0.35592105263157897, 0.44046052631578947, 0.38914473684210527, 0.26875, 0.3868421052631578, 0.34638157894736843, 0.399671052631579, 0.3871710526315789, 0.22828947368421054, 0.4026315789473684, 0.31184210526315786, 0.22960526315789473, 0.28092105263157896, 0.32565789473684215, 0.3026315789473684, 0.4536184210526316, 0.3200657894736842, 0.3381578947368421, 0.3125, 0.3993421052631579, 0.2598684210526315, 0.40855263157894733, 0.36085526315789473, 0.3536184210526315, 0.4078947368421053, 0.22960526315789473, 0.31776315789473686, 0.2960526315789474, 0.37434210526315786, 0.38092105263157894] Best val loss: 10.98718626499176


----- Training resnet18 with sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] -----
Current group: llo_0.8_random0
Epoch [1/80], Training Loss: 40.3329, Validation Loss Current: 9.9558, Validation Loss AVG: 9.9558, lr: 0.001
Epoch [2/80], Training Loss: 39.6149, Validation Loss Current: 9.8373, Validation Loss AVG: 9.8373, lr: 0.001
Epoch [3/80], Training Loss: 39.0502, Validation Loss Current: 9.7011, Validation Loss AVG: 9.7011, lr: 0.001
Epoch [4/80], Training Loss: 38.7183, Validation Loss Current: 9.7072, Validation Loss AVG: 9.7072, lr: 0.001
Epoch [5/80], Training Loss: 38.0167, Validation Loss Current: 9.4678, Validation Loss AVG: 9.4678, lr: 0.001
Epoch [6/80], Training Loss: 37.2050, Validation Loss Current: 9.2690, Validation Loss AVG: 9.2690, lr: 0.001
Epoch [7/80], Training Loss: 37.6389, Validation Loss Current: 9.0503, Validation Loss AVG: 9.0503, lr: 0.001
Epoch [8/80], Training Loss: 36.2688, Validation Loss Current: 8.8708, Validation Loss AVG: 8.8708, lr: 0.001
Epoch [9/80], Training Loss: 34.7962, Validation Loss Current: 8.6361, Validation Loss AVG: 8.6361, lr: 0.001
Epoch [10/80], Training Loss: 34.3972, Validation Loss Current: 8.5567, Validation Loss AVG: 8.5567, lr: 0.001
Epoch [11/80], Training Loss: 33.7956, Validation Loss Current: 8.6681, Validation Loss AVG: 8.6681, lr: 0.001
Epoch [12/80], Training Loss: 33.0563, Validation Loss Current: 8.6166, Validation Loss AVG: 8.6166, lr: 0.001
Epoch [13/80], Training Loss: 32.6647, Validation Loss Current: 8.6751, Validation Loss AVG: 8.6751, lr: 0.001
Epoch [14/80], Training Loss: 31.2525, Validation Loss Current: 7.9017, Validation Loss AVG: 7.9017, lr: 0.001
Epoch [15/80], Training Loss: 29.8039, Validation Loss Current: 8.1477, Validation Loss AVG: 8.1477, lr: 0.001
Epoch [16/80], Training Loss: 30.3086, Validation Loss Current: 7.7282, Validation Loss AVG: 7.7282, lr: 0.001
Epoch [17/80], Training Loss: 28.6242, Validation Loss Current: 8.0576, Validation Loss AVG: 8.0576, lr: 0.001
Epoch [18/80], Training Loss: 27.4175, Validation Loss Current: 8.2130, Validation Loss AVG: 8.2130, lr: 0.001
Epoch [19/80], Training Loss: 28.6320, Validation Loss Current: 7.9503, Validation Loss AVG: 7.9503, lr: 0.001
Epoch [20/80], Training Loss: 27.3219, Validation Loss Current: 7.5198, Validation Loss AVG: 7.5198, lr: 0.001
Epoch [21/80], Training Loss: 26.2724, Validation Loss Current: 12.4967, Validation Loss AVG: 12.4967, lr: 0.001
Epoch [22/80], Training Loss: 26.8209, Validation Loss Current: 7.3655, Validation Loss AVG: 7.3655, lr: 0.001
Epoch [23/80], Training Loss: 25.5682, Validation Loss Current: 7.6481, Validation Loss AVG: 7.6481, lr: 0.001
Epoch [24/80], Training Loss: 25.1148, Validation Loss Current: 7.4523, Validation Loss AVG: 7.4523, lr: 0.001
Epoch [25/80], Training Loss: 25.3142, Validation Loss Current: 8.9104, Validation Loss AVG: 8.9104, lr: 0.001
Epoch [26/80], Training Loss: 24.1438, Validation Loss Current: 7.5325, Validation Loss AVG: 7.5325, lr: 0.001
Epoch [27/80], Training Loss: 23.8030, Validation Loss Current: 7.2586, Validation Loss AVG: 7.2586, lr: 0.001
Epoch [28/80], Training Loss: 22.7815, Validation Loss Current: 7.4612, Validation Loss AVG: 7.4612, lr: 0.001
Epoch [29/80], Training Loss: 22.6508, Validation Loss Current: 9.2913, Validation Loss AVG: 9.2913, lr: 0.001
Epoch [30/80], Training Loss: 20.4722, Validation Loss Current: 6.9996, Validation Loss AVG: 6.9996, lr: 0.001
Epoch [31/80], Training Loss: 19.6214, Validation Loss Current: 6.7414, Validation Loss AVG: 6.7414, lr: 0.001
Epoch [32/80], Training Loss: 19.8770, Validation Loss Current: 7.4478, Validation Loss AVG: 7.4478, lr: 0.001
Epoch [33/80], Training Loss: 20.9444, Validation Loss Current: 9.0683, Validation Loss AVG: 9.0683, lr: 0.001
Epoch [34/80], Training Loss: 19.1682, Validation Loss Current: 8.4339, Validation Loss AVG: 8.4339, lr: 0.001
Epoch [35/80], Training Loss: 17.4228, Validation Loss Current: 7.9390, Validation Loss AVG: 7.9390, lr: 0.001
Epoch [36/80], Training Loss: 18.4503, Validation Loss Current: 8.2904, Validation Loss AVG: 8.2904, lr: 0.001
Epoch [37/80], Training Loss: 17.4784, Validation Loss Current: 6.9502, Validation Loss AVG: 6.9502, lr: 0.001
Epoch [38/80], Training Loss: 15.8474, Validation Loss Current: 7.0853, Validation Loss AVG: 7.0853, lr: 0.001
Epoch [39/80], Training Loss: 14.9477, Validation Loss Current: 7.3616, Validation Loss AVG: 7.3616, lr: 0.001
Epoch [40/80], Training Loss: 14.2510, Validation Loss Current: 6.7414, Validation Loss AVG: 6.7414, lr: 0.001
Epoch [41/80], Training Loss: 13.0660, Validation Loss Current: 9.2487, Validation Loss AVG: 9.2487, lr: 0.001
Epoch [42/80], Training Loss: 12.8135, Validation Loss Current: 8.2235, Validation Loss AVG: 8.2235, lr: 0.001
Epoch [43/80], Training Loss: 12.1006, Validation Loss Current: 9.5637, Validation Loss AVG: 9.5637, lr: 0.001
Epoch [44/80], Training Loss: 11.6769, Validation Loss Current: 8.0712, Validation Loss AVG: 8.0712, lr: 0.001
Epoch [45/80], Training Loss: 13.6388, Validation Loss Current: 8.6595, Validation Loss AVG: 8.6595, lr: 0.001
Epoch [46/80], Training Loss: 12.4211, Validation Loss Current: 7.5942, Validation Loss AVG: 7.5942, lr: 0.001
Epoch [47/80], Training Loss: 11.1027, Validation Loss Current: 7.6076, Validation Loss AVG: 7.6076, lr: 0.001
Epoch [48/80], Training Loss: 9.9675, Validation Loss Current: 7.3677, Validation Loss AVG: 7.3677, lr: 0.001
Epoch [49/80], Training Loss: 11.7083, Validation Loss Current: 8.6777, Validation Loss AVG: 8.6777, lr: 0.001
Epoch [50/80], Training Loss: 8.1313, Validation Loss Current: 7.4283, Validation Loss AVG: 7.4283, lr: 0.001
Epoch [51/80], Training Loss: 6.7735, Validation Loss Current: 6.6570, Validation Loss AVG: 6.6570, lr: 0.001
Epoch [52/80], Training Loss: 5.1595, Validation Loss Current: 6.7968, Validation Loss AVG: 6.7968, lr: 0.001
Epoch [53/80], Training Loss: 5.5987, Validation Loss Current: 10.9860, Validation Loss AVG: 10.9860, lr: 0.001
Epoch [54/80], Training Loss: 11.6124, Validation Loss Current: 15.6604, Validation Loss AVG: 15.6604, lr: 0.001
Epoch [55/80], Training Loss: 12.9692, Validation Loss Current: 10.2053, Validation Loss AVG: 10.2053, lr: 0.001
Epoch [56/80], Training Loss: 8.3926, Validation Loss Current: 8.3729, Validation Loss AVG: 8.3729, lr: 0.001
Epoch [57/80], Training Loss: 8.0063, Validation Loss Current: 7.9343, Validation Loss AVG: 7.9343, lr: 0.001
Epoch [58/80], Training Loss: 6.4672, Validation Loss Current: 9.1404, Validation Loss AVG: 9.1404, lr: 0.001
Epoch [59/80], Training Loss: 7.7345, Validation Loss Current: 8.8145, Validation Loss AVG: 8.8145, lr: 0.001
Epoch [60/80], Training Loss: 13.0432, Validation Loss Current: 9.7195, Validation Loss AVG: 9.7195, lr: 0.001
Epoch [61/80], Training Loss: 12.6204, Validation Loss Current: 9.0272, Validation Loss AVG: 9.0272, lr: 0.001
Epoch [62/80], Training Loss: 8.7286, Validation Loss Current: 7.2209, Validation Loss AVG: 7.2209, lr: 0.001
Epoch [63/80], Training Loss: 6.4013, Validation Loss Current: 7.3500, Validation Loss AVG: 7.3500, lr: 0.001
Epoch [64/80], Training Loss: 7.1793, Validation Loss Current: 7.5243, Validation Loss AVG: 7.5243, lr: 0.001
Epoch [65/80], Training Loss: 6.2278, Validation Loss Current: 9.7694, Validation Loss AVG: 9.7694, lr: 0.001
Epoch [66/80], Training Loss: 7.0744, Validation Loss Current: 9.6889, Validation Loss AVG: 9.6889, lr: 0.001
Epoch [67/80], Training Loss: 5.6690, Validation Loss Current: 9.1098, Validation Loss AVG: 9.1098, lr: 0.001
Epoch [68/80], Training Loss: 4.8392, Validation Loss Current: 7.6477, Validation Loss AVG: 7.6477, lr: 0.001
Epoch [69/80], Training Loss: 3.6616, Validation Loss Current: 7.3457, Validation Loss AVG: 7.3457, lr: 0.001
Epoch [70/80], Training Loss: 6.2422, Validation Loss Current: 7.4128, Validation Loss AVG: 7.4128, lr: 0.001
Epoch [71/80], Training Loss: 6.2183, Validation Loss Current: 9.3350, Validation Loss AVG: 9.3350, lr: 0.001
Epoch [72/80], Training Loss: 5.1014, Validation Loss Current: 9.1886, Validation Loss AVG: 9.1886, lr: 0.001
Epoch [73/80], Training Loss: 8.4617, Validation Loss Current: 9.3362, Validation Loss AVG: 9.3362, lr: 0.001
Epoch [74/80], Training Loss: 5.9132, Validation Loss Current: 8.9113, Validation Loss AVG: 8.9113, lr: 0.001
Epoch [75/80], Training Loss: 4.0250, Validation Loss Current: 9.2750, Validation Loss AVG: 9.2750, lr: 0.001
Epoch [76/80], Training Loss: 4.4851, Validation Loss Current: 8.2342, Validation Loss AVG: 8.2342, lr: 0.001
Epoch [77/80], Training Loss: 5.2094, Validation Loss Current: 11.5917, Validation Loss AVG: 11.5917, lr: 0.001
Epoch [78/80], Training Loss: 10.5591, Validation Loss Current: 9.0461, Validation Loss AVG: 9.0461, lr: 0.001
Epoch [79/80], Training Loss: 5.8563, Validation Loss Current: 8.7976, Validation Loss AVG: 8.7976, lr: 0.001
Epoch [80/80], Training Loss: 4.8368, Validation Loss Current: 10.0558, Validation Loss AVG: 10.0558, lr: 0.001
Patch distance: llo_0.8_random0 finished training. Best epoch: 51 Best val accuracy: [0.24342105263157893, 0.262828947368421, 0.268421052631579, 0.29440789473684215, 0.3174342105263158, 0.3348684210526316, 0.3424342105263158, 0.3782894736842105, 0.38585526315789476, 0.3796052631578948, 0.3875, 0.3786184210526316, 0.39111842105263156, 0.4355263157894737, 0.425, 0.44703947368421054, 0.39835526315789477, 0.39375000000000004, 0.44046052631578947, 0.4753289473684211, 0.3092105263157895, 0.4825657894736842, 0.46907894736842104, 0.4881578947368421, 0.3828947368421053, 0.475, 0.49703947368421053, 0.4838815789473684, 0.3924342105263158, 0.5240131578947368, 0.5414473684210526, 0.4828947368421053, 0.44243421052631576, 0.43980263157894733, 0.47072368421052635, 0.47302631578947374, 0.5414473684210527, 0.5421052631578946, 0.5118421052631578, 0.549342105263158, 0.4513157894736842, 0.5164473684210525, 0.4858552631578948, 0.49703947368421053, 0.4516447368421052, 0.5029605263157895, 0.5177631578947368, 0.5342105263157894, 0.4631578947368421, 0.5460526315789475, 0.593421052631579, 0.5894736842105263, 0.4542763157894737, 0.3759868421052632, 0.4526315789473684, 0.5039473684210526, 0.5361842105263158, 0.49210526315789477, 0.5236842105263158, 0.4825657894736842, 0.4588815789473684, 0.5460526315789473, 0.5710526315789474, 0.5703947368421053, 0.5075657894736842, 0.5332236842105263, 0.5101973684210527, 0.5901315789473685, 0.5914473684210526, 0.5822368421052632, 0.5513157894736842, 0.5378289473684211, 0.5016447368421053, 0.5453947368421053, 0.5375, 0.5730263157894736, 0.46907894736842104, 0.5486842105263158, 0.5621710526315788, 0.5450657894736842] Best val loss: 6.657049834728241


Current group: llo_0.8_random1
Epoch [1/80], Training Loss: 35.3163, Validation Loss Current: 7.5110, Validation Loss AVG: 7.5110, lr: 0.001
Epoch [2/80], Training Loss: 22.9348, Validation Loss Current: 7.5112, Validation Loss AVG: 7.5112, lr: 0.001
Epoch [3/80], Training Loss: 19.3681, Validation Loss Current: 6.0965, Validation Loss AVG: 6.0965, lr: 0.001
Epoch [4/80], Training Loss: 17.7717, Validation Loss Current: 6.5998, Validation Loss AVG: 6.5998, lr: 0.001
Epoch [5/80], Training Loss: 16.8695, Validation Loss Current: 6.6359, Validation Loss AVG: 6.6359, lr: 0.001
Epoch [6/80], Training Loss: 11.9725, Validation Loss Current: 5.7897, Validation Loss AVG: 5.7897, lr: 0.001
Epoch [7/80], Training Loss: 10.1666, Validation Loss Current: 6.0182, Validation Loss AVG: 6.0182, lr: 0.001
Epoch [8/80], Training Loss: 9.1491, Validation Loss Current: 7.6406, Validation Loss AVG: 7.6406, lr: 0.001
Epoch [9/80], Training Loss: 13.7772, Validation Loss Current: 7.1336, Validation Loss AVG: 7.1336, lr: 0.001
Epoch [10/80], Training Loss: 7.6895, Validation Loss Current: 6.1186, Validation Loss AVG: 6.1186, lr: 0.001
Epoch [11/80], Training Loss: 6.0830, Validation Loss Current: 6.4186, Validation Loss AVG: 6.4186, lr: 0.001
Epoch [12/80], Training Loss: 6.3646, Validation Loss Current: 6.7609, Validation Loss AVG: 6.7609, lr: 0.001
Epoch [13/80], Training Loss: 9.7035, Validation Loss Current: 6.9671, Validation Loss AVG: 6.9671, lr: 0.001
Epoch [14/80], Training Loss: 9.2239, Validation Loss Current: 7.9367, Validation Loss AVG: 7.9367, lr: 0.001
Epoch [15/80], Training Loss: 8.4416, Validation Loss Current: 9.8763, Validation Loss AVG: 9.8763, lr: 0.001
Epoch [16/80], Training Loss: 14.4467, Validation Loss Current: 7.4996, Validation Loss AVG: 7.4996, lr: 0.001
Epoch [17/80], Training Loss: 10.3749, Validation Loss Current: 7.8485, Validation Loss AVG: 7.8485, lr: 0.001
Epoch [18/80], Training Loss: 9.3389, Validation Loss Current: 10.5314, Validation Loss AVG: 10.5314, lr: 0.001
Epoch [19/80], Training Loss: 9.3134, Validation Loss Current: 7.5798, Validation Loss AVG: 7.5798, lr: 0.001
Epoch [20/80], Training Loss: 6.5631, Validation Loss Current: 6.8024, Validation Loss AVG: 6.8024, lr: 0.001
Epoch [21/80], Training Loss: 5.9409, Validation Loss Current: 6.7166, Validation Loss AVG: 6.7166, lr: 0.001
Epoch [22/80], Training Loss: 6.0418, Validation Loss Current: 8.1676, Validation Loss AVG: 8.1676, lr: 0.001
Epoch [23/80], Training Loss: 5.7130, Validation Loss Current: 6.7451, Validation Loss AVG: 6.7451, lr: 0.001
Epoch [24/80], Training Loss: 5.5224, Validation Loss Current: 8.3005, Validation Loss AVG: 8.3005, lr: 0.001
Epoch [25/80], Training Loss: 7.9264, Validation Loss Current: 8.1694, Validation Loss AVG: 8.1694, lr: 0.001
Epoch [26/80], Training Loss: 7.2991, Validation Loss Current: 9.2964, Validation Loss AVG: 9.2964, lr: 0.001
Epoch [27/80], Training Loss: 5.0889, Validation Loss Current: 6.8198, Validation Loss AVG: 6.8198, lr: 0.001
Epoch [28/80], Training Loss: 4.1066, Validation Loss Current: 7.5041, Validation Loss AVG: 7.5041, lr: 0.001
Epoch [29/80], Training Loss: 3.3231, Validation Loss Current: 6.4485, Validation Loss AVG: 6.4485, lr: 0.001
Epoch [30/80], Training Loss: 3.7350, Validation Loss Current: 7.1336, Validation Loss AVG: 7.1336, lr: 0.001
Epoch [31/80], Training Loss: 2.1889, Validation Loss Current: 8.7921, Validation Loss AVG: 8.7921, lr: 0.001
Epoch [32/80], Training Loss: 3.2746, Validation Loss Current: 8.6504, Validation Loss AVG: 8.6504, lr: 0.001
Epoch [33/80], Training Loss: 3.0247, Validation Loss Current: 7.7591, Validation Loss AVG: 7.7591, lr: 0.001
Epoch [34/80], Training Loss: 5.1026, Validation Loss Current: 10.9044, Validation Loss AVG: 10.9044, lr: 0.001
Epoch [35/80], Training Loss: 3.5089, Validation Loss Current: 7.3228, Validation Loss AVG: 7.3228, lr: 0.001
Epoch [36/80], Training Loss: 7.7184, Validation Loss Current: 9.5180, Validation Loss AVG: 9.5180, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random1 finished training. Best epoch: 6 Best val accuracy: [0.5726973684210527, 0.55, 0.6131578947368422, 0.5703947368421053, 0.5516447368421054, 0.6148026315789474, 0.624671052631579, 0.5404605263157894, 0.5838815789473685, 0.6233552631578947, 0.6240131578947368, 0.6032894736842105, 0.5789473684210527, 0.5743421052631579, 0.5269736842105264, 0.5773026315789475, 0.5677631578947369, 0.5039473684210527, 0.5861842105263158, 0.593421052631579, 0.6115131578947368, 0.5911184210526316, 0.6101973684210527, 0.5506578947368421, 0.5384868421052631, 0.5447368421052632, 0.6299342105263157, 0.6009868421052631, 0.6348684210526316, 0.6042763157894737, 0.5730263157894736, 0.5825657894736842, 0.5983552631578948, 0.5171052631578947, 0.6157894736842107, 0.5493421052631579] Best val loss: 5.789747905731201


Current group: llo_0.8_random2
Epoch [1/80], Training Loss: 36.8970, Validation Loss Current: 7.6361, Validation Loss AVG: 7.6361, lr: 0.001
Epoch [2/80], Training Loss: 24.0563, Validation Loss Current: 6.5465, Validation Loss AVG: 6.5465, lr: 0.001
Epoch [3/80], Training Loss: 15.5000, Validation Loss Current: 5.7114, Validation Loss AVG: 5.7114, lr: 0.001
Epoch [4/80], Training Loss: 11.7642, Validation Loss Current: 5.5488, Validation Loss AVG: 5.5488, lr: 0.001
Epoch [5/80], Training Loss: 10.1837, Validation Loss Current: 5.8921, Validation Loss AVG: 5.8921, lr: 0.001
Epoch [6/80], Training Loss: 9.1310, Validation Loss Current: 7.0124, Validation Loss AVG: 7.0124, lr: 0.001
Epoch [7/80], Training Loss: 5.9787, Validation Loss Current: 5.2557, Validation Loss AVG: 5.2557, lr: 0.001
Epoch [8/80], Training Loss: 5.9264, Validation Loss Current: 5.4334, Validation Loss AVG: 5.4334, lr: 0.001
Epoch [9/80], Training Loss: 5.5257, Validation Loss Current: 9.3664, Validation Loss AVG: 9.3664, lr: 0.001
Epoch [10/80], Training Loss: 10.5981, Validation Loss Current: 10.8190, Validation Loss AVG: 10.8190, lr: 0.001
Epoch [11/80], Training Loss: 10.5863, Validation Loss Current: 6.0137, Validation Loss AVG: 6.0137, lr: 0.001
Epoch [12/80], Training Loss: 7.6039, Validation Loss Current: 7.9516, Validation Loss AVG: 7.9516, lr: 0.001
Epoch [13/80], Training Loss: 6.0689, Validation Loss Current: 7.0255, Validation Loss AVG: 7.0255, lr: 0.001
Epoch [14/80], Training Loss: 3.5108, Validation Loss Current: 5.9606, Validation Loss AVG: 5.9606, lr: 0.001
Epoch [15/80], Training Loss: 6.1385, Validation Loss Current: 6.5739, Validation Loss AVG: 6.5739, lr: 0.001
Epoch [16/80], Training Loss: 6.2139, Validation Loss Current: 6.6423, Validation Loss AVG: 6.6423, lr: 0.001
Epoch [17/80], Training Loss: 7.0783, Validation Loss Current: 6.8736, Validation Loss AVG: 6.8736, lr: 0.001
Epoch [18/80], Training Loss: 6.9259, Validation Loss Current: 6.7298, Validation Loss AVG: 6.7298, lr: 0.001
Epoch [19/80], Training Loss: 9.3315, Validation Loss Current: 9.7147, Validation Loss AVG: 9.7147, lr: 0.001
Epoch [20/80], Training Loss: 12.7053, Validation Loss Current: 8.0307, Validation Loss AVG: 8.0307, lr: 0.001
Epoch [21/80], Training Loss: 8.5246, Validation Loss Current: 6.8345, Validation Loss AVG: 6.8345, lr: 0.001
Epoch [22/80], Training Loss: 4.5057, Validation Loss Current: 6.2916, Validation Loss AVG: 6.2916, lr: 0.001
Epoch [23/80], Training Loss: 2.8598, Validation Loss Current: 5.9819, Validation Loss AVG: 5.9819, lr: 0.001
Epoch [24/80], Training Loss: 4.6515, Validation Loss Current: 7.3395, Validation Loss AVG: 7.3395, lr: 0.001
Epoch [25/80], Training Loss: 8.9764, Validation Loss Current: 9.8816, Validation Loss AVG: 9.8816, lr: 0.001
Epoch [26/80], Training Loss: 6.6874, Validation Loss Current: 7.1363, Validation Loss AVG: 7.1363, lr: 0.001
Epoch [27/80], Training Loss: 5.9794, Validation Loss Current: 7.0779, Validation Loss AVG: 7.0779, lr: 0.001
Epoch [28/80], Training Loss: 5.6536, Validation Loss Current: 6.6215, Validation Loss AVG: 6.6215, lr: 0.001
Epoch [29/80], Training Loss: 4.7649, Validation Loss Current: 6.9514, Validation Loss AVG: 6.9514, lr: 0.001
Epoch [30/80], Training Loss: 6.9038, Validation Loss Current: 8.7622, Validation Loss AVG: 8.7622, lr: 0.001
Epoch [31/80], Training Loss: 7.9958, Validation Loss Current: 7.2683, Validation Loss AVG: 7.2683, lr: 0.001
Epoch [32/80], Training Loss: 3.7192, Validation Loss Current: 7.1960, Validation Loss AVG: 7.1960, lr: 0.001
Epoch [33/80], Training Loss: 3.3742, Validation Loss Current: 6.6470, Validation Loss AVG: 6.6470, lr: 0.001
Epoch [34/80], Training Loss: 5.0079, Validation Loss Current: 7.7964, Validation Loss AVG: 7.7964, lr: 0.001
Epoch [35/80], Training Loss: 5.0340, Validation Loss Current: 7.3775, Validation Loss AVG: 7.3775, lr: 0.001
Epoch [36/80], Training Loss: 5.9013, Validation Loss Current: 7.3086, Validation Loss AVG: 7.3086, lr: 0.001
Epoch [37/80], Training Loss: 5.0669, Validation Loss Current: 8.2904, Validation Loss AVG: 8.2904, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random2 finished training. Best epoch: 7 Best val accuracy: [0.5828947368421052, 0.6023026315789475, 0.650657894736842, 0.6707236842105264, 0.6296052631578948, 0.6065789473684211, 0.6822368421052631, 0.6740131578947368, 0.5733552631578948, 0.49210526315789477, 0.655921052631579, 0.5990131578947369, 0.6029605263157896, 0.6664473684210526, 0.6335526315789474, 0.6434210526315789, 0.6371710526315789, 0.6546052631578948, 0.5828947368421054, 0.6009868421052632, 0.631578947368421, 0.6588815789473684, 0.675, 0.6398026315789473, 0.5365131578947369, 0.6398026315789473, 0.6378289473684211, 0.6259868421052632, 0.6167763157894737, 0.600328947368421, 0.6223684210526315, 0.638157894736842, 0.6493421052631578, 0.6190789473684211, 0.6509868421052631, 0.6361842105263158, 0.5986842105263157] Best val loss: 5.25565276145935


Current group: llo_0.8_random3
Epoch [1/80], Training Loss: 36.8502, Validation Loss Current: 7.2465, Validation Loss AVG: 7.2465, lr: 0.001
Epoch [2/80], Training Loss: 23.2477, Validation Loss Current: 7.1783, Validation Loss AVG: 7.1783, lr: 0.001
Epoch [3/80], Training Loss: 17.0591, Validation Loss Current: 6.4233, Validation Loss AVG: 6.4233, lr: 0.001
Epoch [4/80], Training Loss: 12.7342, Validation Loss Current: 5.2685, Validation Loss AVG: 5.2685, lr: 0.001
Epoch [5/80], Training Loss: 12.7529, Validation Loss Current: 6.4270, Validation Loss AVG: 6.4270, lr: 0.001
Epoch [6/80], Training Loss: 9.8206, Validation Loss Current: 7.9440, Validation Loss AVG: 7.9440, lr: 0.001
Epoch [7/80], Training Loss: 13.5661, Validation Loss Current: 6.9875, Validation Loss AVG: 6.9875, lr: 0.001
Epoch [8/80], Training Loss: 8.4480, Validation Loss Current: 5.4502, Validation Loss AVG: 5.4502, lr: 0.001
Epoch [9/80], Training Loss: 5.4521, Validation Loss Current: 5.2810, Validation Loss AVG: 5.2810, lr: 0.001
Epoch [10/80], Training Loss: 5.6099, Validation Loss Current: 5.0804, Validation Loss AVG: 5.0804, lr: 0.001
Epoch [11/80], Training Loss: 5.4739, Validation Loss Current: 5.5003, Validation Loss AVG: 5.5003, lr: 0.001
Epoch [12/80], Training Loss: 6.9125, Validation Loss Current: 7.3728, Validation Loss AVG: 7.3728, lr: 0.001
Epoch [13/80], Training Loss: 4.7719, Validation Loss Current: 6.6180, Validation Loss AVG: 6.6180, lr: 0.001
Epoch [14/80], Training Loss: 4.9558, Validation Loss Current: 6.2277, Validation Loss AVG: 6.2277, lr: 0.001
Epoch [15/80], Training Loss: 6.3117, Validation Loss Current: 6.4842, Validation Loss AVG: 6.4842, lr: 0.001
Epoch [16/80], Training Loss: 4.6478, Validation Loss Current: 6.6229, Validation Loss AVG: 6.6229, lr: 0.001
Epoch [17/80], Training Loss: 5.5040, Validation Loss Current: 6.9765, Validation Loss AVG: 6.9765, lr: 0.001
Epoch [18/80], Training Loss: 7.5193, Validation Loss Current: 6.7202, Validation Loss AVG: 6.7202, lr: 0.001
Epoch [19/80], Training Loss: 7.1646, Validation Loss Current: 6.2085, Validation Loss AVG: 6.2085, lr: 0.001
Epoch [20/80], Training Loss: 5.4857, Validation Loss Current: 6.3558, Validation Loss AVG: 6.3558, lr: 0.001
Epoch [21/80], Training Loss: 10.4564, Validation Loss Current: 7.6897, Validation Loss AVG: 7.6897, lr: 0.001
Epoch [22/80], Training Loss: 12.0992, Validation Loss Current: 7.0944, Validation Loss AVG: 7.0944, lr: 0.001
Epoch [23/80], Training Loss: 3.7955, Validation Loss Current: 5.8435, Validation Loss AVG: 5.8435, lr: 0.001
Epoch [24/80], Training Loss: 4.3013, Validation Loss Current: 6.4891, Validation Loss AVG: 6.4891, lr: 0.001
Epoch [25/80], Training Loss: 4.2211, Validation Loss Current: 6.6182, Validation Loss AVG: 6.6182, lr: 0.001
Epoch [26/80], Training Loss: 5.5863, Validation Loss Current: 6.9975, Validation Loss AVG: 6.9975, lr: 0.001
Epoch [27/80], Training Loss: 5.7539, Validation Loss Current: 7.1714, Validation Loss AVG: 7.1714, lr: 0.001
Epoch [28/80], Training Loss: 8.5450, Validation Loss Current: 6.9698, Validation Loss AVG: 6.9698, lr: 0.001
Epoch [29/80], Training Loss: 7.9525, Validation Loss Current: 8.1678, Validation Loss AVG: 8.1678, lr: 0.001
Epoch [30/80], Training Loss: 5.3742, Validation Loss Current: 7.6570, Validation Loss AVG: 7.6570, lr: 0.001
Epoch [31/80], Training Loss: 4.6105, Validation Loss Current: 6.9726, Validation Loss AVG: 6.9726, lr: 0.001
Epoch [32/80], Training Loss: 5.4765, Validation Loss Current: 8.9018, Validation Loss AVG: 8.9018, lr: 0.001
Epoch [33/80], Training Loss: 8.6148, Validation Loss Current: 8.3567, Validation Loss AVG: 8.3567, lr: 0.001
Epoch [34/80], Training Loss: 8.0440, Validation Loss Current: 8.5663, Validation Loss AVG: 8.5663, lr: 0.001
Epoch [35/80], Training Loss: 9.4229, Validation Loss Current: 8.6300, Validation Loss AVG: 8.6300, lr: 0.001
Epoch [36/80], Training Loss: 7.8899, Validation Loss Current: 9.4253, Validation Loss AVG: 9.4253, lr: 0.001
Epoch [37/80], Training Loss: 5.1256, Validation Loss Current: 7.2554, Validation Loss AVG: 7.2554, lr: 0.001
Epoch [38/80], Training Loss: 3.9154, Validation Loss Current: 7.2313, Validation Loss AVG: 7.2313, lr: 0.001
Epoch [39/80], Training Loss: 3.7748, Validation Loss Current: 7.1853, Validation Loss AVG: 7.1853, lr: 0.001
Epoch [40/80], Training Loss: 4.7048, Validation Loss Current: 7.4475, Validation Loss AVG: 7.4475, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random3 finished training. Best epoch: 10 Best val accuracy: [0.5921052631578947, 0.5723684210526315, 0.6111842105263158, 0.6723684210526316, 0.6197368421052631, 0.562171052631579, 0.5815789473684211, 0.6634868421052632, 0.6746710526315789, 0.7046052631578947, 0.6648026315789475, 0.611842105263158, 0.637171052631579, 0.6546052631578949, 0.6506578947368421, 0.6539473684210526, 0.6256578947368421, 0.6493421052631578, 0.6585526315789474, 0.656578947368421, 0.6305921052631579, 0.6134868421052632, 0.6667763157894736, 0.6358552631578946, 0.6470394736842104, 0.6483552631578947, 0.6467105263157895, 0.6266447368421053, 0.5825657894736842, 0.6335526315789475, 0.6230263157894737, 0.5894736842105264, 0.5661184210526315, 0.6029605263157894, 0.5815789473684211, 0.5618421052631579, 0.6161184210526315, 0.6223684210526317, 0.6171052631578948, 0.624671052631579] Best val loss: 5.080368387699127


Current group: 0.8
Epoch [1/80], Training Loss: 30.4148, Validation Loss Current: 7.1984, Validation Loss AVG: 7.1984, lr: 0.001
Epoch [2/80], Training Loss: 21.0690, Validation Loss Current: 8.9587, Validation Loss AVG: 8.9587, lr: 0.001
Epoch [3/80], Training Loss: 14.2761, Validation Loss Current: 7.4813, Validation Loss AVG: 7.4813, lr: 0.001
Epoch [4/80], Training Loss: 10.5443, Validation Loss Current: 7.0619, Validation Loss AVG: 7.0619, lr: 0.001
Epoch [5/80], Training Loss: 6.3402, Validation Loss Current: 7.4982, Validation Loss AVG: 7.4982, lr: 0.001
Epoch [6/80], Training Loss: 3.7044, Validation Loss Current: 7.5661, Validation Loss AVG: 7.5661, lr: 0.001
Epoch [7/80], Training Loss: 3.7276, Validation Loss Current: 7.1321, Validation Loss AVG: 7.1321, lr: 0.001
Epoch [8/80], Training Loss: 2.8949, Validation Loss Current: 7.9503, Validation Loss AVG: 7.9503, lr: 0.001
Epoch [9/80], Training Loss: 3.0035, Validation Loss Current: 7.4437, Validation Loss AVG: 7.4437, lr: 0.001
Epoch [10/80], Training Loss: 8.2731, Validation Loss Current: 8.5831, Validation Loss AVG: 8.5831, lr: 0.001
Epoch [11/80], Training Loss: 3.8245, Validation Loss Current: 7.7723, Validation Loss AVG: 7.7723, lr: 0.001
Epoch [12/80], Training Loss: 4.8319, Validation Loss Current: 7.6236, Validation Loss AVG: 7.6236, lr: 0.001
Epoch [13/80], Training Loss: 3.5392, Validation Loss Current: 8.1745, Validation Loss AVG: 8.1745, lr: 0.001
Epoch [14/80], Training Loss: 2.7729, Validation Loss Current: 8.3133, Validation Loss AVG: 8.3133, lr: 0.001
Epoch [15/80], Training Loss: 3.2097, Validation Loss Current: 8.2979, Validation Loss AVG: 8.2979, lr: 0.001
Epoch [16/80], Training Loss: 5.5007, Validation Loss Current: 8.1342, Validation Loss AVG: 8.1342, lr: 0.001
Epoch [17/80], Training Loss: 4.3473, Validation Loss Current: 9.0065, Validation Loss AVG: 9.0065, lr: 0.001
Epoch [18/80], Training Loss: 4.5250, Validation Loss Current: 10.6992, Validation Loss AVG: 10.6992, lr: 0.001
Epoch [19/80], Training Loss: 4.4439, Validation Loss Current: 8.8543, Validation Loss AVG: 8.8543, lr: 0.001
Epoch [20/80], Training Loss: 3.5025, Validation Loss Current: 8.7533, Validation Loss AVG: 8.7533, lr: 0.001
Epoch [21/80], Training Loss: 2.9296, Validation Loss Current: 8.8210, Validation Loss AVG: 8.8210, lr: 0.001
Epoch [22/80], Training Loss: 2.6661, Validation Loss Current: 8.8310, Validation Loss AVG: 8.8310, lr: 0.001
Epoch [23/80], Training Loss: 4.3235, Validation Loss Current: 8.7563, Validation Loss AVG: 8.7563, lr: 0.001
Epoch [24/80], Training Loss: 2.4299, Validation Loss Current: 9.2330, Validation Loss AVG: 9.2330, lr: 0.001
Epoch [25/80], Training Loss: 4.9176, Validation Loss Current: 8.2591, Validation Loss AVG: 8.2591, lr: 0.001
Epoch [26/80], Training Loss: 5.2018, Validation Loss Current: 9.5329, Validation Loss AVG: 9.5329, lr: 0.001
Epoch [27/80], Training Loss: 2.3109, Validation Loss Current: 8.4190, Validation Loss AVG: 8.4190, lr: 0.001
Epoch [28/80], Training Loss: 2.1310, Validation Loss Current: 8.5780, Validation Loss AVG: 8.5780, lr: 0.001
Epoch [29/80], Training Loss: 2.7325, Validation Loss Current: 9.1257, Validation Loss AVG: 9.1257, lr: 0.001
Epoch [30/80], Training Loss: 7.3425, Validation Loss Current: 11.5991, Validation Loss AVG: 11.5991, lr: 0.001
Epoch [31/80], Training Loss: 3.8784, Validation Loss Current: 8.3944, Validation Loss AVG: 8.3944, lr: 0.001
Epoch [32/80], Training Loss: 5.0693, Validation Loss Current: 8.8193, Validation Loss AVG: 8.8193, lr: 0.001
Epoch [33/80], Training Loss: 2.8188, Validation Loss Current: 8.8821, Validation Loss AVG: 8.8821, lr: 0.001
Epoch [34/80], Training Loss: 3.8798, Validation Loss Current: 9.4406, Validation Loss AVG: 9.4406, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.6148026315789474, 0.54375, 0.6, 0.5763157894736841, 0.5993421052631579, 0.5963815789473684, 0.5983552631578948, 0.5953947368421053, 0.6029605263157896, 0.5736842105263158, 0.5838815789473684, 0.5875, 0.562171052631579, 0.5654605263157895, 0.5733552631578946, 0.5710526315789474, 0.5585526315789474, 0.5121710526315789, 0.5253289473684211, 0.5779605263157895, 0.5855263157894737, 0.5605263157894738, 0.55625, 0.5759868421052632, 0.5786184210526316, 0.5605263157894737, 0.5634868421052632, 0.5667763157894736, 0.54375, 0.5460526315789475, 0.5730263157894736, 0.5444078947368421, 0.5671052631578947, 0.5328947368421052] Best val loss: 7.061944639682769


----- Training resnet18 with sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] -----
Current group: llo_0.4_random0
Epoch [1/80], Training Loss: 40.7960, Validation Loss Current: 10.0403, Validation Loss AVG: 10.0403, lr: 0.001
Epoch [2/80], Training Loss: 39.9577, Validation Loss Current: 9.8813, Validation Loss AVG: 9.8813, lr: 0.001
Epoch [3/80], Training Loss: 39.0465, Validation Loss Current: 9.7796, Validation Loss AVG: 9.7796, lr: 0.001
Epoch [4/80], Training Loss: 38.1801, Validation Loss Current: 9.4829, Validation Loss AVG: 9.4829, lr: 0.001
Epoch [5/80], Training Loss: 37.6286, Validation Loss Current: 9.4451, Validation Loss AVG: 9.4451, lr: 0.001
Epoch [6/80], Training Loss: 36.3332, Validation Loss Current: 9.1466, Validation Loss AVG: 9.1466, lr: 0.001
Epoch [7/80], Training Loss: 35.2638, Validation Loss Current: 8.8692, Validation Loss AVG: 8.8692, lr: 0.001
Epoch [8/80], Training Loss: 35.0479, Validation Loss Current: 8.8240, Validation Loss AVG: 8.8240, lr: 0.001
Epoch [9/80], Training Loss: 33.4833, Validation Loss Current: 8.5185, Validation Loss AVG: 8.5185, lr: 0.001
Epoch [10/80], Training Loss: 31.6820, Validation Loss Current: 8.5443, Validation Loss AVG: 8.5443, lr: 0.001
Epoch [11/80], Training Loss: 31.8489, Validation Loss Current: 8.3887, Validation Loss AVG: 8.3887, lr: 0.001
Epoch [12/80], Training Loss: 31.3547, Validation Loss Current: 8.0960, Validation Loss AVG: 8.0960, lr: 0.001
Epoch [13/80], Training Loss: 31.0749, Validation Loss Current: 8.1216, Validation Loss AVG: 8.1216, lr: 0.001
Epoch [14/80], Training Loss: 30.1819, Validation Loss Current: 7.8612, Validation Loss AVG: 7.8612, lr: 0.001
Epoch [15/80], Training Loss: 29.3710, Validation Loss Current: 7.9015, Validation Loss AVG: 7.9015, lr: 0.001
Epoch [16/80], Training Loss: 28.1887, Validation Loss Current: 7.9815, Validation Loss AVG: 7.9815, lr: 0.001
Epoch [17/80], Training Loss: 28.3147, Validation Loss Current: 7.9370, Validation Loss AVG: 7.9370, lr: 0.001
Epoch [18/80], Training Loss: 27.0631, Validation Loss Current: 7.7801, Validation Loss AVG: 7.7801, lr: 0.001
Epoch [19/80], Training Loss: 26.8512, Validation Loss Current: 7.3464, Validation Loss AVG: 7.3464, lr: 0.001
Epoch [20/80], Training Loss: 25.2359, Validation Loss Current: 7.5264, Validation Loss AVG: 7.5264, lr: 0.001
Epoch [21/80], Training Loss: 25.1959, Validation Loss Current: 9.4900, Validation Loss AVG: 9.4900, lr: 0.001
Epoch [22/80], Training Loss: 25.7011, Validation Loss Current: 8.5677, Validation Loss AVG: 8.5677, lr: 0.001
Epoch [23/80], Training Loss: 24.3621, Validation Loss Current: 7.3039, Validation Loss AVG: 7.3039, lr: 0.001
Epoch [24/80], Training Loss: 23.4369, Validation Loss Current: 7.5285, Validation Loss AVG: 7.5285, lr: 0.001
Epoch [25/80], Training Loss: 24.8914, Validation Loss Current: 7.4925, Validation Loss AVG: 7.4925, lr: 0.001
Epoch [26/80], Training Loss: 24.3502, Validation Loss Current: 7.5260, Validation Loss AVG: 7.5260, lr: 0.001
Epoch [27/80], Training Loss: 22.0280, Validation Loss Current: 7.3306, Validation Loss AVG: 7.3306, lr: 0.001
Epoch [28/80], Training Loss: 20.9204, Validation Loss Current: 7.1786, Validation Loss AVG: 7.1786, lr: 0.001
Epoch [29/80], Training Loss: 20.6414, Validation Loss Current: 7.0124, Validation Loss AVG: 7.0124, lr: 0.001
Epoch [30/80], Training Loss: 19.0200, Validation Loss Current: 7.0896, Validation Loss AVG: 7.0896, lr: 0.001
Epoch [31/80], Training Loss: 17.8200, Validation Loss Current: 6.5026, Validation Loss AVG: 6.5026, lr: 0.001
Epoch [32/80], Training Loss: 18.2749, Validation Loss Current: 6.9357, Validation Loss AVG: 6.9357, lr: 0.001
Epoch [33/80], Training Loss: 17.1455, Validation Loss Current: 8.0585, Validation Loss AVG: 8.0585, lr: 0.001
Epoch [34/80], Training Loss: 17.5078, Validation Loss Current: 6.6934, Validation Loss AVG: 6.6934, lr: 0.001
Epoch [35/80], Training Loss: 15.5977, Validation Loss Current: 6.6767, Validation Loss AVG: 6.6767, lr: 0.001
Epoch [36/80], Training Loss: 15.1000, Validation Loss Current: 6.8758, Validation Loss AVG: 6.8758, lr: 0.001
Epoch [37/80], Training Loss: 13.1096, Validation Loss Current: 6.3280, Validation Loss AVG: 6.3280, lr: 0.001
Epoch [38/80], Training Loss: 13.2239, Validation Loss Current: 9.1510, Validation Loss AVG: 9.1510, lr: 0.001
Epoch [39/80], Training Loss: 17.1228, Validation Loss Current: 7.0917, Validation Loss AVG: 7.0917, lr: 0.001
Epoch [40/80], Training Loss: 14.0147, Validation Loss Current: 7.8165, Validation Loss AVG: 7.8165, lr: 0.001
Epoch [41/80], Training Loss: 11.5058, Validation Loss Current: 8.4313, Validation Loss AVG: 8.4313, lr: 0.001
Epoch [42/80], Training Loss: 11.4265, Validation Loss Current: 7.2207, Validation Loss AVG: 7.2207, lr: 0.001
Epoch [43/80], Training Loss: 14.7866, Validation Loss Current: 7.4811, Validation Loss AVG: 7.4811, lr: 0.001
Epoch [44/80], Training Loss: 12.0328, Validation Loss Current: 6.6533, Validation Loss AVG: 6.6533, lr: 0.001
Epoch [45/80], Training Loss: 10.1072, Validation Loss Current: 7.1686, Validation Loss AVG: 7.1686, lr: 0.001
Epoch [46/80], Training Loss: 10.0152, Validation Loss Current: 6.7983, Validation Loss AVG: 6.7983, lr: 0.001
Epoch [47/80], Training Loss: 10.0988, Validation Loss Current: 12.7190, Validation Loss AVG: 12.7190, lr: 0.001
Epoch [48/80], Training Loss: 12.7244, Validation Loss Current: 9.6140, Validation Loss AVG: 9.6140, lr: 0.001
Epoch [49/80], Training Loss: 10.2959, Validation Loss Current: 7.2819, Validation Loss AVG: 7.2819, lr: 0.001
Epoch [50/80], Training Loss: 8.2306, Validation Loss Current: 7.6194, Validation Loss AVG: 7.6194, lr: 0.001
Epoch [51/80], Training Loss: 7.5468, Validation Loss Current: 6.6384, Validation Loss AVG: 6.6384, lr: 0.001
Epoch [52/80], Training Loss: 5.6336, Validation Loss Current: 6.9870, Validation Loss AVG: 6.9870, lr: 0.001
Epoch [53/80], Training Loss: 5.2981, Validation Loss Current: 7.5336, Validation Loss AVG: 7.5336, lr: 0.001
Epoch [54/80], Training Loss: 9.3652, Validation Loss Current: 8.6737, Validation Loss AVG: 8.6737, lr: 0.001
Epoch [55/80], Training Loss: 11.8623, Validation Loss Current: 8.7406, Validation Loss AVG: 8.7406, lr: 0.001
Epoch [56/80], Training Loss: 7.1799, Validation Loss Current: 7.6968, Validation Loss AVG: 7.6968, lr: 0.001
Epoch [57/80], Training Loss: 5.6197, Validation Loss Current: 7.8776, Validation Loss AVG: 7.8776, lr: 0.001
Epoch [58/80], Training Loss: 8.1688, Validation Loss Current: 7.6282, Validation Loss AVG: 7.6282, lr: 0.001
Epoch [59/80], Training Loss: 6.1734, Validation Loss Current: 7.5769, Validation Loss AVG: 7.5769, lr: 0.001
Epoch [60/80], Training Loss: 9.4611, Validation Loss Current: 9.4618, Validation Loss AVG: 9.4618, lr: 0.001
Epoch [61/80], Training Loss: 6.9618, Validation Loss Current: 7.6527, Validation Loss AVG: 7.6527, lr: 0.001
Epoch [62/80], Training Loss: 4.7087, Validation Loss Current: 8.3437, Validation Loss AVG: 8.3437, lr: 0.001
Epoch [63/80], Training Loss: 5.7155, Validation Loss Current: 8.1683, Validation Loss AVG: 8.1683, lr: 0.001
Epoch [64/80], Training Loss: 6.8537, Validation Loss Current: 8.6953, Validation Loss AVG: 8.6953, lr: 0.001
Epoch [65/80], Training Loss: 5.5449, Validation Loss Current: 7.5710, Validation Loss AVG: 7.5710, lr: 0.001
Epoch [66/80], Training Loss: 4.2391, Validation Loss Current: 7.6199, Validation Loss AVG: 7.6199, lr: 0.001
Epoch [67/80], Training Loss: 3.1017, Validation Loss Current: 7.4880, Validation Loss AVG: 7.4880, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random0 finished training. Best epoch: 37 Best val accuracy: [0.24342105263157893, 0.24605263157894736, 0.25625, 0.28552631578947374, 0.3273026315789474, 0.34375, 0.36875, 0.3680921052631579, 0.40855263157894733, 0.39506578947368426, 0.40625, 0.4233552631578947, 0.44210526315789467, 0.45032894736842105, 0.4421052631578948, 0.44572368421052627, 0.43717105263157896, 0.43947368421052635, 0.4828947368421053, 0.47335526315789467, 0.3592105263157895, 0.40328947368421053, 0.4822368421052632, 0.4720394736842105, 0.4983552631578948, 0.46414473684210533, 0.4792763157894737, 0.4822368421052632, 0.5174342105263158, 0.4921052631578947, 0.5523026315789474, 0.5049342105263158, 0.475, 0.5381578947368421, 0.5404605263157894, 0.5276315789473685, 0.569078947368421, 0.42598684210526316, 0.5342105263157895, 0.5032894736842105, 0.47269736842105264, 0.5236842105263159, 0.49605263157894736, 0.5539473684210525, 0.5391447368421052, 0.5470394736842106, 0.36118421052631583, 0.4753289473684211, 0.5108552631578948, 0.5302631578947368, 0.5654605263157895, 0.5598684210526316, 0.5328947368421052, 0.5279605263157896, 0.5055921052631579, 0.5161184210526316, 0.5519736842105264, 0.5578947368421052, 0.5529605263157894, 0.4983552631578947, 0.55, 0.5351973684210527, 0.5194078947368421, 0.5286184210526315, 0.5618421052631579, 0.5773026315789473, 0.5832236842105263] Best val loss: 6.328004002571106


Current group: llo_0.4_random1
Epoch [1/80], Training Loss: 32.1285, Validation Loss Current: 7.7306, Validation Loss AVG: 7.7306, lr: 0.001
Epoch [2/80], Training Loss: 23.3230, Validation Loss Current: 7.1090, Validation Loss AVG: 7.1090, lr: 0.001
Epoch [3/80], Training Loss: 17.8066, Validation Loss Current: 6.6296, Validation Loss AVG: 6.6296, lr: 0.001
Epoch [4/80], Training Loss: 14.6738, Validation Loss Current: 6.0372, Validation Loss AVG: 6.0372, lr: 0.001
Epoch [5/80], Training Loss: 11.3718, Validation Loss Current: 6.8445, Validation Loss AVG: 6.8445, lr: 0.001
Epoch [6/80], Training Loss: 9.1827, Validation Loss Current: 5.6619, Validation Loss AVG: 5.6619, lr: 0.001
Epoch [7/80], Training Loss: 6.5201, Validation Loss Current: 5.7824, Validation Loss AVG: 5.7824, lr: 0.001
Epoch [8/80], Training Loss: 7.7345, Validation Loss Current: 5.9223, Validation Loss AVG: 5.9223, lr: 0.001
Epoch [9/80], Training Loss: 10.0717, Validation Loss Current: 6.2759, Validation Loss AVG: 6.2759, lr: 0.001
Epoch [10/80], Training Loss: 10.7430, Validation Loss Current: 10.2656, Validation Loss AVG: 10.2656, lr: 0.001
Epoch [11/80], Training Loss: 17.5397, Validation Loss Current: 10.6040, Validation Loss AVG: 10.6040, lr: 0.001
Epoch [12/80], Training Loss: 14.1932, Validation Loss Current: 7.4961, Validation Loss AVG: 7.4961, lr: 0.001
Epoch [13/80], Training Loss: 12.2612, Validation Loss Current: 10.2094, Validation Loss AVG: 10.2094, lr: 0.001
Epoch [14/80], Training Loss: 10.0220, Validation Loss Current: 6.7413, Validation Loss AVG: 6.7413, lr: 0.001
Epoch [15/80], Training Loss: 8.6148, Validation Loss Current: 7.6027, Validation Loss AVG: 7.6027, lr: 0.001
Epoch [16/80], Training Loss: 7.2391, Validation Loss Current: 6.5654, Validation Loss AVG: 6.5654, lr: 0.001
Epoch [17/80], Training Loss: 6.8916, Validation Loss Current: 7.1778, Validation Loss AVG: 7.1778, lr: 0.001
Epoch [18/80], Training Loss: 11.4634, Validation Loss Current: 10.3866, Validation Loss AVG: 10.3866, lr: 0.001
Epoch [19/80], Training Loss: 10.4505, Validation Loss Current: 8.1420, Validation Loss AVG: 8.1420, lr: 0.001
Epoch [20/80], Training Loss: 8.4225, Validation Loss Current: 6.5039, Validation Loss AVG: 6.5039, lr: 0.001
Epoch [21/80], Training Loss: 4.3761, Validation Loss Current: 6.1503, Validation Loss AVG: 6.1503, lr: 0.001
Epoch [22/80], Training Loss: 3.4417, Validation Loss Current: 6.5319, Validation Loss AVG: 6.5319, lr: 0.001
Epoch [23/80], Training Loss: 5.1090, Validation Loss Current: 6.5962, Validation Loss AVG: 6.5962, lr: 0.001
Epoch [24/80], Training Loss: 4.0987, Validation Loss Current: 6.5459, Validation Loss AVG: 6.5459, lr: 0.001
Epoch [25/80], Training Loss: 3.5845, Validation Loss Current: 6.5759, Validation Loss AVG: 6.5759, lr: 0.001
Epoch [26/80], Training Loss: 2.9769, Validation Loss Current: 6.7359, Validation Loss AVG: 6.7359, lr: 0.001
Epoch [27/80], Training Loss: 2.2994, Validation Loss Current: 7.1952, Validation Loss AVG: 7.1952, lr: 0.001
Epoch [28/80], Training Loss: 4.1615, Validation Loss Current: 15.4313, Validation Loss AVG: 15.4313, lr: 0.001
Epoch [29/80], Training Loss: 11.8156, Validation Loss Current: 10.4629, Validation Loss AVG: 10.4629, lr: 0.001
Epoch [30/80], Training Loss: 8.1012, Validation Loss Current: 8.8612, Validation Loss AVG: 8.8612, lr: 0.001
Epoch [31/80], Training Loss: 6.2716, Validation Loss Current: 7.9828, Validation Loss AVG: 7.9828, lr: 0.001
Epoch [32/80], Training Loss: 8.8584, Validation Loss Current: 10.4298, Validation Loss AVG: 10.4298, lr: 0.001
Epoch [33/80], Training Loss: 4.9576, Validation Loss Current: 7.6792, Validation Loss AVG: 7.6792, lr: 0.001
Epoch [34/80], Training Loss: 5.6885, Validation Loss Current: 7.5524, Validation Loss AVG: 7.5524, lr: 0.001
Epoch [35/80], Training Loss: 4.7946, Validation Loss Current: 8.6953, Validation Loss AVG: 8.6953, lr: 0.001
Epoch [36/80], Training Loss: 2.6027, Validation Loss Current: 7.2332, Validation Loss AVG: 7.2332, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random1 finished training. Best epoch: 6 Best val accuracy: [0.5470394736842105, 0.5585526315789473, 0.5786184210526316, 0.6118421052631579, 0.5595394736842104, 0.636513157894737, 0.6335526315789475, 0.6296052631578947, 0.6095394736842106, 0.5039473684210526, 0.4697368421052631, 0.5585526315789473, 0.45427631578947364, 0.6092105263157894, 0.5493421052631579, 0.6200657894736843, 0.58125, 0.46480263157894736, 0.5424342105263158, 0.6026315789473684, 0.6381578947368421, 0.6095394736842106, 0.6082236842105264, 0.6177631578947368, 0.6279605263157895, 0.6486842105263159, 0.5970394736842105, 0.47993421052631574, 0.49572368421052626, 0.5476973684210525, 0.5625, 0.5046052631578948, 0.5815789473684211, 0.5973684210526315, 0.5585526315789473, 0.6226973684210526] Best val loss: 5.66194623708725


Current group: llo_0.4_random2
Epoch [1/80], Training Loss: 31.0516, Validation Loss Current: 8.3787, Validation Loss AVG: 8.3787, lr: 0.001
Epoch [2/80], Training Loss: 24.2205, Validation Loss Current: 7.5968, Validation Loss AVG: 7.5968, lr: 0.001
Epoch [3/80], Training Loss: 19.3915, Validation Loss Current: 6.0407, Validation Loss AVG: 6.0407, lr: 0.001
Epoch [4/80], Training Loss: 13.3890, Validation Loss Current: 6.0320, Validation Loss AVG: 6.0320, lr: 0.001
Epoch [5/80], Training Loss: 9.3622, Validation Loss Current: 5.2733, Validation Loss AVG: 5.2733, lr: 0.001
Epoch [6/80], Training Loss: 9.6791, Validation Loss Current: 5.5064, Validation Loss AVG: 5.5064, lr: 0.001
Epoch [7/80], Training Loss: 8.7603, Validation Loss Current: 6.6431, Validation Loss AVG: 6.6431, lr: 0.001
Epoch [8/80], Training Loss: 9.6208, Validation Loss Current: 5.9770, Validation Loss AVG: 5.9770, lr: 0.001
Epoch [9/80], Training Loss: 6.4715, Validation Loss Current: 9.4027, Validation Loss AVG: 9.4027, lr: 0.001
Epoch [10/80], Training Loss: 9.8450, Validation Loss Current: 8.1726, Validation Loss AVG: 8.1726, lr: 0.001
Epoch [11/80], Training Loss: 9.6817, Validation Loss Current: 6.5633, Validation Loss AVG: 6.5633, lr: 0.001
Epoch [12/80], Training Loss: 7.1039, Validation Loss Current: 7.1286, Validation Loss AVG: 7.1286, lr: 0.001
Epoch [13/80], Training Loss: 6.4059, Validation Loss Current: 5.6473, Validation Loss AVG: 5.6473, lr: 0.001
Epoch [14/80], Training Loss: 5.3668, Validation Loss Current: 6.3234, Validation Loss AVG: 6.3234, lr: 0.001
Epoch [15/80], Training Loss: 7.5756, Validation Loss Current: 6.3612, Validation Loss AVG: 6.3612, lr: 0.001
Epoch [16/80], Training Loss: 5.8484, Validation Loss Current: 7.2014, Validation Loss AVG: 7.2014, lr: 0.001
Epoch [17/80], Training Loss: 8.2806, Validation Loss Current: 6.9679, Validation Loss AVG: 6.9679, lr: 0.001
Epoch [18/80], Training Loss: 7.7815, Validation Loss Current: 6.4484, Validation Loss AVG: 6.4484, lr: 0.001
Epoch [19/80], Training Loss: 3.5724, Validation Loss Current: 6.3620, Validation Loss AVG: 6.3620, lr: 0.001
Epoch [20/80], Training Loss: 4.5305, Validation Loss Current: 7.2429, Validation Loss AVG: 7.2429, lr: 0.001
Epoch [21/80], Training Loss: 8.4993, Validation Loss Current: 9.0226, Validation Loss AVG: 9.0226, lr: 0.001
Epoch [22/80], Training Loss: 5.7183, Validation Loss Current: 8.2085, Validation Loss AVG: 8.2085, lr: 0.001
Epoch [23/80], Training Loss: 4.9278, Validation Loss Current: 7.8596, Validation Loss AVG: 7.8596, lr: 0.001
Epoch [24/80], Training Loss: 5.0514, Validation Loss Current: 7.6476, Validation Loss AVG: 7.6476, lr: 0.001
Epoch [25/80], Training Loss: 4.1308, Validation Loss Current: 7.1293, Validation Loss AVG: 7.1293, lr: 0.001
Epoch [26/80], Training Loss: 4.6271, Validation Loss Current: 6.9027, Validation Loss AVG: 6.9027, lr: 0.001
Epoch [27/80], Training Loss: 2.3445, Validation Loss Current: 7.2928, Validation Loss AVG: 7.2928, lr: 0.001
Epoch [28/80], Training Loss: 2.8315, Validation Loss Current: 6.4517, Validation Loss AVG: 6.4517, lr: 0.001
Epoch [29/80], Training Loss: 6.4128, Validation Loss Current: 7.1575, Validation Loss AVG: 7.1575, lr: 0.001
Epoch [30/80], Training Loss: 7.7568, Validation Loss Current: 7.3387, Validation Loss AVG: 7.3387, lr: 0.001
Epoch [31/80], Training Loss: 4.4446, Validation Loss Current: 7.6418, Validation Loss AVG: 7.6418, lr: 0.001
Epoch [32/80], Training Loss: 4.7985, Validation Loss Current: 7.7327, Validation Loss AVG: 7.7327, lr: 0.001
Epoch [33/80], Training Loss: 2.2706, Validation Loss Current: 7.1243, Validation Loss AVG: 7.1243, lr: 0.001
Epoch [34/80], Training Loss: 2.0615, Validation Loss Current: 7.0402, Validation Loss AVG: 7.0402, lr: 0.001
Epoch [35/80], Training Loss: 2.5478, Validation Loss Current: 8.1196, Validation Loss AVG: 8.1196, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random2 finished training. Best epoch: 5 Best val accuracy: [0.5424342105263158, 0.5381578947368422, 0.6194078947368421, 0.6434210526315789, 0.6657894736842105, 0.6595394736842105, 0.5917763157894737, 0.6486842105263159, 0.5345394736842105, 0.5536184210526315, 0.6046052631578948, 0.6016447368421053, 0.6667763157894737, 0.6171052631578947, 0.6371710526315789, 0.6101973684210525, 0.5832236842105263, 0.6490131578947368, 0.6375, 0.5999999999999999, 0.5848684210526316, 0.5671052631578947, 0.6088815789473684, 0.5924342105263158, 0.6200657894736843, 0.6292763157894737, 0.611842105263158, 0.649671052631579, 0.6115131578947369, 0.6144736842105263, 0.6174342105263158, 0.6101973684210525, 0.6375, 0.631578947368421, 0.6101973684210527] Best val loss: 5.27333379983902


Current group: llo_0.4_random3
Epoch [1/80], Training Loss: 36.1119, Validation Loss Current: 7.7267, Validation Loss AVG: 7.7267, lr: 0.001
Epoch [2/80], Training Loss: 27.1021, Validation Loss Current: 8.1189, Validation Loss AVG: 8.1189, lr: 0.001
Epoch [3/80], Training Loss: 21.0108, Validation Loss Current: 5.9744, Validation Loss AVG: 5.9744, lr: 0.001
Epoch [4/80], Training Loss: 14.6957, Validation Loss Current: 6.2789, Validation Loss AVG: 6.2789, lr: 0.001
Epoch [5/80], Training Loss: 11.8603, Validation Loss Current: 5.7666, Validation Loss AVG: 5.7666, lr: 0.001
Epoch [6/80], Training Loss: 10.2136, Validation Loss Current: 5.7913, Validation Loss AVG: 5.7913, lr: 0.001
Epoch [7/80], Training Loss: 11.5230, Validation Loss Current: 5.7480, Validation Loss AVG: 5.7480, lr: 0.001
Epoch [8/80], Training Loss: 11.1421, Validation Loss Current: 6.2553, Validation Loss AVG: 6.2553, lr: 0.001
Epoch [9/80], Training Loss: 10.2363, Validation Loss Current: 5.8069, Validation Loss AVG: 5.8069, lr: 0.001
Epoch [10/80], Training Loss: 9.0931, Validation Loss Current: 5.7878, Validation Loss AVG: 5.7878, lr: 0.001
Epoch [11/80], Training Loss: 6.8354, Validation Loss Current: 5.6590, Validation Loss AVG: 5.6590, lr: 0.001
Epoch [12/80], Training Loss: 5.7337, Validation Loss Current: 5.8393, Validation Loss AVG: 5.8393, lr: 0.001
Epoch [13/80], Training Loss: 5.1309, Validation Loss Current: 5.6610, Validation Loss AVG: 5.6610, lr: 0.001
Epoch [14/80], Training Loss: 11.5717, Validation Loss Current: 6.6554, Validation Loss AVG: 6.6554, lr: 0.001
Epoch [15/80], Training Loss: 7.7755, Validation Loss Current: 7.9191, Validation Loss AVG: 7.9191, lr: 0.001
Epoch [16/80], Training Loss: 7.9023, Validation Loss Current: 6.2612, Validation Loss AVG: 6.2612, lr: 0.001
Epoch [17/80], Training Loss: 5.6184, Validation Loss Current: 6.4825, Validation Loss AVG: 6.4825, lr: 0.001
Epoch [18/80], Training Loss: 3.8957, Validation Loss Current: 5.7948, Validation Loss AVG: 5.7948, lr: 0.001
Epoch [19/80], Training Loss: 4.5925, Validation Loss Current: 5.9354, Validation Loss AVG: 5.9354, lr: 0.001
Epoch [20/80], Training Loss: 6.3161, Validation Loss Current: 6.6672, Validation Loss AVG: 6.6672, lr: 0.001
Epoch [21/80], Training Loss: 3.6866, Validation Loss Current: 6.6600, Validation Loss AVG: 6.6600, lr: 0.001
Epoch [22/80], Training Loss: 3.5291, Validation Loss Current: 7.1480, Validation Loss AVG: 7.1480, lr: 0.001
Epoch [23/80], Training Loss: 6.4229, Validation Loss Current: 7.9072, Validation Loss AVG: 7.9072, lr: 0.001
Epoch [24/80], Training Loss: 5.4858, Validation Loss Current: 7.3679, Validation Loss AVG: 7.3679, lr: 0.001
Epoch [25/80], Training Loss: 5.1426, Validation Loss Current: 6.8277, Validation Loss AVG: 6.8277, lr: 0.001
Epoch [26/80], Training Loss: 4.7202, Validation Loss Current: 6.4251, Validation Loss AVG: 6.4251, lr: 0.001
Epoch [27/80], Training Loss: 3.9908, Validation Loss Current: 6.2679, Validation Loss AVG: 6.2679, lr: 0.001
Epoch [28/80], Training Loss: 2.2687, Validation Loss Current: 8.4348, Validation Loss AVG: 8.4348, lr: 0.001
Epoch [29/80], Training Loss: 5.4421, Validation Loss Current: 8.2454, Validation Loss AVG: 8.2454, lr: 0.001
Epoch [30/80], Training Loss: 5.6863, Validation Loss Current: 8.1907, Validation Loss AVG: 8.1907, lr: 0.001
Epoch [31/80], Training Loss: 2.5032, Validation Loss Current: 6.2839, Validation Loss AVG: 6.2839, lr: 0.001
Epoch [32/80], Training Loss: 3.3177, Validation Loss Current: 6.2232, Validation Loss AVG: 6.2232, lr: 0.001
Epoch [33/80], Training Loss: 5.8918, Validation Loss Current: 7.3385, Validation Loss AVG: 7.3385, lr: 0.001
Epoch [34/80], Training Loss: 4.3377, Validation Loss Current: 7.2555, Validation Loss AVG: 7.2555, lr: 0.001
Epoch [35/80], Training Loss: 4.3802, Validation Loss Current: 6.5389, Validation Loss AVG: 6.5389, lr: 0.001
Epoch [36/80], Training Loss: 1.6898, Validation Loss Current: 6.5187, Validation Loss AVG: 6.5187, lr: 0.001
Epoch [37/80], Training Loss: 1.0555, Validation Loss Current: 7.0234, Validation Loss AVG: 7.0234, lr: 0.001
Epoch [38/80], Training Loss: 2.1424, Validation Loss Current: 6.6546, Validation Loss AVG: 6.6546, lr: 0.001
Epoch [39/80], Training Loss: 4.2465, Validation Loss Current: 8.1470, Validation Loss AVG: 8.1470, lr: 0.001
Epoch [40/80], Training Loss: 6.6142, Validation Loss Current: 8.6786, Validation Loss AVG: 8.6786, lr: 0.001
Epoch [41/80], Training Loss: 4.4150, Validation Loss Current: 7.1745, Validation Loss AVG: 7.1745, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random3 finished training. Best epoch: 11 Best val accuracy: [0.5773026315789475, 0.5292763157894738, 0.618421052631579, 0.6200657894736842, 0.6289473684210526, 0.6460526315789473, 0.6368421052631579, 0.6240131578947368, 0.6424342105263158, 0.6394736842105263, 0.65, 0.649671052631579, 0.6572368421052632, 0.6072368421052632, 0.5924342105263158, 0.6312499999999999, 0.6381578947368421, 0.6601973684210526, 0.6592105263157896, 0.631578947368421, 0.6282894736842106, 0.6236842105263157, 0.5980263157894736, 0.59375, 0.6404605263157894, 0.6552631578947368, 0.6483552631578948, 0.6009868421052632, 0.59375, 0.6161184210526316, 0.6694078947368421, 0.6532894736842105, 0.6299342105263158, 0.6299342105263157, 0.6549342105263157, 0.6450657894736842, 0.6434210526315789, 0.6513157894736843, 0.6092105263157895, 0.5898026315789474, 0.6220394736842105] Best val loss: 5.659036779403687


Current group: 0.4
Epoch [1/80], Training Loss: 41.5897, Validation Loss Current: 12.2628, Validation Loss AVG: 12.2628, lr: 0.001
Epoch [2/80], Training Loss: 24.8710, Validation Loss Current: 9.1811, Validation Loss AVG: 9.1811, lr: 0.001
Epoch [3/80], Training Loss: 15.3573, Validation Loss Current: 7.3307, Validation Loss AVG: 7.3307, lr: 0.001
Epoch [4/80], Training Loss: 10.7687, Validation Loss Current: 7.0842, Validation Loss AVG: 7.0842, lr: 0.001
Epoch [5/80], Training Loss: 8.6609, Validation Loss Current: 8.0704, Validation Loss AVG: 8.0704, lr: 0.001
Epoch [6/80], Training Loss: 8.9290, Validation Loss Current: 7.5034, Validation Loss AVG: 7.5034, lr: 0.001
Epoch [7/80], Training Loss: 6.7933, Validation Loss Current: 7.4481, Validation Loss AVG: 7.4481, lr: 0.001
Epoch [8/80], Training Loss: 7.1335, Validation Loss Current: 8.3030, Validation Loss AVG: 8.3030, lr: 0.001
Epoch [9/80], Training Loss: 7.7837, Validation Loss Current: 7.0519, Validation Loss AVG: 7.0519, lr: 0.001
Epoch [10/80], Training Loss: 8.9761, Validation Loss Current: 10.2041, Validation Loss AVG: 10.2041, lr: 0.001
Epoch [11/80], Training Loss: 9.4890, Validation Loss Current: 11.1286, Validation Loss AVG: 11.1286, lr: 0.001
Epoch [12/80], Training Loss: 8.7210, Validation Loss Current: 10.6495, Validation Loss AVG: 10.6495, lr: 0.001
Epoch [13/80], Training Loss: 6.3635, Validation Loss Current: 9.7998, Validation Loss AVG: 9.7998, lr: 0.001
Epoch [14/80], Training Loss: 4.7073, Validation Loss Current: 9.0056, Validation Loss AVG: 9.0056, lr: 0.001
Epoch [15/80], Training Loss: 5.0378, Validation Loss Current: 9.2555, Validation Loss AVG: 9.2555, lr: 0.001
Epoch [16/80], Training Loss: 5.1437, Validation Loss Current: 9.9514, Validation Loss AVG: 9.9514, lr: 0.001
Epoch [17/80], Training Loss: 7.4609, Validation Loss Current: 9.3926, Validation Loss AVG: 9.3926, lr: 0.001
Epoch [18/80], Training Loss: 4.2103, Validation Loss Current: 9.0379, Validation Loss AVG: 9.0379, lr: 0.001
Epoch [19/80], Training Loss: 3.4923, Validation Loss Current: 9.0209, Validation Loss AVG: 9.0209, lr: 0.001
Epoch [20/80], Training Loss: 6.2737, Validation Loss Current: 9.2788, Validation Loss AVG: 9.2788, lr: 0.001
Epoch [21/80], Training Loss: 3.1859, Validation Loss Current: 9.8210, Validation Loss AVG: 9.8210, lr: 0.001
Epoch [22/80], Training Loss: 2.7852, Validation Loss Current: 11.9009, Validation Loss AVG: 11.9009, lr: 0.001
Epoch [23/80], Training Loss: 1.5611, Validation Loss Current: 9.6992, Validation Loss AVG: 9.6992, lr: 0.001
Epoch [24/80], Training Loss: 2.3941, Validation Loss Current: 10.1664, Validation Loss AVG: 10.1664, lr: 0.001
Epoch [25/80], Training Loss: 5.5943, Validation Loss Current: 12.6638, Validation Loss AVG: 12.6638, lr: 0.001
Epoch [26/80], Training Loss: 10.7346, Validation Loss Current: 13.4732, Validation Loss AVG: 13.4732, lr: 0.001
Epoch [27/80], Training Loss: 5.6067, Validation Loss Current: 11.3265, Validation Loss AVG: 11.3265, lr: 0.001
Epoch [28/80], Training Loss: 4.9009, Validation Loss Current: 9.9240, Validation Loss AVG: 9.9240, lr: 0.001
Epoch [29/80], Training Loss: 7.5974, Validation Loss Current: 15.2829, Validation Loss AVG: 15.2829, lr: 0.001
Epoch [30/80], Training Loss: 4.3280, Validation Loss Current: 10.0065, Validation Loss AVG: 10.0065, lr: 0.001
Epoch [31/80], Training Loss: 6.2916, Validation Loss Current: 13.1643, Validation Loss AVG: 13.1643, lr: 0.001
Epoch [32/80], Training Loss: 6.0450, Validation Loss Current: 12.0244, Validation Loss AVG: 12.0244, lr: 0.001
Epoch [33/80], Training Loss: 3.8739, Validation Loss Current: 9.9846, Validation Loss AVG: 9.9846, lr: 0.001
Epoch [34/80], Training Loss: 4.1375, Validation Loss Current: 12.7939, Validation Loss AVG: 12.7939, lr: 0.001
Epoch [35/80], Training Loss: 6.3939, Validation Loss Current: 11.1176, Validation Loss AVG: 11.1176, lr: 0.001
Epoch [36/80], Training Loss: 4.0409, Validation Loss Current: 11.9661, Validation Loss AVG: 11.9661, lr: 0.001
Epoch [37/80], Training Loss: 3.4300, Validation Loss Current: 9.6646, Validation Loss AVG: 9.6646, lr: 0.001
Epoch [38/80], Training Loss: 5.6562, Validation Loss Current: 11.5445, Validation Loss AVG: 11.5445, lr: 0.001
Epoch [39/80], Training Loss: 11.8465, Validation Loss Current: 13.1339, Validation Loss AVG: 13.1339, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 9 Best val accuracy: [0.519078947368421, 0.5049342105263157, 0.5621710526315791, 0.5782894736842106, 0.5641447368421052, 0.5473684210526316, 0.575, 0.5552631578947368, 0.5967105263157894, 0.5164473684210527, 0.4651315789473684, 0.46085526315789477, 0.5098684210526315, 0.5325657894736842, 0.5457236842105264, 0.5424342105263158, 0.5144736842105264, 0.5444078947368421, 0.5542763157894737, 0.5565789473684211, 0.531578947368421, 0.4740131578947369, 0.5388157894736842, 0.5424342105263158, 0.5177631578947369, 0.41776315789473684, 0.4990131578947368, 0.5148026315789473, 0.38322368421052627, 0.5467105263157894, 0.4256578947368421, 0.4911184210526316, 0.5355263157894739, 0.4917763157894736, 0.5075657894736841, 0.4828947368421053, 0.5299342105263157, 0.47105263157894733, 0.4927631578947368] Best val loss: 7.051941466331482


----- Training resnet18 with sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] -----
Current group: llo_0.6_random0
Epoch [1/80], Training Loss: 40.2748, Validation Loss Current: 9.9839, Validation Loss AVG: 9.9839, lr: 0.001
Epoch [2/80], Training Loss: 39.6624, Validation Loss Current: 9.8298, Validation Loss AVG: 9.8298, lr: 0.001
Epoch [3/80], Training Loss: 39.3912, Validation Loss Current: 10.1543, Validation Loss AVG: 10.1543, lr: 0.001
Epoch [4/80], Training Loss: 39.1658, Validation Loss Current: 9.7248, Validation Loss AVG: 9.7248, lr: 0.001
Epoch [5/80], Training Loss: 38.1983, Validation Loss Current: 9.5205, Validation Loss AVG: 9.5205, lr: 0.001
Epoch [6/80], Training Loss: 37.6696, Validation Loss Current: 9.4591, Validation Loss AVG: 9.4591, lr: 0.001
Epoch [7/80], Training Loss: 37.6283, Validation Loss Current: 9.2323, Validation Loss AVG: 9.2323, lr: 0.001
Epoch [8/80], Training Loss: 36.6195, Validation Loss Current: 8.9801, Validation Loss AVG: 8.9801, lr: 0.001
Epoch [9/80], Training Loss: 34.9993, Validation Loss Current: 8.7677, Validation Loss AVG: 8.7677, lr: 0.001
Epoch [10/80], Training Loss: 33.6190, Validation Loss Current: 8.6771, Validation Loss AVG: 8.6771, lr: 0.001
Epoch [11/80], Training Loss: 34.0377, Validation Loss Current: 8.8293, Validation Loss AVG: 8.8293, lr: 0.001
Epoch [12/80], Training Loss: 33.6134, Validation Loss Current: 8.5252, Validation Loss AVG: 8.5252, lr: 0.001
Epoch [13/80], Training Loss: 32.8371, Validation Loss Current: 8.3385, Validation Loss AVG: 8.3385, lr: 0.001
Epoch [14/80], Training Loss: 31.7124, Validation Loss Current: 8.0952, Validation Loss AVG: 8.0952, lr: 0.001
Epoch [15/80], Training Loss: 30.3965, Validation Loss Current: 8.2312, Validation Loss AVG: 8.2312, lr: 0.001
Epoch [16/80], Training Loss: 30.3079, Validation Loss Current: 7.9014, Validation Loss AVG: 7.9014, lr: 0.001
Epoch [17/80], Training Loss: 29.7121, Validation Loss Current: 7.9647, Validation Loss AVG: 7.9647, lr: 0.001
Epoch [18/80], Training Loss: 28.6715, Validation Loss Current: 7.6983, Validation Loss AVG: 7.6983, lr: 0.001
Epoch [19/80], Training Loss: 27.7992, Validation Loss Current: 7.4683, Validation Loss AVG: 7.4683, lr: 0.001
Epoch [20/80], Training Loss: 25.7647, Validation Loss Current: 7.5637, Validation Loss AVG: 7.5637, lr: 0.001
Epoch [21/80], Training Loss: 26.5301, Validation Loss Current: 7.4224, Validation Loss AVG: 7.4224, lr: 0.001
Epoch [22/80], Training Loss: 25.7626, Validation Loss Current: 7.8405, Validation Loss AVG: 7.8405, lr: 0.001
Epoch [23/80], Training Loss: 26.3221, Validation Loss Current: 7.1436, Validation Loss AVG: 7.1436, lr: 0.001
Epoch [24/80], Training Loss: 24.7721, Validation Loss Current: 7.0662, Validation Loss AVG: 7.0662, lr: 0.001
Epoch [25/80], Training Loss: 22.6707, Validation Loss Current: 7.2596, Validation Loss AVG: 7.2596, lr: 0.001
Epoch [26/80], Training Loss: 23.2554, Validation Loss Current: 6.8809, Validation Loss AVG: 6.8809, lr: 0.001
Epoch [27/80], Training Loss: 21.6086, Validation Loss Current: 6.9483, Validation Loss AVG: 6.9483, lr: 0.001
Epoch [28/80], Training Loss: 23.3525, Validation Loss Current: 7.7911, Validation Loss AVG: 7.7911, lr: 0.001
Epoch [29/80], Training Loss: 22.3469, Validation Loss Current: 6.7367, Validation Loss AVG: 6.7367, lr: 0.001
Epoch [30/80], Training Loss: 21.1749, Validation Loss Current: 7.1452, Validation Loss AVG: 7.1452, lr: 0.001
Epoch [31/80], Training Loss: 20.1195, Validation Loss Current: 6.9597, Validation Loss AVG: 6.9597, lr: 0.001
Epoch [32/80], Training Loss: 20.0006, Validation Loss Current: 7.1430, Validation Loss AVG: 7.1430, lr: 0.001
Epoch [33/80], Training Loss: 19.3532, Validation Loss Current: 7.1338, Validation Loss AVG: 7.1338, lr: 0.001
Epoch [34/80], Training Loss: 18.4054, Validation Loss Current: 6.7136, Validation Loss AVG: 6.7136, lr: 0.001
Epoch [35/80], Training Loss: 17.6216, Validation Loss Current: 7.4098, Validation Loss AVG: 7.4098, lr: 0.001
Epoch [36/80], Training Loss: 16.6984, Validation Loss Current: 6.9879, Validation Loss AVG: 6.9879, lr: 0.001
Epoch [37/80], Training Loss: 15.5182, Validation Loss Current: 7.2676, Validation Loss AVG: 7.2676, lr: 0.001
Epoch [38/80], Training Loss: 15.9990, Validation Loss Current: 6.9248, Validation Loss AVG: 6.9248, lr: 0.001
Epoch [39/80], Training Loss: 14.8986, Validation Loss Current: 7.2565, Validation Loss AVG: 7.2565, lr: 0.001
Epoch [40/80], Training Loss: 14.4896, Validation Loss Current: 7.5053, Validation Loss AVG: 7.5053, lr: 0.001
Epoch [41/80], Training Loss: 12.9059, Validation Loss Current: 7.7664, Validation Loss AVG: 7.7664, lr: 0.001
Epoch [42/80], Training Loss: 13.8955, Validation Loss Current: 8.8581, Validation Loss AVG: 8.8581, lr: 0.001
Epoch [43/80], Training Loss: 13.9896, Validation Loss Current: 7.0562, Validation Loss AVG: 7.0562, lr: 0.001
Epoch [44/80], Training Loss: 14.4602, Validation Loss Current: 7.1490, Validation Loss AVG: 7.1490, lr: 0.001
Epoch [45/80], Training Loss: 15.8342, Validation Loss Current: 12.1426, Validation Loss AVG: 12.1426, lr: 0.001
Epoch [46/80], Training Loss: 17.6374, Validation Loss Current: 10.7928, Validation Loss AVG: 10.7928, lr: 0.001
Epoch [47/80], Training Loss: 16.1652, Validation Loss Current: 7.4427, Validation Loss AVG: 7.4427, lr: 0.001
Epoch [48/80], Training Loss: 12.1336, Validation Loss Current: 9.4336, Validation Loss AVG: 9.4336, lr: 0.001
Epoch [49/80], Training Loss: 11.7005, Validation Loss Current: 6.8492, Validation Loss AVG: 6.8492, lr: 0.001
Epoch [50/80], Training Loss: 10.5236, Validation Loss Current: 7.4423, Validation Loss AVG: 7.4423, lr: 0.001
Epoch [51/80], Training Loss: 12.5666, Validation Loss Current: 8.4879, Validation Loss AVG: 8.4879, lr: 0.001
Epoch [52/80], Training Loss: 13.3110, Validation Loss Current: 6.7688, Validation Loss AVG: 6.7688, lr: 0.001
Epoch [53/80], Training Loss: 11.4660, Validation Loss Current: 7.4600, Validation Loss AVG: 7.4600, lr: 0.001
Epoch [54/80], Training Loss: 9.0636, Validation Loss Current: 6.5530, Validation Loss AVG: 6.5530, lr: 0.001
Epoch [55/80], Training Loss: 6.8369, Validation Loss Current: 6.5241, Validation Loss AVG: 6.5241, lr: 0.001
Epoch [56/80], Training Loss: 6.7984, Validation Loss Current: 6.9879, Validation Loss AVG: 6.9879, lr: 0.001
Epoch [57/80], Training Loss: 6.3275, Validation Loss Current: 8.1815, Validation Loss AVG: 8.1815, lr: 0.001
Epoch [58/80], Training Loss: 7.4419, Validation Loss Current: 7.8944, Validation Loss AVG: 7.8944, lr: 0.001
Epoch [59/80], Training Loss: 7.2752, Validation Loss Current: 7.6632, Validation Loss AVG: 7.6632, lr: 0.001
Epoch [60/80], Training Loss: 8.1492, Validation Loss Current: 8.5136, Validation Loss AVG: 8.5136, lr: 0.001
Epoch [61/80], Training Loss: 9.9488, Validation Loss Current: 8.4614, Validation Loss AVG: 8.4614, lr: 0.001
Epoch [62/80], Training Loss: 6.7384, Validation Loss Current: 7.6563, Validation Loss AVG: 7.6563, lr: 0.001
Epoch [63/80], Training Loss: 11.9892, Validation Loss Current: 9.4732, Validation Loss AVG: 9.4732, lr: 0.001
Epoch [64/80], Training Loss: 10.0395, Validation Loss Current: 7.4590, Validation Loss AVG: 7.4590, lr: 0.001
Epoch [65/80], Training Loss: 4.9235, Validation Loss Current: 7.3237, Validation Loss AVG: 7.3237, lr: 0.001
Epoch [66/80], Training Loss: 6.4854, Validation Loss Current: 8.1655, Validation Loss AVG: 8.1655, lr: 0.001
Epoch [67/80], Training Loss: 6.1657, Validation Loss Current: 8.0073, Validation Loss AVG: 8.0073, lr: 0.001
Epoch [68/80], Training Loss: 4.7930, Validation Loss Current: 7.7827, Validation Loss AVG: 7.7827, lr: 0.001
Epoch [69/80], Training Loss: 5.6730, Validation Loss Current: 7.9336, Validation Loss AVG: 7.9336, lr: 0.001
Epoch [70/80], Training Loss: 4.1434, Validation Loss Current: 7.9684, Validation Loss AVG: 7.9684, lr: 0.001
Epoch [71/80], Training Loss: 4.0350, Validation Loss Current: 7.6430, Validation Loss AVG: 7.6430, lr: 0.001
Epoch [72/80], Training Loss: 3.8129, Validation Loss Current: 8.2249, Validation Loss AVG: 8.2249, lr: 0.001
Epoch [73/80], Training Loss: 3.9096, Validation Loss Current: 7.8160, Validation Loss AVG: 7.8160, lr: 0.001
Epoch [74/80], Training Loss: 4.8166, Validation Loss Current: 9.2826, Validation Loss AVG: 9.2826, lr: 0.001
Epoch [75/80], Training Loss: 5.3577, Validation Loss Current: 11.1349, Validation Loss AVG: 11.1349, lr: 0.001
Epoch [76/80], Training Loss: 10.3304, Validation Loss Current: 8.9763, Validation Loss AVG: 8.9763, lr: 0.001
Epoch [77/80], Training Loss: 6.2776, Validation Loss Current: 10.5869, Validation Loss AVG: 10.5869, lr: 0.001
Epoch [78/80], Training Loss: 3.8318, Validation Loss Current: 8.1419, Validation Loss AVG: 8.1419, lr: 0.001
Epoch [79/80], Training Loss: 5.1622, Validation Loss Current: 8.5821, Validation Loss AVG: 8.5821, lr: 0.001
Epoch [80/80], Training Loss: 4.8451, Validation Loss Current: 9.6153, Validation Loss AVG: 9.6153, lr: 0.001
Patch distance: llo_0.6_random0 finished training. Best epoch: 55 Best val accuracy: [0.2450657894736842, 0.25690789473684206, 0.21315789473684213, 0.2713815789473685, 0.2779605263157895, 0.32401315789473684, 0.3144736842105263, 0.3460526315789473, 0.3601973684210526, 0.39342105263157895, 0.34769736842105264, 0.41546052631578945, 0.4115131578947368, 0.4496710526315789, 0.42894736842105263, 0.419078947368421, 0.43815789473684214, 0.4526315789473684, 0.4723684210526316, 0.4759868421052632, 0.47138157894736843, 0.4615131578947368, 0.505921052631579, 0.5013157894736843, 0.49078947368421055, 0.5203947368421054, 0.5263157894736843, 0.47302631578947374, 0.5282894736842104, 0.5226973684210525, 0.5177631578947369, 0.5069078947368422, 0.5075657894736841, 0.5401315789473684, 0.4845394736842105, 0.5319078947368421, 0.524671052631579, 0.5190789473684211, 0.5236842105263159, 0.4878289473684211, 0.5138157894736842, 0.4585526315789473, 0.5375, 0.5328947368421053, 0.3470394736842105, 0.42368421052631583, 0.5279605263157896, 0.4634868421052631, 0.5588815789473685, 0.5332236842105262, 0.47993421052631585, 0.5608552631578948, 0.5345394736842105, 0.5766447368421053, 0.5957236842105262, 0.5753289473684211, 0.537171052631579, 0.5427631578947368, 0.5605263157894737, 0.4875, 0.5355263157894737, 0.5598684210526317, 0.4921052631578947, 0.5483552631578947, 0.5763157894736842, 0.5236842105263159, 0.5618421052631579, 0.5601973684210526, 0.5631578947368421, 0.5625, 0.5792763157894736, 0.5516447368421054, 0.5763157894736842, 0.48980263157894743, 0.4473684210526316, 0.5342105263157895, 0.48125, 0.5697368421052632, 0.5667763157894737, 0.5598684210526316] Best val loss: 6.524133348464966


Current group: llo_0.6_random1
Epoch [1/80], Training Loss: 40.3666, Validation Loss Current: 8.5834, Validation Loss AVG: 8.5834, lr: 0.001
Epoch [2/80], Training Loss: 26.9596, Validation Loss Current: 8.0328, Validation Loss AVG: 8.0328, lr: 0.001
Epoch [3/80], Training Loss: 21.2217, Validation Loss Current: 8.1004, Validation Loss AVG: 8.1004, lr: 0.001
Epoch [4/80], Training Loss: 15.7172, Validation Loss Current: 6.4689, Validation Loss AVG: 6.4689, lr: 0.001
Epoch [5/80], Training Loss: 12.1520, Validation Loss Current: 7.9163, Validation Loss AVG: 7.9163, lr: 0.001
Epoch [6/80], Training Loss: 9.9010, Validation Loss Current: 5.9846, Validation Loss AVG: 5.9846, lr: 0.001
Epoch [7/80], Training Loss: 10.1569, Validation Loss Current: 12.2316, Validation Loss AVG: 12.2316, lr: 0.001
Epoch [8/80], Training Loss: 11.1956, Validation Loss Current: 6.7626, Validation Loss AVG: 6.7626, lr: 0.001
Epoch [9/80], Training Loss: 13.2272, Validation Loss Current: 6.8118, Validation Loss AVG: 6.8118, lr: 0.001
Epoch [10/80], Training Loss: 10.8194, Validation Loss Current: 7.5257, Validation Loss AVG: 7.5257, lr: 0.001
Epoch [11/80], Training Loss: 6.8977, Validation Loss Current: 6.6529, Validation Loss AVG: 6.6529, lr: 0.001
Epoch [12/80], Training Loss: 7.1906, Validation Loss Current: 10.6655, Validation Loss AVG: 10.6655, lr: 0.001
Epoch [13/80], Training Loss: 9.2518, Validation Loss Current: 7.1959, Validation Loss AVG: 7.1959, lr: 0.001
Epoch [14/80], Training Loss: 7.1439, Validation Loss Current: 6.8948, Validation Loss AVG: 6.8948, lr: 0.001
Epoch [15/80], Training Loss: 8.0109, Validation Loss Current: 8.7581, Validation Loss AVG: 8.7581, lr: 0.001
Epoch [16/80], Training Loss: 5.7278, Validation Loss Current: 7.2182, Validation Loss AVG: 7.2182, lr: 0.001
Epoch [17/80], Training Loss: 2.7793, Validation Loss Current: 6.4427, Validation Loss AVG: 6.4427, lr: 0.001
Epoch [18/80], Training Loss: 1.7981, Validation Loss Current: 6.6670, Validation Loss AVG: 6.6670, lr: 0.001
Epoch [19/80], Training Loss: 2.3670, Validation Loss Current: 6.5780, Validation Loss AVG: 6.5780, lr: 0.001
Epoch [20/80], Training Loss: 4.8335, Validation Loss Current: 8.4232, Validation Loss AVG: 8.4232, lr: 0.001
Epoch [21/80], Training Loss: 6.0554, Validation Loss Current: 8.2111, Validation Loss AVG: 8.2111, lr: 0.001
Epoch [22/80], Training Loss: 8.4822, Validation Loss Current: 7.1919, Validation Loss AVG: 7.1919, lr: 0.001
Epoch [23/80], Training Loss: 8.2921, Validation Loss Current: 8.0319, Validation Loss AVG: 8.0319, lr: 0.001
Epoch [24/80], Training Loss: 5.8215, Validation Loss Current: 8.0818, Validation Loss AVG: 8.0818, lr: 0.001
Epoch [25/80], Training Loss: 4.7117, Validation Loss Current: 8.2128, Validation Loss AVG: 8.2128, lr: 0.001
Epoch [26/80], Training Loss: 4.1432, Validation Loss Current: 6.8272, Validation Loss AVG: 6.8272, lr: 0.001
Epoch [27/80], Training Loss: 4.6257, Validation Loss Current: 8.1885, Validation Loss AVG: 8.1885, lr: 0.001
Epoch [28/80], Training Loss: 5.3165, Validation Loss Current: 14.6033, Validation Loss AVG: 14.6033, lr: 0.001
Epoch [29/80], Training Loss: 2.8568, Validation Loss Current: 9.7460, Validation Loss AVG: 9.7460, lr: 0.001
Epoch [30/80], Training Loss: 7.7789, Validation Loss Current: 8.6700, Validation Loss AVG: 8.6700, lr: 0.001
Epoch [31/80], Training Loss: 4.4426, Validation Loss Current: 8.3668, Validation Loss AVG: 8.3668, lr: 0.001
Epoch [32/80], Training Loss: 6.0172, Validation Loss Current: 8.1252, Validation Loss AVG: 8.1252, lr: 0.001
Epoch [33/80], Training Loss: 7.6927, Validation Loss Current: 8.5974, Validation Loss AVG: 8.5974, lr: 0.001
Epoch [34/80], Training Loss: 4.1660, Validation Loss Current: 7.6704, Validation Loss AVG: 7.6704, lr: 0.001
Epoch [35/80], Training Loss: 2.3856, Validation Loss Current: 7.6711, Validation Loss AVG: 7.6711, lr: 0.001
Epoch [36/80], Training Loss: 2.8809, Validation Loss Current: 6.9189, Validation Loss AVG: 6.9189, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random1 finished training. Best epoch: 6 Best val accuracy: [0.5292763157894737, 0.5473684210526316, 0.4927631578947368, 0.6032894736842105, 0.5309210526315791, 0.624671052631579, 0.42927631578947373, 0.5832236842105264, 0.5927631578947369, 0.5388157894736841, 0.6039473684210527, 0.5019736842105262, 0.5802631578947368, 0.5990131578947369, 0.5361842105263157, 0.6108552631578947, 0.6220394736842104, 0.6384868421052632, 0.6417763157894737, 0.5986842105263157, 0.5615131578947369, 0.6078947368421053, 0.555921052631579, 0.5845394736842106, 0.6092105263157894, 0.6322368421052632, 0.5828947368421054, 0.45921052631578946, 0.537828947368421, 0.5782894736842105, 0.5707236842105263, 0.6023026315789474, 0.55625, 0.6144736842105264, 0.6253289473684209, 0.6223684210526315] Best val loss: 5.984622728824616


Current group: llo_0.6_random2
Epoch [1/80], Training Loss: 35.8912, Validation Loss Current: 7.3147, Validation Loss AVG: 7.3147, lr: 0.001
Epoch [2/80], Training Loss: 24.9723, Validation Loss Current: 7.7479, Validation Loss AVG: 7.7479, lr: 0.001
Epoch [3/80], Training Loss: 19.1449, Validation Loss Current: 6.9031, Validation Loss AVG: 6.9031, lr: 0.001
Epoch [4/80], Training Loss: 14.6790, Validation Loss Current: 8.6987, Validation Loss AVG: 8.6987, lr: 0.001
Epoch [5/80], Training Loss: 9.8826, Validation Loss Current: 5.4897, Validation Loss AVG: 5.4897, lr: 0.001
Epoch [6/80], Training Loss: 7.8169, Validation Loss Current: 5.9104, Validation Loss AVG: 5.9104, lr: 0.001
Epoch [7/80], Training Loss: 11.5891, Validation Loss Current: 7.8158, Validation Loss AVG: 7.8158, lr: 0.001
Epoch [8/80], Training Loss: 8.6405, Validation Loss Current: 7.0122, Validation Loss AVG: 7.0122, lr: 0.001
Epoch [9/80], Training Loss: 10.2644, Validation Loss Current: 6.8727, Validation Loss AVG: 6.8727, lr: 0.001
Epoch [10/80], Training Loss: 7.4236, Validation Loss Current: 6.5272, Validation Loss AVG: 6.5272, lr: 0.001
Epoch [11/80], Training Loss: 4.9610, Validation Loss Current: 6.1661, Validation Loss AVG: 6.1661, lr: 0.001
Epoch [12/80], Training Loss: 6.1264, Validation Loss Current: 6.4366, Validation Loss AVG: 6.4366, lr: 0.001
Epoch [13/80], Training Loss: 4.2693, Validation Loss Current: 6.3381, Validation Loss AVG: 6.3381, lr: 0.001
Epoch [14/80], Training Loss: 3.6654, Validation Loss Current: 6.5562, Validation Loss AVG: 6.5562, lr: 0.001
Epoch [15/80], Training Loss: 3.4779, Validation Loss Current: 7.0028, Validation Loss AVG: 7.0028, lr: 0.001
Epoch [16/80], Training Loss: 6.2496, Validation Loss Current: 7.3935, Validation Loss AVG: 7.3935, lr: 0.001
Epoch [17/80], Training Loss: 5.2610, Validation Loss Current: 8.4064, Validation Loss AVG: 8.4064, lr: 0.001
Epoch [18/80], Training Loss: 7.1782, Validation Loss Current: 8.8411, Validation Loss AVG: 8.8411, lr: 0.001
Epoch [19/80], Training Loss: 4.3947, Validation Loss Current: 8.6960, Validation Loss AVG: 8.6960, lr: 0.001
Epoch [20/80], Training Loss: 6.8316, Validation Loss Current: 8.1489, Validation Loss AVG: 8.1489, lr: 0.001
Epoch [21/80], Training Loss: 9.0253, Validation Loss Current: 8.1229, Validation Loss AVG: 8.1229, lr: 0.001
Epoch [22/80], Training Loss: 5.4298, Validation Loss Current: 9.7304, Validation Loss AVG: 9.7304, lr: 0.001
Epoch [23/80], Training Loss: 7.2301, Validation Loss Current: 8.0590, Validation Loss AVG: 8.0590, lr: 0.001
Epoch [24/80], Training Loss: 9.1010, Validation Loss Current: 9.0605, Validation Loss AVG: 9.0605, lr: 0.001
Epoch [25/80], Training Loss: 7.1449, Validation Loss Current: 7.3443, Validation Loss AVG: 7.3443, lr: 0.001
Epoch [26/80], Training Loss: 5.5394, Validation Loss Current: 9.8244, Validation Loss AVG: 9.8244, lr: 0.001
Epoch [27/80], Training Loss: 6.6092, Validation Loss Current: 8.2926, Validation Loss AVG: 8.2926, lr: 0.001
Epoch [28/80], Training Loss: 7.7915, Validation Loss Current: 7.2259, Validation Loss AVG: 7.2259, lr: 0.001
Epoch [29/80], Training Loss: 3.1421, Validation Loss Current: 9.5898, Validation Loss AVG: 9.5898, lr: 0.001
Epoch [30/80], Training Loss: 7.2762, Validation Loss Current: 7.4806, Validation Loss AVG: 7.4806, lr: 0.001
Epoch [31/80], Training Loss: 3.5483, Validation Loss Current: 7.3602, Validation Loss AVG: 7.3602, lr: 0.001
Epoch [32/80], Training Loss: 3.2379, Validation Loss Current: 6.9300, Validation Loss AVG: 6.9300, lr: 0.001
Epoch [33/80], Training Loss: 6.7545, Validation Loss Current: 7.5718, Validation Loss AVG: 7.5718, lr: 0.001
Epoch [34/80], Training Loss: 4.5236, Validation Loss Current: 7.7437, Validation Loss AVG: 7.7437, lr: 0.001
Epoch [35/80], Training Loss: 2.2547, Validation Loss Current: 7.5419, Validation Loss AVG: 7.5419, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random2 finished training. Best epoch: 5 Best val accuracy: [0.5875, 0.5394736842105263, 0.5588815789473683, 0.5131578947368421, 0.6608552631578947, 0.6457236842105263, 0.5470394736842106, 0.6197368421052631, 0.5967105263157895, 0.6414473684210527, 0.6644736842105263, 0.6365131578947368, 0.6332236842105263, 0.6536184210526316, 0.6434210526315789, 0.6082236842105264, 0.5598684210526315, 0.5358552631578947, 0.5644736842105263, 0.5917763157894738, 0.5990131578947369, 0.5450657894736842, 0.6164473684210525, 0.5338815789473685, 0.6305921052631579, 0.506578947368421, 0.6161184210526316, 0.6263157894736842, 0.574342105263158, 0.6105263157894737, 0.624671052631579, 0.6355263157894736, 0.6154605263157895, 0.6138157894736842, 0.6388157894736842] Best val loss: 5.4896596550941466


Current group: llo_0.6_random3
Epoch [1/80], Training Loss: 35.3454, Validation Loss Current: 6.2267, Validation Loss AVG: 6.2267, lr: 0.001
Epoch [2/80], Training Loss: 20.1268, Validation Loss Current: 6.1482, Validation Loss AVG: 6.1482, lr: 0.001
Epoch [3/80], Training Loss: 15.4569, Validation Loss Current: 6.2650, Validation Loss AVG: 6.2650, lr: 0.001
Epoch [4/80], Training Loss: 9.9874, Validation Loss Current: 4.8939, Validation Loss AVG: 4.8939, lr: 0.001
Epoch [5/80], Training Loss: 6.6114, Validation Loss Current: 5.1771, Validation Loss AVG: 5.1771, lr: 0.001
Epoch [6/80], Training Loss: 9.3497, Validation Loss Current: 5.3389, Validation Loss AVG: 5.3389, lr: 0.001
Epoch [7/80], Training Loss: 6.4228, Validation Loss Current: 5.2196, Validation Loss AVG: 5.2196, lr: 0.001
Epoch [8/80], Training Loss: 4.9589, Validation Loss Current: 5.9861, Validation Loss AVG: 5.9861, lr: 0.001
Epoch [9/80], Training Loss: 4.9350, Validation Loss Current: 5.4992, Validation Loss AVG: 5.4992, lr: 0.001
Epoch [10/80], Training Loss: 5.5060, Validation Loss Current: 5.7461, Validation Loss AVG: 5.7461, lr: 0.001
Epoch [11/80], Training Loss: 3.2780, Validation Loss Current: 5.5269, Validation Loss AVG: 5.5269, lr: 0.001
Epoch [12/80], Training Loss: 5.9238, Validation Loss Current: 6.2683, Validation Loss AVG: 6.2683, lr: 0.001
Epoch [13/80], Training Loss: 6.3289, Validation Loss Current: 5.9956, Validation Loss AVG: 5.9956, lr: 0.001
Epoch [14/80], Training Loss: 4.1115, Validation Loss Current: 5.6225, Validation Loss AVG: 5.6225, lr: 0.001
Epoch [15/80], Training Loss: 3.1470, Validation Loss Current: 7.7717, Validation Loss AVG: 7.7717, lr: 0.001
Epoch [16/80], Training Loss: 10.2908, Validation Loss Current: 7.2735, Validation Loss AVG: 7.2735, lr: 0.001
Epoch [17/80], Training Loss: 6.7765, Validation Loss Current: 7.2667, Validation Loss AVG: 7.2667, lr: 0.001
Epoch [18/80], Training Loss: 5.7649, Validation Loss Current: 8.4625, Validation Loss AVG: 8.4625, lr: 0.001
Epoch [19/80], Training Loss: 7.1151, Validation Loss Current: 6.7095, Validation Loss AVG: 6.7095, lr: 0.001
Epoch [20/80], Training Loss: 3.3746, Validation Loss Current: 6.4776, Validation Loss AVG: 6.4776, lr: 0.001
Epoch [21/80], Training Loss: 4.3705, Validation Loss Current: 6.2168, Validation Loss AVG: 6.2168, lr: 0.001
Epoch [22/80], Training Loss: 9.9476, Validation Loss Current: 8.5310, Validation Loss AVG: 8.5310, lr: 0.001
Epoch [23/80], Training Loss: 6.2916, Validation Loss Current: 7.7624, Validation Loss AVG: 7.7624, lr: 0.001
Epoch [24/80], Training Loss: 3.7521, Validation Loss Current: 6.5930, Validation Loss AVG: 6.5930, lr: 0.001
Epoch [25/80], Training Loss: 4.4322, Validation Loss Current: 6.9720, Validation Loss AVG: 6.9720, lr: 0.001
Epoch [26/80], Training Loss: 6.2907, Validation Loss Current: 7.7247, Validation Loss AVG: 7.7247, lr: 0.001
Epoch [27/80], Training Loss: 6.8039, Validation Loss Current: 9.0019, Validation Loss AVG: 9.0019, lr: 0.001
Epoch [28/80], Training Loss: 7.2478, Validation Loss Current: 9.1263, Validation Loss AVG: 9.1263, lr: 0.001
Epoch [29/80], Training Loss: 4.9343, Validation Loss Current: 8.5214, Validation Loss AVG: 8.5214, lr: 0.001
Epoch [30/80], Training Loss: 8.1122, Validation Loss Current: 9.6407, Validation Loss AVG: 9.6407, lr: 0.001
Epoch [31/80], Training Loss: 10.1949, Validation Loss Current: 8.9148, Validation Loss AVG: 8.9148, lr: 0.001
Epoch [32/80], Training Loss: 7.3840, Validation Loss Current: 7.3094, Validation Loss AVG: 7.3094, lr: 0.001
Epoch [33/80], Training Loss: 9.1080, Validation Loss Current: 9.9998, Validation Loss AVG: 9.9998, lr: 0.001
Epoch [34/80], Training Loss: 10.4095, Validation Loss Current: 8.5226, Validation Loss AVG: 8.5226, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random3 finished training. Best epoch: 4 Best val accuracy: [0.6444078947368421, 0.6371710526315789, 0.6398026315789475, 0.6944078947368422, 0.6927631578947369, 0.6756578947368421, 0.6921052631578947, 0.6634868421052632, 0.7059210526315789, 0.6529605263157895, 0.6983552631578946, 0.6526315789473685, 0.6654605263157894, 0.6960526315789475, 0.6256578947368421, 0.6256578947368421, 0.6200657894736843, 0.6144736842105263, 0.6365131578947368, 0.6572368421052632, 0.6611842105263157, 0.5911184210526317, 0.6088815789473684, 0.6621710526315789, 0.6430921052631579, 0.6036184210526315, 0.5927631578947369, 0.6055921052631579, 0.5858552631578948, 0.5927631578947368, 0.5822368421052632, 0.6355263157894737, 0.5424342105263158, 0.5858552631578948] Best val loss: 4.893865585327148


Current group: 0.6
Epoch [1/80], Training Loss: 38.0522, Validation Loss Current: 8.6961, Validation Loss AVG: 8.6961, lr: 0.001
Epoch [2/80], Training Loss: 20.4286, Validation Loss Current: 7.2012, Validation Loss AVG: 7.2012, lr: 0.001
Epoch [3/80], Training Loss: 14.9200, Validation Loss Current: 8.6097, Validation Loss AVG: 8.6097, lr: 0.001
Epoch [4/80], Training Loss: 10.8051, Validation Loss Current: 7.8637, Validation Loss AVG: 7.8637, lr: 0.001
Epoch [5/80], Training Loss: 8.7035, Validation Loss Current: 7.5621, Validation Loss AVG: 7.5621, lr: 0.001
Epoch [6/80], Training Loss: 8.8851, Validation Loss Current: 7.5951, Validation Loss AVG: 7.5951, lr: 0.001
Epoch [7/80], Training Loss: 5.1048, Validation Loss Current: 7.6850, Validation Loss AVG: 7.6850, lr: 0.001
Epoch [8/80], Training Loss: 7.1745, Validation Loss Current: 8.1700, Validation Loss AVG: 8.1700, lr: 0.001
Epoch [9/80], Training Loss: 13.4762, Validation Loss Current: 10.2494, Validation Loss AVG: 10.2494, lr: 0.001
Epoch [10/80], Training Loss: 8.4913, Validation Loss Current: 7.9631, Validation Loss AVG: 7.9631, lr: 0.001
Epoch [11/80], Training Loss: 5.3910, Validation Loss Current: 8.1354, Validation Loss AVG: 8.1354, lr: 0.001
Epoch [12/80], Training Loss: 6.0675, Validation Loss Current: 8.0914, Validation Loss AVG: 8.0914, lr: 0.001
Epoch [13/80], Training Loss: 4.3310, Validation Loss Current: 8.8895, Validation Loss AVG: 8.8895, lr: 0.001
Epoch [14/80], Training Loss: 4.2480, Validation Loss Current: 8.8841, Validation Loss AVG: 8.8841, lr: 0.001
Epoch [15/80], Training Loss: 5.8911, Validation Loss Current: 8.7802, Validation Loss AVG: 8.7802, lr: 0.001
Epoch [16/80], Training Loss: 4.8541, Validation Loss Current: 9.2421, Validation Loss AVG: 9.2421, lr: 0.001
Epoch [17/80], Training Loss: 6.3436, Validation Loss Current: 9.9646, Validation Loss AVG: 9.9646, lr: 0.001
Epoch [18/80], Training Loss: 5.6489, Validation Loss Current: 9.4387, Validation Loss AVG: 9.4387, lr: 0.001
Epoch [19/80], Training Loss: 5.9804, Validation Loss Current: 9.7290, Validation Loss AVG: 9.7290, lr: 0.001
Epoch [20/80], Training Loss: 5.0797, Validation Loss Current: 8.9527, Validation Loss AVG: 8.9527, lr: 0.001
Epoch [21/80], Training Loss: 3.6949, Validation Loss Current: 9.4984, Validation Loss AVG: 9.4984, lr: 0.001
Epoch [22/80], Training Loss: 2.8590, Validation Loss Current: 9.0213, Validation Loss AVG: 9.0213, lr: 0.001
Epoch [23/80], Training Loss: 3.5270, Validation Loss Current: 9.2679, Validation Loss AVG: 9.2679, lr: 0.001
Epoch [24/80], Training Loss: 5.0580, Validation Loss Current: 9.6900, Validation Loss AVG: 9.6900, lr: 0.001
Epoch [25/80], Training Loss: 4.9921, Validation Loss Current: 10.3438, Validation Loss AVG: 10.3438, lr: 0.001
Epoch [26/80], Training Loss: 4.0719, Validation Loss Current: 9.8118, Validation Loss AVG: 9.8118, lr: 0.001
Epoch [27/80], Training Loss: 6.6666, Validation Loss Current: 9.9719, Validation Loss AVG: 9.9719, lr: 0.001
Epoch [28/80], Training Loss: 5.3755, Validation Loss Current: 9.8204, Validation Loss AVG: 9.8204, lr: 0.001
Epoch [29/80], Training Loss: 5.1833, Validation Loss Current: 10.3340, Validation Loss AVG: 10.3340, lr: 0.001
Epoch [30/80], Training Loss: 6.6696, Validation Loss Current: 8.7822, Validation Loss AVG: 8.7822, lr: 0.001
Epoch [31/80], Training Loss: 2.7210, Validation Loss Current: 9.5937, Validation Loss AVG: 9.5937, lr: 0.001
Epoch [32/80], Training Loss: 2.8624, Validation Loss Current: 9.4013, Validation Loss AVG: 9.4013, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 2 Best val accuracy: [0.5490131578947369, 0.5986842105263158, 0.5605263157894738, 0.5786184210526315, 0.5907894736842105, 0.5888157894736843, 0.5526315789473684, 0.5595394736842105, 0.5299342105263157, 0.5789473684210525, 0.5674342105263157, 0.5828947368421054, 0.5539473684210525, 0.5384868421052632, 0.5542763157894738, 0.5263157894736843, 0.5332236842105262, 0.5256578947368421, 0.5236842105263158, 0.5539473684210526, 0.5444078947368421, 0.556907894736842, 0.5463815789473684, 0.5223684210526316, 0.5082236842105263, 0.54375, 0.5171052631578947, 0.5256578947368421, 0.5125, 0.5644736842105263, 0.5480263157894736, 0.5342105263157895] Best val loss: 7.201248669624329


----- Training resnet18 with sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] -----
Current group: llo_1_random0
Epoch [1/80], Training Loss: 41.5218, Validation Loss Current: 10.0591, Validation Loss AVG: 10.0591, lr: 0.001
Epoch [2/80], Training Loss: 40.1978, Validation Loss Current: 9.8910, Validation Loss AVG: 9.8910, lr: 0.001
Epoch [3/80], Training Loss: 38.8744, Validation Loss Current: 9.6680, Validation Loss AVG: 9.6680, lr: 0.001
Epoch [4/80], Training Loss: 39.1604, Validation Loss Current: 9.4577, Validation Loss AVG: 9.4577, lr: 0.001
Epoch [5/80], Training Loss: 37.2495, Validation Loss Current: 9.5078, Validation Loss AVG: 9.5078, lr: 0.001
Epoch [6/80], Training Loss: 37.1529, Validation Loss Current: 9.1438, Validation Loss AVG: 9.1438, lr: 0.001
Epoch [7/80], Training Loss: 36.8595, Validation Loss Current: 9.0509, Validation Loss AVG: 9.0509, lr: 0.001
Epoch [8/80], Training Loss: 35.9889, Validation Loss Current: 8.6589, Validation Loss AVG: 8.6589, lr: 0.001
Epoch [9/80], Training Loss: 34.6672, Validation Loss Current: 8.5111, Validation Loss AVG: 8.5111, lr: 0.001
Epoch [10/80], Training Loss: 34.1842, Validation Loss Current: 8.5277, Validation Loss AVG: 8.5277, lr: 0.001
Epoch [11/80], Training Loss: 32.7277, Validation Loss Current: 8.3375, Validation Loss AVG: 8.3375, lr: 0.001
Epoch [12/80], Training Loss: 33.0383, Validation Loss Current: 8.3074, Validation Loss AVG: 8.3074, lr: 0.001
Epoch [13/80], Training Loss: 32.2101, Validation Loss Current: 8.0624, Validation Loss AVG: 8.0624, lr: 0.001
Epoch [14/80], Training Loss: 30.7927, Validation Loss Current: 8.3367, Validation Loss AVG: 8.3367, lr: 0.001
Epoch [15/80], Training Loss: 31.2719, Validation Loss Current: 7.7367, Validation Loss AVG: 7.7367, lr: 0.001
Epoch [16/80], Training Loss: 29.6062, Validation Loss Current: 7.7720, Validation Loss AVG: 7.7720, lr: 0.001
Epoch [17/80], Training Loss: 29.0965, Validation Loss Current: 8.2596, Validation Loss AVG: 8.2596, lr: 0.001
Epoch [18/80], Training Loss: 29.0417, Validation Loss Current: 7.8939, Validation Loss AVG: 7.8939, lr: 0.001
Epoch [19/80], Training Loss: 27.7831, Validation Loss Current: 7.4304, Validation Loss AVG: 7.4304, lr: 0.001
Epoch [20/80], Training Loss: 26.4259, Validation Loss Current: 7.3249, Validation Loss AVG: 7.3249, lr: 0.001
Epoch [21/80], Training Loss: 25.3084, Validation Loss Current: 7.5684, Validation Loss AVG: 7.5684, lr: 0.001
Epoch [22/80], Training Loss: 24.1723, Validation Loss Current: 7.7972, Validation Loss AVG: 7.7972, lr: 0.001
Epoch [23/80], Training Loss: 24.7791, Validation Loss Current: 7.1993, Validation Loss AVG: 7.1993, lr: 0.001
Epoch [24/80], Training Loss: 23.4811, Validation Loss Current: 8.0333, Validation Loss AVG: 8.0333, lr: 0.001
Epoch [25/80], Training Loss: 24.9012, Validation Loss Current: 7.6327, Validation Loss AVG: 7.6327, lr: 0.001
Epoch [26/80], Training Loss: 22.7189, Validation Loss Current: 7.1998, Validation Loss AVG: 7.1998, lr: 0.001
Epoch [27/80], Training Loss: 22.1353, Validation Loss Current: 7.7957, Validation Loss AVG: 7.7957, lr: 0.001
Epoch [28/80], Training Loss: 22.5015, Validation Loss Current: 7.3119, Validation Loss AVG: 7.3119, lr: 0.001
Epoch [29/80], Training Loss: 19.6734, Validation Loss Current: 6.5905, Validation Loss AVG: 6.5905, lr: 0.001
Epoch [30/80], Training Loss: 17.6208, Validation Loss Current: 6.5299, Validation Loss AVG: 6.5299, lr: 0.001
Epoch [31/80], Training Loss: 18.1036, Validation Loss Current: 7.3565, Validation Loss AVG: 7.3565, lr: 0.001
Epoch [32/80], Training Loss: 18.8544, Validation Loss Current: 7.3292, Validation Loss AVG: 7.3292, lr: 0.001
Epoch [33/80], Training Loss: 16.3599, Validation Loss Current: 6.6304, Validation Loss AVG: 6.6304, lr: 0.001
Epoch [34/80], Training Loss: 16.4371, Validation Loss Current: 7.8798, Validation Loss AVG: 7.8798, lr: 0.001
Epoch [35/80], Training Loss: 18.5942, Validation Loss Current: 16.4835, Validation Loss AVG: 16.4835, lr: 0.001
Epoch [36/80], Training Loss: 34.2927, Validation Loss Current: 11.6261, Validation Loss AVG: 11.6261, lr: 0.001
Epoch [37/80], Training Loss: 25.0778, Validation Loss Current: 7.2797, Validation Loss AVG: 7.2797, lr: 0.001
Epoch [38/80], Training Loss: 22.2046, Validation Loss Current: 7.3721, Validation Loss AVG: 7.3721, lr: 0.001
Epoch [39/80], Training Loss: 19.2010, Validation Loss Current: 6.8473, Validation Loss AVG: 6.8473, lr: 0.001
Epoch [40/80], Training Loss: 18.4194, Validation Loss Current: 7.2509, Validation Loss AVG: 7.2509, lr: 0.001
Epoch [41/80], Training Loss: 17.1466, Validation Loss Current: 6.9261, Validation Loss AVG: 6.9261, lr: 0.001
Epoch [42/80], Training Loss: 15.7317, Validation Loss Current: 7.2069, Validation Loss AVG: 7.2069, lr: 0.001
Epoch [43/80], Training Loss: 14.3145, Validation Loss Current: 7.0315, Validation Loss AVG: 7.0315, lr: 0.001
Epoch [44/80], Training Loss: 13.1502, Validation Loss Current: 6.1346, Validation Loss AVG: 6.1346, lr: 0.001
Epoch [45/80], Training Loss: 13.3499, Validation Loss Current: 6.7750, Validation Loss AVG: 6.7750, lr: 0.001
Epoch [46/80], Training Loss: 12.2326, Validation Loss Current: 7.4705, Validation Loss AVG: 7.4705, lr: 0.001
Epoch [47/80], Training Loss: 11.3244, Validation Loss Current: 7.0328, Validation Loss AVG: 7.0328, lr: 0.001
Epoch [48/80], Training Loss: 11.5899, Validation Loss Current: 7.0632, Validation Loss AVG: 7.0632, lr: 0.001
Epoch [49/80], Training Loss: 9.1977, Validation Loss Current: 6.5482, Validation Loss AVG: 6.5482, lr: 0.001
Epoch [50/80], Training Loss: 11.8910, Validation Loss Current: 11.3784, Validation Loss AVG: 11.3784, lr: 0.001
Epoch [51/80], Training Loss: 16.3156, Validation Loss Current: 9.7060, Validation Loss AVG: 9.7060, lr: 0.001
Epoch [52/80], Training Loss: 15.9154, Validation Loss Current: 8.5393, Validation Loss AVG: 8.5393, lr: 0.001
Epoch [53/80], Training Loss: 12.6507, Validation Loss Current: 7.5736, Validation Loss AVG: 7.5736, lr: 0.001
Epoch [54/80], Training Loss: 10.6402, Validation Loss Current: 8.1008, Validation Loss AVG: 8.1008, lr: 0.001
Epoch [55/80], Training Loss: 8.5969, Validation Loss Current: 6.8254, Validation Loss AVG: 6.8254, lr: 0.001
Epoch [56/80], Training Loss: 6.8594, Validation Loss Current: 6.3747, Validation Loss AVG: 6.3747, lr: 0.001
Epoch [57/80], Training Loss: 6.3758, Validation Loss Current: 6.6382, Validation Loss AVG: 6.6382, lr: 0.001
Epoch [58/80], Training Loss: 6.6754, Validation Loss Current: 7.4251, Validation Loss AVG: 7.4251, lr: 0.001
Epoch [59/80], Training Loss: 6.8060, Validation Loss Current: 8.2360, Validation Loss AVG: 8.2360, lr: 0.001
Epoch [60/80], Training Loss: 6.5502, Validation Loss Current: 7.2856, Validation Loss AVG: 7.2856, lr: 0.001
Epoch [61/80], Training Loss: 6.5438, Validation Loss Current: 7.3920, Validation Loss AVG: 7.3920, lr: 0.001
Epoch [62/80], Training Loss: 4.7335, Validation Loss Current: 7.2588, Validation Loss AVG: 7.2588, lr: 0.001
Epoch [63/80], Training Loss: 4.4011, Validation Loss Current: 7.4399, Validation Loss AVG: 7.4399, lr: 0.001
Epoch [64/80], Training Loss: 6.8011, Validation Loss Current: 7.7852, Validation Loss AVG: 7.7852, lr: 0.001
Epoch [65/80], Training Loss: 9.8144, Validation Loss Current: 8.1023, Validation Loss AVG: 8.1023, lr: 0.001
Epoch [66/80], Training Loss: 5.0253, Validation Loss Current: 7.7999, Validation Loss AVG: 7.7999, lr: 0.001
Epoch [67/80], Training Loss: 5.4438, Validation Loss Current: 7.4743, Validation Loss AVG: 7.4743, lr: 0.001
Epoch [68/80], Training Loss: 8.8452, Validation Loss Current: 9.4672, Validation Loss AVG: 9.4672, lr: 0.001
Epoch [69/80], Training Loss: 8.0978, Validation Loss Current: 8.1475, Validation Loss AVG: 8.1475, lr: 0.001
Epoch [70/80], Training Loss: 10.4701, Validation Loss Current: 10.6629, Validation Loss AVG: 10.6629, lr: 0.001
Epoch [71/80], Training Loss: 7.2101, Validation Loss Current: 8.6478, Validation Loss AVG: 8.6478, lr: 0.001
Epoch [72/80], Training Loss: 7.7640, Validation Loss Current: 9.2520, Validation Loss AVG: 9.2520, lr: 0.001
Epoch [73/80], Training Loss: 9.8121, Validation Loss Current: 11.7222, Validation Loss AVG: 11.7222, lr: 0.001
Epoch [74/80], Training Loss: 7.3787, Validation Loss Current: 8.5131, Validation Loss AVG: 8.5131, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random0 finished training. Best epoch: 44 Best val accuracy: [0.23815789473684207, 0.25953947368421054, 0.2825657894736842, 0.31414473684210525, 0.2802631578947369, 0.3200657894736842, 0.362171052631579, 0.3888157894736842, 0.3911184210526316, 0.3884868421052632, 0.4095394736842105, 0.40230263157894736, 0.4355263157894737, 0.4095394736842105, 0.4615131578947368, 0.4549342105263158, 0.43125, 0.44605263157894737, 0.47730263157894737, 0.5052631578947369, 0.48157894736842105, 0.4582236842105264, 0.49539473684210533, 0.45921052631578946, 0.4845394736842105, 0.5013157894736843, 0.4703947368421053, 0.4917763157894736, 0.5473684210526315, 0.5549342105263159, 0.49243421052631586, 0.5144736842105264, 0.5523026315789473, 0.4723684210526315, 0.306578947368421, 0.2865131578947368, 0.49769736842105267, 0.49671052631578955, 0.53125, 0.5335526315789474, 0.524671052631579, 0.5292763157894738, 0.5434210526315789, 0.5891447368421052, 0.5483552631578947, 0.5256578947368421, 0.5381578947368422, 0.5342105263157894, 0.5904605263157896, 0.43618421052631573, 0.44572368421052627, 0.46019736842105263, 0.5256578947368421, 0.5144736842105263, 0.59375, 0.6016447368421053, 0.5907894736842105, 0.5572368421052631, 0.5328947368421053, 0.5901315789473685, 0.5786184210526315, 0.5996710526315789, 0.6, 0.5625, 0.5243421052631578, 0.5516447368421054, 0.5773026315789473, 0.5384868421052632, 0.5641447368421053, 0.44342105263157894, 0.5361842105263157, 0.5144736842105264, 0.47368421052631576, 0.5671052631578947] Best val loss: 6.134586763381958


Current group: llo_1_random1
Epoch [1/80], Training Loss: 33.1889, Validation Loss Current: 7.1162, Validation Loss AVG: 7.1162, lr: 0.001
Epoch [2/80], Training Loss: 24.9983, Validation Loss Current: 7.0488, Validation Loss AVG: 7.0488, lr: 0.001
Epoch [3/80], Training Loss: 18.5209, Validation Loss Current: 6.8254, Validation Loss AVG: 6.8254, lr: 0.001
Epoch [4/80], Training Loss: 15.4685, Validation Loss Current: 6.3944, Validation Loss AVG: 6.3944, lr: 0.001
Epoch [5/80], Training Loss: 12.1141, Validation Loss Current: 5.4448, Validation Loss AVG: 5.4448, lr: 0.001
Epoch [6/80], Training Loss: 10.8962, Validation Loss Current: 5.8348, Validation Loss AVG: 5.8348, lr: 0.001
Epoch [7/80], Training Loss: 11.0007, Validation Loss Current: 5.7497, Validation Loss AVG: 5.7497, lr: 0.001
Epoch [8/80], Training Loss: 8.4711, Validation Loss Current: 5.6621, Validation Loss AVG: 5.6621, lr: 0.001
Epoch [9/80], Training Loss: 9.9738, Validation Loss Current: 6.7724, Validation Loss AVG: 6.7724, lr: 0.001
Epoch [10/80], Training Loss: 6.7452, Validation Loss Current: 5.6064, Validation Loss AVG: 5.6064, lr: 0.001
Epoch [11/80], Training Loss: 6.1654, Validation Loss Current: 6.6416, Validation Loss AVG: 6.6416, lr: 0.001
Epoch [12/80], Training Loss: 7.2583, Validation Loss Current: 6.5255, Validation Loss AVG: 6.5255, lr: 0.001
Epoch [13/80], Training Loss: 5.7516, Validation Loss Current: 6.5942, Validation Loss AVG: 6.5942, lr: 0.001
Epoch [14/80], Training Loss: 9.5430, Validation Loss Current: 7.3626, Validation Loss AVG: 7.3626, lr: 0.001
Epoch [15/80], Training Loss: 10.3495, Validation Loss Current: 8.1197, Validation Loss AVG: 8.1197, lr: 0.001
Epoch [16/80], Training Loss: 5.8531, Validation Loss Current: 7.1134, Validation Loss AVG: 7.1134, lr: 0.001
Epoch [17/80], Training Loss: 5.2190, Validation Loss Current: 6.5502, Validation Loss AVG: 6.5502, lr: 0.001
Epoch [18/80], Training Loss: 5.9489, Validation Loss Current: 7.2462, Validation Loss AVG: 7.2462, lr: 0.001
Epoch [19/80], Training Loss: 8.0683, Validation Loss Current: 6.6509, Validation Loss AVG: 6.6509, lr: 0.001
Epoch [20/80], Training Loss: 5.8209, Validation Loss Current: 8.8612, Validation Loss AVG: 8.8612, lr: 0.001
Epoch [21/80], Training Loss: 5.3755, Validation Loss Current: 7.9052, Validation Loss AVG: 7.9052, lr: 0.001
Epoch [22/80], Training Loss: 3.4771, Validation Loss Current: 6.3499, Validation Loss AVG: 6.3499, lr: 0.001
Epoch [23/80], Training Loss: 5.1694, Validation Loss Current: 6.9690, Validation Loss AVG: 6.9690, lr: 0.001
Epoch [24/80], Training Loss: 7.3389, Validation Loss Current: 8.0113, Validation Loss AVG: 8.0113, lr: 0.001
Epoch [25/80], Training Loss: 8.7938, Validation Loss Current: 8.3373, Validation Loss AVG: 8.3373, lr: 0.001
Epoch [26/80], Training Loss: 7.8915, Validation Loss Current: 6.6663, Validation Loss AVG: 6.6663, lr: 0.001
Epoch [27/80], Training Loss: 8.3363, Validation Loss Current: 7.4097, Validation Loss AVG: 7.4097, lr: 0.001
Epoch [28/80], Training Loss: 10.0112, Validation Loss Current: 6.9546, Validation Loss AVG: 6.9546, lr: 0.001
Epoch [29/80], Training Loss: 5.8551, Validation Loss Current: 6.5078, Validation Loss AVG: 6.5078, lr: 0.001
Epoch [30/80], Training Loss: 6.2421, Validation Loss Current: 8.5042, Validation Loss AVG: 8.5042, lr: 0.001
Epoch [31/80], Training Loss: 6.8074, Validation Loss Current: 9.2886, Validation Loss AVG: 9.2886, lr: 0.001
Epoch [32/80], Training Loss: 3.6942, Validation Loss Current: 6.9280, Validation Loss AVG: 6.9280, lr: 0.001
Epoch [33/80], Training Loss: 4.3714, Validation Loss Current: 7.1229, Validation Loss AVG: 7.1229, lr: 0.001
Epoch [34/80], Training Loss: 4.8808, Validation Loss Current: 9.4895, Validation Loss AVG: 9.4895, lr: 0.001
Epoch [35/80], Training Loss: 3.7772, Validation Loss Current: 7.8254, Validation Loss AVG: 7.8254, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random1 finished training. Best epoch: 5 Best val accuracy: [0.575, 0.5529605263157895, 0.5694078947368421, 0.5789473684210525, 0.6358552631578946, 0.630592105263158, 0.6417763157894737, 0.6322368421052631, 0.6075657894736841, 0.6601973684210526, 0.5963815789473685, 0.6046052631578946, 0.6226973684210526, 0.5970394736842105, 0.51875, 0.6039473684210527, 0.61875, 0.5953947368421052, 0.6361842105263158, 0.5585526315789474, 0.58125, 0.644736842105263, 0.6125, 0.5625, 0.5555921052631578, 0.6144736842105264, 0.5914473684210526, 0.6095394736842106, 0.6319078947368421, 0.6006578947368422, 0.5536184210526316, 0.624671052631579, 0.6092105263157894, 0.5394736842105263, 0.5858552631578947] Best val loss: 5.444807231426239


Current group: llo_1_random2
Epoch [1/80], Training Loss: 36.6074, Validation Loss Current: 6.6344, Validation Loss AVG: 6.6344, lr: 0.001
Epoch [2/80], Training Loss: 23.0686, Validation Loss Current: 7.3077, Validation Loss AVG: 7.3077, lr: 0.001
Epoch [3/80], Training Loss: 19.3944, Validation Loss Current: 7.8239, Validation Loss AVG: 7.8239, lr: 0.001
Epoch [4/80], Training Loss: 13.6587, Validation Loss Current: 5.5356, Validation Loss AVG: 5.5356, lr: 0.001
Epoch [5/80], Training Loss: 10.3862, Validation Loss Current: 5.1206, Validation Loss AVG: 5.1206, lr: 0.001
Epoch [6/80], Training Loss: 12.1257, Validation Loss Current: 5.7926, Validation Loss AVG: 5.7926, lr: 0.001
Epoch [7/80], Training Loss: 15.3633, Validation Loss Current: 6.8793, Validation Loss AVG: 6.8793, lr: 0.001
Epoch [8/80], Training Loss: 12.8941, Validation Loss Current: 7.7813, Validation Loss AVG: 7.7813, lr: 0.001
Epoch [9/80], Training Loss: 9.8233, Validation Loss Current: 5.4355, Validation Loss AVG: 5.4355, lr: 0.001
Epoch [10/80], Training Loss: 7.5360, Validation Loss Current: 5.8887, Validation Loss AVG: 5.8887, lr: 0.001
Epoch [11/80], Training Loss: 6.7178, Validation Loss Current: 6.1836, Validation Loss AVG: 6.1836, lr: 0.001
Epoch [12/80], Training Loss: 4.8114, Validation Loss Current: 5.7512, Validation Loss AVG: 5.7512, lr: 0.001
Epoch [13/80], Training Loss: 4.6980, Validation Loss Current: 5.4570, Validation Loss AVG: 5.4570, lr: 0.001
Epoch [14/80], Training Loss: 3.4671, Validation Loss Current: 5.9461, Validation Loss AVG: 5.9461, lr: 0.001
Epoch [15/80], Training Loss: 6.5142, Validation Loss Current: 5.6166, Validation Loss AVG: 5.6166, lr: 0.001
Epoch [16/80], Training Loss: 5.1786, Validation Loss Current: 6.4702, Validation Loss AVG: 6.4702, lr: 0.001
Epoch [17/80], Training Loss: 7.7537, Validation Loss Current: 6.7431, Validation Loss AVG: 6.7431, lr: 0.001
Epoch [18/80], Training Loss: 7.1312, Validation Loss Current: 6.0805, Validation Loss AVG: 6.0805, lr: 0.001
Epoch [19/80], Training Loss: 7.4188, Validation Loss Current: 5.5091, Validation Loss AVG: 5.5091, lr: 0.001
Epoch [20/80], Training Loss: 2.7151, Validation Loss Current: 5.9185, Validation Loss AVG: 5.9185, lr: 0.001
Epoch [21/80], Training Loss: 2.7836, Validation Loss Current: 5.5586, Validation Loss AVG: 5.5586, lr: 0.001
Epoch [22/80], Training Loss: 3.7224, Validation Loss Current: 6.3245, Validation Loss AVG: 6.3245, lr: 0.001
Epoch [23/80], Training Loss: 3.3597, Validation Loss Current: 6.0881, Validation Loss AVG: 6.0881, lr: 0.001
Epoch [24/80], Training Loss: 3.5500, Validation Loss Current: 7.0446, Validation Loss AVG: 7.0446, lr: 0.001
Epoch [25/80], Training Loss: 4.8160, Validation Loss Current: 7.0764, Validation Loss AVG: 7.0764, lr: 0.001
Epoch [26/80], Training Loss: 5.9141, Validation Loss Current: 9.2933, Validation Loss AVG: 9.2933, lr: 0.001
Epoch [27/80], Training Loss: 3.5317, Validation Loss Current: 6.1223, Validation Loss AVG: 6.1223, lr: 0.001
Epoch [28/80], Training Loss: 4.9282, Validation Loss Current: 7.5880, Validation Loss AVG: 7.5880, lr: 0.001
Epoch [29/80], Training Loss: 4.8869, Validation Loss Current: 8.1288, Validation Loss AVG: 8.1288, lr: 0.001
Epoch [30/80], Training Loss: 3.8470, Validation Loss Current: 6.2650, Validation Loss AVG: 6.2650, lr: 0.001
Epoch [31/80], Training Loss: 4.7239, Validation Loss Current: 6.4418, Validation Loss AVG: 6.4418, lr: 0.001
Epoch [32/80], Training Loss: 3.3071, Validation Loss Current: 6.6669, Validation Loss AVG: 6.6669, lr: 0.001
Epoch [33/80], Training Loss: 2.5508, Validation Loss Current: 7.1458, Validation Loss AVG: 7.1458, lr: 0.001
Epoch [34/80], Training Loss: 7.1247, Validation Loss Current: 9.9434, Validation Loss AVG: 9.9434, lr: 0.001
Epoch [35/80], Training Loss: 5.2819, Validation Loss Current: 7.9052, Validation Loss AVG: 7.9052, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random2 finished training. Best epoch: 5 Best val accuracy: [0.6144736842105263, 0.5625, 0.5388157894736841, 0.6371710526315789, 0.6680921052631579, 0.6375, 0.593421052631579, 0.55625, 0.6595394736842104, 0.6338815789473685, 0.6348684210526316, 0.637171052631579, 0.6661184210526315, 0.6707236842105264, 0.6654605263157894, 0.6375, 0.6394736842105264, 0.6575657894736842, 0.6769736842105262, 0.662828947368421, 0.6911184210526315, 0.6503289473684211, 0.6509868421052631, 0.63125, 0.6299342105263158, 0.58125, 0.6697368421052632, 0.6279605263157896, 0.5786184210526316, 0.6615131578947369, 0.6401315789473684, 0.6457236842105264, 0.6394736842105263, 0.5809210526315789, 0.6095394736842106] Best val loss: 5.120647823810577


Current group: llo_1_random3
Epoch [1/80], Training Loss: 36.0374, Validation Loss Current: 6.5070, Validation Loss AVG: 6.5070, lr: 0.001
Epoch [2/80], Training Loss: 25.3329, Validation Loss Current: 6.8135, Validation Loss AVG: 6.8135, lr: 0.001
Epoch [3/80], Training Loss: 17.4638, Validation Loss Current: 5.8807, Validation Loss AVG: 5.8807, lr: 0.001
Epoch [4/80], Training Loss: 13.5234, Validation Loss Current: 5.7827, Validation Loss AVG: 5.7827, lr: 0.001
Epoch [5/80], Training Loss: 10.9633, Validation Loss Current: 6.4558, Validation Loss AVG: 6.4558, lr: 0.001
Epoch [6/80], Training Loss: 9.8500, Validation Loss Current: 5.5529, Validation Loss AVG: 5.5529, lr: 0.001
Epoch [7/80], Training Loss: 9.3829, Validation Loss Current: 5.4387, Validation Loss AVG: 5.4387, lr: 0.001
Epoch [8/80], Training Loss: 8.0205, Validation Loss Current: 5.4203, Validation Loss AVG: 5.4203, lr: 0.001
Epoch [9/80], Training Loss: 9.2386, Validation Loss Current: 6.2191, Validation Loss AVG: 6.2191, lr: 0.001
Epoch [10/80], Training Loss: 7.5327, Validation Loss Current: 5.5495, Validation Loss AVG: 5.5495, lr: 0.001
Epoch [11/80], Training Loss: 7.8091, Validation Loss Current: 5.9859, Validation Loss AVG: 5.9859, lr: 0.001
Epoch [12/80], Training Loss: 5.5548, Validation Loss Current: 6.1682, Validation Loss AVG: 6.1682, lr: 0.001
Epoch [13/80], Training Loss: 5.8170, Validation Loss Current: 5.8713, Validation Loss AVG: 5.8713, lr: 0.001
Epoch [14/80], Training Loss: 6.0363, Validation Loss Current: 6.3950, Validation Loss AVG: 6.3950, lr: 0.001
Epoch [15/80], Training Loss: 7.9324, Validation Loss Current: 5.9680, Validation Loss AVG: 5.9680, lr: 0.001
Epoch [16/80], Training Loss: 6.4336, Validation Loss Current: 6.4825, Validation Loss AVG: 6.4825, lr: 0.001
Epoch [17/80], Training Loss: 4.9959, Validation Loss Current: 5.4905, Validation Loss AVG: 5.4905, lr: 0.001
Epoch [18/80], Training Loss: 5.3944, Validation Loss Current: 5.5870, Validation Loss AVG: 5.5870, lr: 0.001
Epoch [19/80], Training Loss: 5.8499, Validation Loss Current: 7.1030, Validation Loss AVG: 7.1030, lr: 0.001
Epoch [20/80], Training Loss: 5.8580, Validation Loss Current: 6.0316, Validation Loss AVG: 6.0316, lr: 0.001
Epoch [21/80], Training Loss: 4.9366, Validation Loss Current: 6.2133, Validation Loss AVG: 6.2133, lr: 0.001
Epoch [22/80], Training Loss: 4.3268, Validation Loss Current: 5.9901, Validation Loss AVG: 5.9901, lr: 0.001
Epoch [23/80], Training Loss: 7.5446, Validation Loss Current: 9.8167, Validation Loss AVG: 9.8167, lr: 0.001
Epoch [24/80], Training Loss: 8.3905, Validation Loss Current: 8.2212, Validation Loss AVG: 8.2212, lr: 0.001
Epoch [25/80], Training Loss: 3.1634, Validation Loss Current: 6.1599, Validation Loss AVG: 6.1599, lr: 0.001
Epoch [26/80], Training Loss: 2.2845, Validation Loss Current: 6.6836, Validation Loss AVG: 6.6836, lr: 0.001
Epoch [27/80], Training Loss: 2.8211, Validation Loss Current: 7.2149, Validation Loss AVG: 7.2149, lr: 0.001
Epoch [28/80], Training Loss: 2.8913, Validation Loss Current: 6.5162, Validation Loss AVG: 6.5162, lr: 0.001
Epoch [29/80], Training Loss: 3.2269, Validation Loss Current: 6.8316, Validation Loss AVG: 6.8316, lr: 0.001
Epoch [30/80], Training Loss: 3.1562, Validation Loss Current: 6.2507, Validation Loss AVG: 6.2507, lr: 0.001
Epoch [31/80], Training Loss: 2.7353, Validation Loss Current: 6.3975, Validation Loss AVG: 6.3975, lr: 0.001
Epoch [32/80], Training Loss: 2.2353, Validation Loss Current: 6.7249, Validation Loss AVG: 6.7249, lr: 0.001
Epoch [33/80], Training Loss: 1.2548, Validation Loss Current: 5.9060, Validation Loss AVG: 5.9060, lr: 0.001
Epoch [34/80], Training Loss: 1.6058, Validation Loss Current: 6.6991, Validation Loss AVG: 6.6991, lr: 0.001
Epoch [35/80], Training Loss: 2.2630, Validation Loss Current: 6.6884, Validation Loss AVG: 6.6884, lr: 0.001
Epoch [36/80], Training Loss: 5.7868, Validation Loss Current: 7.2972, Validation Loss AVG: 7.2972, lr: 0.001
Epoch [37/80], Training Loss: 5.4392, Validation Loss Current: 8.6348, Validation Loss AVG: 8.6348, lr: 0.001
Epoch [38/80], Training Loss: 3.4442, Validation Loss Current: 6.5843, Validation Loss AVG: 6.5843, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random3 finished training. Best epoch: 8 Best val accuracy: [0.6111842105263158, 0.6148026315789474, 0.6355263157894737, 0.6519736842105263, 0.6042763157894736, 0.6651315789473684, 0.6809210526315789, 0.6766447368421054, 0.6217105263157895, 0.6848684210526316, 0.6598684210526315, 0.6368421052631579, 0.6769736842105263, 0.6453947368421052, 0.6519736842105263, 0.6694078947368421, 0.6848684210526315, 0.6891447368421053, 0.6523026315789474, 0.6700657894736841, 0.6398026315789473, 0.6648026315789474, 0.5555921052631578, 0.6049342105263158, 0.6608552631578947, 0.6421052631578947, 0.6213815789473685, 0.6756578947368421, 0.6509868421052631, 0.6802631578947368, 0.6674342105263158, 0.6667763157894736, 0.6822368421052631, 0.6592105263157895, 0.6592105263157895, 0.6348684210526316, 0.60625, 0.6523026315789474] Best val loss: 5.420316433906555


Current group: 1
Epoch [1/80], Training Loss: 37.3901, Validation Loss Current: 10.9621, Validation Loss AVG: 11.4552, lr: 0.001
Epoch [2/80], Training Loss: 19.4050, Validation Loss Current: 7.3411, Validation Loss AVG: 10.2357, lr: 0.001
Epoch [3/80], Training Loss: 10.7565, Validation Loss Current: 7.3049, Validation Loss AVG: 10.5164, lr: 0.001
Epoch [4/80], Training Loss: 8.9782, Validation Loss Current: 7.4222, Validation Loss AVG: 8.2058, lr: 0.001
Epoch [5/80], Training Loss: 7.8799, Validation Loss Current: 7.1682, Validation Loss AVG: 10.7723, lr: 0.001
Epoch [6/80], Training Loss: 5.6295, Validation Loss Current: 7.0105, Validation Loss AVG: 11.0602, lr: 0.001
Epoch [7/80], Training Loss: 4.0616, Validation Loss Current: 6.9459, Validation Loss AVG: 10.1286, lr: 0.001
Epoch [8/80], Training Loss: 1.9665, Validation Loss Current: 6.6044, Validation Loss AVG: 9.3841, lr: 0.001
Epoch [9/80], Training Loss: 4.0869, Validation Loss Current: 6.5185, Validation Loss AVG: 9.8117, lr: 0.001
Epoch [10/80], Training Loss: 6.9012, Validation Loss Current: 7.4538, Validation Loss AVG: 12.9842, lr: 0.001
Epoch [11/80], Training Loss: 3.0837, Validation Loss Current: 7.0934, Validation Loss AVG: 10.3016, lr: 0.001
Epoch [12/80], Training Loss: 6.7082, Validation Loss Current: 8.5173, Validation Loss AVG: 11.3012, lr: 0.001
Epoch [13/80], Training Loss: 3.6933, Validation Loss Current: 8.1926, Validation Loss AVG: 11.0050, lr: 0.001
Epoch [14/80], Training Loss: 2.3927, Validation Loss Current: 8.3334, Validation Loss AVG: 10.7411, lr: 0.001
Epoch [15/80], Training Loss: 1.3246, Validation Loss Current: 7.2603, Validation Loss AVG: 11.2544, lr: 0.001
Epoch [16/80], Training Loss: 3.2826, Validation Loss Current: 7.8179, Validation Loss AVG: 11.4187, lr: 0.001
Epoch [17/80], Training Loss: 6.3656, Validation Loss Current: 8.8182, Validation Loss AVG: 12.9573, lr: 0.001
Epoch [18/80], Training Loss: 5.9468, Validation Loss Current: 8.8627, Validation Loss AVG: 12.3926, lr: 0.001
Epoch [19/80], Training Loss: 4.7752, Validation Loss Current: 8.8861, Validation Loss AVG: 10.9514, lr: 0.001
Epoch [20/80], Training Loss: 5.8413, Validation Loss Current: 8.4407, Validation Loss AVG: 12.1859, lr: 0.001
Epoch [21/80], Training Loss: 7.2557, Validation Loss Current: 10.5405, Validation Loss AVG: 13.3682, lr: 0.001
Epoch [22/80], Training Loss: 7.0976, Validation Loss Current: 9.5065, Validation Loss AVG: 11.7687, lr: 0.001
Epoch [23/80], Training Loss: 9.3841, Validation Loss Current: 7.7273, Validation Loss AVG: 10.9121, lr: 0.001
Epoch [24/80], Training Loss: 7.7338, Validation Loss Current: 7.6402, Validation Loss AVG: 10.9989, lr: 0.001
Epoch [25/80], Training Loss: 2.8301, Validation Loss Current: 7.5324, Validation Loss AVG: 10.9683, lr: 0.001
Epoch [26/80], Training Loss: 3.5801, Validation Loss Current: 7.8440, Validation Loss AVG: 12.3651, lr: 0.001
Epoch [27/80], Training Loss: 2.6237, Validation Loss Current: 7.9413, Validation Loss AVG: 11.3770, lr: 0.001
Epoch [28/80], Training Loss: 2.1780, Validation Loss Current: 6.9120, Validation Loss AVG: 11.3264, lr: 0.001
Epoch [29/80], Training Loss: 2.3576, Validation Loss Current: 6.8363, Validation Loss AVG: 14.4058, lr: 0.001
Epoch [30/80], Training Loss: 2.8802, Validation Loss Current: 7.3960, Validation Loss AVG: 14.6008, lr: 0.001
Epoch [31/80], Training Loss: 2.5537, Validation Loss Current: 7.4286, Validation Loss AVG: 12.3532, lr: 0.001
Epoch [32/80], Training Loss: 2.7132, Validation Loss Current: 7.6104, Validation Loss AVG: 12.7783, lr: 0.001
Epoch [33/80], Training Loss: 4.1190, Validation Loss Current: 8.2835, Validation Loss AVG: 11.3085, lr: 0.001
Epoch [34/80], Training Loss: 4.3842, Validation Loss Current: 8.1833, Validation Loss AVG: 11.7903, lr: 0.001
Epoch [35/80], Training Loss: 5.0790, Validation Loss Current: 9.2685, Validation Loss AVG: 14.6402, lr: 0.001
Epoch [36/80], Training Loss: 3.1847, Validation Loss Current: 7.2962, Validation Loss AVG: 12.2834, lr: 0.001
Epoch [37/80], Training Loss: 2.0488, Validation Loss Current: 7.7265, Validation Loss AVG: 12.8541, lr: 0.001
Epoch [38/80], Training Loss: 3.6384, Validation Loss Current: 7.6800, Validation Loss AVG: 11.8831, lr: 0.001
Epoch [39/80], Training Loss: 6.6494, Validation Loss Current: 8.7570, Validation Loss AVG: 12.8622, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 9 Best val accuracy: [0.46875, 0.5674342105263158, 0.5476973684210527, 0.600328947368421, 0.5921052631578947, 0.5822368421052632, 0.6134868421052632, 0.6266447368421053, 0.6085526315789473, 0.6151315789473685, 0.5986842105263158, 0.5756578947368421, 0.5838815789473685, 0.5953947368421053, 0.6200657894736842, 0.6134868421052632, 0.5592105263157895, 0.5674342105263158, 0.5723684210526315, 0.5953947368421053, 0.5394736842105263, 0.5509868421052632, 0.59375, 0.5953947368421053, 0.6299342105263158, 0.600328947368421, 0.6118421052631579, 0.6381578947368421, 0.6529605263157895, 0.6134868421052632, 0.6085526315789473, 0.6069078947368421, 0.600328947368421, 0.6069078947368421, 0.5526315789473685, 0.6365131578947368, 0.6200657894736842, 0.6069078947368421, 0.5625] Best val loss: 6.518529653549194


Fold: 2
----- Training resnet18 with sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] -----
Current group: llo_0.2_random0
Epoch [1/80], Training Loss: 40.2635, Validation Loss Current: 10.0986, Validation Loss AVG: 10.0986, lr: 0.001
Epoch [2/80], Training Loss: 39.0809, Validation Loss Current: 10.0230, Validation Loss AVG: 10.0230, lr: 0.001
Epoch [3/80], Training Loss: 38.7655, Validation Loss Current: 9.9129, Validation Loss AVG: 9.9129, lr: 0.001
Epoch [4/80], Training Loss: 37.7342, Validation Loss Current: 9.6863, Validation Loss AVG: 9.6863, lr: 0.001
Epoch [5/80], Training Loss: 36.1464, Validation Loss Current: 9.5146, Validation Loss AVG: 9.5146, lr: 0.001
Epoch [6/80], Training Loss: 35.1620, Validation Loss Current: 9.3227, Validation Loss AVG: 9.3227, lr: 0.001
Epoch [7/80], Training Loss: 34.7574, Validation Loss Current: 9.0231, Validation Loss AVG: 9.0231, lr: 0.001
Epoch [8/80], Training Loss: 32.5770, Validation Loss Current: 9.1726, Validation Loss AVG: 9.1726, lr: 0.001
Epoch [9/80], Training Loss: 31.7652, Validation Loss Current: 9.0067, Validation Loss AVG: 9.0067, lr: 0.001
Epoch [10/80], Training Loss: 31.6403, Validation Loss Current: 8.5897, Validation Loss AVG: 8.5897, lr: 0.001
Epoch [11/80], Training Loss: 29.9780, Validation Loss Current: 8.4067, Validation Loss AVG: 8.4067, lr: 0.001
Epoch [12/80], Training Loss: 30.0518, Validation Loss Current: 8.2892, Validation Loss AVG: 8.2892, lr: 0.001
Epoch [13/80], Training Loss: 28.2220, Validation Loss Current: 8.3594, Validation Loss AVG: 8.3594, lr: 0.001
Epoch [14/80], Training Loss: 28.2189, Validation Loss Current: 8.0650, Validation Loss AVG: 8.0650, lr: 0.001
Epoch [15/80], Training Loss: 27.2368, Validation Loss Current: 8.2347, Validation Loss AVG: 8.2347, lr: 0.001
Epoch [16/80], Training Loss: 26.6492, Validation Loss Current: 7.9851, Validation Loss AVG: 7.9851, lr: 0.001
Epoch [17/80], Training Loss: 25.1315, Validation Loss Current: 7.5425, Validation Loss AVG: 7.5425, lr: 0.001
Epoch [18/80], Training Loss: 24.1007, Validation Loss Current: 7.7761, Validation Loss AVG: 7.7761, lr: 0.001
Epoch [19/80], Training Loss: 24.8901, Validation Loss Current: 7.7534, Validation Loss AVG: 7.7534, lr: 0.001
Epoch [20/80], Training Loss: 23.7685, Validation Loss Current: 7.3946, Validation Loss AVG: 7.3946, lr: 0.001
Epoch [21/80], Training Loss: 22.4795, Validation Loss Current: 7.4980, Validation Loss AVG: 7.4980, lr: 0.001
Epoch [22/80], Training Loss: 19.9787, Validation Loss Current: 7.4406, Validation Loss AVG: 7.4406, lr: 0.001
Epoch [23/80], Training Loss: 21.2069, Validation Loss Current: 7.7653, Validation Loss AVG: 7.7653, lr: 0.001
Epoch [24/80], Training Loss: 21.4616, Validation Loss Current: 7.6575, Validation Loss AVG: 7.6575, lr: 0.001
Epoch [25/80], Training Loss: 19.3038, Validation Loss Current: 7.0709, Validation Loss AVG: 7.0709, lr: 0.001
Epoch [26/80], Training Loss: 17.4012, Validation Loss Current: 7.1471, Validation Loss AVG: 7.1471, lr: 0.001
Epoch [27/80], Training Loss: 18.9102, Validation Loss Current: 9.2235, Validation Loss AVG: 9.2235, lr: 0.001
Epoch [28/80], Training Loss: 19.3580, Validation Loss Current: 7.3247, Validation Loss AVG: 7.3247, lr: 0.001
Epoch [29/80], Training Loss: 17.9125, Validation Loss Current: 7.8744, Validation Loss AVG: 7.8744, lr: 0.001
Epoch [30/80], Training Loss: 16.8433, Validation Loss Current: 8.1892, Validation Loss AVG: 8.1892, lr: 0.001
Epoch [31/80], Training Loss: 16.3065, Validation Loss Current: 6.8967, Validation Loss AVG: 6.8967, lr: 0.001
Epoch [32/80], Training Loss: 14.7135, Validation Loss Current: 7.0848, Validation Loss AVG: 7.0848, lr: 0.001
Epoch [33/80], Training Loss: 13.2434, Validation Loss Current: 7.0329, Validation Loss AVG: 7.0329, lr: 0.001
Epoch [34/80], Training Loss: 13.5362, Validation Loss Current: 7.7258, Validation Loss AVG: 7.7258, lr: 0.001
Epoch [35/80], Training Loss: 11.5043, Validation Loss Current: 7.3998, Validation Loss AVG: 7.3998, lr: 0.001
Epoch [36/80], Training Loss: 11.3561, Validation Loss Current: 8.5333, Validation Loss AVG: 8.5333, lr: 0.001
Epoch [37/80], Training Loss: 19.3374, Validation Loss Current: 12.2277, Validation Loss AVG: 12.2277, lr: 0.001
Epoch [38/80], Training Loss: 17.1219, Validation Loss Current: 9.0413, Validation Loss AVG: 9.0413, lr: 0.001
Epoch [39/80], Training Loss: 12.1186, Validation Loss Current: 6.9677, Validation Loss AVG: 6.9677, lr: 0.001
Epoch [40/80], Training Loss: 10.5201, Validation Loss Current: 7.0544, Validation Loss AVG: 7.0544, lr: 0.001
Epoch [41/80], Training Loss: 8.3169, Validation Loss Current: 6.8258, Validation Loss AVG: 6.8258, lr: 0.001
Epoch [42/80], Training Loss: 9.4113, Validation Loss Current: 8.5440, Validation Loss AVG: 8.5440, lr: 0.001
Epoch [43/80], Training Loss: 9.9518, Validation Loss Current: 7.6375, Validation Loss AVG: 7.6375, lr: 0.001
Epoch [44/80], Training Loss: 7.8408, Validation Loss Current: 7.2620, Validation Loss AVG: 7.2620, lr: 0.001
Epoch [45/80], Training Loss: 7.1816, Validation Loss Current: 8.5587, Validation Loss AVG: 8.5587, lr: 0.001
Epoch [46/80], Training Loss: 11.0028, Validation Loss Current: 9.7339, Validation Loss AVG: 9.7339, lr: 0.001
Epoch [47/80], Training Loss: 7.1509, Validation Loss Current: 9.6215, Validation Loss AVG: 9.6215, lr: 0.001
Epoch [48/80], Training Loss: 7.4789, Validation Loss Current: 10.2022, Validation Loss AVG: 10.2022, lr: 0.001
Epoch [49/80], Training Loss: 5.9657, Validation Loss Current: 8.0968, Validation Loss AVG: 8.0968, lr: 0.001
Epoch [50/80], Training Loss: 5.4750, Validation Loss Current: 8.6903, Validation Loss AVG: 8.6903, lr: 0.001
Epoch [51/80], Training Loss: 6.2033, Validation Loss Current: 9.7635, Validation Loss AVG: 9.7635, lr: 0.001
Epoch [52/80], Training Loss: 8.2944, Validation Loss Current: 9.2701, Validation Loss AVG: 9.2701, lr: 0.001
Epoch [53/80], Training Loss: 6.8309, Validation Loss Current: 8.5419, Validation Loss AVG: 8.5419, lr: 0.001
Epoch [54/80], Training Loss: 5.6499, Validation Loss Current: 9.6047, Validation Loss AVG: 9.6047, lr: 0.001
Epoch [55/80], Training Loss: 6.5563, Validation Loss Current: 9.4657, Validation Loss AVG: 9.4657, lr: 0.001
Epoch [56/80], Training Loss: 4.1533, Validation Loss Current: 8.1663, Validation Loss AVG: 8.1663, lr: 0.001
Epoch [57/80], Training Loss: 5.5947, Validation Loss Current: 12.1618, Validation Loss AVG: 12.1618, lr: 0.001
Epoch [58/80], Training Loss: 15.0251, Validation Loss Current: 12.2979, Validation Loss AVG: 12.2979, lr: 0.001
Epoch [59/80], Training Loss: 13.4647, Validation Loss Current: 11.2335, Validation Loss AVG: 11.2335, lr: 0.001
Epoch [60/80], Training Loss: 9.0077, Validation Loss Current: 7.9505, Validation Loss AVG: 7.9505, lr: 0.001
Epoch [61/80], Training Loss: 6.0372, Validation Loss Current: 7.9968, Validation Loss AVG: 7.9968, lr: 0.001
Epoch [62/80], Training Loss: 9.5436, Validation Loss Current: 8.1078, Validation Loss AVG: 8.1078, lr: 0.001
Epoch [63/80], Training Loss: 6.4217, Validation Loss Current: 8.0043, Validation Loss AVG: 8.0043, lr: 0.001
Epoch [64/80], Training Loss: 6.5596, Validation Loss Current: 8.5420, Validation Loss AVG: 8.5420, lr: 0.001
Epoch [65/80], Training Loss: 8.1640, Validation Loss Current: 10.9795, Validation Loss AVG: 10.9795, lr: 0.001
Epoch [66/80], Training Loss: 4.6486, Validation Loss Current: 7.8416, Validation Loss AVG: 7.8416, lr: 0.001
Epoch [67/80], Training Loss: 5.2867, Validation Loss Current: 10.0633, Validation Loss AVG: 10.0633, lr: 0.001
Epoch [68/80], Training Loss: 6.0780, Validation Loss Current: 8.8463, Validation Loss AVG: 8.8463, lr: 0.001
Epoch [69/80], Training Loss: 4.4198, Validation Loss Current: 8.9267, Validation Loss AVG: 8.9267, lr: 0.001
Epoch [70/80], Training Loss: 5.5338, Validation Loss Current: 9.9419, Validation Loss AVG: 9.9419, lr: 0.001
Epoch [71/80], Training Loss: 3.8987, Validation Loss Current: 8.2820, Validation Loss AVG: 8.2820, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random0 finished training. Best epoch: 41 Best val accuracy: [0.23322368421052628, 0.23651315789473681, 0.2463815789473684, 0.26644736842105265, 0.29309210526315793, 0.3161184210526316, 0.3470394736842105, 0.33092105263157895, 0.3473684210526316, 0.3828947368421053, 0.3927631578947368, 0.3973684210526316, 0.4088815789473685, 0.41381578947368425, 0.4006578947368421, 0.4358552631578948, 0.4618421052631579, 0.43881578947368427, 0.4631578947368421, 0.4657894736842104, 0.46644736842105267, 0.4753289473684211, 0.4582236842105264, 0.46381578947368424, 0.49934210526315786, 0.5009868421052632, 0.4082236842105263, 0.5069078947368422, 0.4743421052631579, 0.46842105263157896, 0.5256578947368421, 0.5039473684210527, 0.5125, 0.4990131578947368, 0.5108552631578948, 0.46381578947368424, 0.41052631578947363, 0.40625, 0.5434210526315789, 0.5345394736842105, 0.5388157894736841, 0.49375, 0.5115131578947368, 0.5463815789473684, 0.5319078947368421, 0.47006578947368416, 0.47664473684210523, 0.4894736842105264, 0.5128289473684211, 0.5253289473684211, 0.49046052631578946, 0.4950657894736842, 0.5273026315789473, 0.46282894736842106, 0.5263157894736843, 0.5276315789473685, 0.4411184210526316, 0.41907894736842105, 0.40230263157894736, 0.5342105263157895, 0.5125, 0.5144736842105263, 0.5299342105263157, 0.5075657894736842, 0.4598684210526316, 0.54375, 0.5082236842105263, 0.5095394736842105, 0.5210526315789474, 0.5144736842105263, 0.5519736842105263] Best val loss: 6.825834894180298


Current group: llo_0.2_random1
Epoch [1/80], Training Loss: 29.7186, Validation Loss Current: 7.5651, Validation Loss AVG: 7.5651, lr: 0.001
Epoch [2/80], Training Loss: 21.4555, Validation Loss Current: 6.3735, Validation Loss AVG: 6.3735, lr: 0.001
Epoch [3/80], Training Loss: 19.7201, Validation Loss Current: 6.8674, Validation Loss AVG: 6.8674, lr: 0.001
Epoch [4/80], Training Loss: 15.9377, Validation Loss Current: 8.0334, Validation Loss AVG: 8.0334, lr: 0.001
Epoch [5/80], Training Loss: 14.8230, Validation Loss Current: 6.3472, Validation Loss AVG: 6.3472, lr: 0.001
Epoch [6/80], Training Loss: 12.7744, Validation Loss Current: 7.3047, Validation Loss AVG: 7.3047, lr: 0.001
Epoch [7/80], Training Loss: 10.7698, Validation Loss Current: 8.4330, Validation Loss AVG: 8.4330, lr: 0.001
Epoch [8/80], Training Loss: 12.0889, Validation Loss Current: 10.3666, Validation Loss AVG: 10.3666, lr: 0.001
Epoch [9/80], Training Loss: 12.2497, Validation Loss Current: 7.1928, Validation Loss AVG: 7.1928, lr: 0.001
Epoch [10/80], Training Loss: 8.6620, Validation Loss Current: 7.0152, Validation Loss AVG: 7.0152, lr: 0.001
Epoch [11/80], Training Loss: 7.8894, Validation Loss Current: 6.0282, Validation Loss AVG: 6.0282, lr: 0.001
Epoch [12/80], Training Loss: 6.4060, Validation Loss Current: 7.2426, Validation Loss AVG: 7.2426, lr: 0.001
Epoch [13/80], Training Loss: 6.0266, Validation Loss Current: 7.1752, Validation Loss AVG: 7.1752, lr: 0.001
Epoch [14/80], Training Loss: 8.9244, Validation Loss Current: 6.7209, Validation Loss AVG: 6.7209, lr: 0.001
Epoch [15/80], Training Loss: 7.0118, Validation Loss Current: 7.4832, Validation Loss AVG: 7.4832, lr: 0.001
Epoch [16/80], Training Loss: 6.9700, Validation Loss Current: 7.1523, Validation Loss AVG: 7.1523, lr: 0.001
Epoch [17/80], Training Loss: 7.0558, Validation Loss Current: 6.8147, Validation Loss AVG: 6.8147, lr: 0.001
Epoch [18/80], Training Loss: 4.9779, Validation Loss Current: 6.6123, Validation Loss AVG: 6.6123, lr: 0.001
Epoch [19/80], Training Loss: 7.1606, Validation Loss Current: 8.3846, Validation Loss AVG: 8.3846, lr: 0.001
Epoch [20/80], Training Loss: 9.0432, Validation Loss Current: 6.7351, Validation Loss AVG: 6.7351, lr: 0.001
Epoch [21/80], Training Loss: 6.7744, Validation Loss Current: 13.0930, Validation Loss AVG: 13.0930, lr: 0.001
Epoch [22/80], Training Loss: 13.3577, Validation Loss Current: 8.9193, Validation Loss AVG: 8.9193, lr: 0.001
Epoch [23/80], Training Loss: 5.6473, Validation Loss Current: 7.1715, Validation Loss AVG: 7.1715, lr: 0.001
Epoch [24/80], Training Loss: 4.4988, Validation Loss Current: 7.7354, Validation Loss AVG: 7.7354, lr: 0.001
Epoch [25/80], Training Loss: 5.2052, Validation Loss Current: 7.6372, Validation Loss AVG: 7.6372, lr: 0.001
Epoch [26/80], Training Loss: 4.6062, Validation Loss Current: 8.2702, Validation Loss AVG: 8.2702, lr: 0.001
Epoch [27/80], Training Loss: 6.1650, Validation Loss Current: 11.2816, Validation Loss AVG: 11.2816, lr: 0.001
Epoch [28/80], Training Loss: 7.6074, Validation Loss Current: 10.2726, Validation Loss AVG: 10.2726, lr: 0.001
Epoch [29/80], Training Loss: 7.8615, Validation Loss Current: 7.9101, Validation Loss AVG: 7.9101, lr: 0.001
Epoch [30/80], Training Loss: 4.2178, Validation Loss Current: 8.6272, Validation Loss AVG: 8.6272, lr: 0.001
Epoch [31/80], Training Loss: 3.3080, Validation Loss Current: 7.0478, Validation Loss AVG: 7.0478, lr: 0.001
Epoch [32/80], Training Loss: 5.8033, Validation Loss Current: 7.4337, Validation Loss AVG: 7.4337, lr: 0.001
Epoch [33/80], Training Loss: 3.7065, Validation Loss Current: 7.4356, Validation Loss AVG: 7.4356, lr: 0.001
Epoch [34/80], Training Loss: 2.5533, Validation Loss Current: 7.3123, Validation Loss AVG: 7.3123, lr: 0.001
Epoch [35/80], Training Loss: 1.2432, Validation Loss Current: 7.7243, Validation Loss AVG: 7.7243, lr: 0.001
Epoch [36/80], Training Loss: 2.8065, Validation Loss Current: 7.1032, Validation Loss AVG: 7.1032, lr: 0.001
Epoch [37/80], Training Loss: 3.5799, Validation Loss Current: 9.6712, Validation Loss AVG: 9.6712, lr: 0.001
Epoch [38/80], Training Loss: 7.4677, Validation Loss Current: 7.4811, Validation Loss AVG: 7.4811, lr: 0.001
Epoch [39/80], Training Loss: 4.1823, Validation Loss Current: 8.7841, Validation Loss AVG: 8.7841, lr: 0.001
Epoch [40/80], Training Loss: 2.7592, Validation Loss Current: 7.2709, Validation Loss AVG: 7.2709, lr: 0.001
Epoch [41/80], Training Loss: 3.1192, Validation Loss Current: 7.6724, Validation Loss AVG: 7.6724, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random1 finished training. Best epoch: 11 Best val accuracy: [0.525657894736842, 0.6072368421052632, 0.5496710526315789, 0.5552631578947369, 0.6049342105263158, 0.5710526315789474, 0.5082236842105263, 0.47368421052631576, 0.5575657894736843, 0.5789473684210527, 0.6197368421052631, 0.5878289473684211, 0.5667763157894736, 0.5884868421052631, 0.5720394736842105, 0.5875, 0.6078947368421053, 0.6236842105263157, 0.5608552631578947, 0.6210526315789473, 0.4338815789473684, 0.48157894736842105, 0.5881578947368421, 0.5789473684210525, 0.5759868421052632, 0.5641447368421052, 0.49868421052631573, 0.5480263157894738, 0.5789473684210527, 0.5851973684210525, 0.5976973684210527, 0.6118421052631579, 0.6016447368421053, 0.6243421052631579, 0.6111842105263158, 0.6190789473684211, 0.5305921052631579, 0.6039473684210527, 0.5848684210526316, 0.6032894736842105, 0.6141447368421052] Best val loss: 6.0282257437706


Current group: llo_0.2_random2
Epoch [1/80], Training Loss: 33.2473, Validation Loss Current: 8.0147, Validation Loss AVG: 8.0147, lr: 0.001
Epoch [2/80], Training Loss: 23.4974, Validation Loss Current: 6.5876, Validation Loss AVG: 6.5876, lr: 0.001
Epoch [3/80], Training Loss: 15.8724, Validation Loss Current: 7.0958, Validation Loss AVG: 7.0958, lr: 0.001
Epoch [4/80], Training Loss: 13.4585, Validation Loss Current: 5.9053, Validation Loss AVG: 5.9053, lr: 0.001
Epoch [5/80], Training Loss: 11.3529, Validation Loss Current: 5.5633, Validation Loss AVG: 5.5633, lr: 0.001
Epoch [6/80], Training Loss: 9.1139, Validation Loss Current: 5.5738, Validation Loss AVG: 5.5738, lr: 0.001
Epoch [7/80], Training Loss: 7.0450, Validation Loss Current: 5.6141, Validation Loss AVG: 5.6141, lr: 0.001
Epoch [8/80], Training Loss: 4.9491, Validation Loss Current: 5.7075, Validation Loss AVG: 5.7075, lr: 0.001
Epoch [9/80], Training Loss: 3.4072, Validation Loss Current: 5.6243, Validation Loss AVG: 5.6243, lr: 0.001
Epoch [10/80], Training Loss: 3.7821, Validation Loss Current: 5.7593, Validation Loss AVG: 5.7593, lr: 0.001
Epoch [11/80], Training Loss: 2.6861, Validation Loss Current: 5.4057, Validation Loss AVG: 5.4057, lr: 0.001
Epoch [12/80], Training Loss: 2.1189, Validation Loss Current: 5.3538, Validation Loss AVG: 5.3538, lr: 0.001
Epoch [13/80], Training Loss: 4.3859, Validation Loss Current: 5.6105, Validation Loss AVG: 5.6105, lr: 0.001
Epoch [14/80], Training Loss: 3.0882, Validation Loss Current: 6.7026, Validation Loss AVG: 6.7026, lr: 0.001
Epoch [15/80], Training Loss: 3.8236, Validation Loss Current: 8.1305, Validation Loss AVG: 8.1305, lr: 0.001
Epoch [16/80], Training Loss: 3.2293, Validation Loss Current: 5.8733, Validation Loss AVG: 5.8733, lr: 0.001
Epoch [17/80], Training Loss: 6.0181, Validation Loss Current: 12.0505, Validation Loss AVG: 12.0505, lr: 0.001
Epoch [18/80], Training Loss: 12.4069, Validation Loss Current: 7.6414, Validation Loss AVG: 7.6414, lr: 0.001
Epoch [19/80], Training Loss: 6.6681, Validation Loss Current: 7.7346, Validation Loss AVG: 7.7346, lr: 0.001
Epoch [20/80], Training Loss: 5.6570, Validation Loss Current: 8.1293, Validation Loss AVG: 8.1293, lr: 0.001
Epoch [21/80], Training Loss: 6.1734, Validation Loss Current: 8.3552, Validation Loss AVG: 8.3552, lr: 0.001
Epoch [22/80], Training Loss: 6.8766, Validation Loss Current: 7.3402, Validation Loss AVG: 7.3402, lr: 0.001
Epoch [23/80], Training Loss: 5.5010, Validation Loss Current: 7.3755, Validation Loss AVG: 7.3755, lr: 0.001
Epoch [24/80], Training Loss: 3.6832, Validation Loss Current: 8.2193, Validation Loss AVG: 8.2193, lr: 0.001
Epoch [25/80], Training Loss: 7.0636, Validation Loss Current: 9.9468, Validation Loss AVG: 9.9468, lr: 0.001
Epoch [26/80], Training Loss: 4.9825, Validation Loss Current: 7.1691, Validation Loss AVG: 7.1691, lr: 0.001
Epoch [27/80], Training Loss: 3.4814, Validation Loss Current: 6.9990, Validation Loss AVG: 6.9990, lr: 0.001
Epoch [28/80], Training Loss: 3.5423, Validation Loss Current: 6.7696, Validation Loss AVG: 6.7696, lr: 0.001
Epoch [29/80], Training Loss: 2.1024, Validation Loss Current: 6.6873, Validation Loss AVG: 6.6873, lr: 0.001
Epoch [30/80], Training Loss: 1.9582, Validation Loss Current: 6.4337, Validation Loss AVG: 6.4337, lr: 0.001
Epoch [31/80], Training Loss: 3.4568, Validation Loss Current: 6.8796, Validation Loss AVG: 6.8796, lr: 0.001
Epoch [32/80], Training Loss: 2.2511, Validation Loss Current: 7.0286, Validation Loss AVG: 7.0286, lr: 0.001
Epoch [33/80], Training Loss: 0.9293, Validation Loss Current: 6.8861, Validation Loss AVG: 6.8861, lr: 0.001
Epoch [34/80], Training Loss: 1.9156, Validation Loss Current: 7.1205, Validation Loss AVG: 7.1205, lr: 0.001
Epoch [35/80], Training Loss: 3.8977, Validation Loss Current: 7.1063, Validation Loss AVG: 7.1063, lr: 0.001
Epoch [36/80], Training Loss: 3.7898, Validation Loss Current: 10.8009, Validation Loss AVG: 10.8009, lr: 0.001
Epoch [37/80], Training Loss: 1.7522, Validation Loss Current: 6.6351, Validation Loss AVG: 6.6351, lr: 0.001
Epoch [38/80], Training Loss: 1.9540, Validation Loss Current: 7.2735, Validation Loss AVG: 7.2735, lr: 0.001
Epoch [39/80], Training Loss: 2.5892, Validation Loss Current: 6.9282, Validation Loss AVG: 6.9282, lr: 0.001
Epoch [40/80], Training Loss: 5.2649, Validation Loss Current: 6.5472, Validation Loss AVG: 6.5472, lr: 0.001
Epoch [41/80], Training Loss: 2.0377, Validation Loss Current: 7.4889, Validation Loss AVG: 7.4889, lr: 0.001
Epoch [42/80], Training Loss: 3.9979, Validation Loss Current: 6.9604, Validation Loss AVG: 6.9604, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random2 finished training. Best epoch: 12 Best val accuracy: [0.5358552631578947, 0.5973684210526315, 0.5809210526315789, 0.6213815789473685, 0.6588815789473685, 0.6575657894736842, 0.6506578947368421, 0.6539473684210526, 0.6463815789473684, 0.6710526315789473, 0.6710526315789475, 0.6730263157894736, 0.6480263157894737, 0.6391447368421052, 0.6279605263157894, 0.6601973684210527, 0.4861842105263158, 0.6078947368421053, 0.5858552631578947, 0.5993421052631579, 0.5917763157894738, 0.5917763157894738, 0.5911184210526316, 0.5447368421052632, 0.5585526315789474, 0.6207236842105264, 0.6473684210526316, 0.6509868421052631, 0.638157894736842, 0.6486842105263158, 0.6375, 0.6407894736842106, 0.6378289473684211, 0.6434210526315789, 0.6328947368421053, 0.5457236842105264, 0.6463815789473684, 0.6493421052631578, 0.6401315789473684, 0.6536184210526316, 0.6299342105263157, 0.649671052631579] Best val loss: 5.353782743215561


Current group: llo_0.2_random3
Epoch [1/80], Training Loss: 35.0649, Validation Loss Current: 7.8976, Validation Loss AVG: 7.8976, lr: 0.001
Epoch [2/80], Training Loss: 21.8078, Validation Loss Current: 5.4869, Validation Loss AVG: 5.4869, lr: 0.001
Epoch [3/80], Training Loss: 12.1002, Validation Loss Current: 5.4056, Validation Loss AVG: 5.4056, lr: 0.001
Epoch [4/80], Training Loss: 11.9567, Validation Loss Current: 6.0558, Validation Loss AVG: 6.0558, lr: 0.001
Epoch [5/80], Training Loss: 8.5713, Validation Loss Current: 5.5478, Validation Loss AVG: 5.5478, lr: 0.001
Epoch [6/80], Training Loss: 7.2930, Validation Loss Current: 5.4917, Validation Loss AVG: 5.4917, lr: 0.001
Epoch [7/80], Training Loss: 6.3540, Validation Loss Current: 6.1986, Validation Loss AVG: 6.1986, lr: 0.001
Epoch [8/80], Training Loss: 5.9749, Validation Loss Current: 7.0533, Validation Loss AVG: 7.0533, lr: 0.001
Epoch [9/80], Training Loss: 6.0788, Validation Loss Current: 5.5797, Validation Loss AVG: 5.5797, lr: 0.001
Epoch [10/80], Training Loss: 7.0443, Validation Loss Current: 5.6121, Validation Loss AVG: 5.6121, lr: 0.001
Epoch [11/80], Training Loss: 7.0417, Validation Loss Current: 6.8197, Validation Loss AVG: 6.8197, lr: 0.001
Epoch [12/80], Training Loss: 6.7680, Validation Loss Current: 6.1927, Validation Loss AVG: 6.1927, lr: 0.001
Epoch [13/80], Training Loss: 3.2435, Validation Loss Current: 5.8039, Validation Loss AVG: 5.8039, lr: 0.001
Epoch [14/80], Training Loss: 3.1793, Validation Loss Current: 6.1284, Validation Loss AVG: 6.1284, lr: 0.001
Epoch [15/80], Training Loss: 2.0230, Validation Loss Current: 6.3497, Validation Loss AVG: 6.3497, lr: 0.001
Epoch [16/80], Training Loss: 3.2072, Validation Loss Current: 5.7665, Validation Loss AVG: 5.7665, lr: 0.001
Epoch [17/80], Training Loss: 4.1450, Validation Loss Current: 7.6726, Validation Loss AVG: 7.6726, lr: 0.001
Epoch [18/80], Training Loss: 8.6322, Validation Loss Current: 7.7116, Validation Loss AVG: 7.7116, lr: 0.001
Epoch [19/80], Training Loss: 8.0637, Validation Loss Current: 6.1448, Validation Loss AVG: 6.1448, lr: 0.001
Epoch [20/80], Training Loss: 2.5383, Validation Loss Current: 5.7695, Validation Loss AVG: 5.7695, lr: 0.001
Epoch [21/80], Training Loss: 1.4707, Validation Loss Current: 5.6756, Validation Loss AVG: 5.6756, lr: 0.001
Epoch [22/80], Training Loss: 1.5626, Validation Loss Current: 5.5423, Validation Loss AVG: 5.5423, lr: 0.001
Epoch [23/80], Training Loss: 4.1557, Validation Loss Current: 5.9958, Validation Loss AVG: 5.9958, lr: 0.001
Epoch [24/80], Training Loss: 2.7734, Validation Loss Current: 6.4176, Validation Loss AVG: 6.4176, lr: 0.001
Epoch [25/80], Training Loss: 2.4907, Validation Loss Current: 6.5159, Validation Loss AVG: 6.5159, lr: 0.001
Epoch [26/80], Training Loss: 5.0519, Validation Loss Current: 8.5171, Validation Loss AVG: 8.5171, lr: 0.001
Epoch [27/80], Training Loss: 3.3132, Validation Loss Current: 7.0980, Validation Loss AVG: 7.0980, lr: 0.001
Epoch [28/80], Training Loss: 2.6384, Validation Loss Current: 6.9364, Validation Loss AVG: 6.9364, lr: 0.001
Epoch [29/80], Training Loss: 2.6114, Validation Loss Current: 6.7655, Validation Loss AVG: 6.7655, lr: 0.001
Epoch [30/80], Training Loss: 2.1251, Validation Loss Current: 6.5654, Validation Loss AVG: 6.5654, lr: 0.001
Epoch [31/80], Training Loss: 4.9340, Validation Loss Current: 7.8385, Validation Loss AVG: 7.8385, lr: 0.001
Epoch [32/80], Training Loss: 7.9266, Validation Loss Current: 6.5776, Validation Loss AVG: 6.5776, lr: 0.001
Epoch [33/80], Training Loss: 5.5554, Validation Loss Current: 6.4624, Validation Loss AVG: 6.4624, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random3 finished training. Best epoch: 3 Best val accuracy: [0.6328947368421053, 0.6769736842105264, 0.66875, 0.6625, 0.6842105263157895, 0.6730263157894737, 0.6667763157894737, 0.6634868421052631, 0.6792763157894737, 0.6621710526315789, 0.6407894736842105, 0.662828947368421, 0.687171052631579, 0.6657894736842105, 0.6782894736842107, 0.6822368421052631, 0.6519736842105264, 0.6296052631578948, 0.6654605263157894, 0.6657894736842105, 0.6838815789473685, 0.6828947368421053, 0.6756578947368421, 0.6490131578947368, 0.6401315789473684, 0.6240131578947368, 0.6562499999999999, 0.6680921052631579, 0.662828947368421, 0.6601973684210527, 0.6355263157894737, 0.6414473684210527, 0.6536184210526316] Best val loss: 5.405563306808472


Current group: 0.2
Epoch [1/80], Training Loss: 49.3623, Validation Loss Current: 22.4344, Validation Loss AVG: 22.4344, lr: 0.001
Epoch [2/80], Training Loss: 28.6760, Validation Loss Current: 17.2368, Validation Loss AVG: 17.2368, lr: 0.001
Epoch [3/80], Training Loss: 22.1688, Validation Loss Current: 13.6447, Validation Loss AVG: 13.6447, lr: 0.001
Epoch [4/80], Training Loss: 18.6813, Validation Loss Current: 11.7571, Validation Loss AVG: 11.7571, lr: 0.001
Epoch [5/80], Training Loss: 13.7528, Validation Loss Current: 9.9074, Validation Loss AVG: 9.9074, lr: 0.001
Epoch [6/80], Training Loss: 12.2275, Validation Loss Current: 12.0350, Validation Loss AVG: 12.0350, lr: 0.001
Epoch [7/80], Training Loss: 10.0316, Validation Loss Current: 15.3872, Validation Loss AVG: 15.3872, lr: 0.001
Epoch [8/80], Training Loss: 6.9610, Validation Loss Current: 12.7282, Validation Loss AVG: 12.7282, lr: 0.001
Epoch [9/80], Training Loss: 7.2601, Validation Loss Current: 17.0647, Validation Loss AVG: 17.0647, lr: 0.001
Epoch [10/80], Training Loss: 6.1983, Validation Loss Current: 12.4889, Validation Loss AVG: 12.4889, lr: 0.001
Epoch [11/80], Training Loss: 5.0633, Validation Loss Current: 15.5846, Validation Loss AVG: 15.5846, lr: 0.001
Epoch [12/80], Training Loss: 7.0237, Validation Loss Current: 13.4565, Validation Loss AVG: 13.4565, lr: 0.001
Epoch [13/80], Training Loss: 6.0596, Validation Loss Current: 15.7720, Validation Loss AVG: 15.7720, lr: 0.001
Epoch [14/80], Training Loss: 3.7792, Validation Loss Current: 16.0187, Validation Loss AVG: 16.0187, lr: 0.001
Epoch [15/80], Training Loss: 3.7779, Validation Loss Current: 13.1518, Validation Loss AVG: 13.1518, lr: 0.001
Epoch [16/80], Training Loss: 6.2173, Validation Loss Current: 17.4876, Validation Loss AVG: 17.4876, lr: 0.001
Epoch [17/80], Training Loss: 7.1209, Validation Loss Current: 19.8072, Validation Loss AVG: 19.8072, lr: 0.001
Epoch [18/80], Training Loss: 6.8016, Validation Loss Current: 21.1446, Validation Loss AVG: 21.1446, lr: 0.001
Epoch [19/80], Training Loss: 3.2053, Validation Loss Current: 14.7186, Validation Loss AVG: 14.7186, lr: 0.001
Epoch [20/80], Training Loss: 1.1313, Validation Loss Current: 14.5470, Validation Loss AVG: 14.5470, lr: 0.001
Epoch [21/80], Training Loss: 1.3360, Validation Loss Current: 17.9850, Validation Loss AVG: 17.9850, lr: 0.001
Epoch [22/80], Training Loss: 6.8645, Validation Loss Current: 18.4089, Validation Loss AVG: 18.4089, lr: 0.001
Epoch [23/80], Training Loss: 8.8485, Validation Loss Current: 22.0530, Validation Loss AVG: 22.0530, lr: 0.001
Epoch [24/80], Training Loss: 10.4265, Validation Loss Current: 23.4807, Validation Loss AVG: 23.4807, lr: 0.001
Epoch [25/80], Training Loss: 8.3491, Validation Loss Current: 19.0993, Validation Loss AVG: 19.0993, lr: 0.001
Epoch [26/80], Training Loss: 7.8545, Validation Loss Current: 20.3773, Validation Loss AVG: 20.3773, lr: 0.001
Epoch [27/80], Training Loss: 5.4012, Validation Loss Current: 20.5039, Validation Loss AVG: 20.5039, lr: 0.001
Epoch [28/80], Training Loss: 6.2940, Validation Loss Current: 19.2757, Validation Loss AVG: 19.2757, lr: 0.001
Epoch [29/80], Training Loss: 10.0792, Validation Loss Current: 22.8125, Validation Loss AVG: 22.8125, lr: 0.001
Epoch [30/80], Training Loss: 6.4037, Validation Loss Current: 19.2248, Validation Loss AVG: 19.2248, lr: 0.001
Epoch [31/80], Training Loss: 4.5184, Validation Loss Current: 20.6062, Validation Loss AVG: 20.6062, lr: 0.001
Epoch [32/80], Training Loss: 1.8454, Validation Loss Current: 17.2300, Validation Loss AVG: 17.2300, lr: 0.001
Epoch [33/80], Training Loss: 0.8805, Validation Loss Current: 16.4511, Validation Loss AVG: 16.4511, lr: 0.001
Epoch [34/80], Training Loss: 0.7347, Validation Loss Current: 17.0235, Validation Loss AVG: 17.0235, lr: 0.001
Epoch [35/80], Training Loss: 1.3025, Validation Loss Current: 17.1676, Validation Loss AVG: 17.1676, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 5 Best val accuracy: [0.30394736842105263, 0.2934210526315789, 0.3838815789473684, 0.43322368421052626, 0.4720394736842105, 0.40230263157894736, 0.30723684210526314, 0.3973684210526316, 0.36907894736842106, 0.44506578947368425, 0.37664473684210525, 0.41217105263157894, 0.3460526315789474, 0.42302631578947364, 0.4384868421052632, 0.37236842105263157, 0.3361842105263158, 0.39342105263157895, 0.41776315789473684, 0.4447368421052632, 0.35230263157894737, 0.4128289473684211, 0.2970394736842105, 0.2914473684210526, 0.34111842105263157, 0.35230263157894737, 0.3848684210526316, 0.31447368421052635, 0.3766447368421053, 0.32171052631578945, 0.3740131578947368, 0.3917763157894737, 0.39539473684210524, 0.39342105263157895, 0.38717105263157897] Best val loss: 9.907396483421326


----- Training resnet18 with sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] -----
Current group: llo_0.8_random0
Epoch [1/80], Training Loss: 40.2984, Validation Loss Current: 10.0906, Validation Loss AVG: 10.0906, lr: 0.001
Epoch [2/80], Training Loss: 39.7446, Validation Loss Current: 10.0014, Validation Loss AVG: 10.0014, lr: 0.001
Epoch [3/80], Training Loss: 39.2095, Validation Loss Current: 9.7520, Validation Loss AVG: 9.7520, lr: 0.001
Epoch [4/80], Training Loss: 38.1928, Validation Loss Current: 9.4753, Validation Loss AVG: 9.4753, lr: 0.001
Epoch [5/80], Training Loss: 37.4124, Validation Loss Current: 9.3777, Validation Loss AVG: 9.3777, lr: 0.001
Epoch [6/80], Training Loss: 36.1862, Validation Loss Current: 9.0537, Validation Loss AVG: 9.0537, lr: 0.001
Epoch [7/80], Training Loss: 36.2386, Validation Loss Current: 8.8876, Validation Loss AVG: 8.8876, lr: 0.001
Epoch [8/80], Training Loss: 35.1466, Validation Loss Current: 8.8155, Validation Loss AVG: 8.8155, lr: 0.001
Epoch [9/80], Training Loss: 34.1623, Validation Loss Current: 8.7380, Validation Loss AVG: 8.7380, lr: 0.001
Epoch [10/80], Training Loss: 33.0234, Validation Loss Current: 8.4005, Validation Loss AVG: 8.4005, lr: 0.001
Epoch [11/80], Training Loss: 32.0054, Validation Loss Current: 8.2962, Validation Loss AVG: 8.2962, lr: 0.001
Epoch [12/80], Training Loss: 31.7430, Validation Loss Current: 8.2829, Validation Loss AVG: 8.2829, lr: 0.001
Epoch [13/80], Training Loss: 31.2577, Validation Loss Current: 7.9102, Validation Loss AVG: 7.9102, lr: 0.001
Epoch [14/80], Training Loss: 29.1340, Validation Loss Current: 7.8367, Validation Loss AVG: 7.8367, lr: 0.001
Epoch [15/80], Training Loss: 29.4888, Validation Loss Current: 7.8327, Validation Loss AVG: 7.8327, lr: 0.001
Epoch [16/80], Training Loss: 28.4413, Validation Loss Current: 7.7211, Validation Loss AVG: 7.7211, lr: 0.001
Epoch [17/80], Training Loss: 28.4720, Validation Loss Current: 7.6796, Validation Loss AVG: 7.6796, lr: 0.001
Epoch [18/80], Training Loss: 27.5921, Validation Loss Current: 8.0318, Validation Loss AVG: 8.0318, lr: 0.001
Epoch [19/80], Training Loss: 26.8691, Validation Loss Current: 14.2721, Validation Loss AVG: 14.2721, lr: 0.001
Epoch [20/80], Training Loss: 30.0004, Validation Loss Current: 9.3463, Validation Loss AVG: 9.3463, lr: 0.001
Epoch [21/80], Training Loss: 28.3650, Validation Loss Current: 8.2771, Validation Loss AVG: 8.2771, lr: 0.001
Epoch [22/80], Training Loss: 28.8488, Validation Loss Current: 8.0099, Validation Loss AVG: 8.0099, lr: 0.001
Epoch [23/80], Training Loss: 24.9616, Validation Loss Current: 7.6410, Validation Loss AVG: 7.6410, lr: 0.001
Epoch [24/80], Training Loss: 24.5257, Validation Loss Current: 7.1994, Validation Loss AVG: 7.1994, lr: 0.001
Epoch [25/80], Training Loss: 24.1774, Validation Loss Current: 8.2382, Validation Loss AVG: 8.2382, lr: 0.001
Epoch [26/80], Training Loss: 23.4025, Validation Loss Current: 7.0463, Validation Loss AVG: 7.0463, lr: 0.001
Epoch [27/80], Training Loss: 22.3300, Validation Loss Current: 7.6156, Validation Loss AVG: 7.6156, lr: 0.001
Epoch [28/80], Training Loss: 22.4548, Validation Loss Current: 6.8824, Validation Loss AVG: 6.8824, lr: 0.001
Epoch [29/80], Training Loss: 19.6915, Validation Loss Current: 7.1153, Validation Loss AVG: 7.1153, lr: 0.001
Epoch [30/80], Training Loss: 18.5851, Validation Loss Current: 6.6201, Validation Loss AVG: 6.6201, lr: 0.001
Epoch [31/80], Training Loss: 19.6591, Validation Loss Current: 6.7429, Validation Loss AVG: 6.7429, lr: 0.001
Epoch [32/80], Training Loss: 18.6947, Validation Loss Current: 6.8373, Validation Loss AVG: 6.8373, lr: 0.001
Epoch [33/80], Training Loss: 17.7340, Validation Loss Current: 9.2375, Validation Loss AVG: 9.2375, lr: 0.001
Epoch [34/80], Training Loss: 17.6488, Validation Loss Current: 6.9838, Validation Loss AVG: 6.9838, lr: 0.001
Epoch [35/80], Training Loss: 14.7000, Validation Loss Current: 7.1113, Validation Loss AVG: 7.1113, lr: 0.001
Epoch [36/80], Training Loss: 13.8210, Validation Loss Current: 8.4386, Validation Loss AVG: 8.4386, lr: 0.001
Epoch [37/80], Training Loss: 14.6039, Validation Loss Current: 6.9569, Validation Loss AVG: 6.9569, lr: 0.001
Epoch [38/80], Training Loss: 12.7058, Validation Loss Current: 11.2737, Validation Loss AVG: 11.2737, lr: 0.001
Epoch [39/80], Training Loss: 18.6587, Validation Loss Current: 7.5787, Validation Loss AVG: 7.5787, lr: 0.001
Epoch [40/80], Training Loss: 15.3510, Validation Loss Current: 7.5352, Validation Loss AVG: 7.5352, lr: 0.001
Epoch [41/80], Training Loss: 13.5649, Validation Loss Current: 7.6868, Validation Loss AVG: 7.6868, lr: 0.001
Epoch [42/80], Training Loss: 11.9329, Validation Loss Current: 7.0707, Validation Loss AVG: 7.0707, lr: 0.001
Epoch [43/80], Training Loss: 10.3577, Validation Loss Current: 7.3429, Validation Loss AVG: 7.3429, lr: 0.001
Epoch [44/80], Training Loss: 10.7009, Validation Loss Current: 7.0412, Validation Loss AVG: 7.0412, lr: 0.001
Epoch [45/80], Training Loss: 10.7678, Validation Loss Current: 7.6062, Validation Loss AVG: 7.6062, lr: 0.001
Epoch [46/80], Training Loss: 11.2045, Validation Loss Current: 6.8132, Validation Loss AVG: 6.8132, lr: 0.001
Epoch [47/80], Training Loss: 12.1726, Validation Loss Current: 7.9693, Validation Loss AVG: 7.9693, lr: 0.001
Epoch [48/80], Training Loss: 8.9923, Validation Loss Current: 7.6988, Validation Loss AVG: 7.6988, lr: 0.001
Epoch [49/80], Training Loss: 8.3112, Validation Loss Current: 7.1212, Validation Loss AVG: 7.1212, lr: 0.001
Epoch [50/80], Training Loss: 8.0814, Validation Loss Current: 7.5227, Validation Loss AVG: 7.5227, lr: 0.001
Epoch [51/80], Training Loss: 7.2385, Validation Loss Current: 7.6488, Validation Loss AVG: 7.6488, lr: 0.001
Epoch [52/80], Training Loss: 5.3973, Validation Loss Current: 7.9561, Validation Loss AVG: 7.9561, lr: 0.001
Epoch [53/80], Training Loss: 8.0325, Validation Loss Current: 8.9958, Validation Loss AVG: 8.9958, lr: 0.001
Epoch [54/80], Training Loss: 10.5427, Validation Loss Current: 10.9066, Validation Loss AVG: 10.9066, lr: 0.001
Epoch [55/80], Training Loss: 8.6998, Validation Loss Current: 8.1131, Validation Loss AVG: 8.1131, lr: 0.001
Epoch [56/80], Training Loss: 8.3985, Validation Loss Current: 7.7432, Validation Loss AVG: 7.7432, lr: 0.001
Epoch [57/80], Training Loss: 6.8472, Validation Loss Current: 7.8845, Validation Loss AVG: 7.8845, lr: 0.001
Epoch [58/80], Training Loss: 6.0903, Validation Loss Current: 7.3563, Validation Loss AVG: 7.3563, lr: 0.001
Epoch [59/80], Training Loss: 6.9257, Validation Loss Current: 7.4324, Validation Loss AVG: 7.4324, lr: 0.001
Epoch [60/80], Training Loss: 7.8591, Validation Loss Current: 8.2436, Validation Loss AVG: 8.2436, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random0 finished training. Best epoch: 30 Best val accuracy: [0.22598684210526315, 0.23289473684210527, 0.2894736842105263, 0.2986842105263158, 0.2986842105263158, 0.3450657894736842, 0.35625, 0.3592105263157895, 0.3611842105263158, 0.41019736842105264, 0.40493421052631584, 0.40032894736842106, 0.4453947368421053, 0.44013157894736843, 0.45625, 0.4444078947368421, 0.4421052631578948, 0.4476973684210527, 0.23157894736842102, 0.3476973684210526, 0.4217105263157895, 0.4269736842105264, 0.4677631578947368, 0.4842105263157895, 0.44506578947368414, 0.5052631578947369, 0.48157894736842105, 0.5108552631578946, 0.5078947368421052, 0.5374999999999999, 0.5253289473684211, 0.5273026315789474, 0.44572368421052627, 0.5243421052631579, 0.5279605263157895, 0.48355263157894746, 0.5358552631578948, 0.42269736842105265, 0.4776315789473684, 0.49802631578947365, 0.5223684210526316, 0.5463815789473684, 0.5513157894736842, 0.5503289473684212, 0.5240131578947368, 0.5921052631578948, 0.5319078947368421, 0.5115131578947368, 0.5700657894736842, 0.5746710526315789, 0.56875, 0.5276315789473685, 0.5, 0.4832236842105263, 0.5338815789473684, 0.5305921052631579, 0.525, 0.587171052631579, 0.5726973684210527, 0.5358552631578947] Best val loss: 6.620144724845886


Current group: llo_0.8_random1
Epoch [1/80], Training Loss: 33.1680, Validation Loss Current: 7.4639, Validation Loss AVG: 7.4639, lr: 0.001
Epoch [2/80], Training Loss: 26.1402, Validation Loss Current: 13.3122, Validation Loss AVG: 13.3122, lr: 0.001
Epoch [3/80], Training Loss: 22.2734, Validation Loss Current: 7.1223, Validation Loss AVG: 7.1223, lr: 0.001
Epoch [4/80], Training Loss: 19.5711, Validation Loss Current: 7.6651, Validation Loss AVG: 7.6651, lr: 0.001
Epoch [5/80], Training Loss: 16.0175, Validation Loss Current: 6.9699, Validation Loss AVG: 6.9699, lr: 0.001
Epoch [6/80], Training Loss: 13.4554, Validation Loss Current: 7.0183, Validation Loss AVG: 7.0183, lr: 0.001
Epoch [7/80], Training Loss: 10.7255, Validation Loss Current: 8.2280, Validation Loss AVG: 8.2280, lr: 0.001
Epoch [8/80], Training Loss: 11.4076, Validation Loss Current: 6.2005, Validation Loss AVG: 6.2005, lr: 0.001
Epoch [9/80], Training Loss: 11.5238, Validation Loss Current: 8.9370, Validation Loss AVG: 8.9370, lr: 0.001
Epoch [10/80], Training Loss: 11.7753, Validation Loss Current: 8.0217, Validation Loss AVG: 8.0217, lr: 0.001
Epoch [11/80], Training Loss: 7.6956, Validation Loss Current: 5.8481, Validation Loss AVG: 5.8481, lr: 0.001
Epoch [12/80], Training Loss: 6.4476, Validation Loss Current: 6.6791, Validation Loss AVG: 6.6791, lr: 0.001
Epoch [13/80], Training Loss: 8.9742, Validation Loss Current: 8.2445, Validation Loss AVG: 8.2445, lr: 0.001
Epoch [14/80], Training Loss: 14.2086, Validation Loss Current: 8.6856, Validation Loss AVG: 8.6856, lr: 0.001
Epoch [15/80], Training Loss: 16.3916, Validation Loss Current: 10.8645, Validation Loss AVG: 10.8645, lr: 0.001
Epoch [16/80], Training Loss: 14.1793, Validation Loss Current: 10.8997, Validation Loss AVG: 10.8997, lr: 0.001
Epoch [17/80], Training Loss: 11.6300, Validation Loss Current: 7.5799, Validation Loss AVG: 7.5799, lr: 0.001
Epoch [18/80], Training Loss: 6.6575, Validation Loss Current: 6.8050, Validation Loss AVG: 6.8050, lr: 0.001
Epoch [19/80], Training Loss: 5.8361, Validation Loss Current: 6.3755, Validation Loss AVG: 6.3755, lr: 0.001
Epoch [20/80], Training Loss: 6.8044, Validation Loss Current: 6.8116, Validation Loss AVG: 6.8116, lr: 0.001
Epoch [21/80], Training Loss: 9.3394, Validation Loss Current: 12.4474, Validation Loss AVG: 12.4474, lr: 0.001
Epoch [22/80], Training Loss: 8.3190, Validation Loss Current: 7.1006, Validation Loss AVG: 7.1006, lr: 0.001
Epoch [23/80], Training Loss: 5.1010, Validation Loss Current: 7.1629, Validation Loss AVG: 7.1629, lr: 0.001
Epoch [24/80], Training Loss: 4.8803, Validation Loss Current: 7.2846, Validation Loss AVG: 7.2846, lr: 0.001
Epoch [25/80], Training Loss: 6.6113, Validation Loss Current: 8.4187, Validation Loss AVG: 8.4187, lr: 0.001
Epoch [26/80], Training Loss: 7.6402, Validation Loss Current: 6.7767, Validation Loss AVG: 6.7767, lr: 0.001
Epoch [27/80], Training Loss: 5.5623, Validation Loss Current: 7.0831, Validation Loss AVG: 7.0831, lr: 0.001
Epoch [28/80], Training Loss: 4.7735, Validation Loss Current: 6.7110, Validation Loss AVG: 6.7110, lr: 0.001
Epoch [29/80], Training Loss: 5.4920, Validation Loss Current: 8.0592, Validation Loss AVG: 8.0592, lr: 0.001
Epoch [30/80], Training Loss: 4.3644, Validation Loss Current: 7.4351, Validation Loss AVG: 7.4351, lr: 0.001
Epoch [31/80], Training Loss: 5.0543, Validation Loss Current: 9.1083, Validation Loss AVG: 9.1083, lr: 0.001
Epoch [32/80], Training Loss: 6.2045, Validation Loss Current: 8.0992, Validation Loss AVG: 8.0992, lr: 0.001
Epoch [33/80], Training Loss: 4.3763, Validation Loss Current: 7.0612, Validation Loss AVG: 7.0612, lr: 0.001
Epoch [34/80], Training Loss: 4.2306, Validation Loss Current: 8.1430, Validation Loss AVG: 8.1430, lr: 0.001
Epoch [35/80], Training Loss: 4.6884, Validation Loss Current: 8.7396, Validation Loss AVG: 8.7396, lr: 0.001
Epoch [36/80], Training Loss: 4.2823, Validation Loss Current: 7.6119, Validation Loss AVG: 7.6119, lr: 0.001
Epoch [37/80], Training Loss: 2.6396, Validation Loss Current: 8.6162, Validation Loss AVG: 8.6162, lr: 0.001
Epoch [38/80], Training Loss: 6.2465, Validation Loss Current: 14.4262, Validation Loss AVG: 14.4262, lr: 0.001
Epoch [39/80], Training Loss: 4.2953, Validation Loss Current: 7.2652, Validation Loss AVG: 7.2652, lr: 0.001
Epoch [40/80], Training Loss: 3.9965, Validation Loss Current: 9.9843, Validation Loss AVG: 9.9843, lr: 0.001
Epoch [41/80], Training Loss: 4.1350, Validation Loss Current: 9.2775, Validation Loss AVG: 9.2775, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random1 finished training. Best epoch: 11 Best val accuracy: [0.53125, 0.3766447368421053, 0.5490131578947368, 0.5480263157894736, 0.5618421052631579, 0.5421052631578948, 0.5256578947368421, 0.6121710526315789, 0.55, 0.524671052631579, 0.65, 0.6138157894736842, 0.5276315789473685, 0.5121710526315789, 0.4654605263157895, 0.46743421052631573, 0.562171052631579, 0.6151315789473684, 0.6289473684210526, 0.6075657894736841, 0.4634868421052632, 0.6171052631578947, 0.5763157894736841, 0.6006578947368422, 0.5917763157894737, 0.5990131578947369, 0.6115131578947368, 0.6322368421052632, 0.5763157894736841, 0.6164473684210526, 0.562828947368421, 0.5542763157894737, 0.6233552631578948, 0.5944078947368421, 0.5523026315789473, 0.624671052631579, 0.5671052631578948, 0.49934210526315786, 0.6141447368421052, 0.5075657894736842, 0.5851973684210525] Best val loss: 5.848125374317169


Current group: llo_0.8_random2
Epoch [1/80], Training Loss: 35.1715, Validation Loss Current: 7.0288, Validation Loss AVG: 7.0288, lr: 0.001
Epoch [2/80], Training Loss: 22.4012, Validation Loss Current: 6.2460, Validation Loss AVG: 6.2460, lr: 0.001
Epoch [3/80], Training Loss: 20.9128, Validation Loss Current: 8.6537, Validation Loss AVG: 8.6537, lr: 0.001
Epoch [4/80], Training Loss: 22.4341, Validation Loss Current: 7.0001, Validation Loss AVG: 7.0001, lr: 0.001
Epoch [5/80], Training Loss: 15.4555, Validation Loss Current: 6.9865, Validation Loss AVG: 6.9865, lr: 0.001
Epoch [6/80], Training Loss: 15.9136, Validation Loss Current: 7.4401, Validation Loss AVG: 7.4401, lr: 0.001
Epoch [7/80], Training Loss: 15.9449, Validation Loss Current: 11.0276, Validation Loss AVG: 11.0276, lr: 0.001
Epoch [8/80], Training Loss: 13.4473, Validation Loss Current: 6.0577, Validation Loss AVG: 6.0577, lr: 0.001
Epoch [9/80], Training Loss: 10.0463, Validation Loss Current: 5.6513, Validation Loss AVG: 5.6513, lr: 0.001
Epoch [10/80], Training Loss: 10.8812, Validation Loss Current: 6.9634, Validation Loss AVG: 6.9634, lr: 0.001
Epoch [11/80], Training Loss: 8.1281, Validation Loss Current: 5.5068, Validation Loss AVG: 5.5068, lr: 0.001
Epoch [12/80], Training Loss: 6.7486, Validation Loss Current: 7.3402, Validation Loss AVG: 7.3402, lr: 0.001
Epoch [13/80], Training Loss: 8.9449, Validation Loss Current: 6.7674, Validation Loss AVG: 6.7674, lr: 0.001
Epoch [14/80], Training Loss: 8.4514, Validation Loss Current: 7.3623, Validation Loss AVG: 7.3623, lr: 0.001
Epoch [15/80], Training Loss: 5.4712, Validation Loss Current: 6.5668, Validation Loss AVG: 6.5668, lr: 0.001
Epoch [16/80], Training Loss: 4.9885, Validation Loss Current: 5.9980, Validation Loss AVG: 5.9980, lr: 0.001
Epoch [17/80], Training Loss: 7.1799, Validation Loss Current: 8.5182, Validation Loss AVG: 8.5182, lr: 0.001
Epoch [18/80], Training Loss: 11.0618, Validation Loss Current: 9.8840, Validation Loss AVG: 9.8840, lr: 0.001
Epoch [19/80], Training Loss: 11.2990, Validation Loss Current: 6.4846, Validation Loss AVG: 6.4846, lr: 0.001
Epoch [20/80], Training Loss: 6.6737, Validation Loss Current: 7.2415, Validation Loss AVG: 7.2415, lr: 0.001
Epoch [21/80], Training Loss: 5.5434, Validation Loss Current: 6.0596, Validation Loss AVG: 6.0596, lr: 0.001
Epoch [22/80], Training Loss: 3.8522, Validation Loss Current: 5.7601, Validation Loss AVG: 5.7601, lr: 0.001
Epoch [23/80], Training Loss: 4.3895, Validation Loss Current: 6.1796, Validation Loss AVG: 6.1796, lr: 0.001
Epoch [24/80], Training Loss: 3.4580, Validation Loss Current: 6.0912, Validation Loss AVG: 6.0912, lr: 0.001
Epoch [25/80], Training Loss: 4.6438, Validation Loss Current: 6.8474, Validation Loss AVG: 6.8474, lr: 0.001
Epoch [26/80], Training Loss: 4.0377, Validation Loss Current: 7.3021, Validation Loss AVG: 7.3021, lr: 0.001
Epoch [27/80], Training Loss: 4.8702, Validation Loss Current: 7.4352, Validation Loss AVG: 7.4352, lr: 0.001
Epoch [28/80], Training Loss: 3.3251, Validation Loss Current: 6.8241, Validation Loss AVG: 6.8241, lr: 0.001
Epoch [29/80], Training Loss: 2.6091, Validation Loss Current: 6.7812, Validation Loss AVG: 6.7812, lr: 0.001
Epoch [30/80], Training Loss: 1.6981, Validation Loss Current: 6.3751, Validation Loss AVG: 6.3751, lr: 0.001
Epoch [31/80], Training Loss: 1.7931, Validation Loss Current: 6.5150, Validation Loss AVG: 6.5150, lr: 0.001
Epoch [32/80], Training Loss: 2.4793, Validation Loss Current: 8.4071, Validation Loss AVG: 8.4071, lr: 0.001
Epoch [33/80], Training Loss: 1.9854, Validation Loss Current: 6.9365, Validation Loss AVG: 6.9365, lr: 0.001
Epoch [34/80], Training Loss: 1.1935, Validation Loss Current: 6.4466, Validation Loss AVG: 6.4466, lr: 0.001
Epoch [35/80], Training Loss: 2.0488, Validation Loss Current: 6.9511, Validation Loss AVG: 6.9511, lr: 0.001
Epoch [36/80], Training Loss: 4.6197, Validation Loss Current: 7.0968, Validation Loss AVG: 7.0968, lr: 0.001
Epoch [37/80], Training Loss: 2.8869, Validation Loss Current: 7.1522, Validation Loss AVG: 7.1522, lr: 0.001
Epoch [38/80], Training Loss: 1.8009, Validation Loss Current: 6.3407, Validation Loss AVG: 6.3407, lr: 0.001
Epoch [39/80], Training Loss: 2.2755, Validation Loss Current: 7.0798, Validation Loss AVG: 7.0798, lr: 0.001
Epoch [40/80], Training Loss: 5.7101, Validation Loss Current: 7.9244, Validation Loss AVG: 7.9244, lr: 0.001
Epoch [41/80], Training Loss: 3.1591, Validation Loss Current: 7.7520, Validation Loss AVG: 7.7520, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random2 finished training. Best epoch: 11 Best val accuracy: [0.6207236842105264, 0.6111842105263158, 0.5164473684210527, 0.5529605263157894, 0.594078947368421, 0.5667763157894736, 0.48519736842105265, 0.6075657894736841, 0.6463815789473684, 0.6042763157894736, 0.6546052631578948, 0.587171052631579, 0.6121710526315789, 0.5983552631578948, 0.6460526315789474, 0.6539473684210526, 0.6171052631578948, 0.4671052631578948, 0.64375, 0.5835526315789473, 0.6427631578947369, 0.6723684210526316, 0.6664473684210526, 0.6460526315789473, 0.6355263157894737, 0.6095394736842106, 0.649671052631579, 0.6460526315789472, 0.6365131578947368, 0.6786184210526316, 0.6769736842105264, 0.5930921052631579, 0.6740131578947369, 0.6796052631578947, 0.6779605263157895, 0.6582236842105262, 0.6447368421052632, 0.6799342105263158, 0.6404605263157894, 0.6200657894736843, 0.6207236842105264] Best val loss: 5.50683958530426


Current group: llo_0.8_random3
Epoch [1/80], Training Loss: 37.7077, Validation Loss Current: 7.1985, Validation Loss AVG: 7.1985, lr: 0.001
Epoch [2/80], Training Loss: 21.2759, Validation Loss Current: 5.6794, Validation Loss AVG: 5.6794, lr: 0.001
Epoch [3/80], Training Loss: 16.8125, Validation Loss Current: 5.1074, Validation Loss AVG: 5.1074, lr: 0.001
Epoch [4/80], Training Loss: 12.4221, Validation Loss Current: 6.3896, Validation Loss AVG: 6.3896, lr: 0.001
Epoch [5/80], Training Loss: 11.2182, Validation Loss Current: 4.8228, Validation Loss AVG: 4.8228, lr: 0.001
Epoch [6/80], Training Loss: 12.8408, Validation Loss Current: 10.3555, Validation Loss AVG: 10.3555, lr: 0.001
Epoch [7/80], Training Loss: 8.2946, Validation Loss Current: 5.0806, Validation Loss AVG: 5.0806, lr: 0.001
Epoch [8/80], Training Loss: 6.6870, Validation Loss Current: 5.2876, Validation Loss AVG: 5.2876, lr: 0.001
Epoch [9/80], Training Loss: 8.2221, Validation Loss Current: 7.3970, Validation Loss AVG: 7.3970, lr: 0.001
Epoch [10/80], Training Loss: 7.8042, Validation Loss Current: 6.3686, Validation Loss AVG: 6.3686, lr: 0.001
Epoch [11/80], Training Loss: 7.8202, Validation Loss Current: 8.1350, Validation Loss AVG: 8.1350, lr: 0.001
Epoch [12/80], Training Loss: 10.0580, Validation Loss Current: 10.2320, Validation Loss AVG: 10.2320, lr: 0.001
Epoch [13/80], Training Loss: 11.8590, Validation Loss Current: 8.8559, Validation Loss AVG: 8.8559, lr: 0.001
Epoch [14/80], Training Loss: 15.5778, Validation Loss Current: 9.2120, Validation Loss AVG: 9.2120, lr: 0.001
Epoch [15/80], Training Loss: 8.4024, Validation Loss Current: 5.8000, Validation Loss AVG: 5.8000, lr: 0.001
Epoch [16/80], Training Loss: 3.5015, Validation Loss Current: 5.2272, Validation Loss AVG: 5.2272, lr: 0.001
Epoch [17/80], Training Loss: 3.3618, Validation Loss Current: 5.0917, Validation Loss AVG: 5.0917, lr: 0.001
Epoch [18/80], Training Loss: 4.0563, Validation Loss Current: 6.4552, Validation Loss AVG: 6.4552, lr: 0.001
Epoch [19/80], Training Loss: 9.4881, Validation Loss Current: 8.6716, Validation Loss AVG: 8.6716, lr: 0.001
Epoch [20/80], Training Loss: 6.0464, Validation Loss Current: 9.8319, Validation Loss AVG: 9.8319, lr: 0.001
Epoch [21/80], Training Loss: 7.5309, Validation Loss Current: 7.7014, Validation Loss AVG: 7.7014, lr: 0.001
Epoch [22/80], Training Loss: 5.6424, Validation Loss Current: 6.3779, Validation Loss AVG: 6.3779, lr: 0.001
Epoch [23/80], Training Loss: 2.7429, Validation Loss Current: 5.2962, Validation Loss AVG: 5.2962, lr: 0.001
Epoch [24/80], Training Loss: 3.2437, Validation Loss Current: 5.7785, Validation Loss AVG: 5.7785, lr: 0.001
Epoch [25/80], Training Loss: 7.2767, Validation Loss Current: 6.9711, Validation Loss AVG: 6.9711, lr: 0.001
Epoch [26/80], Training Loss: 3.5734, Validation Loss Current: 6.1615, Validation Loss AVG: 6.1615, lr: 0.001
Epoch [27/80], Training Loss: 3.1344, Validation Loss Current: 5.8930, Validation Loss AVG: 5.8930, lr: 0.001
Epoch [28/80], Training Loss: 5.2970, Validation Loss Current: 7.4982, Validation Loss AVG: 7.4982, lr: 0.001
Epoch [29/80], Training Loss: 5.2418, Validation Loss Current: 6.4521, Validation Loss AVG: 6.4521, lr: 0.001
Epoch [30/80], Training Loss: 4.8701, Validation Loss Current: 5.5022, Validation Loss AVG: 5.5022, lr: 0.001
Epoch [31/80], Training Loss: 4.0017, Validation Loss Current: 7.4310, Validation Loss AVG: 7.4310, lr: 0.001
Epoch [32/80], Training Loss: 5.1758, Validation Loss Current: 9.4159, Validation Loss AVG: 9.4159, lr: 0.001
Epoch [33/80], Training Loss: 8.7666, Validation Loss Current: 11.3866, Validation Loss AVG: 11.3866, lr: 0.001
Epoch [34/80], Training Loss: 10.8934, Validation Loss Current: 9.4928, Validation Loss AVG: 9.4928, lr: 0.001
Epoch [35/80], Training Loss: 10.4115, Validation Loss Current: 10.0718, Validation Loss AVG: 10.0718, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random3 finished training. Best epoch: 5 Best val accuracy: [0.6019736842105263, 0.6332236842105263, 0.6868421052631579, 0.6421052631578947, 0.7115131578947369, 0.5292763157894738, 0.6875, 0.6851973684210526, 0.5957236842105262, 0.6223684210526315, 0.594078947368421, 0.5552631578947368, 0.49605263157894736, 0.5575657894736843, 0.6707236842105264, 0.6858552631578948, 0.6953947368421053, 0.6309210526315789, 0.5625, 0.531578947368421, 0.6032894736842105, 0.6588815789473684, 0.687171052631579, 0.6848684210526316, 0.6328947368421053, 0.6519736842105264, 0.6638157894736841, 0.6325657894736842, 0.6628289473684211, 0.6845394736842105, 0.631578947368421, 0.5986842105263157, 0.4740131578947368, 0.6098684210526316, 0.5223684210526315] Best val loss: 4.82279623746872


Current group: 0.8
Epoch [1/80], Training Loss: 31.2873, Validation Loss Current: 10.4457, Validation Loss AVG: 10.4457, lr: 0.001
Epoch [2/80], Training Loss: 18.5657, Validation Loss Current: 7.0883, Validation Loss AVG: 7.0883, lr: 0.001
Epoch [3/80], Training Loss: 11.2480, Validation Loss Current: 7.0361, Validation Loss AVG: 7.0361, lr: 0.001
Epoch [4/80], Training Loss: 8.5485, Validation Loss Current: 6.5545, Validation Loss AVG: 6.5545, lr: 0.001
Epoch [5/80], Training Loss: 8.6781, Validation Loss Current: 7.7526, Validation Loss AVG: 7.7526, lr: 0.001
Epoch [6/80], Training Loss: 6.0554, Validation Loss Current: 7.7411, Validation Loss AVG: 7.7411, lr: 0.001
Epoch [7/80], Training Loss: 6.1018, Validation Loss Current: 6.6432, Validation Loss AVG: 6.6432, lr: 0.001
Epoch [8/80], Training Loss: 6.5826, Validation Loss Current: 7.8779, Validation Loss AVG: 7.8779, lr: 0.001
Epoch [9/80], Training Loss: 4.6672, Validation Loss Current: 7.5284, Validation Loss AVG: 7.5284, lr: 0.001
Epoch [10/80], Training Loss: 3.2194, Validation Loss Current: 7.1437, Validation Loss AVG: 7.1437, lr: 0.001
Epoch [11/80], Training Loss: 4.3838, Validation Loss Current: 7.7538, Validation Loss AVG: 7.7538, lr: 0.001
Epoch [12/80], Training Loss: 5.4082, Validation Loss Current: 7.7223, Validation Loss AVG: 7.7223, lr: 0.001
Epoch [13/80], Training Loss: 6.1957, Validation Loss Current: 7.6683, Validation Loss AVG: 7.6683, lr: 0.001
Epoch [14/80], Training Loss: 6.5865, Validation Loss Current: 7.4625, Validation Loss AVG: 7.4625, lr: 0.001
Epoch [15/80], Training Loss: 3.2588, Validation Loss Current: 8.4955, Validation Loss AVG: 8.4955, lr: 0.001
Epoch [16/80], Training Loss: 3.1917, Validation Loss Current: 7.5793, Validation Loss AVG: 7.5793, lr: 0.001
Epoch [17/80], Training Loss: 4.8620, Validation Loss Current: 8.9417, Validation Loss AVG: 8.9417, lr: 0.001
Epoch [18/80], Training Loss: 9.9498, Validation Loss Current: 9.1606, Validation Loss AVG: 9.1606, lr: 0.001
Epoch [19/80], Training Loss: 5.9948, Validation Loss Current: 9.6846, Validation Loss AVG: 9.6846, lr: 0.001
Epoch [20/80], Training Loss: 2.9198, Validation Loss Current: 8.2217, Validation Loss AVG: 8.2217, lr: 0.001
Epoch [21/80], Training Loss: 4.0280, Validation Loss Current: 7.7135, Validation Loss AVG: 7.7135, lr: 0.001
Epoch [22/80], Training Loss: 1.9406, Validation Loss Current: 8.0209, Validation Loss AVG: 8.0209, lr: 0.001
Epoch [23/80], Training Loss: 2.4406, Validation Loss Current: 8.6441, Validation Loss AVG: 8.6441, lr: 0.001
Epoch [24/80], Training Loss: 4.5261, Validation Loss Current: 9.1143, Validation Loss AVG: 9.1143, lr: 0.001
Epoch [25/80], Training Loss: 6.0395, Validation Loss Current: 10.0905, Validation Loss AVG: 10.0905, lr: 0.001
Epoch [26/80], Training Loss: 5.8426, Validation Loss Current: 8.7989, Validation Loss AVG: 8.7989, lr: 0.001
Epoch [27/80], Training Loss: 4.7710, Validation Loss Current: 14.8676, Validation Loss AVG: 14.8676, lr: 0.001
Epoch [28/80], Training Loss: 4.4905, Validation Loss Current: 9.2825, Validation Loss AVG: 9.2825, lr: 0.001
Epoch [29/80], Training Loss: 3.3999, Validation Loss Current: 10.3766, Validation Loss AVG: 10.3766, lr: 0.001
Epoch [30/80], Training Loss: 2.0127, Validation Loss Current: 8.2079, Validation Loss AVG: 8.2079, lr: 0.001
Epoch [31/80], Training Loss: 5.8637, Validation Loss Current: 12.2617, Validation Loss AVG: 12.2617, lr: 0.001
Epoch [32/80], Training Loss: 2.2836, Validation Loss Current: 10.5276, Validation Loss AVG: 10.5276, lr: 0.001
Epoch [33/80], Training Loss: 1.2621, Validation Loss Current: 8.9065, Validation Loss AVG: 8.9065, lr: 0.001
Epoch [34/80], Training Loss: 1.8717, Validation Loss Current: 9.3509, Validation Loss AVG: 9.3509, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 4 Best val accuracy: [0.5118421052631579, 0.5815789473684211, 0.6125, 0.6190789473684211, 0.581578947368421, 0.599342105263158, 0.61875, 0.6177631578947368, 0.5947368421052632, 0.6210526315789474, 0.5621710526315791, 0.5993421052631579, 0.5875, 0.59375, 0.5697368421052633, 0.5914473684210526, 0.5779605263157894, 0.5384868421052632, 0.5167763157894737, 0.5779605263157894, 0.5766447368421053, 0.5819078947368421, 0.5789473684210527, 0.56875, 0.5279605263157895, 0.5427631578947368, 0.44144736842105264, 0.5444078947368421, 0.5125, 0.5677631578947369, 0.5115131578947368, 0.54375, 0.56875, 0.5572368421052631] Best val loss: 6.55451899766922


----- Training resnet18 with sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] -----
Current group: llo_0.4_random0
Epoch [1/80], Training Loss: 40.7508, Validation Loss Current: 10.1101, Validation Loss AVG: 10.1101, lr: 0.001
Epoch [2/80], Training Loss: 38.7884, Validation Loss Current: 9.8897, Validation Loss AVG: 9.8897, lr: 0.001
Epoch [3/80], Training Loss: 38.5891, Validation Loss Current: 9.6883, Validation Loss AVG: 9.6883, lr: 0.001
Epoch [4/80], Training Loss: 37.4657, Validation Loss Current: 9.5757, Validation Loss AVG: 9.5757, lr: 0.001
Epoch [5/80], Training Loss: 36.9067, Validation Loss Current: 9.4949, Validation Loss AVG: 9.4949, lr: 0.001
Epoch [6/80], Training Loss: 35.9196, Validation Loss Current: 9.3646, Validation Loss AVG: 9.3646, lr: 0.001
Epoch [7/80], Training Loss: 35.1366, Validation Loss Current: 9.2392, Validation Loss AVG: 9.2392, lr: 0.001
Epoch [8/80], Training Loss: 34.6073, Validation Loss Current: 8.8689, Validation Loss AVG: 8.8689, lr: 0.001
Epoch [9/80], Training Loss: 33.7424, Validation Loss Current: 8.7601, Validation Loss AVG: 8.7601, lr: 0.001
Epoch [10/80], Training Loss: 32.2285, Validation Loss Current: 8.6193, Validation Loss AVG: 8.6193, lr: 0.001
Epoch [11/80], Training Loss: 32.8089, Validation Loss Current: 8.6583, Validation Loss AVG: 8.6583, lr: 0.001
Epoch [12/80], Training Loss: 30.7922, Validation Loss Current: 8.4989, Validation Loss AVG: 8.4989, lr: 0.001
Epoch [13/80], Training Loss: 30.7127, Validation Loss Current: 8.3265, Validation Loss AVG: 8.3265, lr: 0.001
Epoch [14/80], Training Loss: 29.4656, Validation Loss Current: 8.3515, Validation Loss AVG: 8.3515, lr: 0.001
Epoch [15/80], Training Loss: 28.5272, Validation Loss Current: 8.4511, Validation Loss AVG: 8.4511, lr: 0.001
Epoch [16/80], Training Loss: 28.8940, Validation Loss Current: 8.0850, Validation Loss AVG: 8.0850, lr: 0.001
Epoch [17/80], Training Loss: 29.4670, Validation Loss Current: 10.0471, Validation Loss AVG: 10.0471, lr: 0.001
Epoch [18/80], Training Loss: 29.2449, Validation Loss Current: 7.9389, Validation Loss AVG: 7.9389, lr: 0.001
Epoch [19/80], Training Loss: 28.0732, Validation Loss Current: 9.6771, Validation Loss AVG: 9.6771, lr: 0.001
Epoch [20/80], Training Loss: 27.0612, Validation Loss Current: 8.1485, Validation Loss AVG: 8.1485, lr: 0.001
Epoch [21/80], Training Loss: 26.5631, Validation Loss Current: 7.9079, Validation Loss AVG: 7.9079, lr: 0.001
Epoch [22/80], Training Loss: 26.2533, Validation Loss Current: 7.7373, Validation Loss AVG: 7.7373, lr: 0.001
Epoch [23/80], Training Loss: 25.7469, Validation Loss Current: 7.5422, Validation Loss AVG: 7.5422, lr: 0.001
Epoch [24/80], Training Loss: 24.5684, Validation Loss Current: 7.2125, Validation Loss AVG: 7.2125, lr: 0.001
Epoch [25/80], Training Loss: 24.0200, Validation Loss Current: 7.3366, Validation Loss AVG: 7.3366, lr: 0.001
Epoch [26/80], Training Loss: 22.7784, Validation Loss Current: 7.5195, Validation Loss AVG: 7.5195, lr: 0.001
Epoch [27/80], Training Loss: 21.2248, Validation Loss Current: 7.2491, Validation Loss AVG: 7.2491, lr: 0.001
Epoch [28/80], Training Loss: 21.1061, Validation Loss Current: 7.1138, Validation Loss AVG: 7.1138, lr: 0.001
Epoch [29/80], Training Loss: 19.4474, Validation Loss Current: 7.0870, Validation Loss AVG: 7.0870, lr: 0.001
Epoch [30/80], Training Loss: 20.2671, Validation Loss Current: 7.5371, Validation Loss AVG: 7.5371, lr: 0.001
Epoch [31/80], Training Loss: 19.7838, Validation Loss Current: 7.6616, Validation Loss AVG: 7.6616, lr: 0.001
Epoch [32/80], Training Loss: 19.2918, Validation Loss Current: 8.2631, Validation Loss AVG: 8.2631, lr: 0.001
Epoch [33/80], Training Loss: 19.1094, Validation Loss Current: 7.5473, Validation Loss AVG: 7.5473, lr: 0.001
Epoch [34/80], Training Loss: 18.4490, Validation Loss Current: 8.1277, Validation Loss AVG: 8.1277, lr: 0.001
Epoch [35/80], Training Loss: 17.7430, Validation Loss Current: 7.6319, Validation Loss AVG: 7.6319, lr: 0.001
Epoch [36/80], Training Loss: 16.3043, Validation Loss Current: 7.2396, Validation Loss AVG: 7.2396, lr: 0.001
Epoch [37/80], Training Loss: 14.0599, Validation Loss Current: 6.7472, Validation Loss AVG: 6.7472, lr: 0.001
Epoch [38/80], Training Loss: 14.0812, Validation Loss Current: 6.7095, Validation Loss AVG: 6.7095, lr: 0.001
Epoch [39/80], Training Loss: 14.1710, Validation Loss Current: 6.8466, Validation Loss AVG: 6.8466, lr: 0.001
Epoch [40/80], Training Loss: 12.4550, Validation Loss Current: 7.5015, Validation Loss AVG: 7.5015, lr: 0.001
Epoch [41/80], Training Loss: 11.1705, Validation Loss Current: 6.6300, Validation Loss AVG: 6.6300, lr: 0.001
Epoch [42/80], Training Loss: 11.5817, Validation Loss Current: 7.0209, Validation Loss AVG: 7.0209, lr: 0.001
Epoch [43/80], Training Loss: 11.3156, Validation Loss Current: 6.9870, Validation Loss AVG: 6.9870, lr: 0.001
Epoch [44/80], Training Loss: 10.6008, Validation Loss Current: 6.8492, Validation Loss AVG: 6.8492, lr: 0.001
Epoch [45/80], Training Loss: 8.2270, Validation Loss Current: 7.2927, Validation Loss AVG: 7.2927, lr: 0.001
Epoch [46/80], Training Loss: 7.8047, Validation Loss Current: 7.8811, Validation Loss AVG: 7.8811, lr: 0.001
Epoch [47/80], Training Loss: 7.2044, Validation Loss Current: 7.7489, Validation Loss AVG: 7.7489, lr: 0.001
Epoch [48/80], Training Loss: 6.5059, Validation Loss Current: 6.8216, Validation Loss AVG: 6.8216, lr: 0.001
Epoch [49/80], Training Loss: 7.5767, Validation Loss Current: 6.9573, Validation Loss AVG: 6.9573, lr: 0.001
Epoch [50/80], Training Loss: 7.2677, Validation Loss Current: 7.0275, Validation Loss AVG: 7.0275, lr: 0.001
Epoch [51/80], Training Loss: 8.2714, Validation Loss Current: 8.8336, Validation Loss AVG: 8.8336, lr: 0.001
Epoch [52/80], Training Loss: 8.4225, Validation Loss Current: 7.3033, Validation Loss AVG: 7.3033, lr: 0.001
Epoch [53/80], Training Loss: 8.4265, Validation Loss Current: 11.1410, Validation Loss AVG: 11.1410, lr: 0.001
Epoch [54/80], Training Loss: 7.5416, Validation Loss Current: 8.2549, Validation Loss AVG: 8.2549, lr: 0.001
Epoch [55/80], Training Loss: 6.1481, Validation Loss Current: 8.3353, Validation Loss AVG: 8.3353, lr: 0.001
Epoch [56/80], Training Loss: 8.1826, Validation Loss Current: 11.0221, Validation Loss AVG: 11.0221, lr: 0.001
Epoch [57/80], Training Loss: 9.4297, Validation Loss Current: 12.5038, Validation Loss AVG: 12.5038, lr: 0.001
Epoch [58/80], Training Loss: 7.6338, Validation Loss Current: 13.3627, Validation Loss AVG: 13.3627, lr: 0.001
Epoch [59/80], Training Loss: 16.2008, Validation Loss Current: 9.2364, Validation Loss AVG: 9.2364, lr: 0.001
Epoch [60/80], Training Loss: 20.2674, Validation Loss Current: 9.7871, Validation Loss AVG: 9.7871, lr: 0.001
Epoch [61/80], Training Loss: 13.6012, Validation Loss Current: 8.4031, Validation Loss AVG: 8.4031, lr: 0.001
Epoch [62/80], Training Loss: 10.8321, Validation Loss Current: 8.2136, Validation Loss AVG: 8.2136, lr: 0.001
Epoch [63/80], Training Loss: 9.1639, Validation Loss Current: 8.0450, Validation Loss AVG: 8.0450, lr: 0.001
Epoch [64/80], Training Loss: 7.4341, Validation Loss Current: 7.3149, Validation Loss AVG: 7.3149, lr: 0.001
Epoch [65/80], Training Loss: 5.7022, Validation Loss Current: 8.8873, Validation Loss AVG: 8.8873, lr: 0.001
Epoch [66/80], Training Loss: 5.2043, Validation Loss Current: 9.1199, Validation Loss AVG: 9.1199, lr: 0.001
Epoch [67/80], Training Loss: 3.9573, Validation Loss Current: 7.4811, Validation Loss AVG: 7.4811, lr: 0.001
Epoch [68/80], Training Loss: 5.1862, Validation Loss Current: 8.1762, Validation Loss AVG: 8.1762, lr: 0.001
Epoch [69/80], Training Loss: 9.5382, Validation Loss Current: 9.0113, Validation Loss AVG: 9.0113, lr: 0.001
Epoch [70/80], Training Loss: 7.3684, Validation Loss Current: 11.8972, Validation Loss AVG: 11.8972, lr: 0.001
Epoch [71/80], Training Loss: 7.6198, Validation Loss Current: 12.6786, Validation Loss AVG: 12.6786, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random0 finished training. Best epoch: 41 Best val accuracy: [0.2302631578947368, 0.25032894736842104, 0.2822368421052631, 0.28059210526315786, 0.31019736842105267, 0.30427631578947373, 0.3157894736842105, 0.3585526315789474, 0.37664473684210525, 0.38651315789473684, 0.38125, 0.3901315789473684, 0.4266447368421053, 0.4078947368421052, 0.40625, 0.40657894736842104, 0.3243421052631579, 0.4457236842105264, 0.33552631578947373, 0.4253289473684211, 0.4476973684210527, 0.45723684210526316, 0.4621710526315789, 0.49078947368421055, 0.4796052631578947, 0.4825657894736842, 0.49177631578947373, 0.5026315789473684, 0.5046052631578947, 0.4743421052631579, 0.46743421052631573, 0.4526315789473684, 0.4898026315789473, 0.44243421052631576, 0.4894736842105264, 0.5069078947368422, 0.5414473684210527, 0.5401315789473684, 0.5480263157894736, 0.5148026315789475, 0.5654605263157896, 0.5273026315789474, 0.5460526315789475, 0.5575657894736842, 0.5276315789473685, 0.5177631578947368, 0.530921052631579, 0.5713815789473684, 0.5680921052631579, 0.5743421052631579, 0.5039473684210526, 0.5490131578947368, 0.4773026315789474, 0.5115131578947368, 0.5207236842105263, 0.46809210526315786, 0.3894736842105263, 0.42105263157894735, 0.48848684210526316, 0.475, 0.5161184210526316, 0.5069078947368422, 0.5269736842105263, 0.5746710526315789, 0.5220394736842107, 0.5190789473684211, 0.5888157894736843, 0.5266447368421053, 0.5381578947368421, 0.4480263157894737, 0.4463815789473684] Best val loss: 6.630028152465821


Current group: llo_0.4_random1
Epoch [1/80], Training Loss: 29.6228, Validation Loss Current: 7.0793, Validation Loss AVG: 7.0793, lr: 0.001
Epoch [2/80], Training Loss: 21.0810, Validation Loss Current: 7.4154, Validation Loss AVG: 7.4154, lr: 0.001
Epoch [3/80], Training Loss: 16.6539, Validation Loss Current: 6.8414, Validation Loss AVG: 6.8414, lr: 0.001
Epoch [4/80], Training Loss: 15.2947, Validation Loss Current: 6.7512, Validation Loss AVG: 6.7512, lr: 0.001
Epoch [5/80], Training Loss: 13.5166, Validation Loss Current: 7.5786, Validation Loss AVG: 7.5786, lr: 0.001
Epoch [6/80], Training Loss: 12.4562, Validation Loss Current: 8.6740, Validation Loss AVG: 8.6740, lr: 0.001
Epoch [7/80], Training Loss: 10.0448, Validation Loss Current: 6.4154, Validation Loss AVG: 6.4154, lr: 0.001
Epoch [8/80], Training Loss: 9.5838, Validation Loss Current: 7.3013, Validation Loss AVG: 7.3013, lr: 0.001
Epoch [9/80], Training Loss: 14.5475, Validation Loss Current: 8.6772, Validation Loss AVG: 8.6772, lr: 0.001
Epoch [10/80], Training Loss: 10.9714, Validation Loss Current: 8.4538, Validation Loss AVG: 8.4538, lr: 0.001
Epoch [11/80], Training Loss: 9.3762, Validation Loss Current: 6.4234, Validation Loss AVG: 6.4234, lr: 0.001
Epoch [12/80], Training Loss: 9.5129, Validation Loss Current: 6.8760, Validation Loss AVG: 6.8760, lr: 0.001
Epoch [13/80], Training Loss: 7.2120, Validation Loss Current: 7.0052, Validation Loss AVG: 7.0052, lr: 0.001
Epoch [14/80], Training Loss: 5.6718, Validation Loss Current: 6.9814, Validation Loss AVG: 6.9814, lr: 0.001
Epoch [15/80], Training Loss: 4.9508, Validation Loss Current: 6.7249, Validation Loss AVG: 6.7249, lr: 0.001
Epoch [16/80], Training Loss: 6.8477, Validation Loss Current: 8.7403, Validation Loss AVG: 8.7403, lr: 0.001
Epoch [17/80], Training Loss: 8.0668, Validation Loss Current: 10.9010, Validation Loss AVG: 10.9010, lr: 0.001
Epoch [18/80], Training Loss: 13.1509, Validation Loss Current: 7.6318, Validation Loss AVG: 7.6318, lr: 0.001
Epoch [19/80], Training Loss: 6.9018, Validation Loss Current: 8.1986, Validation Loss AVG: 8.1986, lr: 0.001
Epoch [20/80], Training Loss: 7.6065, Validation Loss Current: 7.6366, Validation Loss AVG: 7.6366, lr: 0.001
Epoch [21/80], Training Loss: 7.4744, Validation Loss Current: 7.8665, Validation Loss AVG: 7.8665, lr: 0.001
Epoch [22/80], Training Loss: 5.5218, Validation Loss Current: 6.6870, Validation Loss AVG: 6.6870, lr: 0.001
Epoch [23/80], Training Loss: 5.1373, Validation Loss Current: 9.1864, Validation Loss AVG: 9.1864, lr: 0.001
Epoch [24/80], Training Loss: 7.4481, Validation Loss Current: 10.5559, Validation Loss AVG: 10.5559, lr: 0.001
Epoch [25/80], Training Loss: 7.3048, Validation Loss Current: 8.3104, Validation Loss AVG: 8.3104, lr: 0.001
Epoch [26/80], Training Loss: 7.9757, Validation Loss Current: 8.1234, Validation Loss AVG: 8.1234, lr: 0.001
Epoch [27/80], Training Loss: 6.8303, Validation Loss Current: 7.1610, Validation Loss AVG: 7.1610, lr: 0.001
Epoch [28/80], Training Loss: 4.7464, Validation Loss Current: 7.4702, Validation Loss AVG: 7.4702, lr: 0.001
Epoch [29/80], Training Loss: 4.8066, Validation Loss Current: 7.2577, Validation Loss AVG: 7.2577, lr: 0.001
Epoch [30/80], Training Loss: 5.8306, Validation Loss Current: 8.7499, Validation Loss AVG: 8.7499, lr: 0.001
Epoch [31/80], Training Loss: 6.2227, Validation Loss Current: 8.1070, Validation Loss AVG: 8.1070, lr: 0.001
Epoch [32/80], Training Loss: 4.7898, Validation Loss Current: 9.3417, Validation Loss AVG: 9.3417, lr: 0.001
Epoch [33/80], Training Loss: 9.0033, Validation Loss Current: 10.9520, Validation Loss AVG: 10.9520, lr: 0.001
Epoch [34/80], Training Loss: 9.7663, Validation Loss Current: 8.8731, Validation Loss AVG: 8.8731, lr: 0.001
Epoch [35/80], Training Loss: 4.6466, Validation Loss Current: 7.8759, Validation Loss AVG: 7.8759, lr: 0.001
Epoch [36/80], Training Loss: 2.8171, Validation Loss Current: 7.1858, Validation Loss AVG: 7.1858, lr: 0.001
Epoch [37/80], Training Loss: 1.9731, Validation Loss Current: 7.2222, Validation Loss AVG: 7.2222, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random1 finished training. Best epoch: 7 Best val accuracy: [0.5878289473684211, 0.5210526315789473, 0.5799342105263159, 0.5555921052631578, 0.5503289473684211, 0.5296052631578947, 0.6023026315789475, 0.5832236842105264, 0.5190789473684211, 0.5565789473684211, 0.6036184210526315, 0.6, 0.6032894736842105, 0.5970394736842105, 0.6144736842105264, 0.5628289473684212, 0.5039473684210526, 0.5490131578947368, 0.5710526315789475, 0.5792763157894737, 0.5756578947368421, 0.6299342105263158, 0.5611842105263157, 0.5190789473684211, 0.5779605263157894, 0.6036184210526315, 0.6075657894736842, 0.6217105263157895, 0.6111842105263158, 0.5898026315789474, 0.5786184210526316, 0.55625, 0.4832236842105263, 0.5631578947368421, 0.5976973684210527, 0.6322368421052632, 0.624671052631579] Best val loss: 6.415416860580445


Current group: llo_0.4_random2
Epoch [1/80], Training Loss: 31.5462, Validation Loss Current: 6.7783, Validation Loss AVG: 6.7783, lr: 0.001
Epoch [2/80], Training Loss: 21.3406, Validation Loss Current: 10.9949, Validation Loss AVG: 10.9949, lr: 0.001
Epoch [3/80], Training Loss: 18.9220, Validation Loss Current: 6.0449, Validation Loss AVG: 6.0449, lr: 0.001
Epoch [4/80], Training Loss: 16.6600, Validation Loss Current: 6.8131, Validation Loss AVG: 6.8131, lr: 0.001
Epoch [5/80], Training Loss: 11.9519, Validation Loss Current: 5.8244, Validation Loss AVG: 5.8244, lr: 0.001
Epoch [6/80], Training Loss: 9.0326, Validation Loss Current: 5.3085, Validation Loss AVG: 5.3085, lr: 0.001
Epoch [7/80], Training Loss: 7.9075, Validation Loss Current: 5.5980, Validation Loss AVG: 5.5980, lr: 0.001
Epoch [8/80], Training Loss: 6.4227, Validation Loss Current: 5.1879, Validation Loss AVG: 5.1879, lr: 0.001
Epoch [9/80], Training Loss: 6.5181, Validation Loss Current: 5.5106, Validation Loss AVG: 5.5106, lr: 0.001
Epoch [10/80], Training Loss: 8.4494, Validation Loss Current: 8.1441, Validation Loss AVG: 8.1441, lr: 0.001
Epoch [11/80], Training Loss: 8.3166, Validation Loss Current: 6.4730, Validation Loss AVG: 6.4730, lr: 0.001
Epoch [12/80], Training Loss: 7.7757, Validation Loss Current: 5.7064, Validation Loss AVG: 5.7064, lr: 0.001
Epoch [13/80], Training Loss: 5.0543, Validation Loss Current: 6.7284, Validation Loss AVG: 6.7284, lr: 0.001
Epoch [14/80], Training Loss: 7.0930, Validation Loss Current: 6.4247, Validation Loss AVG: 6.4247, lr: 0.001
Epoch [15/80], Training Loss: 7.6610, Validation Loss Current: 6.6209, Validation Loss AVG: 6.6209, lr: 0.001
Epoch [16/80], Training Loss: 5.3160, Validation Loss Current: 5.5370, Validation Loss AVG: 5.5370, lr: 0.001
Epoch [17/80], Training Loss: 3.7324, Validation Loss Current: 5.7228, Validation Loss AVG: 5.7228, lr: 0.001
Epoch [18/80], Training Loss: 3.4922, Validation Loss Current: 7.1284, Validation Loss AVG: 7.1284, lr: 0.001
Epoch [19/80], Training Loss: 3.3251, Validation Loss Current: 5.3063, Validation Loss AVG: 5.3063, lr: 0.001
Epoch [20/80], Training Loss: 5.8480, Validation Loss Current: 6.0439, Validation Loss AVG: 6.0439, lr: 0.001
Epoch [21/80], Training Loss: 3.1705, Validation Loss Current: 6.3509, Validation Loss AVG: 6.3509, lr: 0.001
Epoch [22/80], Training Loss: 3.3327, Validation Loss Current: 5.8813, Validation Loss AVG: 5.8813, lr: 0.001
Epoch [23/80], Training Loss: 4.0116, Validation Loss Current: 8.7583, Validation Loss AVG: 8.7583, lr: 0.001
Epoch [24/80], Training Loss: 5.8769, Validation Loss Current: 7.1849, Validation Loss AVG: 7.1849, lr: 0.001
Epoch [25/80], Training Loss: 3.5706, Validation Loss Current: 6.8177, Validation Loss AVG: 6.8177, lr: 0.001
Epoch [26/80], Training Loss: 1.3607, Validation Loss Current: 5.9598, Validation Loss AVG: 5.9598, lr: 0.001
Epoch [27/80], Training Loss: 1.4325, Validation Loss Current: 6.3888, Validation Loss AVG: 6.3888, lr: 0.001
Epoch [28/80], Training Loss: 3.5973, Validation Loss Current: 6.5798, Validation Loss AVG: 6.5798, lr: 0.001
Epoch [29/80], Training Loss: 5.1044, Validation Loss Current: 7.3763, Validation Loss AVG: 7.3763, lr: 0.001
Epoch [30/80], Training Loss: 2.9144, Validation Loss Current: 7.5870, Validation Loss AVG: 7.5870, lr: 0.001
Epoch [31/80], Training Loss: 3.0709, Validation Loss Current: 6.8376, Validation Loss AVG: 6.8376, lr: 0.001
Epoch [32/80], Training Loss: 5.7442, Validation Loss Current: 7.8449, Validation Loss AVG: 7.8449, lr: 0.001
Epoch [33/80], Training Loss: 7.2640, Validation Loss Current: 7.8493, Validation Loss AVG: 7.8493, lr: 0.001
Epoch [34/80], Training Loss: 4.0416, Validation Loss Current: 8.1729, Validation Loss AVG: 8.1729, lr: 0.001
Epoch [35/80], Training Loss: 8.9717, Validation Loss Current: 7.5358, Validation Loss AVG: 7.5358, lr: 0.001
Epoch [36/80], Training Loss: 5.4341, Validation Loss Current: 7.9442, Validation Loss AVG: 7.9442, lr: 0.001
Epoch [37/80], Training Loss: 5.3634, Validation Loss Current: 6.6336, Validation Loss AVG: 6.6336, lr: 0.001
Epoch [38/80], Training Loss: 3.8069, Validation Loss Current: 6.9480, Validation Loss AVG: 6.9480, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random2 finished training. Best epoch: 8 Best val accuracy: [0.5986842105263158, 0.4651315789473684, 0.6421052631578947, 0.5822368421052632, 0.6572368421052631, 0.6802631578947368, 0.6769736842105263, 0.6911184210526315, 0.6789473684210525, 0.5983552631578947, 0.656578947368421, 0.6674342105263158, 0.6075657894736842, 0.6424342105263159, 0.6200657894736842, 0.6911184210526315, 0.6730263157894737, 0.6325657894736842, 0.7029605263157895, 0.6680921052631579, 0.6700657894736842, 0.6848684210526316, 0.5963815789473685, 0.6210526315789473, 0.6552631578947368, 0.6884868421052632, 0.675, 0.6753289473684212, 0.6213815789473685, 0.6503289473684211, 0.6625, 0.6384868421052632, 0.63125, 0.6171052631578947, 0.6174342105263158, 0.6138157894736842, 0.6661184210526316, 0.6578947368421053] Best val loss: 5.187941229343414


Current group: llo_0.4_random3
Epoch [1/80], Training Loss: 35.7486, Validation Loss Current: 6.0698, Validation Loss AVG: 6.0698, lr: 0.001
Epoch [2/80], Training Loss: 20.8247, Validation Loss Current: 6.5213, Validation Loss AVG: 6.5213, lr: 0.001
Epoch [3/80], Training Loss: 17.6507, Validation Loss Current: 5.9208, Validation Loss AVG: 5.9208, lr: 0.001
Epoch [4/80], Training Loss: 12.5734, Validation Loss Current: 6.8100, Validation Loss AVG: 6.8100, lr: 0.001
Epoch [5/80], Training Loss: 9.7358, Validation Loss Current: 6.1960, Validation Loss AVG: 6.1960, lr: 0.001
Epoch [6/80], Training Loss: 8.4734, Validation Loss Current: 8.9721, Validation Loss AVG: 8.9721, lr: 0.001
Epoch [7/80], Training Loss: 10.0742, Validation Loss Current: 7.2402, Validation Loss AVG: 7.2402, lr: 0.001
Epoch [8/80], Training Loss: 9.1572, Validation Loss Current: 6.8713, Validation Loss AVG: 6.8713, lr: 0.001
Epoch [9/80], Training Loss: 8.1706, Validation Loss Current: 6.3202, Validation Loss AVG: 6.3202, lr: 0.001
Epoch [10/80], Training Loss: 7.9061, Validation Loss Current: 6.4919, Validation Loss AVG: 6.4919, lr: 0.001
Epoch [11/80], Training Loss: 5.4266, Validation Loss Current: 6.7967, Validation Loss AVG: 6.7967, lr: 0.001
Epoch [12/80], Training Loss: 6.7856, Validation Loss Current: 5.2070, Validation Loss AVG: 5.2070, lr: 0.001
Epoch [13/80], Training Loss: 4.7219, Validation Loss Current: 5.6435, Validation Loss AVG: 5.6435, lr: 0.001
Epoch [14/80], Training Loss: 4.7755, Validation Loss Current: 6.0068, Validation Loss AVG: 6.0068, lr: 0.001
Epoch [15/80], Training Loss: 3.0777, Validation Loss Current: 6.3390, Validation Loss AVG: 6.3390, lr: 0.001
Epoch [16/80], Training Loss: 2.4044, Validation Loss Current: 5.2196, Validation Loss AVG: 5.2196, lr: 0.001
Epoch [17/80], Training Loss: 7.5641, Validation Loss Current: 6.0289, Validation Loss AVG: 6.0289, lr: 0.001
Epoch [18/80], Training Loss: 8.0694, Validation Loss Current: 6.3432, Validation Loss AVG: 6.3432, lr: 0.001
Epoch [19/80], Training Loss: 5.3802, Validation Loss Current: 6.3415, Validation Loss AVG: 6.3415, lr: 0.001
Epoch [20/80], Training Loss: 3.1815, Validation Loss Current: 5.4977, Validation Loss AVG: 5.4977, lr: 0.001
Epoch [21/80], Training Loss: 2.6429, Validation Loss Current: 5.9755, Validation Loss AVG: 5.9755, lr: 0.001
Epoch [22/80], Training Loss: 2.6063, Validation Loss Current: 6.1492, Validation Loss AVG: 6.1492, lr: 0.001
Epoch [23/80], Training Loss: 5.9931, Validation Loss Current: 5.9354, Validation Loss AVG: 5.9354, lr: 0.001
Epoch [24/80], Training Loss: 5.2291, Validation Loss Current: 5.9141, Validation Loss AVG: 5.9141, lr: 0.001
Epoch [25/80], Training Loss: 8.6292, Validation Loss Current: 6.7485, Validation Loss AVG: 6.7485, lr: 0.001
Epoch [26/80], Training Loss: 6.8661, Validation Loss Current: 7.3135, Validation Loss AVG: 7.3135, lr: 0.001
Epoch [27/80], Training Loss: 5.7804, Validation Loss Current: 6.0670, Validation Loss AVG: 6.0670, lr: 0.001
Epoch [28/80], Training Loss: 3.5055, Validation Loss Current: 6.2979, Validation Loss AVG: 6.2979, lr: 0.001
Epoch [29/80], Training Loss: 1.7678, Validation Loss Current: 5.8173, Validation Loss AVG: 5.8173, lr: 0.001
Epoch [30/80], Training Loss: 1.7946, Validation Loss Current: 5.5285, Validation Loss AVG: 5.5285, lr: 0.001
Epoch [31/80], Training Loss: 5.0601, Validation Loss Current: 6.2139, Validation Loss AVG: 6.2139, lr: 0.001
Epoch [32/80], Training Loss: 6.0965, Validation Loss Current: 6.9273, Validation Loss AVG: 6.9273, lr: 0.001
Epoch [33/80], Training Loss: 4.1127, Validation Loss Current: 6.3083, Validation Loss AVG: 6.3083, lr: 0.001
Epoch [34/80], Training Loss: 7.4531, Validation Loss Current: 7.2485, Validation Loss AVG: 7.2485, lr: 0.001
Epoch [35/80], Training Loss: 3.7382, Validation Loss Current: 6.4958, Validation Loss AVG: 6.4958, lr: 0.001
Epoch [36/80], Training Loss: 1.8677, Validation Loss Current: 6.2020, Validation Loss AVG: 6.2020, lr: 0.001
Epoch [37/80], Training Loss: 2.2729, Validation Loss Current: 5.9982, Validation Loss AVG: 5.9982, lr: 0.001
Epoch [38/80], Training Loss: 5.0641, Validation Loss Current: 6.7020, Validation Loss AVG: 6.7020, lr: 0.001
Epoch [39/80], Training Loss: 4.0689, Validation Loss Current: 6.5199, Validation Loss AVG: 6.5199, lr: 0.001
Epoch [40/80], Training Loss: 5.9839, Validation Loss Current: 6.6542, Validation Loss AVG: 6.6542, lr: 0.001
Epoch [41/80], Training Loss: 2.4072, Validation Loss Current: 6.6210, Validation Loss AVG: 6.6210, lr: 0.001
Epoch [42/80], Training Loss: 1.6925, Validation Loss Current: 6.5255, Validation Loss AVG: 6.5255, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random3 finished training. Best epoch: 12 Best val accuracy: [0.6726973684210525, 0.6335526315789475, 0.6615131578947369, 0.6009868421052632, 0.63125, 0.550986842105263, 0.6125, 0.6236842105263158, 0.631578947368421, 0.6470394736842106, 0.6348684210526315, 0.7052631578947368, 0.687171052631579, 0.6796052631578948, 0.6674342105263158, 0.7157894736842106, 0.6993421052631579, 0.6509868421052631, 0.6457236842105264, 0.6894736842105263, 0.6819078947368421, 0.6848684210526316, 0.6723684210526316, 0.6799342105263158, 0.6615131578947369, 0.6335526315789475, 0.6858552631578948, 0.6588815789473684, 0.6891447368421053, 0.6894736842105262, 0.6634868421052632, 0.6542763157894738, 0.655921052631579, 0.6476973684210525, 0.6549342105263157, 0.6802631578947368, 0.681907894736842, 0.662828947368421, 0.6592105263157894, 0.6588815789473683, 0.6717105263157894, 0.6858552631578947] Best val loss: 5.206972050666809


Current group: 0.4
Epoch [1/80], Training Loss: 41.3341, Validation Loss Current: 8.2192, Validation Loss AVG: 8.2192, lr: 0.001
Epoch [2/80], Training Loss: 21.7436, Validation Loss Current: 7.6714, Validation Loss AVG: 7.6714, lr: 0.001
Epoch [3/80], Training Loss: 15.4848, Validation Loss Current: 6.8372, Validation Loss AVG: 6.8372, lr: 0.001
Epoch [4/80], Training Loss: 11.2523, Validation Loss Current: 6.4437, Validation Loss AVG: 6.4437, lr: 0.001
Epoch [5/80], Training Loss: 10.0298, Validation Loss Current: 7.6793, Validation Loss AVG: 7.6793, lr: 0.001
Epoch [6/80], Training Loss: 7.8364, Validation Loss Current: 7.1945, Validation Loss AVG: 7.1945, lr: 0.001
Epoch [7/80], Training Loss: 5.5044, Validation Loss Current: 8.3942, Validation Loss AVG: 8.3942, lr: 0.001
Epoch [8/80], Training Loss: 6.0498, Validation Loss Current: 8.0616, Validation Loss AVG: 8.0616, lr: 0.001
Epoch [9/80], Training Loss: 7.0478, Validation Loss Current: 8.6743, Validation Loss AVG: 8.6743, lr: 0.001
Epoch [10/80], Training Loss: 5.4560, Validation Loss Current: 7.9870, Validation Loss AVG: 7.9870, lr: 0.001
Epoch [11/80], Training Loss: 7.9146, Validation Loss Current: 8.0998, Validation Loss AVG: 8.0998, lr: 0.001
Epoch [12/80], Training Loss: 5.6728, Validation Loss Current: 10.1214, Validation Loss AVG: 10.1214, lr: 0.001
Epoch [13/80], Training Loss: 5.8881, Validation Loss Current: 11.3646, Validation Loss AVG: 11.3646, lr: 0.001
Epoch [14/80], Training Loss: 4.7236, Validation Loss Current: 9.3878, Validation Loss AVG: 9.3878, lr: 0.001
Epoch [15/80], Training Loss: 4.2021, Validation Loss Current: 8.9170, Validation Loss AVG: 8.9170, lr: 0.001
Epoch [16/80], Training Loss: 6.7115, Validation Loss Current: 13.8723, Validation Loss AVG: 13.8723, lr: 0.001
Epoch [17/80], Training Loss: 8.9686, Validation Loss Current: 11.0272, Validation Loss AVG: 11.0272, lr: 0.001
Epoch [18/80], Training Loss: 8.4397, Validation Loss Current: 8.4251, Validation Loss AVG: 8.4251, lr: 0.001
Epoch [19/80], Training Loss: 5.2393, Validation Loss Current: 10.8342, Validation Loss AVG: 10.8342, lr: 0.001
Epoch [20/80], Training Loss: 5.4429, Validation Loss Current: 8.8393, Validation Loss AVG: 8.8393, lr: 0.001
Epoch [21/80], Training Loss: 2.6025, Validation Loss Current: 8.8847, Validation Loss AVG: 8.8847, lr: 0.001
Epoch [22/80], Training Loss: 2.0031, Validation Loss Current: 8.6795, Validation Loss AVG: 8.6795, lr: 0.001
Epoch [23/80], Training Loss: 3.0843, Validation Loss Current: 8.9353, Validation Loss AVG: 8.9353, lr: 0.001
Epoch [24/80], Training Loss: 2.0257, Validation Loss Current: 10.0352, Validation Loss AVG: 10.0352, lr: 0.001
Epoch [25/80], Training Loss: 1.4783, Validation Loss Current: 8.4209, Validation Loss AVG: 8.4209, lr: 0.001
Epoch [26/80], Training Loss: 2.9750, Validation Loss Current: 8.8065, Validation Loss AVG: 8.8065, lr: 0.001
Epoch [27/80], Training Loss: 6.3286, Validation Loss Current: 10.6121, Validation Loss AVG: 10.6121, lr: 0.001
Epoch [28/80], Training Loss: 5.5292, Validation Loss Current: 11.9989, Validation Loss AVG: 11.9989, lr: 0.001
Epoch [29/80], Training Loss: 3.7808, Validation Loss Current: 9.5417, Validation Loss AVG: 9.5417, lr: 0.001
Epoch [30/80], Training Loss: 3.5533, Validation Loss Current: 10.4407, Validation Loss AVG: 10.4407, lr: 0.001
Epoch [31/80], Training Loss: 2.9412, Validation Loss Current: 10.9560, Validation Loss AVG: 10.9560, lr: 0.001
Epoch [32/80], Training Loss: 4.5891, Validation Loss Current: 12.7482, Validation Loss AVG: 12.7482, lr: 0.001
Epoch [33/80], Training Loss: 4.1747, Validation Loss Current: 10.2235, Validation Loss AVG: 10.2235, lr: 0.001
Epoch [34/80], Training Loss: 3.4731, Validation Loss Current: 9.7345, Validation Loss AVG: 9.7345, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 4 Best val accuracy: [0.5967105263157896, 0.5769736842105263, 0.6055921052631579, 0.6243421052631579, 0.5625, 0.587171052631579, 0.5759868421052632, 0.5713815789473684, 0.5496710526315789, 0.5927631578947368, 0.5832236842105264, 0.5638157894736843, 0.4792763157894737, 0.5638157894736843, 0.5842105263157895, 0.4582236842105263, 0.5072368421052632, 0.5766447368421053, 0.5088815789473683, 0.5733552631578946, 0.5578947368421053, 0.5585526315789473, 0.5838815789473684, 0.5509868421052632, 0.5937500000000001, 0.5713815789473684, 0.5226973684210526, 0.5190789473684211, 0.5523026315789473, 0.5276315789473685, 0.5072368421052631, 0.5190789473684211, 0.5430921052631579, 0.5523026315789473] Best val loss: 6.443748879432678


----- Training resnet18 with sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] -----
Current group: llo_0.6_random0
Epoch [1/80], Training Loss: 41.2437, Validation Loss Current: 10.1654, Validation Loss AVG: 10.1654, lr: 0.001
Epoch [2/80], Training Loss: 39.7027, Validation Loss Current: 10.0510, Validation Loss AVG: 10.0510, lr: 0.001
Epoch [3/80], Training Loss: 39.3595, Validation Loss Current: 9.9589, Validation Loss AVG: 9.9589, lr: 0.001
Epoch [4/80], Training Loss: 38.7670, Validation Loss Current: 9.7638, Validation Loss AVG: 9.7638, lr: 0.001
Epoch [5/80], Training Loss: 38.1784, Validation Loss Current: 9.7644, Validation Loss AVG: 9.7644, lr: 0.001
Epoch [6/80], Training Loss: 37.5751, Validation Loss Current: 9.4537, Validation Loss AVG: 9.4537, lr: 0.001
Epoch [7/80], Training Loss: 36.3665, Validation Loss Current: 9.2239, Validation Loss AVG: 9.2239, lr: 0.001
Epoch [8/80], Training Loss: 35.8232, Validation Loss Current: 9.1004, Validation Loss AVG: 9.1004, lr: 0.001
Epoch [9/80], Training Loss: 35.4539, Validation Loss Current: 8.8922, Validation Loss AVG: 8.8922, lr: 0.001
Epoch [10/80], Training Loss: 34.1992, Validation Loss Current: 8.7325, Validation Loss AVG: 8.7325, lr: 0.001
Epoch [11/80], Training Loss: 33.1465, Validation Loss Current: 8.5930, Validation Loss AVG: 8.5930, lr: 0.001
Epoch [12/80], Training Loss: 32.3053, Validation Loss Current: 8.4367, Validation Loss AVG: 8.4367, lr: 0.001
Epoch [13/80], Training Loss: 30.2933, Validation Loss Current: 8.2246, Validation Loss AVG: 8.2246, lr: 0.001
Epoch [14/80], Training Loss: 30.8375, Validation Loss Current: 8.7650, Validation Loss AVG: 8.7650, lr: 0.001
Epoch [15/80], Training Loss: 30.5248, Validation Loss Current: 8.1073, Validation Loss AVG: 8.1073, lr: 0.001
Epoch [16/80], Training Loss: 31.1001, Validation Loss Current: 8.2582, Validation Loss AVG: 8.2582, lr: 0.001
Epoch [17/80], Training Loss: 30.0665, Validation Loss Current: 8.3924, Validation Loss AVG: 8.3924, lr: 0.001
Epoch [18/80], Training Loss: 28.8512, Validation Loss Current: 8.0883, Validation Loss AVG: 8.0883, lr: 0.001
Epoch [19/80], Training Loss: 27.4241, Validation Loss Current: 8.1740, Validation Loss AVG: 8.1740, lr: 0.001
Epoch [20/80], Training Loss: 27.9103, Validation Loss Current: 11.0631, Validation Loss AVG: 11.0631, lr: 0.001
Epoch [21/80], Training Loss: 30.4984, Validation Loss Current: 8.5318, Validation Loss AVG: 8.5318, lr: 0.001
Epoch [22/80], Training Loss: 28.4824, Validation Loss Current: 7.6769, Validation Loss AVG: 7.6769, lr: 0.001
Epoch [23/80], Training Loss: 27.0699, Validation Loss Current: 8.1651, Validation Loss AVG: 8.1651, lr: 0.001
Epoch [24/80], Training Loss: 25.4596, Validation Loss Current: 7.8311, Validation Loss AVG: 7.8311, lr: 0.001
Epoch [25/80], Training Loss: 25.1961, Validation Loss Current: 7.2696, Validation Loss AVG: 7.2696, lr: 0.001
Epoch [26/80], Training Loss: 23.3977, Validation Loss Current: 7.5118, Validation Loss AVG: 7.5118, lr: 0.001
Epoch [27/80], Training Loss: 23.4128, Validation Loss Current: 7.9014, Validation Loss AVG: 7.9014, lr: 0.001
Epoch [28/80], Training Loss: 21.2313, Validation Loss Current: 7.0843, Validation Loss AVG: 7.0843, lr: 0.001
Epoch [29/80], Training Loss: 22.0707, Validation Loss Current: 7.2527, Validation Loss AVG: 7.2527, lr: 0.001
Epoch [30/80], Training Loss: 23.5121, Validation Loss Current: 7.3899, Validation Loss AVG: 7.3899, lr: 0.001
Epoch [31/80], Training Loss: 21.8272, Validation Loss Current: 7.3497, Validation Loss AVG: 7.3497, lr: 0.001
Epoch [32/80], Training Loss: 20.4879, Validation Loss Current: 7.1244, Validation Loss AVG: 7.1244, lr: 0.001
Epoch [33/80], Training Loss: 19.0519, Validation Loss Current: 7.6787, Validation Loss AVG: 7.6787, lr: 0.001
Epoch [34/80], Training Loss: 20.4798, Validation Loss Current: 7.1795, Validation Loss AVG: 7.1795, lr: 0.001
Epoch [35/80], Training Loss: 19.3598, Validation Loss Current: 6.9901, Validation Loss AVG: 6.9901, lr: 0.001
Epoch [36/80], Training Loss: 16.6286, Validation Loss Current: 7.1156, Validation Loss AVG: 7.1156, lr: 0.001
Epoch [37/80], Training Loss: 15.3905, Validation Loss Current: 7.6352, Validation Loss AVG: 7.6352, lr: 0.001
Epoch [38/80], Training Loss: 15.0918, Validation Loss Current: 7.1603, Validation Loss AVG: 7.1603, lr: 0.001
Epoch [39/80], Training Loss: 12.6800, Validation Loss Current: 7.1415, Validation Loss AVG: 7.1415, lr: 0.001
Epoch [40/80], Training Loss: 12.4256, Validation Loss Current: 6.8958, Validation Loss AVG: 6.8958, lr: 0.001
Epoch [41/80], Training Loss: 13.2955, Validation Loss Current: 7.2013, Validation Loss AVG: 7.2013, lr: 0.001
Epoch [42/80], Training Loss: 12.6635, Validation Loss Current: 8.2890, Validation Loss AVG: 8.2890, lr: 0.001
Epoch [43/80], Training Loss: 11.0502, Validation Loss Current: 7.4057, Validation Loss AVG: 7.4057, lr: 0.001
Epoch [44/80], Training Loss: 12.6136, Validation Loss Current: 12.7073, Validation Loss AVG: 12.7073, lr: 0.001
Epoch [45/80], Training Loss: 14.4728, Validation Loss Current: 8.6589, Validation Loss AVG: 8.6589, lr: 0.001
Epoch [46/80], Training Loss: 11.9383, Validation Loss Current: 8.4931, Validation Loss AVG: 8.4931, lr: 0.001
Epoch [47/80], Training Loss: 13.3433, Validation Loss Current: 9.4899, Validation Loss AVG: 9.4899, lr: 0.001
Epoch [48/80], Training Loss: 11.6168, Validation Loss Current: 7.9187, Validation Loss AVG: 7.9187, lr: 0.001
Epoch [49/80], Training Loss: 10.3984, Validation Loss Current: 8.8595, Validation Loss AVG: 8.8595, lr: 0.001
Epoch [50/80], Training Loss: 10.7361, Validation Loss Current: 7.3539, Validation Loss AVG: 7.3539, lr: 0.001
Epoch [51/80], Training Loss: 9.5689, Validation Loss Current: 8.3832, Validation Loss AVG: 8.3832, lr: 0.001
Epoch [52/80], Training Loss: 8.9681, Validation Loss Current: 7.6181, Validation Loss AVG: 7.6181, lr: 0.001
Epoch [53/80], Training Loss: 6.4406, Validation Loss Current: 7.3638, Validation Loss AVG: 7.3638, lr: 0.001
Epoch [54/80], Training Loss: 6.0099, Validation Loss Current: 8.5737, Validation Loss AVG: 8.5737, lr: 0.001
Epoch [55/80], Training Loss: 6.6980, Validation Loss Current: 8.7304, Validation Loss AVG: 8.7304, lr: 0.001
Epoch [56/80], Training Loss: 5.9058, Validation Loss Current: 7.7261, Validation Loss AVG: 7.7261, lr: 0.001
Epoch [57/80], Training Loss: 6.2728, Validation Loss Current: 8.1905, Validation Loss AVG: 8.1905, lr: 0.001
Epoch [58/80], Training Loss: 7.1725, Validation Loss Current: 8.3065, Validation Loss AVG: 8.3065, lr: 0.001
Epoch [59/80], Training Loss: 6.7563, Validation Loss Current: 9.1591, Validation Loss AVG: 9.1591, lr: 0.001
Epoch [60/80], Training Loss: 8.7983, Validation Loss Current: 8.9673, Validation Loss AVG: 8.9673, lr: 0.001
Epoch [61/80], Training Loss: 6.3150, Validation Loss Current: 7.1568, Validation Loss AVG: 7.1568, lr: 0.001
Epoch [62/80], Training Loss: 6.3430, Validation Loss Current: 8.6203, Validation Loss AVG: 8.6203, lr: 0.001
Epoch [63/80], Training Loss: 10.6679, Validation Loss Current: 8.5055, Validation Loss AVG: 8.5055, lr: 0.001
Epoch [64/80], Training Loss: 10.1543, Validation Loss Current: 9.2644, Validation Loss AVG: 9.2644, lr: 0.001
Epoch [65/80], Training Loss: 8.9666, Validation Loss Current: 8.6515, Validation Loss AVG: 8.6515, lr: 0.001
Epoch [66/80], Training Loss: 9.4874, Validation Loss Current: 8.4612, Validation Loss AVG: 8.4612, lr: 0.001
Epoch [67/80], Training Loss: 7.9649, Validation Loss Current: 8.3245, Validation Loss AVG: 8.3245, lr: 0.001
Epoch [68/80], Training Loss: 8.5168, Validation Loss Current: 10.5732, Validation Loss AVG: 10.5732, lr: 0.001
Epoch [69/80], Training Loss: 9.0337, Validation Loss Current: 9.0158, Validation Loss AVG: 9.0158, lr: 0.001
Epoch [70/80], Training Loss: 6.1902, Validation Loss Current: 7.7656, Validation Loss AVG: 7.7656, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random0 finished training. Best epoch: 40 Best val accuracy: [0.1950657894736842, 0.23190789473684212, 0.2450657894736842, 0.2756578947368421, 0.27269736842105263, 0.2983552631578947, 0.3286184210526316, 0.33453947368421055, 0.36019736842105254, 0.36414473684210524, 0.3927631578947368, 0.3845394736842106, 0.4046052631578947, 0.36217105263157895, 0.4118421052631579, 0.4144736842105264, 0.4200657894736842, 0.42828947368421055, 0.4223684210526316, 0.3279605263157895, 0.3917763157894737, 0.4588815789473685, 0.4355263157894737, 0.46414473684210533, 0.47993421052631574, 0.47631578947368425, 0.4654605263157895, 0.499342105263158, 0.49243421052631575, 0.48519736842105265, 0.4792763157894737, 0.49934210526315786, 0.48684210526315785, 0.4947368421052632, 0.5148026315789475, 0.5101973684210527, 0.5085526315789475, 0.5026315789473684, 0.5332236842105262, 0.5407894736842105, 0.5220394736842107, 0.49868421052631573, 0.5332236842105263, 0.39769736842105263, 0.47828947368421054, 0.4753289473684211, 0.4578947368421053, 0.5036184210526315, 0.47960526315789476, 0.5223684210526317, 0.49078947368421055, 0.5134868421052632, 0.5674342105263158, 0.5095394736842105, 0.5335526315789474, 0.5233552631578948, 0.5286184210526316, 0.5473684210526316, 0.5105263157894736, 0.4960526315789474, 0.5615131578947368, 0.5342105263157895, 0.5036184210526315, 0.5144736842105263, 0.500328947368421, 0.53125, 0.5180921052631579, 0.4789473684210527, 0.48256578947368417, 0.5598684210526316] Best val loss: 6.895753109455109


Current group: llo_0.6_random1
Epoch [1/80], Training Loss: 32.8632, Validation Loss Current: 8.1665, Validation Loss AVG: 8.1665, lr: 0.001
Epoch [2/80], Training Loss: 21.7221, Validation Loss Current: 6.6863, Validation Loss AVG: 6.6863, lr: 0.001
Epoch [3/80], Training Loss: 16.9396, Validation Loss Current: 7.1680, Validation Loss AVG: 7.1680, lr: 0.001
Epoch [4/80], Training Loss: 14.5064, Validation Loss Current: 6.2200, Validation Loss AVG: 6.2200, lr: 0.001
Epoch [5/80], Training Loss: 13.7688, Validation Loss Current: 8.0590, Validation Loss AVG: 8.0590, lr: 0.001
Epoch [6/80], Training Loss: 13.7439, Validation Loss Current: 7.1621, Validation Loss AVG: 7.1621, lr: 0.001
Epoch [7/80], Training Loss: 11.9467, Validation Loss Current: 5.8261, Validation Loss AVG: 5.8261, lr: 0.001
Epoch [8/80], Training Loss: 8.6740, Validation Loss Current: 6.1106, Validation Loss AVG: 6.1106, lr: 0.001
Epoch [9/80], Training Loss: 8.6507, Validation Loss Current: 7.3967, Validation Loss AVG: 7.3967, lr: 0.001
Epoch [10/80], Training Loss: 11.3512, Validation Loss Current: 7.0711, Validation Loss AVG: 7.0711, lr: 0.001
Epoch [11/80], Training Loss: 7.1351, Validation Loss Current: 6.2384, Validation Loss AVG: 6.2384, lr: 0.001
Epoch [12/80], Training Loss: 8.2528, Validation Loss Current: 8.2158, Validation Loss AVG: 8.2158, lr: 0.001
Epoch [13/80], Training Loss: 5.8878, Validation Loss Current: 8.0527, Validation Loss AVG: 8.0527, lr: 0.001
Epoch [14/80], Training Loss: 7.3864, Validation Loss Current: 9.6362, Validation Loss AVG: 9.6362, lr: 0.001
Epoch [15/80], Training Loss: 9.3752, Validation Loss Current: 9.6116, Validation Loss AVG: 9.6116, lr: 0.001
Epoch [16/80], Training Loss: 6.1205, Validation Loss Current: 7.5904, Validation Loss AVG: 7.5904, lr: 0.001
Epoch [17/80], Training Loss: 4.9660, Validation Loss Current: 7.1657, Validation Loss AVG: 7.1657, lr: 0.001
Epoch [18/80], Training Loss: 9.1191, Validation Loss Current: 7.7743, Validation Loss AVG: 7.7743, lr: 0.001
Epoch [19/80], Training Loss: 8.2458, Validation Loss Current: 8.1174, Validation Loss AVG: 8.1174, lr: 0.001
Epoch [20/80], Training Loss: 10.3631, Validation Loss Current: 7.8188, Validation Loss AVG: 7.8188, lr: 0.001
Epoch [21/80], Training Loss: 8.3378, Validation Loss Current: 7.9227, Validation Loss AVG: 7.9227, lr: 0.001
Epoch [22/80], Training Loss: 8.4597, Validation Loss Current: 9.3746, Validation Loss AVG: 9.3746, lr: 0.001
Epoch [23/80], Training Loss: 5.6145, Validation Loss Current: 8.0094, Validation Loss AVG: 8.0094, lr: 0.001
Epoch [24/80], Training Loss: 5.8299, Validation Loss Current: 7.8126, Validation Loss AVG: 7.8126, lr: 0.001
Epoch [25/80], Training Loss: 3.4072, Validation Loss Current: 7.0767, Validation Loss AVG: 7.0767, lr: 0.001
Epoch [26/80], Training Loss: 5.9257, Validation Loss Current: 9.2809, Validation Loss AVG: 9.2809, lr: 0.001
Epoch [27/80], Training Loss: 9.6918, Validation Loss Current: 8.4305, Validation Loss AVG: 8.4305, lr: 0.001
Epoch [28/80], Training Loss: 6.6375, Validation Loss Current: 8.4203, Validation Loss AVG: 8.4203, lr: 0.001
Epoch [29/80], Training Loss: 5.1057, Validation Loss Current: 7.8397, Validation Loss AVG: 7.8397, lr: 0.001
Epoch [30/80], Training Loss: 3.7485, Validation Loss Current: 8.2632, Validation Loss AVG: 8.2632, lr: 0.001
Epoch [31/80], Training Loss: 3.3573, Validation Loss Current: 7.9901, Validation Loss AVG: 7.9901, lr: 0.001
Epoch [32/80], Training Loss: 3.4920, Validation Loss Current: 10.4409, Validation Loss AVG: 10.4409, lr: 0.001
Epoch [33/80], Training Loss: 6.7214, Validation Loss Current: 9.5102, Validation Loss AVG: 9.5102, lr: 0.001
Epoch [34/80], Training Loss: 4.7105, Validation Loss Current: 8.2693, Validation Loss AVG: 8.2693, lr: 0.001
Epoch [35/80], Training Loss: 4.1949, Validation Loss Current: 8.6119, Validation Loss AVG: 8.6119, lr: 0.001
Epoch [36/80], Training Loss: 3.1068, Validation Loss Current: 7.6097, Validation Loss AVG: 7.6097, lr: 0.001
Epoch [37/80], Training Loss: 2.2958, Validation Loss Current: 7.6915, Validation Loss AVG: 7.6915, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random1 finished training. Best epoch: 7 Best val accuracy: [0.4944078947368421, 0.5634868421052631, 0.5542763157894737, 0.619407894736842, 0.5470394736842105, 0.5648026315789474, 0.6463815789473684, 0.6328947368421053, 0.6059210526315789, 0.5848684210526316, 0.63125, 0.5131578947368421, 0.5753289473684211, 0.5332236842105262, 0.5269736842105263, 0.5947368421052632, 0.6286184210526315, 0.5805921052631579, 0.5523026315789474, 0.5924342105263158, 0.5782894736842106, 0.519078947368421, 0.5894736842105263, 0.5986842105263157, 0.631578947368421, 0.575, 0.5819078947368421, 0.5424342105263158, 0.60625, 0.5822368421052632, 0.6085526315789473, 0.5184210526315789, 0.5703947368421052, 0.5963815789473684, 0.5976973684210527, 0.618421052631579, 0.6210526315789473] Best val loss: 5.826109230518341


Current group: llo_0.6_random2
Epoch [1/80], Training Loss: 34.9052, Validation Loss Current: 8.0197, Validation Loss AVG: 8.0197, lr: 0.001
Epoch [2/80], Training Loss: 23.0918, Validation Loss Current: 7.5393, Validation Loss AVG: 7.5393, lr: 0.001
Epoch [3/80], Training Loss: 14.6237, Validation Loss Current: 6.1768, Validation Loss AVG: 6.1768, lr: 0.001
Epoch [4/80], Training Loss: 11.4525, Validation Loss Current: 5.8772, Validation Loss AVG: 5.8772, lr: 0.001
Epoch [5/80], Training Loss: 11.5760, Validation Loss Current: 6.3093, Validation Loss AVG: 6.3093, lr: 0.001
Epoch [6/80], Training Loss: 11.0706, Validation Loss Current: 6.8078, Validation Loss AVG: 6.8078, lr: 0.001
Epoch [7/80], Training Loss: 8.0046, Validation Loss Current: 5.9742, Validation Loss AVG: 5.9742, lr: 0.001
Epoch [8/80], Training Loss: 5.4682, Validation Loss Current: 5.5980, Validation Loss AVG: 5.5980, lr: 0.001
Epoch [9/80], Training Loss: 5.0308, Validation Loss Current: 6.8992, Validation Loss AVG: 6.8992, lr: 0.001
Epoch [10/80], Training Loss: 6.3597, Validation Loss Current: 6.9802, Validation Loss AVG: 6.9802, lr: 0.001
Epoch [11/80], Training Loss: 8.5892, Validation Loss Current: 8.2437, Validation Loss AVG: 8.2437, lr: 0.001
Epoch [12/80], Training Loss: 8.9883, Validation Loss Current: 7.8399, Validation Loss AVG: 7.8399, lr: 0.001
Epoch [13/80], Training Loss: 12.5592, Validation Loss Current: 7.9916, Validation Loss AVG: 7.9916, lr: 0.001
Epoch [14/80], Training Loss: 7.6787, Validation Loss Current: 6.1632, Validation Loss AVG: 6.1632, lr: 0.001
Epoch [15/80], Training Loss: 5.3860, Validation Loss Current: 6.8232, Validation Loss AVG: 6.8232, lr: 0.001
Epoch [16/80], Training Loss: 3.2147, Validation Loss Current: 6.2109, Validation Loss AVG: 6.2109, lr: 0.001
Epoch [17/80], Training Loss: 2.6801, Validation Loss Current: 6.2254, Validation Loss AVG: 6.2254, lr: 0.001
Epoch [18/80], Training Loss: 3.4910, Validation Loss Current: 6.4822, Validation Loss AVG: 6.4822, lr: 0.001
Epoch [19/80], Training Loss: 6.6432, Validation Loss Current: 7.4969, Validation Loss AVG: 7.4969, lr: 0.001
Epoch [20/80], Training Loss: 7.3564, Validation Loss Current: 7.6519, Validation Loss AVG: 7.6519, lr: 0.001
Epoch [21/80], Training Loss: 4.7257, Validation Loss Current: 6.7761, Validation Loss AVG: 6.7761, lr: 0.001
Epoch [22/80], Training Loss: 4.4529, Validation Loss Current: 6.9224, Validation Loss AVG: 6.9224, lr: 0.001
Epoch [23/80], Training Loss: 7.4701, Validation Loss Current: 8.4033, Validation Loss AVG: 8.4033, lr: 0.001
Epoch [24/80], Training Loss: 5.0560, Validation Loss Current: 10.4279, Validation Loss AVG: 10.4279, lr: 0.001
Epoch [25/80], Training Loss: 5.4478, Validation Loss Current: 7.7141, Validation Loss AVG: 7.7141, lr: 0.001
Epoch [26/80], Training Loss: 7.4797, Validation Loss Current: 7.6497, Validation Loss AVG: 7.6497, lr: 0.001
Epoch [27/80], Training Loss: 9.8944, Validation Loss Current: 9.2701, Validation Loss AVG: 9.2701, lr: 0.001
Epoch [28/80], Training Loss: 5.7865, Validation Loss Current: 8.1850, Validation Loss AVG: 8.1850, lr: 0.001
Epoch [29/80], Training Loss: 5.4279, Validation Loss Current: 7.5356, Validation Loss AVG: 7.5356, lr: 0.001
Epoch [30/80], Training Loss: 5.5495, Validation Loss Current: 7.9150, Validation Loss AVG: 7.9150, lr: 0.001
Epoch [31/80], Training Loss: 5.3795, Validation Loss Current: 7.6069, Validation Loss AVG: 7.6069, lr: 0.001
Epoch [32/80], Training Loss: 8.8941, Validation Loss Current: 7.7132, Validation Loss AVG: 7.7132, lr: 0.001
Epoch [33/80], Training Loss: 8.7355, Validation Loss Current: 9.3457, Validation Loss AVG: 9.3457, lr: 0.001
Epoch [34/80], Training Loss: 5.6094, Validation Loss Current: 9.4949, Validation Loss AVG: 9.4949, lr: 0.001
Epoch [35/80], Training Loss: 7.2795, Validation Loss Current: 8.2673, Validation Loss AVG: 8.2673, lr: 0.001
Epoch [36/80], Training Loss: 5.6395, Validation Loss Current: 8.3250, Validation Loss AVG: 8.3250, lr: 0.001
Epoch [37/80], Training Loss: 7.7569, Validation Loss Current: 8.2210, Validation Loss AVG: 8.2210, lr: 0.001
Epoch [38/80], Training Loss: 7.3166, Validation Loss Current: 13.8826, Validation Loss AVG: 13.8826, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random2 finished training. Best epoch: 8 Best val accuracy: [0.5805921052631579, 0.5532894736842106, 0.6243421052631579, 0.649671052631579, 0.6463815789473685, 0.624671052631579, 0.6480263157894737, 0.6789473684210527, 0.6355263157894737, 0.6549342105263158, 0.5697368421052632, 0.5973684210526317, 0.5825657894736842, 0.6430921052631579, 0.6309210526315789, 0.6476973684210525, 0.6546052631578947, 0.6506578947368421, 0.60625, 0.6203947368421053, 0.6444078947368421, 0.6480263157894738, 0.5891447368421053, 0.5598684210526316, 0.6174342105263158, 0.6157894736842107, 0.5723684210526316, 0.5917763157894738, 0.6085526315789475, 0.6226973684210526, 0.6226973684210526, 0.5986842105263157, 0.5914473684210526, 0.5648026315789474, 0.5720394736842105, 0.605921052631579, 0.6075657894736842, 0.4582236842105264] Best val loss: 5.597958743572235


Current group: llo_0.6_random3
Epoch [1/80], Training Loss: 37.3038, Validation Loss Current: 6.8249, Validation Loss AVG: 6.8249, lr: 0.001
Epoch [2/80], Training Loss: 21.7639, Validation Loss Current: 5.9924, Validation Loss AVG: 5.9924, lr: 0.001
Epoch [3/80], Training Loss: 17.3051, Validation Loss Current: 6.5968, Validation Loss AVG: 6.5968, lr: 0.001
Epoch [4/80], Training Loss: 11.2185, Validation Loss Current: 4.9903, Validation Loss AVG: 4.9903, lr: 0.001
Epoch [5/80], Training Loss: 10.7211, Validation Loss Current: 5.5400, Validation Loss AVG: 5.5400, lr: 0.001
Epoch [6/80], Training Loss: 8.5122, Validation Loss Current: 5.1585, Validation Loss AVG: 5.1585, lr: 0.001
Epoch [7/80], Training Loss: 7.8458, Validation Loss Current: 7.3588, Validation Loss AVG: 7.3588, lr: 0.001
Epoch [8/80], Training Loss: 11.7131, Validation Loss Current: 6.8189, Validation Loss AVG: 6.8189, lr: 0.001
Epoch [9/80], Training Loss: 10.7079, Validation Loss Current: 7.6520, Validation Loss AVG: 7.6520, lr: 0.001
Epoch [10/80], Training Loss: 8.0470, Validation Loss Current: 6.4629, Validation Loss AVG: 6.4629, lr: 0.001
Epoch [11/80], Training Loss: 6.5889, Validation Loss Current: 5.7768, Validation Loss AVG: 5.7768, lr: 0.001
Epoch [12/80], Training Loss: 6.5183, Validation Loss Current: 5.7724, Validation Loss AVG: 5.7724, lr: 0.001
Epoch [13/80], Training Loss: 7.2109, Validation Loss Current: 6.1523, Validation Loss AVG: 6.1523, lr: 0.001
Epoch [14/80], Training Loss: 6.4915, Validation Loss Current: 5.6172, Validation Loss AVG: 5.6172, lr: 0.001
Epoch [15/80], Training Loss: 3.5064, Validation Loss Current: 6.2619, Validation Loss AVG: 6.2619, lr: 0.001
Epoch [16/80], Training Loss: 4.1293, Validation Loss Current: 6.3930, Validation Loss AVG: 6.3930, lr: 0.001
Epoch [17/80], Training Loss: 5.1051, Validation Loss Current: 7.8754, Validation Loss AVG: 7.8754, lr: 0.001
Epoch [18/80], Training Loss: 4.8257, Validation Loss Current: 8.1067, Validation Loss AVG: 8.1067, lr: 0.001
Epoch [19/80], Training Loss: 5.5267, Validation Loss Current: 7.2275, Validation Loss AVG: 7.2275, lr: 0.001
Epoch [20/80], Training Loss: 5.1293, Validation Loss Current: 5.9020, Validation Loss AVG: 5.9020, lr: 0.001
Epoch [21/80], Training Loss: 3.6717, Validation Loss Current: 6.4395, Validation Loss AVG: 6.4395, lr: 0.001
Epoch [22/80], Training Loss: 3.0318, Validation Loss Current: 6.3813, Validation Loss AVG: 6.3813, lr: 0.001
Epoch [23/80], Training Loss: 2.8132, Validation Loss Current: 7.0993, Validation Loss AVG: 7.0993, lr: 0.001
Epoch [24/80], Training Loss: 2.0498, Validation Loss Current: 6.1710, Validation Loss AVG: 6.1710, lr: 0.001
Epoch [25/80], Training Loss: 1.0981, Validation Loss Current: 6.4485, Validation Loss AVG: 6.4485, lr: 0.001
Epoch [26/80], Training Loss: 2.2931, Validation Loss Current: 7.1082, Validation Loss AVG: 7.1082, lr: 0.001
Epoch [27/80], Training Loss: 5.6033, Validation Loss Current: 6.7954, Validation Loss AVG: 6.7954, lr: 0.001
Epoch [28/80], Training Loss: 1.9732, Validation Loss Current: 6.7010, Validation Loss AVG: 6.7010, lr: 0.001
Epoch [29/80], Training Loss: 3.2027, Validation Loss Current: 6.6006, Validation Loss AVG: 6.6006, lr: 0.001
Epoch [30/80], Training Loss: 5.4320, Validation Loss Current: 7.0892, Validation Loss AVG: 7.0892, lr: 0.001
Epoch [31/80], Training Loss: 7.4628, Validation Loss Current: 8.3549, Validation Loss AVG: 8.3549, lr: 0.001
Epoch [32/80], Training Loss: 5.8937, Validation Loss Current: 7.1202, Validation Loss AVG: 7.1202, lr: 0.001
Epoch [33/80], Training Loss: 2.8821, Validation Loss Current: 7.3631, Validation Loss AVG: 7.3631, lr: 0.001
Epoch [34/80], Training Loss: 4.7908, Validation Loss Current: 8.1322, Validation Loss AVG: 8.1322, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random3 finished training. Best epoch: 4 Best val accuracy: [0.5851973684210527, 0.65, 0.5648026315789474, 0.6802631578947368, 0.6638157894736842, 0.6815789473684212, 0.6078947368421053, 0.6013157894736842, 0.5973684210526315, 0.6273026315789474, 0.6661184210526316, 0.6625, 0.6503289473684211, 0.6608552631578947, 0.6730263157894737, 0.6529605263157896, 0.5832236842105264, 0.6157894736842106, 0.6391447368421053, 0.6700657894736841, 0.6500000000000001, 0.6532894736842106, 0.6424342105263158, 0.6802631578947369, 0.6723684210526316, 0.6263157894736843, 0.6486842105263158, 0.6493421052631578, 0.6605263157894736, 0.6476973684210526, 0.5907894736842106, 0.6332236842105263, 0.6328947368421053, 0.6217105263157896] Best val loss: 4.990309429168701


Current group: 0.6
Epoch [1/80], Training Loss: 34.9290, Validation Loss Current: 8.2235, Validation Loss AVG: 8.2235, lr: 0.001
Epoch [2/80], Training Loss: 22.3998, Validation Loss Current: 7.3901, Validation Loss AVG: 7.3901, lr: 0.001
Epoch [3/80], Training Loss: 14.8375, Validation Loss Current: 7.4525, Validation Loss AVG: 7.4525, lr: 0.001
Epoch [4/80], Training Loss: 9.4936, Validation Loss Current: 7.9685, Validation Loss AVG: 7.9685, lr: 0.001
Epoch [5/80], Training Loss: 5.4536, Validation Loss Current: 6.4290, Validation Loss AVG: 6.4290, lr: 0.001
Epoch [6/80], Training Loss: 4.5329, Validation Loss Current: 7.5060, Validation Loss AVG: 7.5060, lr: 0.001
Epoch [7/80], Training Loss: 5.6514, Validation Loss Current: 10.0100, Validation Loss AVG: 10.0100, lr: 0.001
Epoch [8/80], Training Loss: 7.1117, Validation Loss Current: 8.6517, Validation Loss AVG: 8.6517, lr: 0.001
Epoch [9/80], Training Loss: 4.2017, Validation Loss Current: 7.9137, Validation Loss AVG: 7.9137, lr: 0.001
Epoch [10/80], Training Loss: 6.0610, Validation Loss Current: 8.4017, Validation Loss AVG: 8.4017, lr: 0.001
Epoch [11/80], Training Loss: 6.6918, Validation Loss Current: 7.6177, Validation Loss AVG: 7.6177, lr: 0.001
Epoch [12/80], Training Loss: 7.7659, Validation Loss Current: 8.1871, Validation Loss AVG: 8.1871, lr: 0.001
Epoch [13/80], Training Loss: 3.3337, Validation Loss Current: 7.8583, Validation Loss AVG: 7.8583, lr: 0.001
Epoch [14/80], Training Loss: 4.4320, Validation Loss Current: 7.5088, Validation Loss AVG: 7.5088, lr: 0.001
Epoch [15/80], Training Loss: 2.8827, Validation Loss Current: 7.9494, Validation Loss AVG: 7.9494, lr: 0.001
Epoch [16/80], Training Loss: 3.7665, Validation Loss Current: 8.7825, Validation Loss AVG: 8.7825, lr: 0.001
Epoch [17/80], Training Loss: 5.0801, Validation Loss Current: 9.9968, Validation Loss AVG: 9.9968, lr: 0.001
Epoch [18/80], Training Loss: 2.4185, Validation Loss Current: 7.9198, Validation Loss AVG: 7.9198, lr: 0.001
Epoch [19/80], Training Loss: 1.2560, Validation Loss Current: 8.2480, Validation Loss AVG: 8.2480, lr: 0.001
Epoch [20/80], Training Loss: 1.0364, Validation Loss Current: 7.6317, Validation Loss AVG: 7.6317, lr: 0.001
Epoch [21/80], Training Loss: 2.9884, Validation Loss Current: 8.4806, Validation Loss AVG: 8.4806, lr: 0.001
Epoch [22/80], Training Loss: 6.5739, Validation Loss Current: 9.7005, Validation Loss AVG: 9.7005, lr: 0.001
Epoch [23/80], Training Loss: 4.2055, Validation Loss Current: 12.3447, Validation Loss AVG: 12.3447, lr: 0.001
Epoch [24/80], Training Loss: 7.3568, Validation Loss Current: 10.0655, Validation Loss AVG: 10.0655, lr: 0.001
Epoch [25/80], Training Loss: 6.8579, Validation Loss Current: 10.6247, Validation Loss AVG: 10.6247, lr: 0.001
Epoch [26/80], Training Loss: 4.9604, Validation Loss Current: 8.7221, Validation Loss AVG: 8.7221, lr: 0.001
Epoch [27/80], Training Loss: 6.9770, Validation Loss Current: 9.4917, Validation Loss AVG: 9.4917, lr: 0.001
Epoch [28/80], Training Loss: 3.3463, Validation Loss Current: 8.7357, Validation Loss AVG: 8.7357, lr: 0.001
Epoch [29/80], Training Loss: 4.0591, Validation Loss Current: 9.2570, Validation Loss AVG: 9.2570, lr: 0.001
Epoch [30/80], Training Loss: 4.4730, Validation Loss Current: 9.3634, Validation Loss AVG: 9.3634, lr: 0.001
Epoch [31/80], Training Loss: 1.8779, Validation Loss Current: 9.3706, Validation Loss AVG: 9.3706, lr: 0.001
Epoch [32/80], Training Loss: 2.0939, Validation Loss Current: 9.6187, Validation Loss AVG: 9.6187, lr: 0.001
Epoch [33/80], Training Loss: 4.4044, Validation Loss Current: 11.3826, Validation Loss AVG: 11.3826, lr: 0.001
Epoch [34/80], Training Loss: 3.9021, Validation Loss Current: 10.6273, Validation Loss AVG: 10.6273, lr: 0.001
Epoch [35/80], Training Loss: 2.9060, Validation Loss Current: 10.0855, Validation Loss AVG: 10.0855, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 5 Best val accuracy: [0.6190789473684211, 0.6075657894736842, 0.5914473684210526, 0.562171052631579, 0.6200657894736842, 0.6154605263157895, 0.49144736842105263, 0.5822368421052632, 0.5753289473684211, 0.5888157894736843, 0.5944078947368421, 0.5878289473684211, 0.5838815789473684, 0.6108552631578947, 0.5986842105263157, 0.5861842105263159, 0.5190789473684211, 0.6016447368421053, 0.5842105263157895, 0.605263157894737, 0.569078947368421, 0.5532894736842106, 0.5055921052631579, 0.5361842105263158, 0.5253289473684211, 0.5605263157894737, 0.5509868421052632, 0.575, 0.5555921052631578, 0.5414473684210527, 0.5684210526315789, 0.5450657894736842, 0.5233552631578947, 0.5282894736842106, 0.5513157894736842] Best val loss: 6.428992486000061


----- Training resnet18 with sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] -----
Current group: llo_1_random0
Epoch [1/80], Training Loss: 41.9680, Validation Loss Current: 10.1534, Validation Loss AVG: 10.1534, lr: 0.001
Epoch [2/80], Training Loss: 40.1559, Validation Loss Current: 9.9906, Validation Loss AVG: 9.9906, lr: 0.001
Epoch [3/80], Training Loss: 39.5331, Validation Loss Current: 10.0738, Validation Loss AVG: 10.0738, lr: 0.001
Epoch [4/80], Training Loss: 39.2078, Validation Loss Current: 9.8472, Validation Loss AVG: 9.8472, lr: 0.001
Epoch [5/80], Training Loss: 38.5420, Validation Loss Current: 9.7109, Validation Loss AVG: 9.7109, lr: 0.001
Epoch [6/80], Training Loss: 37.6168, Validation Loss Current: 9.6618, Validation Loss AVG: 9.6618, lr: 0.001
Epoch [7/80], Training Loss: 37.5132, Validation Loss Current: 9.3837, Validation Loss AVG: 9.3837, lr: 0.001
Epoch [8/80], Training Loss: 36.8317, Validation Loss Current: 9.1546, Validation Loss AVG: 9.1546, lr: 0.001
Epoch [9/80], Training Loss: 35.4867, Validation Loss Current: 9.2557, Validation Loss AVG: 9.2557, lr: 0.001
Epoch [10/80], Training Loss: 35.4356, Validation Loss Current: 8.9356, Validation Loss AVG: 8.9356, lr: 0.001
Epoch [11/80], Training Loss: 33.7802, Validation Loss Current: 8.8122, Validation Loss AVG: 8.8122, lr: 0.001
Epoch [12/80], Training Loss: 33.8125, Validation Loss Current: 8.6614, Validation Loss AVG: 8.6614, lr: 0.001
Epoch [13/80], Training Loss: 33.4751, Validation Loss Current: 8.4795, Validation Loss AVG: 8.4795, lr: 0.001
Epoch [14/80], Training Loss: 32.3641, Validation Loss Current: 8.3625, Validation Loss AVG: 8.3625, lr: 0.001
Epoch [15/80], Training Loss: 31.6777, Validation Loss Current: 8.1793, Validation Loss AVG: 8.1793, lr: 0.001
Epoch [16/80], Training Loss: 30.6547, Validation Loss Current: 8.2034, Validation Loss AVG: 8.2034, lr: 0.001
Epoch [17/80], Training Loss: 29.5439, Validation Loss Current: 8.2430, Validation Loss AVG: 8.2430, lr: 0.001
Epoch [18/80], Training Loss: 28.8707, Validation Loss Current: 7.9686, Validation Loss AVG: 7.9686, lr: 0.001
Epoch [19/80], Training Loss: 28.3484, Validation Loss Current: 7.8068, Validation Loss AVG: 7.8068, lr: 0.001
Epoch [20/80], Training Loss: 27.4628, Validation Loss Current: 7.8306, Validation Loss AVG: 7.8306, lr: 0.001
Epoch [21/80], Training Loss: 27.0195, Validation Loss Current: 7.5376, Validation Loss AVG: 7.5376, lr: 0.001
Epoch [22/80], Training Loss: 26.5875, Validation Loss Current: 7.8298, Validation Loss AVG: 7.8298, lr: 0.001
Epoch [23/80], Training Loss: 26.4424, Validation Loss Current: 7.7867, Validation Loss AVG: 7.7867, lr: 0.001
Epoch [24/80], Training Loss: 25.5093, Validation Loss Current: 7.7988, Validation Loss AVG: 7.7988, lr: 0.001
Epoch [25/80], Training Loss: 24.3892, Validation Loss Current: 7.5266, Validation Loss AVG: 7.5266, lr: 0.001
Epoch [26/80], Training Loss: 22.6322, Validation Loss Current: 7.5781, Validation Loss AVG: 7.5781, lr: 0.001
Epoch [27/80], Training Loss: 22.0485, Validation Loss Current: 7.9167, Validation Loss AVG: 7.9167, lr: 0.001
Epoch [28/80], Training Loss: 23.2870, Validation Loss Current: 7.8743, Validation Loss AVG: 7.8743, lr: 0.001
Epoch [29/80], Training Loss: 21.7023, Validation Loss Current: 7.7534, Validation Loss AVG: 7.7534, lr: 0.001
Epoch [30/80], Training Loss: 23.5437, Validation Loss Current: 8.9461, Validation Loss AVG: 8.9461, lr: 0.001
Epoch [31/80], Training Loss: 21.1757, Validation Loss Current: 7.6815, Validation Loss AVG: 7.6815, lr: 0.001
Epoch [32/80], Training Loss: 20.2750, Validation Loss Current: 7.6345, Validation Loss AVG: 7.6345, lr: 0.001
Epoch [33/80], Training Loss: 18.6554, Validation Loss Current: 7.3022, Validation Loss AVG: 7.3022, lr: 0.001
Epoch [34/80], Training Loss: 18.0553, Validation Loss Current: 8.6176, Validation Loss AVG: 8.6176, lr: 0.001
Epoch [35/80], Training Loss: 18.2541, Validation Loss Current: 7.1038, Validation Loss AVG: 7.1038, lr: 0.001
Epoch [36/80], Training Loss: 16.6466, Validation Loss Current: 7.5560, Validation Loss AVG: 7.5560, lr: 0.001
Epoch [37/80], Training Loss: 15.0566, Validation Loss Current: 7.0726, Validation Loss AVG: 7.0726, lr: 0.001
Epoch [38/80], Training Loss: 14.6681, Validation Loss Current: 7.3570, Validation Loss AVG: 7.3570, lr: 0.001
Epoch [39/80], Training Loss: 13.9951, Validation Loss Current: 6.9205, Validation Loss AVG: 6.9205, lr: 0.001
Epoch [40/80], Training Loss: 13.4647, Validation Loss Current: 6.6569, Validation Loss AVG: 6.6569, lr: 0.001
Epoch [41/80], Training Loss: 11.8939, Validation Loss Current: 7.0776, Validation Loss AVG: 7.0776, lr: 0.001
Epoch [42/80], Training Loss: 12.5811, Validation Loss Current: 6.8171, Validation Loss AVG: 6.8171, lr: 0.001
Epoch [43/80], Training Loss: 12.1070, Validation Loss Current: 7.1716, Validation Loss AVG: 7.1716, lr: 0.001
Epoch [44/80], Training Loss: 11.7280, Validation Loss Current: 6.8572, Validation Loss AVG: 6.8572, lr: 0.001
Epoch [45/80], Training Loss: 11.6760, Validation Loss Current: 7.4761, Validation Loss AVG: 7.4761, lr: 0.001
Epoch [46/80], Training Loss: 8.7253, Validation Loss Current: 6.9914, Validation Loss AVG: 6.9914, lr: 0.001
Epoch [47/80], Training Loss: 6.6763, Validation Loss Current: 6.8875, Validation Loss AVG: 6.8875, lr: 0.001
Epoch [48/80], Training Loss: 6.6050, Validation Loss Current: 7.4455, Validation Loss AVG: 7.4455, lr: 0.001
Epoch [49/80], Training Loss: 8.8159, Validation Loss Current: 7.6817, Validation Loss AVG: 7.6817, lr: 0.001
Epoch [50/80], Training Loss: 10.2943, Validation Loss Current: 11.2156, Validation Loss AVG: 11.2156, lr: 0.001
Epoch [51/80], Training Loss: 11.5160, Validation Loss Current: 8.8071, Validation Loss AVG: 8.8071, lr: 0.001
Epoch [52/80], Training Loss: 8.6752, Validation Loss Current: 7.8631, Validation Loss AVG: 7.8631, lr: 0.001
Epoch [53/80], Training Loss: 5.9719, Validation Loss Current: 10.2433, Validation Loss AVG: 10.2433, lr: 0.001
Epoch [54/80], Training Loss: 9.0284, Validation Loss Current: 9.2109, Validation Loss AVG: 9.2109, lr: 0.001
Epoch [55/80], Training Loss: 6.7788, Validation Loss Current: 8.5649, Validation Loss AVG: 8.5649, lr: 0.001
Epoch [56/80], Training Loss: 9.5129, Validation Loss Current: 8.5661, Validation Loss AVG: 8.5661, lr: 0.001
Epoch [57/80], Training Loss: 7.7344, Validation Loss Current: 8.0863, Validation Loss AVG: 8.0863, lr: 0.001
Epoch [58/80], Training Loss: 6.2718, Validation Loss Current: 9.0597, Validation Loss AVG: 9.0597, lr: 0.001
Epoch [59/80], Training Loss: 5.7057, Validation Loss Current: 8.5569, Validation Loss AVG: 8.5569, lr: 0.001
Epoch [60/80], Training Loss: 5.7908, Validation Loss Current: 8.2948, Validation Loss AVG: 8.2948, lr: 0.001
Epoch [61/80], Training Loss: 5.9097, Validation Loss Current: 8.2276, Validation Loss AVG: 8.2276, lr: 0.001
Epoch [62/80], Training Loss: 4.0412, Validation Loss Current: 8.0564, Validation Loss AVG: 8.0564, lr: 0.001
Epoch [63/80], Training Loss: 4.0012, Validation Loss Current: 9.5963, Validation Loss AVG: 9.5963, lr: 0.001
Epoch [64/80], Training Loss: 9.7843, Validation Loss Current: 10.9717, Validation Loss AVG: 10.9717, lr: 0.001
Epoch [65/80], Training Loss: 9.3028, Validation Loss Current: 9.8527, Validation Loss AVG: 9.8527, lr: 0.001
Epoch [66/80], Training Loss: 8.1002, Validation Loss Current: 10.6799, Validation Loss AVG: 10.6799, lr: 0.001
Epoch [67/80], Training Loss: 7.6504, Validation Loss Current: 9.9101, Validation Loss AVG: 9.9101, lr: 0.001
Epoch [68/80], Training Loss: 7.7950, Validation Loss Current: 9.7664, Validation Loss AVG: 9.7664, lr: 0.001
Epoch [69/80], Training Loss: 4.3657, Validation Loss Current: 9.8257, Validation Loss AVG: 9.8257, lr: 0.001
Epoch [70/80], Training Loss: 5.2077, Validation Loss Current: 9.6951, Validation Loss AVG: 9.6951, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random0 finished training. Best epoch: 40 Best val accuracy: [0.22269736842105262, 0.23125, 0.23322368421052633, 0.2694078947368421, 0.2766447368421053, 0.28585526315789467, 0.3125, 0.3269736842105263, 0.32467105263157897, 0.3513157894736842, 0.36184210526315785, 0.3743421052631579, 0.4, 0.3963815789473684, 0.41907894736842105, 0.42467105263157895, 0.40888157894736843, 0.4286184210526316, 0.4625, 0.4421052631578948, 0.47171052631578947, 0.45, 0.4338815789473684, 0.4526315789473684, 0.4723684210526316, 0.46085526315789477, 0.46052631578947373, 0.4625, 0.4809210526315789, 0.4082236842105263, 0.48355263157894735, 0.47269736842105264, 0.4930921052631579, 0.4447368421052632, 0.49736842105263157, 0.525, 0.5138157894736841, 0.49144736842105263, 0.5348684210526315, 0.5427631578947368, 0.5365131578947369, 0.5513157894736842, 0.5342105263157895, 0.5496710526315789, 0.5217105263157895, 0.5529605263157895, 0.5549342105263159, 0.5289473684210526, 0.5388157894736842, 0.4302631578947368, 0.487171052631579, 0.5388157894736842, 0.50625, 0.4677631578947368, 0.5154605263157894, 0.5266447368421052, 0.5279605263157895, 0.5115131578947368, 0.5069078947368422, 0.5424342105263158, 0.5335526315789474, 0.5355263157894736, 0.5098684210526316, 0.47302631578947374, 0.5174342105263159, 0.49868421052631584, 0.4944078947368421, 0.5095394736842105, 0.49407894736842106, 0.5391447368421053] Best val loss: 6.6568749189376835


Current group: llo_1_random1
Epoch [1/80], Training Loss: 34.7053, Validation Loss Current: 8.7840, Validation Loss AVG: 8.7840, lr: 0.001
Epoch [2/80], Training Loss: 29.6741, Validation Loss Current: 10.0708, Validation Loss AVG: 10.0708, lr: 0.001
Epoch [3/80], Training Loss: 23.9979, Validation Loss Current: 8.8355, Validation Loss AVG: 8.8355, lr: 0.001
Epoch [4/80], Training Loss: 22.0707, Validation Loss Current: 7.7480, Validation Loss AVG: 7.7480, lr: 0.001
Epoch [5/80], Training Loss: 16.0430, Validation Loss Current: 6.2501, Validation Loss AVG: 6.2501, lr: 0.001
Epoch [6/80], Training Loss: 12.7779, Validation Loss Current: 6.5558, Validation Loss AVG: 6.5558, lr: 0.001
Epoch [7/80], Training Loss: 10.0099, Validation Loss Current: 6.0768, Validation Loss AVG: 6.0768, lr: 0.001
Epoch [8/80], Training Loss: 8.6999, Validation Loss Current: 7.0113, Validation Loss AVG: 7.0113, lr: 0.001
Epoch [9/80], Training Loss: 6.5371, Validation Loss Current: 5.9978, Validation Loss AVG: 5.9978, lr: 0.001
Epoch [10/80], Training Loss: 6.4244, Validation Loss Current: 7.6650, Validation Loss AVG: 7.6650, lr: 0.001
Epoch [11/80], Training Loss: 9.1346, Validation Loss Current: 9.0843, Validation Loss AVG: 9.0843, lr: 0.001
Epoch [12/80], Training Loss: 12.2257, Validation Loss Current: 8.4005, Validation Loss AVG: 8.4005, lr: 0.001
Epoch [13/80], Training Loss: 9.6638, Validation Loss Current: 8.3395, Validation Loss AVG: 8.3395, lr: 0.001
Epoch [14/80], Training Loss: 8.3547, Validation Loss Current: 8.0708, Validation Loss AVG: 8.0708, lr: 0.001
Epoch [15/80], Training Loss: 7.9448, Validation Loss Current: 10.4105, Validation Loss AVG: 10.4105, lr: 0.001
Epoch [16/80], Training Loss: 12.1675, Validation Loss Current: 8.1500, Validation Loss AVG: 8.1500, lr: 0.001
Epoch [17/80], Training Loss: 8.0553, Validation Loss Current: 7.3261, Validation Loss AVG: 7.3261, lr: 0.001
Epoch [18/80], Training Loss: 7.4486, Validation Loss Current: 8.8676, Validation Loss AVG: 8.8676, lr: 0.001
Epoch [19/80], Training Loss: 7.3750, Validation Loss Current: 7.2729, Validation Loss AVG: 7.2729, lr: 0.001
Epoch [20/80], Training Loss: 7.3695, Validation Loss Current: 7.8502, Validation Loss AVG: 7.8502, lr: 0.001
Epoch [21/80], Training Loss: 8.7364, Validation Loss Current: 7.7035, Validation Loss AVG: 7.7035, lr: 0.001
Epoch [22/80], Training Loss: 7.1425, Validation Loss Current: 8.5855, Validation Loss AVG: 8.5855, lr: 0.001
Epoch [23/80], Training Loss: 7.1566, Validation Loss Current: 8.9333, Validation Loss AVG: 8.9333, lr: 0.001
Epoch [24/80], Training Loss: 4.6665, Validation Loss Current: 12.0241, Validation Loss AVG: 12.0241, lr: 0.001
Epoch [25/80], Training Loss: 11.1993, Validation Loss Current: 9.7718, Validation Loss AVG: 9.7718, lr: 0.001
Epoch [26/80], Training Loss: 7.1128, Validation Loss Current: 8.2638, Validation Loss AVG: 8.2638, lr: 0.001
Epoch [27/80], Training Loss: 4.2367, Validation Loss Current: 7.5981, Validation Loss AVG: 7.5981, lr: 0.001
Epoch [28/80], Training Loss: 6.1697, Validation Loss Current: 7.8439, Validation Loss AVG: 7.8439, lr: 0.001
Epoch [29/80], Training Loss: 4.4754, Validation Loss Current: 8.0613, Validation Loss AVG: 8.0613, lr: 0.001
Epoch [30/80], Training Loss: 4.7031, Validation Loss Current: 8.3722, Validation Loss AVG: 8.3722, lr: 0.001
Epoch [31/80], Training Loss: 5.7687, Validation Loss Current: 8.8556, Validation Loss AVG: 8.8556, lr: 0.001
Epoch [32/80], Training Loss: 3.7521, Validation Loss Current: 8.2318, Validation Loss AVG: 8.2318, lr: 0.001
Epoch [33/80], Training Loss: 2.6246, Validation Loss Current: 8.0108, Validation Loss AVG: 8.0108, lr: 0.001
Epoch [34/80], Training Loss: 1.9695, Validation Loss Current: 7.2886, Validation Loss AVG: 7.2886, lr: 0.001
Epoch [35/80], Training Loss: 2.1794, Validation Loss Current: 7.4854, Validation Loss AVG: 7.4854, lr: 0.001
Epoch [36/80], Training Loss: 3.1079, Validation Loss Current: 8.1659, Validation Loss AVG: 8.1659, lr: 0.001
Epoch [37/80], Training Loss: 12.0919, Validation Loss Current: 9.4509, Validation Loss AVG: 9.4509, lr: 0.001
Epoch [38/80], Training Loss: 8.8977, Validation Loss Current: 8.8468, Validation Loss AVG: 8.8468, lr: 0.001
Epoch [39/80], Training Loss: 8.2321, Validation Loss Current: 8.7597, Validation Loss AVG: 8.7597, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random1 finished training. Best epoch: 9 Best val accuracy: [0.4832236842105263, 0.4046052631578948, 0.4723684210526316, 0.48881578947368426, 0.5851973684210526, 0.5700657894736841, 0.6085526315789473, 0.5924342105263157, 0.6328947368421053, 0.5631578947368421, 0.5305921052631579, 0.5552631578947368, 0.5447368421052631, 0.5546052631578947, 0.42894736842105263, 0.5335526315789474, 0.5740131578947368, 0.5263157894736843, 0.5924342105263158, 0.5661184210526315, 0.5832236842105263, 0.5421052631578948, 0.5641447368421053, 0.4355263157894737, 0.5269736842105263, 0.562828947368421, 0.5792763157894736, 0.5960526315789474, 0.5868421052631578, 0.5868421052631578, 0.5546052631578948, 0.5950657894736843, 0.6049342105263158, 0.6082236842105264, 0.6151315789473684, 0.5891447368421052, 0.5319078947368421, 0.5407894736842105, 0.5967105263157895] Best val loss: 5.997784662246704


Current group: llo_1_random2
Epoch [1/80], Training Loss: 37.8489, Validation Loss Current: 8.1039, Validation Loss AVG: 8.1039, lr: 0.001
Epoch [2/80], Training Loss: 28.5011, Validation Loss Current: 9.5122, Validation Loss AVG: 9.5122, lr: 0.001
Epoch [3/80], Training Loss: 21.5531, Validation Loss Current: 7.2365, Validation Loss AVG: 7.2365, lr: 0.001
Epoch [4/80], Training Loss: 16.6921, Validation Loss Current: 6.0121, Validation Loss AVG: 6.0121, lr: 0.001
Epoch [5/80], Training Loss: 10.1228, Validation Loss Current: 5.7623, Validation Loss AVG: 5.7623, lr: 0.001
Epoch [6/80], Training Loss: 9.4180, Validation Loss Current: 5.3943, Validation Loss AVG: 5.3943, lr: 0.001
Epoch [7/80], Training Loss: 5.9398, Validation Loss Current: 5.9252, Validation Loss AVG: 5.9252, lr: 0.001
Epoch [8/80], Training Loss: 5.3256, Validation Loss Current: 6.2868, Validation Loss AVG: 6.2868, lr: 0.001
Epoch [9/80], Training Loss: 7.3244, Validation Loss Current: 7.2848, Validation Loss AVG: 7.2848, lr: 0.001
Epoch [10/80], Training Loss: 8.4546, Validation Loss Current: 6.3003, Validation Loss AVG: 6.3003, lr: 0.001
Epoch [11/80], Training Loss: 7.6091, Validation Loss Current: 7.1691, Validation Loss AVG: 7.1691, lr: 0.001
Epoch [12/80], Training Loss: 4.9104, Validation Loss Current: 7.3881, Validation Loss AVG: 7.3881, lr: 0.001
Epoch [13/80], Training Loss: 4.7707, Validation Loss Current: 6.5388, Validation Loss AVG: 6.5388, lr: 0.001
Epoch [14/80], Training Loss: 4.7676, Validation Loss Current: 7.2596, Validation Loss AVG: 7.2596, lr: 0.001
Epoch [15/80], Training Loss: 7.1025, Validation Loss Current: 8.0770, Validation Loss AVG: 8.0770, lr: 0.001
Epoch [16/80], Training Loss: 4.1734, Validation Loss Current: 7.0736, Validation Loss AVG: 7.0736, lr: 0.001
Epoch [17/80], Training Loss: 4.0577, Validation Loss Current: 6.8331, Validation Loss AVG: 6.8331, lr: 0.001
Epoch [18/80], Training Loss: 4.6103, Validation Loss Current: 7.2936, Validation Loss AVG: 7.2936, lr: 0.001
Epoch [19/80], Training Loss: 5.8307, Validation Loss Current: 6.8938, Validation Loss AVG: 6.8938, lr: 0.001
Epoch [20/80], Training Loss: 5.8888, Validation Loss Current: 12.4829, Validation Loss AVG: 12.4829, lr: 0.001
Epoch [21/80], Training Loss: 4.9670, Validation Loss Current: 10.5142, Validation Loss AVG: 10.5142, lr: 0.001
Epoch [22/80], Training Loss: 5.2352, Validation Loss Current: 8.3142, Validation Loss AVG: 8.3142, lr: 0.001
Epoch [23/80], Training Loss: 5.6855, Validation Loss Current: 8.5474, Validation Loss AVG: 8.5474, lr: 0.001
Epoch [24/80], Training Loss: 4.6632, Validation Loss Current: 7.9296, Validation Loss AVG: 7.9296, lr: 0.001
Epoch [25/80], Training Loss: 4.6980, Validation Loss Current: 8.4798, Validation Loss AVG: 8.4798, lr: 0.001
Epoch [26/80], Training Loss: 4.9195, Validation Loss Current: 7.9240, Validation Loss AVG: 7.9240, lr: 0.001
Epoch [27/80], Training Loss: 4.3041, Validation Loss Current: 7.7198, Validation Loss AVG: 7.7198, lr: 0.001
Epoch [28/80], Training Loss: 9.7598, Validation Loss Current: 9.3935, Validation Loss AVG: 9.3935, lr: 0.001
Epoch [29/80], Training Loss: 9.3143, Validation Loss Current: 8.1833, Validation Loss AVG: 8.1833, lr: 0.001
Epoch [30/80], Training Loss: 8.5767, Validation Loss Current: 8.9143, Validation Loss AVG: 8.9143, lr: 0.001
Epoch [31/80], Training Loss: 4.1092, Validation Loss Current: 8.9427, Validation Loss AVG: 8.9427, lr: 0.001
Epoch [32/80], Training Loss: 2.6177, Validation Loss Current: 8.9682, Validation Loss AVG: 8.9682, lr: 0.001
Epoch [33/80], Training Loss: 5.7620, Validation Loss Current: 10.7867, Validation Loss AVG: 10.7867, lr: 0.001
Epoch [34/80], Training Loss: 9.8523, Validation Loss Current: 12.3230, Validation Loss AVG: 12.3230, lr: 0.001
Epoch [35/80], Training Loss: 6.4531, Validation Loss Current: 7.9156, Validation Loss AVG: 7.9156, lr: 0.001
Epoch [36/80], Training Loss: 4.4958, Validation Loss Current: 8.0334, Validation Loss AVG: 8.0334, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random2 finished training. Best epoch: 6 Best val accuracy: [0.5552631578947369, 0.5273026315789474, 0.5733552631578948, 0.6319078947368421, 0.6351973684210527, 0.6700657894736842, 0.6407894736842106, 0.6503289473684211, 0.6085526315789472, 0.6519736842105263, 0.5907894736842105, 0.6055921052631579, 0.6631578947368421, 0.5996710526315789, 0.6036184210526315, 0.6259868421052632, 0.6421052631578947, 0.6141447368421054, 0.6375, 0.5128289473684211, 0.531578947368421, 0.6289473684210527, 0.5684210526315789, 0.6203947368421053, 0.5733552631578946, 0.6223684210526316, 0.6069078947368421, 0.5529605263157895, 0.6148026315789473, 0.5838815789473684, 0.5851973684210525, 0.5950657894736842, 0.5503289473684211, 0.49967105263157896, 0.6059210526315789, 0.5901315789473683] Best val loss: 5.39428346157074


Current group: llo_1_random3
Epoch [1/80], Training Loss: 40.6479, Validation Loss Current: 7.0327, Validation Loss AVG: 7.0327, lr: 0.001
Epoch [2/80], Training Loss: 23.2649, Validation Loss Current: 5.3066, Validation Loss AVG: 5.3066, lr: 0.001
Epoch [3/80], Training Loss: 17.4172, Validation Loss Current: 6.3738, Validation Loss AVG: 6.3738, lr: 0.001
Epoch [4/80], Training Loss: 14.5845, Validation Loss Current: 5.9559, Validation Loss AVG: 5.9559, lr: 0.001
Epoch [5/80], Training Loss: 14.1510, Validation Loss Current: 6.4084, Validation Loss AVG: 6.4084, lr: 0.001
Epoch [6/80], Training Loss: 9.0196, Validation Loss Current: 5.4577, Validation Loss AVG: 5.4577, lr: 0.001
Epoch [7/80], Training Loss: 5.3703, Validation Loss Current: 5.3996, Validation Loss AVG: 5.3996, lr: 0.001
Epoch [8/80], Training Loss: 4.7263, Validation Loss Current: 5.1453, Validation Loss AVG: 5.1453, lr: 0.001
Epoch [9/80], Training Loss: 3.6863, Validation Loss Current: 5.5218, Validation Loss AVG: 5.5218, lr: 0.001
Epoch [10/80], Training Loss: 6.4230, Validation Loss Current: 5.5142, Validation Loss AVG: 5.5142, lr: 0.001
Epoch [11/80], Training Loss: 10.0390, Validation Loss Current: 5.8016, Validation Loss AVG: 5.8016, lr: 0.001
Epoch [12/80], Training Loss: 9.5915, Validation Loss Current: 7.5654, Validation Loss AVG: 7.5654, lr: 0.001
Epoch [13/80], Training Loss: 5.3615, Validation Loss Current: 6.4430, Validation Loss AVG: 6.4430, lr: 0.001
Epoch [14/80], Training Loss: 4.5660, Validation Loss Current: 6.4530, Validation Loss AVG: 6.4530, lr: 0.001
Epoch [15/80], Training Loss: 9.7496, Validation Loss Current: 6.6546, Validation Loss AVG: 6.6546, lr: 0.001
Epoch [16/80], Training Loss: 11.5902, Validation Loss Current: 7.7885, Validation Loss AVG: 7.7885, lr: 0.001
Epoch [17/80], Training Loss: 12.8213, Validation Loss Current: 6.7578, Validation Loss AVG: 6.7578, lr: 0.001
Epoch [18/80], Training Loss: 8.6450, Validation Loss Current: 9.8328, Validation Loss AVG: 9.8328, lr: 0.001
Epoch [19/80], Training Loss: 14.4679, Validation Loss Current: 10.9295, Validation Loss AVG: 10.9295, lr: 0.001
Epoch [20/80], Training Loss: 8.7619, Validation Loss Current: 7.0779, Validation Loss AVG: 7.0779, lr: 0.001
Epoch [21/80], Training Loss: 7.9249, Validation Loss Current: 6.7415, Validation Loss AVG: 6.7415, lr: 0.001
Epoch [22/80], Training Loss: 4.3522, Validation Loss Current: 6.2991, Validation Loss AVG: 6.2991, lr: 0.001
Epoch [23/80], Training Loss: 3.3471, Validation Loss Current: 6.0412, Validation Loss AVG: 6.0412, lr: 0.001
Epoch [24/80], Training Loss: 5.1181, Validation Loss Current: 7.3679, Validation Loss AVG: 7.3679, lr: 0.001
Epoch [25/80], Training Loss: 8.2877, Validation Loss Current: 7.2766, Validation Loss AVG: 7.2766, lr: 0.001
Epoch [26/80], Training Loss: 6.2466, Validation Loss Current: 7.2045, Validation Loss AVG: 7.2045, lr: 0.001
Epoch [27/80], Training Loss: 6.2306, Validation Loss Current: 8.3113, Validation Loss AVG: 8.3113, lr: 0.001
Epoch [28/80], Training Loss: 8.5482, Validation Loss Current: 9.0849, Validation Loss AVG: 9.0849, lr: 0.001
Epoch [29/80], Training Loss: 8.1907, Validation Loss Current: 7.9926, Validation Loss AVG: 7.9926, lr: 0.001
Epoch [30/80], Training Loss: 4.6802, Validation Loss Current: 7.6412, Validation Loss AVG: 7.6412, lr: 0.001
Epoch [31/80], Training Loss: 7.7970, Validation Loss Current: 7.5707, Validation Loss AVG: 7.5707, lr: 0.001
Epoch [32/80], Training Loss: 7.8468, Validation Loss Current: 8.6691, Validation Loss AVG: 8.6691, lr: 0.001
Epoch [33/80], Training Loss: 7.8192, Validation Loss Current: 7.0443, Validation Loss AVG: 7.0443, lr: 0.001
Epoch [34/80], Training Loss: 5.0269, Validation Loss Current: 6.9024, Validation Loss AVG: 6.9024, lr: 0.001
Epoch [35/80], Training Loss: 6.8096, Validation Loss Current: 7.4848, Validation Loss AVG: 7.4848, lr: 0.001
Epoch [36/80], Training Loss: 4.1925, Validation Loss Current: 7.8946, Validation Loss AVG: 7.8946, lr: 0.001
Epoch [37/80], Training Loss: 5.7036, Validation Loss Current: 8.0227, Validation Loss AVG: 8.0227, lr: 0.001
Epoch [38/80], Training Loss: 13.6372, Validation Loss Current: 10.7503, Validation Loss AVG: 10.7503, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random3 finished training. Best epoch: 8 Best val accuracy: [0.6233552631578948, 0.668092105263158, 0.6098684210526316, 0.6582236842105262, 0.637828947368421, 0.6769736842105263, 0.6881578947368421, 0.6934210526315789, 0.6776315789473684, 0.6917763157894737, 0.6815789473684212, 0.624671052631579, 0.6450657894736842, 0.6483552631578948, 0.6483552631578947, 0.6082236842105264, 0.6394736842105264, 0.5509868421052632, 0.4707236842105263, 0.5878289473684211, 0.6342105263157894, 0.6486842105263158, 0.6664473684210526, 0.6101973684210527, 0.6200657894736842, 0.6128289473684211, 0.5680921052631578, 0.5881578947368421, 0.6046052631578946, 0.625328947368421, 0.6157894736842107, 0.5578947368421053, 0.6226973684210526, 0.625, 0.6108552631578947, 0.6026315789473684, 0.6029605263157896, 0.5302631578947368] Best val loss: 5.145261824131012


Current group: 1
Epoch [1/80], Training Loss: 38.0491, Validation Loss Current: 8.9212, Validation Loss AVG: 9.2002, lr: 0.001
Epoch [2/80], Training Loss: 21.7626, Validation Loss Current: 9.3017, Validation Loss AVG: 9.0705, lr: 0.001
Epoch [3/80], Training Loss: 15.0533, Validation Loss Current: 7.5851, Validation Loss AVG: 8.1054, lr: 0.001
Epoch [4/80], Training Loss: 12.8300, Validation Loss Current: 6.4211, Validation Loss AVG: 8.2428, lr: 0.001
Epoch [5/80], Training Loss: 7.8592, Validation Loss Current: 12.1838, Validation Loss AVG: 14.6972, lr: 0.001
Epoch [6/80], Training Loss: 9.8707, Validation Loss Current: 7.8226, Validation Loss AVG: 8.5297, lr: 0.001
Epoch [7/80], Training Loss: 7.4554, Validation Loss Current: 7.4573, Validation Loss AVG: 10.3232, lr: 0.001
Epoch [8/80], Training Loss: 6.3678, Validation Loss Current: 9.2902, Validation Loss AVG: 11.4863, lr: 0.001
Epoch [9/80], Training Loss: 3.2609, Validation Loss Current: 6.6119, Validation Loss AVG: 9.0307, lr: 0.001
Epoch [10/80], Training Loss: 5.2185, Validation Loss Current: 6.6154, Validation Loss AVG: 9.3635, lr: 0.001
Epoch [11/80], Training Loss: 4.3593, Validation Loss Current: 8.0285, Validation Loss AVG: 11.4137, lr: 0.001
Epoch [12/80], Training Loss: 3.7831, Validation Loss Current: 6.7601, Validation Loss AVG: 9.3663, lr: 0.001
Epoch [13/80], Training Loss: 2.9569, Validation Loss Current: 7.4838, Validation Loss AVG: 11.1493, lr: 0.001
Epoch [14/80], Training Loss: 2.1483, Validation Loss Current: 6.9367, Validation Loss AVG: 9.9551, lr: 0.001
Epoch [15/80], Training Loss: 4.0837, Validation Loss Current: 7.0199, Validation Loss AVG: 10.6956, lr: 0.001
Epoch [16/80], Training Loss: 4.6320, Validation Loss Current: 7.4211, Validation Loss AVG: 11.6971, lr: 0.001
Epoch [17/80], Training Loss: 4.8233, Validation Loss Current: 8.6078, Validation Loss AVG: 12.0742, lr: 0.001
Epoch [18/80], Training Loss: 6.3896, Validation Loss Current: 7.7588, Validation Loss AVG: 10.9353, lr: 0.001
Epoch [19/80], Training Loss: 6.1900, Validation Loss Current: 8.3682, Validation Loss AVG: 11.6923, lr: 0.001
Epoch [20/80], Training Loss: 3.1083, Validation Loss Current: 7.5615, Validation Loss AVG: 12.2001, lr: 0.001
Epoch [21/80], Training Loss: 5.6223, Validation Loss Current: 7.3439, Validation Loss AVG: 11.8630, lr: 0.001
Epoch [22/80], Training Loss: 8.5999, Validation Loss Current: 8.6879, Validation Loss AVG: 12.5868, lr: 0.001
Epoch [23/80], Training Loss: 7.7367, Validation Loss Current: 8.0019, Validation Loss AVG: 13.1294, lr: 0.001
Epoch [24/80], Training Loss: 3.8650, Validation Loss Current: 7.4811, Validation Loss AVG: 11.6937, lr: 0.001
Epoch [25/80], Training Loss: 2.8061, Validation Loss Current: 7.5289, Validation Loss AVG: 10.8582, lr: 0.001
Epoch [26/80], Training Loss: 2.5638, Validation Loss Current: 7.1412, Validation Loss AVG: 10.7578, lr: 0.001
Epoch [27/80], Training Loss: 1.6367, Validation Loss Current: 7.3022, Validation Loss AVG: 12.4267, lr: 0.001
Epoch [28/80], Training Loss: 4.6463, Validation Loss Current: 7.3430, Validation Loss AVG: 12.1925, lr: 0.001
Epoch [29/80], Training Loss: 3.8710, Validation Loss Current: 8.9481, Validation Loss AVG: 10.6180, lr: 0.001
Epoch [30/80], Training Loss: 3.8036, Validation Loss Current: 7.6951, Validation Loss AVG: 12.5243, lr: 0.001
Epoch [31/80], Training Loss: 2.4809, Validation Loss Current: 8.0590, Validation Loss AVG: 11.7096, lr: 0.001
Epoch [32/80], Training Loss: 2.0109, Validation Loss Current: 8.8137, Validation Loss AVG: 11.8047, lr: 0.001
Epoch [33/80], Training Loss: 3.2026, Validation Loss Current: 7.8836, Validation Loss AVG: 11.2151, lr: 0.001
Epoch [34/80], Training Loss: 3.3448, Validation Loss Current: 8.2748, Validation Loss AVG: 12.3654, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 4 Best val accuracy: [0.555921052631579, 0.5148026315789473, 0.5625, 0.6036184210526315, 0.5148026315789473, 0.5394736842105263, 0.5641447368421053, 0.5756578947368421, 0.618421052631579, 0.6019736842105263, 0.587171052631579, 0.5970394736842105, 0.5838815789473685, 0.5740131578947368, 0.6101973684210527, 0.625, 0.5904605263157895, 0.5888157894736842, 0.569078947368421, 0.587171052631579, 0.5789473684210527, 0.5773026315789473, 0.5592105263157895, 0.6101973684210527, 0.6365131578947368, 0.6101973684210527, 0.6348684210526315, 0.6381578947368421, 0.5805921052631579, 0.6036184210526315, 0.5888157894736842, 0.631578947368421, 0.6069078947368421, 0.5904605263157895] Best val loss: 6.4210569858551025


Fold: 3
----- Training resnet18 with sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] -----
Current group: llo_0.2_random0
Epoch [1/80], Training Loss: 41.7848, Validation Loss Current: 10.0205, Validation Loss AVG: 10.0205, lr: 0.001
Epoch [2/80], Training Loss: 39.4007, Validation Loss Current: 9.8101, Validation Loss AVG: 9.8101, lr: 0.001
Epoch [3/80], Training Loss: 39.3237, Validation Loss Current: 9.6416, Validation Loss AVG: 9.6416, lr: 0.001
Epoch [4/80], Training Loss: 38.2176, Validation Loss Current: 9.4766, Validation Loss AVG: 9.4766, lr: 0.001
Epoch [5/80], Training Loss: 36.8818, Validation Loss Current: 9.3183, Validation Loss AVG: 9.3183, lr: 0.001
Epoch [6/80], Training Loss: 36.2306, Validation Loss Current: 9.1332, Validation Loss AVG: 9.1332, lr: 0.001
Epoch [7/80], Training Loss: 34.7972, Validation Loss Current: 8.7980, Validation Loss AVG: 8.7980, lr: 0.001
Epoch [8/80], Training Loss: 33.4686, Validation Loss Current: 8.6960, Validation Loss AVG: 8.6960, lr: 0.001
Epoch [9/80], Training Loss: 33.4552, Validation Loss Current: 8.3717, Validation Loss AVG: 8.3717, lr: 0.001
Epoch [10/80], Training Loss: 31.2812, Validation Loss Current: 8.2247, Validation Loss AVG: 8.2247, lr: 0.001
Epoch [11/80], Training Loss: 31.2168, Validation Loss Current: 8.2761, Validation Loss AVG: 8.2761, lr: 0.001
Epoch [12/80], Training Loss: 30.6659, Validation Loss Current: 8.6087, Validation Loss AVG: 8.6087, lr: 0.001
Epoch [13/80], Training Loss: 29.5315, Validation Loss Current: 8.3311, Validation Loss AVG: 8.3311, lr: 0.001
Epoch [14/80], Training Loss: 28.8641, Validation Loss Current: 8.7773, Validation Loss AVG: 8.7773, lr: 0.001
Epoch [15/80], Training Loss: 29.6689, Validation Loss Current: 7.9858, Validation Loss AVG: 7.9858, lr: 0.001
Epoch [16/80], Training Loss: 29.1558, Validation Loss Current: 7.9106, Validation Loss AVG: 7.9106, lr: 0.001
Epoch [17/80], Training Loss: 27.5030, Validation Loss Current: 7.5741, Validation Loss AVG: 7.5741, lr: 0.001
Epoch [18/80], Training Loss: 27.3382, Validation Loss Current: 7.6002, Validation Loss AVG: 7.6002, lr: 0.001
Epoch [19/80], Training Loss: 27.4166, Validation Loss Current: 7.5850, Validation Loss AVG: 7.5850, lr: 0.001
Epoch [20/80], Training Loss: 26.7645, Validation Loss Current: 7.5400, Validation Loss AVG: 7.5400, lr: 0.001
Epoch [21/80], Training Loss: 24.9117, Validation Loss Current: 7.7174, Validation Loss AVG: 7.7174, lr: 0.001
Epoch [22/80], Training Loss: 25.0043, Validation Loss Current: 7.3291, Validation Loss AVG: 7.3291, lr: 0.001
Epoch [23/80], Training Loss: 23.2679, Validation Loss Current: 6.9432, Validation Loss AVG: 6.9432, lr: 0.001
Epoch [24/80], Training Loss: 23.0891, Validation Loss Current: 7.2790, Validation Loss AVG: 7.2790, lr: 0.001
Epoch [25/80], Training Loss: 21.5571, Validation Loss Current: 6.7703, Validation Loss AVG: 6.7703, lr: 0.001
Epoch [26/80], Training Loss: 21.0593, Validation Loss Current: 7.2141, Validation Loss AVG: 7.2141, lr: 0.001
Epoch [27/80], Training Loss: 21.2387, Validation Loss Current: 6.8415, Validation Loss AVG: 6.8415, lr: 0.001
Epoch [28/80], Training Loss: 20.7407, Validation Loss Current: 7.0376, Validation Loss AVG: 7.0376, lr: 0.001
Epoch [29/80], Training Loss: 21.7026, Validation Loss Current: 7.1604, Validation Loss AVG: 7.1604, lr: 0.001
Epoch [30/80], Training Loss: 19.4048, Validation Loss Current: 6.9600, Validation Loss AVG: 6.9600, lr: 0.001
Epoch [31/80], Training Loss: 18.0895, Validation Loss Current: 6.7199, Validation Loss AVG: 6.7199, lr: 0.001
Epoch [32/80], Training Loss: 16.5815, Validation Loss Current: 8.0397, Validation Loss AVG: 8.0397, lr: 0.001
Epoch [33/80], Training Loss: 17.1416, Validation Loss Current: 6.9225, Validation Loss AVG: 6.9225, lr: 0.001
Epoch [34/80], Training Loss: 16.4239, Validation Loss Current: 6.6718, Validation Loss AVG: 6.6718, lr: 0.001
Epoch [35/80], Training Loss: 14.3561, Validation Loss Current: 7.1546, Validation Loss AVG: 7.1546, lr: 0.001
Epoch [36/80], Training Loss: 15.0621, Validation Loss Current: 6.9339, Validation Loss AVG: 6.9339, lr: 0.001
Epoch [37/80], Training Loss: 14.6890, Validation Loss Current: 8.0976, Validation Loss AVG: 8.0976, lr: 0.001
Epoch [38/80], Training Loss: 12.8816, Validation Loss Current: 6.8145, Validation Loss AVG: 6.8145, lr: 0.001
Epoch [39/80], Training Loss: 11.6223, Validation Loss Current: 8.3315, Validation Loss AVG: 8.3315, lr: 0.001
Epoch [40/80], Training Loss: 11.5108, Validation Loss Current: 7.1436, Validation Loss AVG: 7.1436, lr: 0.001
Epoch [41/80], Training Loss: 12.0766, Validation Loss Current: 7.3558, Validation Loss AVG: 7.3558, lr: 0.001
Epoch [42/80], Training Loss: 11.9907, Validation Loss Current: 6.9228, Validation Loss AVG: 6.9228, lr: 0.001
Epoch [43/80], Training Loss: 12.8978, Validation Loss Current: 9.2490, Validation Loss AVG: 9.2490, lr: 0.001
Epoch [44/80], Training Loss: 10.3222, Validation Loss Current: 8.1059, Validation Loss AVG: 8.1059, lr: 0.001
Epoch [45/80], Training Loss: 8.0917, Validation Loss Current: 6.6954, Validation Loss AVG: 6.6954, lr: 0.001
Epoch [46/80], Training Loss: 6.7393, Validation Loss Current: 6.8552, Validation Loss AVG: 6.8552, lr: 0.001
Epoch [47/80], Training Loss: 7.4745, Validation Loss Current: 6.9823, Validation Loss AVG: 6.9823, lr: 0.001
Epoch [48/80], Training Loss: 7.3437, Validation Loss Current: 8.2788, Validation Loss AVG: 8.2788, lr: 0.001
Epoch [49/80], Training Loss: 6.6770, Validation Loss Current: 7.1261, Validation Loss AVG: 7.1261, lr: 0.001
Epoch [50/80], Training Loss: 5.3487, Validation Loss Current: 7.9161, Validation Loss AVG: 7.9161, lr: 0.001
Epoch [51/80], Training Loss: 6.2671, Validation Loss Current: 12.2504, Validation Loss AVG: 12.2504, lr: 0.001
Epoch [52/80], Training Loss: 6.6007, Validation Loss Current: 6.8074, Validation Loss AVG: 6.8074, lr: 0.001
Epoch [53/80], Training Loss: 4.2599, Validation Loss Current: 7.8694, Validation Loss AVG: 7.8694, lr: 0.001
Epoch [54/80], Training Loss: 4.6841, Validation Loss Current: 8.1348, Validation Loss AVG: 8.1348, lr: 0.001
Epoch [55/80], Training Loss: 7.2172, Validation Loss Current: 8.1493, Validation Loss AVG: 8.1493, lr: 0.001
Epoch [56/80], Training Loss: 7.1001, Validation Loss Current: 8.2069, Validation Loss AVG: 8.2069, lr: 0.001
Epoch [57/80], Training Loss: 4.5198, Validation Loss Current: 7.7706, Validation Loss AVG: 7.7706, lr: 0.001
Epoch [58/80], Training Loss: 4.6042, Validation Loss Current: 8.9633, Validation Loss AVG: 8.9633, lr: 0.001
Epoch [59/80], Training Loss: 4.9066, Validation Loss Current: 7.7519, Validation Loss AVG: 7.7519, lr: 0.001
Epoch [60/80], Training Loss: 5.1231, Validation Loss Current: 10.4380, Validation Loss AVG: 10.4380, lr: 0.001
Epoch [61/80], Training Loss: 4.6536, Validation Loss Current: 8.1025, Validation Loss AVG: 8.1025, lr: 0.001
Epoch [62/80], Training Loss: 4.7591, Validation Loss Current: 8.1803, Validation Loss AVG: 8.1803, lr: 0.001
Epoch [63/80], Training Loss: 6.0787, Validation Loss Current: 8.2284, Validation Loss AVG: 8.2284, lr: 0.001
Epoch [64/80], Training Loss: 4.7293, Validation Loss Current: 8.4252, Validation Loss AVG: 8.4252, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random0 finished training. Best epoch: 34 Best val accuracy: [0.23947368421052628, 0.2618421052631579, 0.30657894736842106, 0.3197368421052632, 0.31019736842105267, 0.35657894736842105, 0.36447368421052634, 0.3605263157894737, 0.4167763157894736, 0.4134868421052632, 0.42434210526315785, 0.36677631578947373, 0.3907894736842105, 0.3769736842105263, 0.43157894736842106, 0.43421052631578955, 0.46611842105263157, 0.4631578947368421, 0.4625, 0.4552631578947368, 0.4457236842105264, 0.46907894736842104, 0.5095394736842105, 0.4858552631578947, 0.53125, 0.4789473684210527, 0.5230263157894737, 0.5095394736842105, 0.499342105263158, 0.5217105263157895, 0.5325657894736843, 0.4720394736842105, 0.5217105263157894, 0.5483552631578947, 0.5223684210526316, 0.5411184210526315, 0.46842105263157896, 0.5473684210526316, 0.4891447368421053, 0.5230263157894737, 0.5138157894736842, 0.5592105263157894, 0.4743421052631579, 0.5305921052631579, 0.5723684210526316, 0.5726973684210527, 0.5434210526315789, 0.5125, 0.5578947368421053, 0.5417763157894737, 0.4302631578947368, 0.5907894736842104, 0.5526315789473685, 0.5430921052631579, 0.5174342105263158, 0.5407894736842105, 0.5453947368421053, 0.5476973684210525, 0.5625, 0.46578947368421053, 0.5726973684210527, 0.5217105263157895, 0.55, 0.5648026315789474] Best val loss: 6.671823668479919


Current group: llo_0.2_random1
Epoch [1/80], Training Loss: 29.9315, Validation Loss Current: 8.6341, Validation Loss AVG: 8.6341, lr: 0.001
Epoch [2/80], Training Loss: 23.2448, Validation Loss Current: 7.0641, Validation Loss AVG: 7.0641, lr: 0.001
Epoch [3/80], Training Loss: 16.3652, Validation Loss Current: 6.3317, Validation Loss AVG: 6.3317, lr: 0.001
Epoch [4/80], Training Loss: 14.0130, Validation Loss Current: 6.3116, Validation Loss AVG: 6.3116, lr: 0.001
Epoch [5/80], Training Loss: 11.1172, Validation Loss Current: 6.3590, Validation Loss AVG: 6.3590, lr: 0.001
Epoch [6/80], Training Loss: 11.5465, Validation Loss Current: 5.9661, Validation Loss AVG: 5.9661, lr: 0.001
Epoch [7/80], Training Loss: 12.6938, Validation Loss Current: 10.0011, Validation Loss AVG: 10.0011, lr: 0.001
Epoch [8/80], Training Loss: 21.1834, Validation Loss Current: 7.2586, Validation Loss AVG: 7.2586, lr: 0.001
Epoch [9/80], Training Loss: 15.2106, Validation Loss Current: 6.9459, Validation Loss AVG: 6.9459, lr: 0.001
Epoch [10/80], Training Loss: 11.9110, Validation Loss Current: 6.3105, Validation Loss AVG: 6.3105, lr: 0.001
Epoch [11/80], Training Loss: 7.4705, Validation Loss Current: 6.1871, Validation Loss AVG: 6.1871, lr: 0.001
Epoch [12/80], Training Loss: 7.6963, Validation Loss Current: 5.7991, Validation Loss AVG: 5.7991, lr: 0.001
Epoch [13/80], Training Loss: 7.3573, Validation Loss Current: 6.1080, Validation Loss AVG: 6.1080, lr: 0.001
Epoch [14/80], Training Loss: 5.9956, Validation Loss Current: 7.6191, Validation Loss AVG: 7.6191, lr: 0.001
Epoch [15/80], Training Loss: 7.2867, Validation Loss Current: 7.2028, Validation Loss AVG: 7.2028, lr: 0.001
Epoch [16/80], Training Loss: 7.0412, Validation Loss Current: 7.7372, Validation Loss AVG: 7.7372, lr: 0.001
Epoch [17/80], Training Loss: 5.5924, Validation Loss Current: 6.9719, Validation Loss AVG: 6.9719, lr: 0.001
Epoch [18/80], Training Loss: 5.5257, Validation Loss Current: 6.7607, Validation Loss AVG: 6.7607, lr: 0.001
Epoch [19/80], Training Loss: 7.9350, Validation Loss Current: 6.8472, Validation Loss AVG: 6.8472, lr: 0.001
Epoch [20/80], Training Loss: 9.0352, Validation Loss Current: 12.1762, Validation Loss AVG: 12.1762, lr: 0.001
Epoch [21/80], Training Loss: 11.5630, Validation Loss Current: 9.2927, Validation Loss AVG: 9.2927, lr: 0.001
Epoch [22/80], Training Loss: 10.9590, Validation Loss Current: 8.8201, Validation Loss AVG: 8.8201, lr: 0.001
Epoch [23/80], Training Loss: 7.2395, Validation Loss Current: 8.6107, Validation Loss AVG: 8.6107, lr: 0.001
Epoch [24/80], Training Loss: 6.3545, Validation Loss Current: 8.6417, Validation Loss AVG: 8.6417, lr: 0.001
Epoch [25/80], Training Loss: 7.1742, Validation Loss Current: 8.3597, Validation Loss AVG: 8.3597, lr: 0.001
Epoch [26/80], Training Loss: 6.4016, Validation Loss Current: 7.5424, Validation Loss AVG: 7.5424, lr: 0.001
Epoch [27/80], Training Loss: 4.6953, Validation Loss Current: 7.0280, Validation Loss AVG: 7.0280, lr: 0.001
Epoch [28/80], Training Loss: 3.7028, Validation Loss Current: 7.0364, Validation Loss AVG: 7.0364, lr: 0.001
Epoch [29/80], Training Loss: 5.0462, Validation Loss Current: 7.8443, Validation Loss AVG: 7.8443, lr: 0.001
Epoch [30/80], Training Loss: 4.3817, Validation Loss Current: 7.6206, Validation Loss AVG: 7.6206, lr: 0.001
Epoch [31/80], Training Loss: 3.6863, Validation Loss Current: 7.2881, Validation Loss AVG: 7.2881, lr: 0.001
Epoch [32/80], Training Loss: 1.5894, Validation Loss Current: 6.3487, Validation Loss AVG: 6.3487, lr: 0.001
Epoch [33/80], Training Loss: 1.2614, Validation Loss Current: 6.5276, Validation Loss AVG: 6.5276, lr: 0.001
Epoch [34/80], Training Loss: 4.3489, Validation Loss Current: 7.8886, Validation Loss AVG: 7.8886, lr: 0.001
Epoch [35/80], Training Loss: 5.0823, Validation Loss Current: 7.3827, Validation Loss AVG: 7.3827, lr: 0.001
Epoch [36/80], Training Loss: 6.2984, Validation Loss Current: 7.9595, Validation Loss AVG: 7.9595, lr: 0.001
Epoch [37/80], Training Loss: 3.4686, Validation Loss Current: 7.0651, Validation Loss AVG: 7.0651, lr: 0.001
Epoch [38/80], Training Loss: 6.0811, Validation Loss Current: 9.6760, Validation Loss AVG: 9.6760, lr: 0.001
Epoch [39/80], Training Loss: 3.0738, Validation Loss Current: 8.4795, Validation Loss AVG: 8.4795, lr: 0.001
Epoch [40/80], Training Loss: 2.3663, Validation Loss Current: 7.0148, Validation Loss AVG: 7.0148, lr: 0.001
Epoch [41/80], Training Loss: 4.0010, Validation Loss Current: 8.0939, Validation Loss AVG: 8.0939, lr: 0.001
Epoch [42/80], Training Loss: 4.8910, Validation Loss Current: 8.7947, Validation Loss AVG: 8.7947, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random1 finished training. Best epoch: 12 Best val accuracy: [0.5398026315789475, 0.5575657894736842, 0.6098684210526315, 0.5976973684210527, 0.6207236842105264, 0.612171052631579, 0.4848684210526316, 0.5463815789473684, 0.5529605263157895, 0.6118421052631579, 0.6111842105263158, 0.6309210526315789, 0.6427631578947368, 0.55625, 0.5677631578947369, 0.5361842105263157, 0.5973684210526315, 0.6075657894736842, 0.6036184210526315, 0.49703947368421053, 0.4894736842105264, 0.5180921052631579, 0.5417763157894737, 0.5516447368421054, 0.5894736842105264, 0.5888157894736843, 0.6125, 0.6042763157894737, 0.575, 0.5990131578947369, 0.5986842105263157, 0.6351973684210526, 0.6421052631578947, 0.5703947368421052, 0.6134868421052632, 0.5677631578947369, 0.6194078947368421, 0.562171052631579, 0.5983552631578948, 0.6207236842105264, 0.6013157894736842, 0.5509868421052632] Best val loss: 5.799071288108825


Current group: llo_0.2_random2
Epoch [1/80], Training Loss: 30.5149, Validation Loss Current: 8.6268, Validation Loss AVG: 8.6268, lr: 0.001
Epoch [2/80], Training Loss: 23.4528, Validation Loss Current: 8.5545, Validation Loss AVG: 8.5545, lr: 0.001
Epoch [3/80], Training Loss: 16.2495, Validation Loss Current: 6.7759, Validation Loss AVG: 6.7759, lr: 0.001
Epoch [4/80], Training Loss: 12.6250, Validation Loss Current: 6.3147, Validation Loss AVG: 6.3147, lr: 0.001
Epoch [5/80], Training Loss: 9.3808, Validation Loss Current: 6.0781, Validation Loss AVG: 6.0781, lr: 0.001
Epoch [6/80], Training Loss: 5.4018, Validation Loss Current: 5.9028, Validation Loss AVG: 5.9028, lr: 0.001
Epoch [7/80], Training Loss: 4.5720, Validation Loss Current: 6.5235, Validation Loss AVG: 6.5235, lr: 0.001
Epoch [8/80], Training Loss: 7.5185, Validation Loss Current: 6.8343, Validation Loss AVG: 6.8343, lr: 0.001
Epoch [9/80], Training Loss: 9.7428, Validation Loss Current: 7.9764, Validation Loss AVG: 7.9764, lr: 0.001
Epoch [10/80], Training Loss: 7.3937, Validation Loss Current: 6.3906, Validation Loss AVG: 6.3906, lr: 0.001
Epoch [11/80], Training Loss: 5.8344, Validation Loss Current: 8.3199, Validation Loss AVG: 8.3199, lr: 0.001
Epoch [12/80], Training Loss: 7.4964, Validation Loss Current: 7.9724, Validation Loss AVG: 7.9724, lr: 0.001
Epoch [13/80], Training Loss: 6.8712, Validation Loss Current: 6.7792, Validation Loss AVG: 6.7792, lr: 0.001
Epoch [14/80], Training Loss: 4.1733, Validation Loss Current: 6.0135, Validation Loss AVG: 6.0135, lr: 0.001
Epoch [15/80], Training Loss: 3.2804, Validation Loss Current: 7.1493, Validation Loss AVG: 7.1493, lr: 0.001
Epoch [16/80], Training Loss: 2.7587, Validation Loss Current: 6.6123, Validation Loss AVG: 6.6123, lr: 0.001
Epoch [17/80], Training Loss: 2.9921, Validation Loss Current: 6.9234, Validation Loss AVG: 6.9234, lr: 0.001
Epoch [18/80], Training Loss: 3.9733, Validation Loss Current: 7.9485, Validation Loss AVG: 7.9485, lr: 0.001
Epoch [19/80], Training Loss: 3.6320, Validation Loss Current: 8.8200, Validation Loss AVG: 8.8200, lr: 0.001
Epoch [20/80], Training Loss: 2.7633, Validation Loss Current: 6.5383, Validation Loss AVG: 6.5383, lr: 0.001
Epoch [21/80], Training Loss: 2.1472, Validation Loss Current: 6.4496, Validation Loss AVG: 6.4496, lr: 0.001
Epoch [22/80], Training Loss: 1.1081, Validation Loss Current: 6.4654, Validation Loss AVG: 6.4654, lr: 0.001
Epoch [23/80], Training Loss: 0.6454, Validation Loss Current: 6.4634, Validation Loss AVG: 6.4634, lr: 0.001
Epoch [24/80], Training Loss: 0.4643, Validation Loss Current: 7.0296, Validation Loss AVG: 7.0296, lr: 0.001
Epoch [25/80], Training Loss: 2.1244, Validation Loss Current: 6.6356, Validation Loss AVG: 6.6356, lr: 0.001
Epoch [26/80], Training Loss: 5.0938, Validation Loss Current: 8.7509, Validation Loss AVG: 8.7509, lr: 0.001
Epoch [27/80], Training Loss: 4.9466, Validation Loss Current: 7.5687, Validation Loss AVG: 7.5687, lr: 0.001
Epoch [28/80], Training Loss: 3.2396, Validation Loss Current: 7.8796, Validation Loss AVG: 7.8796, lr: 0.001
Epoch [29/80], Training Loss: 6.8853, Validation Loss Current: 8.5489, Validation Loss AVG: 8.5489, lr: 0.001
Epoch [30/80], Training Loss: 7.6428, Validation Loss Current: 8.7434, Validation Loss AVG: 8.7434, lr: 0.001
Epoch [31/80], Training Loss: 7.3230, Validation Loss Current: 8.3343, Validation Loss AVG: 8.3343, lr: 0.001
Epoch [32/80], Training Loss: 3.7943, Validation Loss Current: 7.2828, Validation Loss AVG: 7.2828, lr: 0.001
Epoch [33/80], Training Loss: 2.5690, Validation Loss Current: 8.2517, Validation Loss AVG: 8.2517, lr: 0.001
Epoch [34/80], Training Loss: 4.1354, Validation Loss Current: 8.0376, Validation Loss AVG: 8.0376, lr: 0.001
Epoch [35/80], Training Loss: 4.3448, Validation Loss Current: 7.7889, Validation Loss AVG: 7.7889, lr: 0.001
Epoch [36/80], Training Loss: 5.0511, Validation Loss Current: 8.8732, Validation Loss AVG: 8.8732, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random2 finished training. Best epoch: 6 Best val accuracy: [0.5555921052631579, 0.5457236842105264, 0.593421052631579, 0.6243421052631579, 0.6503289473684212, 0.6302631578947369, 0.636513157894737, 0.6055921052631579, 0.6075657894736842, 0.6292763157894737, 0.5957236842105263, 0.5569078947368421, 0.6180921052631578, 0.6292763157894737, 0.6190789473684211, 0.6371710526315789, 0.6210526315789473, 0.6072368421052632, 0.5726973684210527, 0.6348684210526316, 0.6378289473684211, 0.6384868421052631, 0.6480263157894737, 0.6450657894736842, 0.649671052631579, 0.5845394736842104, 0.6263157894736843, 0.5924342105263157, 0.5970394736842105, 0.5700657894736841, 0.5927631578947368, 0.6197368421052631, 0.5858552631578947, 0.6, 0.6131578947368421, 0.5960526315789474] Best val loss: 5.902826511859894


Current group: llo_0.2_random3
Epoch [1/80], Training Loss: 33.8023, Validation Loss Current: 6.5007, Validation Loss AVG: 6.5007, lr: 0.001
Epoch [2/80], Training Loss: 19.8654, Validation Loss Current: 6.5550, Validation Loss AVG: 6.5550, lr: 0.001
Epoch [3/80], Training Loss: 12.5181, Validation Loss Current: 5.4791, Validation Loss AVG: 5.4791, lr: 0.001
Epoch [4/80], Training Loss: 11.8601, Validation Loss Current: 6.0957, Validation Loss AVG: 6.0957, lr: 0.001
Epoch [5/80], Training Loss: 11.2779, Validation Loss Current: 5.6997, Validation Loss AVG: 5.6997, lr: 0.001
Epoch [6/80], Training Loss: 11.2839, Validation Loss Current: 5.9377, Validation Loss AVG: 5.9377, lr: 0.001
Epoch [7/80], Training Loss: 14.1687, Validation Loss Current: 8.5984, Validation Loss AVG: 8.5984, lr: 0.001
Epoch [8/80], Training Loss: 16.0704, Validation Loss Current: 7.7619, Validation Loss AVG: 7.7619, lr: 0.001
Epoch [9/80], Training Loss: 8.8985, Validation Loss Current: 6.6077, Validation Loss AVG: 6.6077, lr: 0.001
Epoch [10/80], Training Loss: 5.5651, Validation Loss Current: 5.4692, Validation Loss AVG: 5.4692, lr: 0.001
Epoch [11/80], Training Loss: 4.5030, Validation Loss Current: 5.9766, Validation Loss AVG: 5.9766, lr: 0.001
Epoch [12/80], Training Loss: 2.7292, Validation Loss Current: 5.0289, Validation Loss AVG: 5.0289, lr: 0.001
Epoch [13/80], Training Loss: 2.9889, Validation Loss Current: 5.6406, Validation Loss AVG: 5.6406, lr: 0.001
Epoch [14/80], Training Loss: 5.9911, Validation Loss Current: 5.9412, Validation Loss AVG: 5.9412, lr: 0.001
Epoch [15/80], Training Loss: 4.6522, Validation Loss Current: 5.6386, Validation Loss AVG: 5.6386, lr: 0.001
Epoch [16/80], Training Loss: 3.0539, Validation Loss Current: 5.7005, Validation Loss AVG: 5.7005, lr: 0.001
Epoch [17/80], Training Loss: 3.0418, Validation Loss Current: 5.9453, Validation Loss AVG: 5.9453, lr: 0.001
Epoch [18/80], Training Loss: 3.8412, Validation Loss Current: 9.8455, Validation Loss AVG: 9.8455, lr: 0.001
Epoch [19/80], Training Loss: 7.2397, Validation Loss Current: 11.1436, Validation Loss AVG: 11.1436, lr: 0.001
Epoch [20/80], Training Loss: 6.8121, Validation Loss Current: 7.8266, Validation Loss AVG: 7.8266, lr: 0.001
Epoch [21/80], Training Loss: 8.0638, Validation Loss Current: 8.1410, Validation Loss AVG: 8.1410, lr: 0.001
Epoch [22/80], Training Loss: 4.2139, Validation Loss Current: 6.6463, Validation Loss AVG: 6.6463, lr: 0.001
Epoch [23/80], Training Loss: 4.0185, Validation Loss Current: 6.0887, Validation Loss AVG: 6.0887, lr: 0.001
Epoch [24/80], Training Loss: 4.5756, Validation Loss Current: 6.7361, Validation Loss AVG: 6.7361, lr: 0.001
Epoch [25/80], Training Loss: 5.3249, Validation Loss Current: 6.6690, Validation Loss AVG: 6.6690, lr: 0.001
Epoch [26/80], Training Loss: 4.7244, Validation Loss Current: 7.0983, Validation Loss AVG: 7.0983, lr: 0.001
Epoch [27/80], Training Loss: 4.3538, Validation Loss Current: 6.8960, Validation Loss AVG: 6.8960, lr: 0.001
Epoch [28/80], Training Loss: 5.3492, Validation Loss Current: 9.1289, Validation Loss AVG: 9.1289, lr: 0.001
Epoch [29/80], Training Loss: 3.6250, Validation Loss Current: 7.1603, Validation Loss AVG: 7.1603, lr: 0.001
Epoch [30/80], Training Loss: 2.1031, Validation Loss Current: 6.4133, Validation Loss AVG: 6.4133, lr: 0.001
Epoch [31/80], Training Loss: 3.6047, Validation Loss Current: 6.5086, Validation Loss AVG: 6.5086, lr: 0.001
Epoch [32/80], Training Loss: 4.5737, Validation Loss Current: 7.0510, Validation Loss AVG: 7.0510, lr: 0.001
Epoch [33/80], Training Loss: 5.0171, Validation Loss Current: 6.4799, Validation Loss AVG: 6.4799, lr: 0.001
Epoch [34/80], Training Loss: 3.9758, Validation Loss Current: 7.5083, Validation Loss AVG: 7.5083, lr: 0.001
Epoch [35/80], Training Loss: 4.9239, Validation Loss Current: 6.5215, Validation Loss AVG: 6.5215, lr: 0.001
Epoch [36/80], Training Loss: 4.1661, Validation Loss Current: 6.5872, Validation Loss AVG: 6.5872, lr: 0.001
Epoch [37/80], Training Loss: 4.7193, Validation Loss Current: 6.9647, Validation Loss AVG: 6.9647, lr: 0.001
Epoch [38/80], Training Loss: 3.9097, Validation Loss Current: 7.1377, Validation Loss AVG: 7.1377, lr: 0.001
Epoch [39/80], Training Loss: 2.7087, Validation Loss Current: 6.4332, Validation Loss AVG: 6.4332, lr: 0.001
Epoch [40/80], Training Loss: 5.0646, Validation Loss Current: 6.7475, Validation Loss AVG: 6.7475, lr: 0.001
Epoch [41/80], Training Loss: 4.1789, Validation Loss Current: 7.2419, Validation Loss AVG: 7.2419, lr: 0.001
Epoch [42/80], Training Loss: 3.5269, Validation Loss Current: 7.4359, Validation Loss AVG: 7.4359, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random3 finished training. Best epoch: 12 Best val accuracy: [0.6161184210526316, 0.6282894736842105, 0.6592105263157895, 0.6578947368421052, 0.6536184210526316, 0.6509868421052631, 0.5496710526315789, 0.5805921052631579, 0.6111842105263159, 0.662828947368421, 0.6480263157894737, 0.6911184210526315, 0.6605263157894739, 0.6707236842105264, 0.6881578947368421, 0.6779605263157895, 0.66875, 0.5259868421052631, 0.5029605263157895, 0.6092105263157894, 0.5605263157894738, 0.6421052631578947, 0.6450657894736842, 0.6440789473684211, 0.6361842105263158, 0.6582236842105262, 0.6440789473684212, 0.5677631578947369, 0.6279605263157895, 0.66875, 0.6523026315789473, 0.6407894736842105, 0.6519736842105263, 0.6177631578947368, 0.667763157894737, 0.661842105263158, 0.6532894736842105, 0.6226973684210526, 0.6536184210526316, 0.6282894736842104, 0.6223684210526316, 0.6236842105263158] Best val loss: 5.02889096736908


Current group: 0.2
Epoch [1/80], Training Loss: 47.8695, Validation Loss Current: 14.2419, Validation Loss AVG: 14.2419, lr: 0.001
Epoch [2/80], Training Loss: 29.6620, Validation Loss Current: 14.0448, Validation Loss AVG: 14.0448, lr: 0.001
Epoch [3/80], Training Loss: 24.2725, Validation Loss Current: 15.5647, Validation Loss AVG: 15.5647, lr: 0.001
Epoch [4/80], Training Loss: 21.1302, Validation Loss Current: 13.6896, Validation Loss AVG: 13.6896, lr: 0.001
Epoch [5/80], Training Loss: 17.9701, Validation Loss Current: 10.8567, Validation Loss AVG: 10.8567, lr: 0.001
Epoch [6/80], Training Loss: 15.0593, Validation Loss Current: 11.4685, Validation Loss AVG: 11.4685, lr: 0.001
Epoch [7/80], Training Loss: 16.1414, Validation Loss Current: 15.9216, Validation Loss AVG: 15.9216, lr: 0.001
Epoch [8/80], Training Loss: 11.6042, Validation Loss Current: 11.3162, Validation Loss AVG: 11.3162, lr: 0.001
Epoch [9/80], Training Loss: 9.7729, Validation Loss Current: 13.2772, Validation Loss AVG: 13.2772, lr: 0.001
Epoch [10/80], Training Loss: 9.4422, Validation Loss Current: 12.9104, Validation Loss AVG: 12.9104, lr: 0.001
Epoch [11/80], Training Loss: 8.5751, Validation Loss Current: 15.4920, Validation Loss AVG: 15.4920, lr: 0.001
Epoch [12/80], Training Loss: 6.7448, Validation Loss Current: 16.7503, Validation Loss AVG: 16.7503, lr: 0.001
Epoch [13/80], Training Loss: 5.8465, Validation Loss Current: 13.1551, Validation Loss AVG: 13.1551, lr: 0.001
Epoch [14/80], Training Loss: 8.7034, Validation Loss Current: 17.4188, Validation Loss AVG: 17.4188, lr: 0.001
Epoch [15/80], Training Loss: 7.9780, Validation Loss Current: 17.1878, Validation Loss AVG: 17.1878, lr: 0.001
Epoch [16/80], Training Loss: 9.8188, Validation Loss Current: 20.1211, Validation Loss AVG: 20.1211, lr: 0.001
Epoch [17/80], Training Loss: 12.0680, Validation Loss Current: 18.4374, Validation Loss AVG: 18.4374, lr: 0.001
Epoch [18/80], Training Loss: 9.9078, Validation Loss Current: 17.8258, Validation Loss AVG: 17.8258, lr: 0.001
Epoch [19/80], Training Loss: 6.8509, Validation Loss Current: 16.4042, Validation Loss AVG: 16.4042, lr: 0.001
Epoch [20/80], Training Loss: 5.9359, Validation Loss Current: 15.6979, Validation Loss AVG: 15.6979, lr: 0.001
Epoch [21/80], Training Loss: 8.9496, Validation Loss Current: 17.2286, Validation Loss AVG: 17.2286, lr: 0.001
Epoch [22/80], Training Loss: 5.8484, Validation Loss Current: 16.6020, Validation Loss AVG: 16.6020, lr: 0.001
Epoch [23/80], Training Loss: 7.0391, Validation Loss Current: 15.7687, Validation Loss AVG: 15.7687, lr: 0.001
Epoch [24/80], Training Loss: 5.1384, Validation Loss Current: 14.4928, Validation Loss AVG: 14.4928, lr: 0.001
Epoch [25/80], Training Loss: 3.6928, Validation Loss Current: 15.6882, Validation Loss AVG: 15.6882, lr: 0.001
Epoch [26/80], Training Loss: 3.5301, Validation Loss Current: 19.4590, Validation Loss AVG: 19.4590, lr: 0.001
Epoch [27/80], Training Loss: 6.9225, Validation Loss Current: 22.1252, Validation Loss AVG: 22.1252, lr: 0.001
Epoch [28/80], Training Loss: 5.6933, Validation Loss Current: 19.2882, Validation Loss AVG: 19.2882, lr: 0.001
Epoch [29/80], Training Loss: 9.5062, Validation Loss Current: 25.7068, Validation Loss AVG: 25.7068, lr: 0.001
Epoch [30/80], Training Loss: 7.0949, Validation Loss Current: 20.0458, Validation Loss AVG: 20.0458, lr: 0.001
Epoch [31/80], Training Loss: 3.5414, Validation Loss Current: 14.5298, Validation Loss AVG: 14.5298, lr: 0.001
Epoch [32/80], Training Loss: 1.4796, Validation Loss Current: 16.1221, Validation Loss AVG: 16.1221, lr: 0.001
Epoch [33/80], Training Loss: 0.9076, Validation Loss Current: 14.3890, Validation Loss AVG: 14.3890, lr: 0.001
Epoch [34/80], Training Loss: 1.2230, Validation Loss Current: 17.7761, Validation Loss AVG: 17.7761, lr: 0.001
Epoch [35/80], Training Loss: 2.7802, Validation Loss Current: 17.0279, Validation Loss AVG: 17.0279, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 5 Best val accuracy: [0.38256578947368414, 0.33848684210526314, 0.3138157894736842, 0.3648026315789473, 0.44375, 0.46644736842105256, 0.3838815789473684, 0.46907894736842104, 0.3611842105263158, 0.4233552631578948, 0.3986842105263158, 0.3279605263157895, 0.4, 0.34375, 0.3453947368421052, 0.38355263157894737, 0.30953947368421053, 0.35263157894736846, 0.3503289473684211, 0.38190789473684206, 0.3717105263157895, 0.42434210526315785, 0.42598684210526316, 0.43125, 0.3871710526315789, 0.3680921052631579, 0.34638157894736843, 0.3773026315789474, 0.2473684210526316, 0.3680921052631579, 0.42664473684210524, 0.4098684210526315, 0.44375, 0.3677631578947368, 0.4052631578947368] Best val loss: 10.856681656837463


----- Training resnet18 with sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] -----
Current group: llo_0.8_random0
Epoch [1/80], Training Loss: 40.7821, Validation Loss Current: 10.0312, Validation Loss AVG: 10.0312, lr: 0.001
Epoch [2/80], Training Loss: 40.1939, Validation Loss Current: 9.9217, Validation Loss AVG: 9.9217, lr: 0.001
Epoch [3/80], Training Loss: 39.4941, Validation Loss Current: 9.8133, Validation Loss AVG: 9.8133, lr: 0.001
Epoch [4/80], Training Loss: 38.5347, Validation Loss Current: 9.5144, Validation Loss AVG: 9.5144, lr: 0.001
Epoch [5/80], Training Loss: 38.1605, Validation Loss Current: 9.4634, Validation Loss AVG: 9.4634, lr: 0.001
Epoch [6/80], Training Loss: 37.3327, Validation Loss Current: 9.1095, Validation Loss AVG: 9.1095, lr: 0.001
Epoch [7/80], Training Loss: 36.0840, Validation Loss Current: 8.9845, Validation Loss AVG: 8.9845, lr: 0.001
Epoch [8/80], Training Loss: 35.4690, Validation Loss Current: 8.9508, Validation Loss AVG: 8.9508, lr: 0.001
Epoch [9/80], Training Loss: 33.8809, Validation Loss Current: 8.5521, Validation Loss AVG: 8.5521, lr: 0.001
Epoch [10/80], Training Loss: 33.7271, Validation Loss Current: 8.5906, Validation Loss AVG: 8.5906, lr: 0.001
Epoch [11/80], Training Loss: 33.7008, Validation Loss Current: 8.0953, Validation Loss AVG: 8.0953, lr: 0.001
Epoch [12/80], Training Loss: 31.8705, Validation Loss Current: 7.9538, Validation Loss AVG: 7.9538, lr: 0.001
Epoch [13/80], Training Loss: 31.3808, Validation Loss Current: 7.7653, Validation Loss AVG: 7.7653, lr: 0.001
Epoch [14/80], Training Loss: 30.9693, Validation Loss Current: 7.4866, Validation Loss AVG: 7.4866, lr: 0.001
Epoch [15/80], Training Loss: 30.3082, Validation Loss Current: 7.6231, Validation Loss AVG: 7.6231, lr: 0.001
Epoch [16/80], Training Loss: 29.6952, Validation Loss Current: 8.0364, Validation Loss AVG: 8.0364, lr: 0.001
Epoch [17/80], Training Loss: 29.7600, Validation Loss Current: 8.3135, Validation Loss AVG: 8.3135, lr: 0.001
Epoch [18/80], Training Loss: 28.5779, Validation Loss Current: 7.3173, Validation Loss AVG: 7.3173, lr: 0.001
Epoch [19/80], Training Loss: 26.1806, Validation Loss Current: 7.5421, Validation Loss AVG: 7.5421, lr: 0.001
Epoch [20/80], Training Loss: 27.4340, Validation Loss Current: 7.3204, Validation Loss AVG: 7.3204, lr: 0.001
Epoch [21/80], Training Loss: 25.6224, Validation Loss Current: 7.0572, Validation Loss AVG: 7.0572, lr: 0.001
Epoch [22/80], Training Loss: 26.5714, Validation Loss Current: 7.3553, Validation Loss AVG: 7.3553, lr: 0.001
Epoch [23/80], Training Loss: 25.7579, Validation Loss Current: 7.1854, Validation Loss AVG: 7.1854, lr: 0.001
Epoch [24/80], Training Loss: 24.0575, Validation Loss Current: 6.9387, Validation Loss AVG: 6.9387, lr: 0.001
Epoch [25/80], Training Loss: 22.9579, Validation Loss Current: 7.4611, Validation Loss AVG: 7.4611, lr: 0.001
Epoch [26/80], Training Loss: 22.6256, Validation Loss Current: 6.9882, Validation Loss AVG: 6.9882, lr: 0.001
Epoch [27/80], Training Loss: 22.0876, Validation Loss Current: 7.0726, Validation Loss AVG: 7.0726, lr: 0.001
Epoch [28/80], Training Loss: 22.2324, Validation Loss Current: 6.8028, Validation Loss AVG: 6.8028, lr: 0.001
Epoch [29/80], Training Loss: 19.9864, Validation Loss Current: 6.7036, Validation Loss AVG: 6.7036, lr: 0.001
Epoch [30/80], Training Loss: 18.3515, Validation Loss Current: 7.0208, Validation Loss AVG: 7.0208, lr: 0.001
Epoch [31/80], Training Loss: 18.7007, Validation Loss Current: 6.4201, Validation Loss AVG: 6.4201, lr: 0.001
Epoch [32/80], Training Loss: 17.3086, Validation Loss Current: 6.4403, Validation Loss AVG: 6.4403, lr: 0.001
Epoch [33/80], Training Loss: 18.1359, Validation Loss Current: 6.9185, Validation Loss AVG: 6.9185, lr: 0.001
Epoch [34/80], Training Loss: 18.9184, Validation Loss Current: 7.0188, Validation Loss AVG: 7.0188, lr: 0.001
Epoch [35/80], Training Loss: 18.0713, Validation Loss Current: 6.8121, Validation Loss AVG: 6.8121, lr: 0.001
Epoch [36/80], Training Loss: 17.3324, Validation Loss Current: 7.6293, Validation Loss AVG: 7.6293, lr: 0.001
Epoch [37/80], Training Loss: 20.7826, Validation Loss Current: 7.8490, Validation Loss AVG: 7.8490, lr: 0.001
Epoch [38/80], Training Loss: 19.0825, Validation Loss Current: 7.4606, Validation Loss AVG: 7.4606, lr: 0.001
Epoch [39/80], Training Loss: 15.9033, Validation Loss Current: 7.0658, Validation Loss AVG: 7.0658, lr: 0.001
Epoch [40/80], Training Loss: 15.3721, Validation Loss Current: 8.1480, Validation Loss AVG: 8.1480, lr: 0.001
Epoch [41/80], Training Loss: 11.7187, Validation Loss Current: 6.4347, Validation Loss AVG: 6.4347, lr: 0.001
Epoch [42/80], Training Loss: 11.6787, Validation Loss Current: 8.2725, Validation Loss AVG: 8.2725, lr: 0.001
Epoch [43/80], Training Loss: 12.9027, Validation Loss Current: 8.4696, Validation Loss AVG: 8.4696, lr: 0.001
Epoch [44/80], Training Loss: 12.1278, Validation Loss Current: 6.6870, Validation Loss AVG: 6.6870, lr: 0.001
Epoch [45/80], Training Loss: 11.5858, Validation Loss Current: 7.1973, Validation Loss AVG: 7.1973, lr: 0.001
Epoch [46/80], Training Loss: 10.5275, Validation Loss Current: 6.7354, Validation Loss AVG: 6.7354, lr: 0.001
Epoch [47/80], Training Loss: 7.9374, Validation Loss Current: 6.3296, Validation Loss AVG: 6.3296, lr: 0.001
Epoch [48/80], Training Loss: 7.4334, Validation Loss Current: 6.9516, Validation Loss AVG: 6.9516, lr: 0.001
Epoch [49/80], Training Loss: 8.6461, Validation Loss Current: 8.0653, Validation Loss AVG: 8.0653, lr: 0.001
Epoch [50/80], Training Loss: 8.8041, Validation Loss Current: 7.1717, Validation Loss AVG: 7.1717, lr: 0.001
Epoch [51/80], Training Loss: 7.4275, Validation Loss Current: 7.9993, Validation Loss AVG: 7.9993, lr: 0.001
Epoch [52/80], Training Loss: 9.1843, Validation Loss Current: 9.7786, Validation Loss AVG: 9.7786, lr: 0.001
Epoch [53/80], Training Loss: 6.8005, Validation Loss Current: 6.7722, Validation Loss AVG: 6.7722, lr: 0.001
Epoch [54/80], Training Loss: 4.7834, Validation Loss Current: 6.3513, Validation Loss AVG: 6.3513, lr: 0.001
Epoch [55/80], Training Loss: 5.3649, Validation Loss Current: 6.7838, Validation Loss AVG: 6.7838, lr: 0.001
Epoch [56/80], Training Loss: 5.5142, Validation Loss Current: 7.4371, Validation Loss AVG: 7.4371, lr: 0.001
Epoch [57/80], Training Loss: 6.2876, Validation Loss Current: 7.2947, Validation Loss AVG: 7.2947, lr: 0.001
Epoch [58/80], Training Loss: 9.1698, Validation Loss Current: 8.9500, Validation Loss AVG: 8.9500, lr: 0.001
Epoch [59/80], Training Loss: 12.1659, Validation Loss Current: 11.2387, Validation Loss AVG: 11.2387, lr: 0.001
Epoch [60/80], Training Loss: 6.0082, Validation Loss Current: 7.1530, Validation Loss AVG: 7.1530, lr: 0.001
Epoch [61/80], Training Loss: 5.2638, Validation Loss Current: 7.5841, Validation Loss AVG: 7.5841, lr: 0.001
Epoch [62/80], Training Loss: 6.4264, Validation Loss Current: 8.1547, Validation Loss AVG: 8.1547, lr: 0.001
Epoch [63/80], Training Loss: 7.6583, Validation Loss Current: 7.1809, Validation Loss AVG: 7.1809, lr: 0.001
Epoch [64/80], Training Loss: 8.3612, Validation Loss Current: 7.8650, Validation Loss AVG: 7.8650, lr: 0.001
Epoch [65/80], Training Loss: 6.9407, Validation Loss Current: 8.6782, Validation Loss AVG: 8.6782, lr: 0.001
Epoch [66/80], Training Loss: 10.3044, Validation Loss Current: 9.0927, Validation Loss AVG: 9.0927, lr: 0.001
Epoch [67/80], Training Loss: 9.2466, Validation Loss Current: 8.9503, Validation Loss AVG: 8.9503, lr: 0.001
Epoch [68/80], Training Loss: 5.3480, Validation Loss Current: 8.5780, Validation Loss AVG: 8.5780, lr: 0.001
Epoch [69/80], Training Loss: 3.6424, Validation Loss Current: 7.2008, Validation Loss AVG: 7.2008, lr: 0.001
Epoch [70/80], Training Loss: 4.9021, Validation Loss Current: 7.8826, Validation Loss AVG: 7.8826, lr: 0.001
Epoch [71/80], Training Loss: 4.7621, Validation Loss Current: 8.6086, Validation Loss AVG: 8.6086, lr: 0.001
Epoch [72/80], Training Loss: 5.2338, Validation Loss Current: 8.7855, Validation Loss AVG: 8.7855, lr: 0.001
Epoch [73/80], Training Loss: 8.6469, Validation Loss Current: 12.4392, Validation Loss AVG: 12.4392, lr: 0.001
Epoch [74/80], Training Loss: 11.0929, Validation Loss Current: 16.3520, Validation Loss AVG: 16.3520, lr: 0.001
Epoch [75/80], Training Loss: 11.2321, Validation Loss Current: 13.9314, Validation Loss AVG: 13.9314, lr: 0.001
Epoch [76/80], Training Loss: 7.4538, Validation Loss Current: 9.3623, Validation Loss AVG: 9.3623, lr: 0.001
Epoch [77/80], Training Loss: 6.6409, Validation Loss Current: 8.9772, Validation Loss AVG: 8.9772, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random0 finished training. Best epoch: 47 Best val accuracy: [0.23815789473684212, 0.27368421052631586, 0.26085526315789476, 0.3003289473684211, 0.32335526315789476, 0.3371710526315789, 0.3595394736842105, 0.3391447368421052, 0.3940789473684211, 0.37796052631578947, 0.43486842105263157, 0.44046052631578947, 0.45394736842105265, 0.48881578947368426, 0.44605263157894737, 0.43782894736842104, 0.4128289473684211, 0.48684210526315785, 0.46644736842105267, 0.4822368421052632, 0.5078947368421053, 0.4720394736842105, 0.5006578947368421, 0.5092105263157894, 0.4838815789473684, 0.5019736842105263, 0.5032894736842105, 0.5299342105263157, 0.5384868421052632, 0.50625, 0.5542763157894737, 0.555921052631579, 0.5263157894736843, 0.5151315789473684, 0.5243421052631578, 0.4930921052631579, 0.4930921052631579, 0.48914473684210524, 0.5019736842105263, 0.4805921052631579, 0.555921052631579, 0.4825657894736842, 0.4529605263157895, 0.5516447368421054, 0.5519736842105263, 0.5582236842105264, 0.5960526315789474, 0.5608552631578948, 0.5082236842105263, 0.5447368421052632, 0.5407894736842105, 0.5095394736842105, 0.5736842105263158, 0.6105263157894737, 0.5756578947368421, 0.5513157894736842, 0.5726973684210527, 0.4861842105263158, 0.44506578947368425, 0.5519736842105263, 0.5634868421052631, 0.5641447368421053, 0.5720394736842105, 0.5434210526315789, 0.5338815789473684, 0.5154605263157894, 0.5184210526315789, 0.5467105263157895, 0.5911184210526315, 0.5519736842105264, 0.5421052631578946, 0.5453947368421053, 0.4009868421052632, 0.37203947368421053, 0.43519736842105267, 0.5444078947368421, 0.524671052631579] Best val loss: 6.329597759246826


Current group: llo_0.8_random1
Epoch [1/80], Training Loss: 36.6981, Validation Loss Current: 9.7725, Validation Loss AVG: 9.7725, lr: 0.001
Epoch [2/80], Training Loss: 28.6856, Validation Loss Current: 8.6711, Validation Loss AVG: 8.6711, lr: 0.001
Epoch [3/80], Training Loss: 21.6173, Validation Loss Current: 7.5485, Validation Loss AVG: 7.5485, lr: 0.001
Epoch [4/80], Training Loss: 19.0501, Validation Loss Current: 7.0153, Validation Loss AVG: 7.0153, lr: 0.001
Epoch [5/80], Training Loss: 14.4804, Validation Loss Current: 5.8121, Validation Loss AVG: 5.8121, lr: 0.001
Epoch [6/80], Training Loss: 14.3323, Validation Loss Current: 8.8496, Validation Loss AVG: 8.8496, lr: 0.001
Epoch [7/80], Training Loss: 13.6327, Validation Loss Current: 6.5399, Validation Loss AVG: 6.5399, lr: 0.001
Epoch [8/80], Training Loss: 11.4736, Validation Loss Current: 6.9447, Validation Loss AVG: 6.9447, lr: 0.001
Epoch [9/80], Training Loss: 10.9280, Validation Loss Current: 7.1636, Validation Loss AVG: 7.1636, lr: 0.001
Epoch [10/80], Training Loss: 11.9361, Validation Loss Current: 9.6849, Validation Loss AVG: 9.6849, lr: 0.001
Epoch [11/80], Training Loss: 17.4648, Validation Loss Current: 9.3520, Validation Loss AVG: 9.3520, lr: 0.001
Epoch [12/80], Training Loss: 12.1784, Validation Loss Current: 7.8717, Validation Loss AVG: 7.8717, lr: 0.001
Epoch [13/80], Training Loss: 8.5943, Validation Loss Current: 9.3106, Validation Loss AVG: 9.3106, lr: 0.001
Epoch [14/80], Training Loss: 6.3897, Validation Loss Current: 7.3882, Validation Loss AVG: 7.3882, lr: 0.001
Epoch [15/80], Training Loss: 5.6105, Validation Loss Current: 7.1163, Validation Loss AVG: 7.1163, lr: 0.001
Epoch [16/80], Training Loss: 6.7953, Validation Loss Current: 7.7868, Validation Loss AVG: 7.7868, lr: 0.001
Epoch [17/80], Training Loss: 7.0455, Validation Loss Current: 7.9171, Validation Loss AVG: 7.9171, lr: 0.001
Epoch [18/80], Training Loss: 5.7812, Validation Loss Current: 9.2582, Validation Loss AVG: 9.2582, lr: 0.001
Epoch [19/80], Training Loss: 7.7226, Validation Loss Current: 8.8393, Validation Loss AVG: 8.8393, lr: 0.001
Epoch [20/80], Training Loss: 4.6762, Validation Loss Current: 7.6859, Validation Loss AVG: 7.6859, lr: 0.001
Epoch [21/80], Training Loss: 6.3471, Validation Loss Current: 7.5190, Validation Loss AVG: 7.5190, lr: 0.001
Epoch [22/80], Training Loss: 11.6348, Validation Loss Current: 10.3273, Validation Loss AVG: 10.3273, lr: 0.001
Epoch [23/80], Training Loss: 12.5198, Validation Loss Current: 10.4679, Validation Loss AVG: 10.4679, lr: 0.001
Epoch [24/80], Training Loss: 9.2419, Validation Loss Current: 8.5934, Validation Loss AVG: 8.5934, lr: 0.001
Epoch [25/80], Training Loss: 10.2842, Validation Loss Current: 9.6371, Validation Loss AVG: 9.6371, lr: 0.001
Epoch [26/80], Training Loss: 7.7867, Validation Loss Current: 7.3952, Validation Loss AVG: 7.3952, lr: 0.001
Epoch [27/80], Training Loss: 5.7847, Validation Loss Current: 7.8381, Validation Loss AVG: 7.8381, lr: 0.001
Epoch [28/80], Training Loss: 7.5189, Validation Loss Current: 7.5503, Validation Loss AVG: 7.5503, lr: 0.001
Epoch [29/80], Training Loss: 4.8142, Validation Loss Current: 8.1784, Validation Loss AVG: 8.1784, lr: 0.001
Epoch [30/80], Training Loss: 6.5401, Validation Loss Current: 7.4845, Validation Loss AVG: 7.4845, lr: 0.001
Epoch [31/80], Training Loss: 7.9969, Validation Loss Current: 8.1714, Validation Loss AVG: 8.1714, lr: 0.001
Epoch [32/80], Training Loss: 6.6173, Validation Loss Current: 8.9862, Validation Loss AVG: 8.9862, lr: 0.001
Epoch [33/80], Training Loss: 4.0619, Validation Loss Current: 7.1246, Validation Loss AVG: 7.1246, lr: 0.001
Epoch [34/80], Training Loss: 4.9879, Validation Loss Current: 8.3204, Validation Loss AVG: 8.3204, lr: 0.001
Epoch [35/80], Training Loss: 2.9728, Validation Loss Current: 9.9456, Validation Loss AVG: 9.9456, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random1 finished training. Best epoch: 5 Best val accuracy: [0.49934210526315786, 0.5, 0.5151315789473684, 0.55625, 0.6289473684210527, 0.5483552631578947, 0.5898026315789474, 0.5881578947368421, 0.5720394736842105, 0.5, 0.5108552631578946, 0.5368421052631579, 0.5430921052631579, 0.5828947368421054, 0.5924342105263157, 0.5677631578947369, 0.6049342105263158, 0.5358552631578947, 0.549671052631579, 0.6, 0.5809210526315789, 0.4953947368421052, 0.5157894736842106, 0.5822368421052632, 0.5092105263157894, 0.6023026315789473, 0.6207236842105261, 0.5990131578947369, 0.5776315789473684, 0.6197368421052631, 0.5911184210526317, 0.5240131578947368, 0.6217105263157895, 0.618421052631579, 0.5427631578947368] Best val loss: 5.81214302778244


Current group: llo_0.8_random2
Epoch [1/80], Training Loss: 37.4464, Validation Loss Current: 7.7902, Validation Loss AVG: 7.7902, lr: 0.001
Epoch [2/80], Training Loss: 20.5515, Validation Loss Current: 6.9748, Validation Loss AVG: 6.9748, lr: 0.001
Epoch [3/80], Training Loss: 16.8121, Validation Loss Current: 5.5381, Validation Loss AVG: 5.5381, lr: 0.001
Epoch [4/80], Training Loss: 13.6773, Validation Loss Current: 5.9927, Validation Loss AVG: 5.9927, lr: 0.001
Epoch [5/80], Training Loss: 10.2168, Validation Loss Current: 5.2834, Validation Loss AVG: 5.2834, lr: 0.001
Epoch [6/80], Training Loss: 8.6127, Validation Loss Current: 6.2416, Validation Loss AVG: 6.2416, lr: 0.001
Epoch [7/80], Training Loss: 7.1182, Validation Loss Current: 6.4151, Validation Loss AVG: 6.4151, lr: 0.001
Epoch [8/80], Training Loss: 4.1238, Validation Loss Current: 4.9078, Validation Loss AVG: 4.9078, lr: 0.001
Epoch [9/80], Training Loss: 2.7981, Validation Loss Current: 5.2359, Validation Loss AVG: 5.2359, lr: 0.001
Epoch [10/80], Training Loss: 2.9489, Validation Loss Current: 5.0922, Validation Loss AVG: 5.0922, lr: 0.001
Epoch [11/80], Training Loss: 4.6412, Validation Loss Current: 5.5442, Validation Loss AVG: 5.5442, lr: 0.001
Epoch [12/80], Training Loss: 4.7117, Validation Loss Current: 6.8402, Validation Loss AVG: 6.8402, lr: 0.001
Epoch [13/80], Training Loss: 5.9021, Validation Loss Current: 7.1218, Validation Loss AVG: 7.1218, lr: 0.001
Epoch [14/80], Training Loss: 9.1425, Validation Loss Current: 6.7357, Validation Loss AVG: 6.7357, lr: 0.001
Epoch [15/80], Training Loss: 6.7210, Validation Loss Current: 9.0061, Validation Loss AVG: 9.0061, lr: 0.001
Epoch [16/80], Training Loss: 13.8257, Validation Loss Current: 10.0932, Validation Loss AVG: 10.0932, lr: 0.001
Epoch [17/80], Training Loss: 7.0211, Validation Loss Current: 8.8227, Validation Loss AVG: 8.8227, lr: 0.001
Epoch [18/80], Training Loss: 9.0084, Validation Loss Current: 10.3312, Validation Loss AVG: 10.3312, lr: 0.001
Epoch [19/80], Training Loss: 6.3660, Validation Loss Current: 8.1480, Validation Loss AVG: 8.1480, lr: 0.001
Epoch [20/80], Training Loss: 4.9492, Validation Loss Current: 6.8084, Validation Loss AVG: 6.8084, lr: 0.001
Epoch [21/80], Training Loss: 3.1425, Validation Loss Current: 5.9187, Validation Loss AVG: 5.9187, lr: 0.001
Epoch [22/80], Training Loss: 5.4323, Validation Loss Current: 6.1185, Validation Loss AVG: 6.1185, lr: 0.001
Epoch [23/80], Training Loss: 4.2342, Validation Loss Current: 7.3239, Validation Loss AVG: 7.3239, lr: 0.001
Epoch [24/80], Training Loss: 7.5650, Validation Loss Current: 8.2771, Validation Loss AVG: 8.2771, lr: 0.001
Epoch [25/80], Training Loss: 8.7693, Validation Loss Current: 9.3217, Validation Loss AVG: 9.3217, lr: 0.001
Epoch [26/80], Training Loss: 7.1812, Validation Loss Current: 8.1240, Validation Loss AVG: 8.1240, lr: 0.001
Epoch [27/80], Training Loss: 14.2468, Validation Loss Current: 10.3060, Validation Loss AVG: 10.3060, lr: 0.001
Epoch [28/80], Training Loss: 8.1600, Validation Loss Current: 8.2192, Validation Loss AVG: 8.2192, lr: 0.001
Epoch [29/80], Training Loss: 4.9438, Validation Loss Current: 7.8879, Validation Loss AVG: 7.8879, lr: 0.001
Epoch [30/80], Training Loss: 4.2557, Validation Loss Current: 7.3488, Validation Loss AVG: 7.3488, lr: 0.001
Epoch [31/80], Training Loss: 6.0873, Validation Loss Current: 6.9856, Validation Loss AVG: 6.9856, lr: 0.001
Epoch [32/80], Training Loss: 3.2743, Validation Loss Current: 13.0443, Validation Loss AVG: 13.0443, lr: 0.001
Epoch [33/80], Training Loss: 6.3973, Validation Loss Current: 8.7428, Validation Loss AVG: 8.7428, lr: 0.001
Epoch [34/80], Training Loss: 3.1207, Validation Loss Current: 7.8124, Validation Loss AVG: 7.8124, lr: 0.001
Epoch [35/80], Training Loss: 3.9758, Validation Loss Current: 7.8593, Validation Loss AVG: 7.8593, lr: 0.001
Epoch [36/80], Training Loss: 2.5744, Validation Loss Current: 6.9449, Validation Loss AVG: 6.9449, lr: 0.001
Epoch [37/80], Training Loss: 3.8163, Validation Loss Current: 8.8186, Validation Loss AVG: 8.8186, lr: 0.001
Epoch [38/80], Training Loss: 6.0018, Validation Loss Current: 9.1777, Validation Loss AVG: 9.1777, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random2 finished training. Best epoch: 8 Best val accuracy: [0.5891447368421052, 0.619407894736842, 0.662828947368421, 0.6338815789473684, 0.6769736842105264, 0.6450657894736842, 0.6470394736842104, 0.7098684210526315, 0.6950657894736842, 0.7095394736842107, 0.6822368421052631, 0.6555921052631579, 0.6384868421052631, 0.6371710526315789, 0.5680921052631579, 0.5259868421052631, 0.56875, 0.49375, 0.5986842105263157, 0.6411184210526316, 0.6740131578947368, 0.6766447368421052, 0.6092105263157894, 0.6134868421052632, 0.5641447368421053, 0.5845394736842104, 0.4901315789473684, 0.5980263157894736, 0.6296052631578947, 0.625, 0.6319078947368422, 0.5223684210526316, 0.5848684210526315, 0.6279605263157895, 0.6302631578947369, 0.6444078947368421, 0.5973684210526315, 0.575] Best val loss: 4.9077502369880674


Current group: llo_0.8_random3
Epoch [1/80], Training Loss: 38.4009, Validation Loss Current: 8.4381, Validation Loss AVG: 8.4381, lr: 0.001
Epoch [2/80], Training Loss: 23.2442, Validation Loss Current: 6.8280, Validation Loss AVG: 6.8280, lr: 0.001
Epoch [3/80], Training Loss: 19.4943, Validation Loss Current: 7.2618, Validation Loss AVG: 7.2618, lr: 0.001
Epoch [4/80], Training Loss: 11.4877, Validation Loss Current: 4.7897, Validation Loss AVG: 4.7897, lr: 0.001
Epoch [5/80], Training Loss: 9.8312, Validation Loss Current: 4.8186, Validation Loss AVG: 4.8186, lr: 0.001
Epoch [6/80], Training Loss: 13.3654, Validation Loss Current: 5.8298, Validation Loss AVG: 5.8298, lr: 0.001
Epoch [7/80], Training Loss: 11.5471, Validation Loss Current: 6.7831, Validation Loss AVG: 6.7831, lr: 0.001
Epoch [8/80], Training Loss: 8.5348, Validation Loss Current: 5.5968, Validation Loss AVG: 5.5968, lr: 0.001
Epoch [9/80], Training Loss: 6.0703, Validation Loss Current: 5.2352, Validation Loss AVG: 5.2352, lr: 0.001
Epoch [10/80], Training Loss: 7.5535, Validation Loss Current: 5.7844, Validation Loss AVG: 5.7844, lr: 0.001
Epoch [11/80], Training Loss: 7.1974, Validation Loss Current: 5.7982, Validation Loss AVG: 5.7982, lr: 0.001
Epoch [12/80], Training Loss: 8.3242, Validation Loss Current: 5.5164, Validation Loss AVG: 5.5164, lr: 0.001
Epoch [13/80], Training Loss: 7.3921, Validation Loss Current: 6.0040, Validation Loss AVG: 6.0040, lr: 0.001
Epoch [14/80], Training Loss: 5.5741, Validation Loss Current: 5.7715, Validation Loss AVG: 5.7715, lr: 0.001
Epoch [15/80], Training Loss: 7.1624, Validation Loss Current: 6.9698, Validation Loss AVG: 6.9698, lr: 0.001
Epoch [16/80], Training Loss: 8.1766, Validation Loss Current: 5.3753, Validation Loss AVG: 5.3753, lr: 0.001
Epoch [17/80], Training Loss: 9.1405, Validation Loss Current: 5.5087, Validation Loss AVG: 5.5087, lr: 0.001
Epoch [18/80], Training Loss: 5.7937, Validation Loss Current: 7.0707, Validation Loss AVG: 7.0707, lr: 0.001
Epoch [19/80], Training Loss: 5.8550, Validation Loss Current: 6.6294, Validation Loss AVG: 6.6294, lr: 0.001
Epoch [20/80], Training Loss: 2.1833, Validation Loss Current: 5.2275, Validation Loss AVG: 5.2275, lr: 0.001
Epoch [21/80], Training Loss: 2.6215, Validation Loss Current: 5.6811, Validation Loss AVG: 5.6811, lr: 0.001
Epoch [22/80], Training Loss: 3.1438, Validation Loss Current: 5.7558, Validation Loss AVG: 5.7558, lr: 0.001
Epoch [23/80], Training Loss: 2.6808, Validation Loss Current: 5.7907, Validation Loss AVG: 5.7907, lr: 0.001
Epoch [24/80], Training Loss: 3.6907, Validation Loss Current: 6.0575, Validation Loss AVG: 6.0575, lr: 0.001
Epoch [25/80], Training Loss: 6.4814, Validation Loss Current: 7.1615, Validation Loss AVG: 7.1615, lr: 0.001
Epoch [26/80], Training Loss: 8.2680, Validation Loss Current: 6.4551, Validation Loss AVG: 6.4551, lr: 0.001
Epoch [27/80], Training Loss: 5.0908, Validation Loss Current: 6.6551, Validation Loss AVG: 6.6551, lr: 0.001
Epoch [28/80], Training Loss: 6.6032, Validation Loss Current: 6.9520, Validation Loss AVG: 6.9520, lr: 0.001
Epoch [29/80], Training Loss: 4.3893, Validation Loss Current: 6.6815, Validation Loss AVG: 6.6815, lr: 0.001
Epoch [30/80], Training Loss: 3.1150, Validation Loss Current: 7.2547, Validation Loss AVG: 7.2547, lr: 0.001
Epoch [31/80], Training Loss: 3.4918, Validation Loss Current: 6.9348, Validation Loss AVG: 6.9348, lr: 0.001
Epoch [32/80], Training Loss: 2.6976, Validation Loss Current: 7.0120, Validation Loss AVG: 7.0120, lr: 0.001
Epoch [33/80], Training Loss: 5.1349, Validation Loss Current: 7.1318, Validation Loss AVG: 7.1318, lr: 0.001
Epoch [34/80], Training Loss: 3.9614, Validation Loss Current: 7.0663, Validation Loss AVG: 7.0663, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random3 finished training. Best epoch: 4 Best val accuracy: [0.5493421052631579, 0.6121710526315789, 0.5651315789473684, 0.7032894736842106, 0.7023026315789472, 0.65625, 0.6184210526315789, 0.6717105263157894, 0.6884868421052631, 0.6608552631578948, 0.6555921052631579, 0.68125, 0.6720394736842106, 0.6585526315789474, 0.6555921052631579, 0.6917763157894737, 0.6957236842105263, 0.6328947368421053, 0.6519736842105264, 0.6993421052631578, 0.6819078947368421, 0.6845394736842105, 0.6894736842105262, 0.6845394736842104, 0.6493421052631579, 0.6555921052631579, 0.6546052631578948, 0.6401315789473684, 0.6546052631578948, 0.6256578947368421, 0.6743421052631579, 0.6582236842105263, 0.6694078947368421, 0.6536184210526316] Best val loss: 4.789709222316742


Current group: 0.8
Epoch [1/80], Training Loss: 34.9519, Validation Loss Current: 11.1881, Validation Loss AVG: 11.1881, lr: 0.001
Epoch [2/80], Training Loss: 19.1280, Validation Loss Current: 9.4203, Validation Loss AVG: 9.4203, lr: 0.001
Epoch [3/80], Training Loss: 11.6644, Validation Loss Current: 9.6547, Validation Loss AVG: 9.6547, lr: 0.001
Epoch [4/80], Training Loss: 8.9283, Validation Loss Current: 7.4502, Validation Loss AVG: 7.4502, lr: 0.001
Epoch [5/80], Training Loss: 9.8288, Validation Loss Current: 8.4067, Validation Loss AVG: 8.4067, lr: 0.001
Epoch [6/80], Training Loss: 5.7936, Validation Loss Current: 7.3972, Validation Loss AVG: 7.3972, lr: 0.001
Epoch [7/80], Training Loss: 7.8845, Validation Loss Current: 7.6774, Validation Loss AVG: 7.6774, lr: 0.001
Epoch [8/80], Training Loss: 4.5033, Validation Loss Current: 7.9033, Validation Loss AVG: 7.9033, lr: 0.001
Epoch [9/80], Training Loss: 7.1432, Validation Loss Current: 7.7727, Validation Loss AVG: 7.7727, lr: 0.001
Epoch [10/80], Training Loss: 5.5918, Validation Loss Current: 7.3600, Validation Loss AVG: 7.3600, lr: 0.001
Epoch [11/80], Training Loss: 3.9199, Validation Loss Current: 8.2267, Validation Loss AVG: 8.2267, lr: 0.001
Epoch [12/80], Training Loss: 2.5598, Validation Loss Current: 7.7313, Validation Loss AVG: 7.7313, lr: 0.001
Epoch [13/80], Training Loss: 2.8248, Validation Loss Current: 7.2297, Validation Loss AVG: 7.2297, lr: 0.001
Epoch [14/80], Training Loss: 3.4703, Validation Loss Current: 7.8574, Validation Loss AVG: 7.8574, lr: 0.001
Epoch [15/80], Training Loss: 4.8417, Validation Loss Current: 9.7790, Validation Loss AVG: 9.7790, lr: 0.001
Epoch [16/80], Training Loss: 4.5035, Validation Loss Current: 8.7503, Validation Loss AVG: 8.7503, lr: 0.001
Epoch [17/80], Training Loss: 9.0958, Validation Loss Current: 8.7017, Validation Loss AVG: 8.7017, lr: 0.001
Epoch [18/80], Training Loss: 6.6718, Validation Loss Current: 8.9990, Validation Loss AVG: 8.9990, lr: 0.001
Epoch [19/80], Training Loss: 8.1002, Validation Loss Current: 11.3627, Validation Loss AVG: 11.3627, lr: 0.001
Epoch [20/80], Training Loss: 3.1541, Validation Loss Current: 8.6559, Validation Loss AVG: 8.6559, lr: 0.001
Epoch [21/80], Training Loss: 4.0968, Validation Loss Current: 8.3686, Validation Loss AVG: 8.3686, lr: 0.001
Epoch [22/80], Training Loss: 3.2083, Validation Loss Current: 8.7216, Validation Loss AVG: 8.7216, lr: 0.001
Epoch [23/80], Training Loss: 2.6183, Validation Loss Current: 9.2634, Validation Loss AVG: 9.2634, lr: 0.001
Epoch [24/80], Training Loss: 1.7257, Validation Loss Current: 10.3239, Validation Loss AVG: 10.3239, lr: 0.001
Epoch [25/80], Training Loss: 2.1483, Validation Loss Current: 8.1209, Validation Loss AVG: 8.1209, lr: 0.001
Epoch [26/80], Training Loss: 3.6767, Validation Loss Current: 9.9171, Validation Loss AVG: 9.9171, lr: 0.001
Epoch [27/80], Training Loss: 3.6596, Validation Loss Current: 9.3936, Validation Loss AVG: 9.3936, lr: 0.001
Epoch [28/80], Training Loss: 3.0397, Validation Loss Current: 9.8322, Validation Loss AVG: 9.8322, lr: 0.001
Epoch [29/80], Training Loss: 5.5754, Validation Loss Current: 10.4179, Validation Loss AVG: 10.4179, lr: 0.001
Epoch [30/80], Training Loss: 5.2528, Validation Loss Current: 8.3961, Validation Loss AVG: 8.3961, lr: 0.001
Epoch [31/80], Training Loss: 5.0202, Validation Loss Current: 8.9864, Validation Loss AVG: 8.9864, lr: 0.001
Epoch [32/80], Training Loss: 2.7319, Validation Loss Current: 9.4745, Validation Loss AVG: 9.4745, lr: 0.001
Epoch [33/80], Training Loss: 2.4460, Validation Loss Current: 8.1582, Validation Loss AVG: 8.1582, lr: 0.001
Epoch [34/80], Training Loss: 3.1837, Validation Loss Current: 9.4836, Validation Loss AVG: 9.4836, lr: 0.001
Epoch [35/80], Training Loss: 1.5972, Validation Loss Current: 8.8395, Validation Loss AVG: 8.8395, lr: 0.001
Epoch [36/80], Training Loss: 1.6377, Validation Loss Current: 8.8162, Validation Loss AVG: 8.8162, lr: 0.001
Epoch [37/80], Training Loss: 1.8479, Validation Loss Current: 10.1242, Validation Loss AVG: 10.1242, lr: 0.001
Epoch [38/80], Training Loss: 2.7525, Validation Loss Current: 8.8040, Validation Loss AVG: 8.8040, lr: 0.001
Epoch [39/80], Training Loss: 1.9677, Validation Loss Current: 9.5887, Validation Loss AVG: 9.5887, lr: 0.001
Epoch [40/80], Training Loss: 3.2945, Validation Loss Current: 9.4055, Validation Loss AVG: 9.4055, lr: 0.001
Epoch [41/80], Training Loss: 6.1535, Validation Loss Current: 10.7812, Validation Loss AVG: 10.7812, lr: 0.001
Epoch [42/80], Training Loss: 7.8163, Validation Loss Current: 9.8297, Validation Loss AVG: 9.8297, lr: 0.001
Epoch [43/80], Training Loss: 4.0343, Validation Loss Current: 9.6776, Validation Loss AVG: 9.6776, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 13 Best val accuracy: [0.47335526315789467, 0.5427631578947368, 0.5470394736842106, 0.5927631578947369, 0.5595394736842105, 0.6125, 0.5894736842105263, 0.5753289473684211, 0.5746710526315789, 0.6019736842105263, 0.5812499999999999, 0.5815789473684211, 0.594078947368421, 0.5963815789473684, 0.5486842105263159, 0.5421052631578946, 0.5697368421052631, 0.5467105263157894, 0.4980263157894737, 0.5697368421052632, 0.5700657894736842, 0.5832236842105263, 0.5575657894736842, 0.5223684210526316, 0.59375, 0.5575657894736843, 0.5592105263157895, 0.5348684210526315, 0.5144736842105263, 0.562828947368421, 0.5638157894736843, 0.5276315789473685, 0.5759868421052632, 0.5601973684210526, 0.5674342105263158, 0.5740131578947368, 0.524671052631579, 0.5651315789473684, 0.5555921052631578, 0.5490131578947368, 0.51875, 0.5342105263157895, 0.5328947368421053] Best val loss: 7.229684603214264


----- Training resnet18 with sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] -----
Current group: llo_0.4_random0
Epoch [1/80], Training Loss: 41.7565, Validation Loss Current: 10.0624, Validation Loss AVG: 10.0624, lr: 0.001
Epoch [2/80], Training Loss: 39.8578, Validation Loss Current: 9.9281, Validation Loss AVG: 9.9281, lr: 0.001
Epoch [3/80], Training Loss: 39.4277, Validation Loss Current: 9.9982, Validation Loss AVG: 9.9982, lr: 0.001
Epoch [4/80], Training Loss: 38.6110, Validation Loss Current: 9.3285, Validation Loss AVG: 9.3285, lr: 0.001
Epoch [5/80], Training Loss: 37.3210, Validation Loss Current: 9.1895, Validation Loss AVG: 9.1895, lr: 0.001
Epoch [6/80], Training Loss: 36.8741, Validation Loss Current: 9.1520, Validation Loss AVG: 9.1520, lr: 0.001
Epoch [7/80], Training Loss: 35.1350, Validation Loss Current: 8.9341, Validation Loss AVG: 8.9341, lr: 0.001
Epoch [8/80], Training Loss: 34.0908, Validation Loss Current: 8.7571, Validation Loss AVG: 8.7571, lr: 0.001
Epoch [9/80], Training Loss: 34.1133, Validation Loss Current: 8.4775, Validation Loss AVG: 8.4775, lr: 0.001
Epoch [10/80], Training Loss: 32.6055, Validation Loss Current: 8.4643, Validation Loss AVG: 8.4643, lr: 0.001
Epoch [11/80], Training Loss: 31.8019, Validation Loss Current: 8.4485, Validation Loss AVG: 8.4485, lr: 0.001
Epoch [12/80], Training Loss: 32.1571, Validation Loss Current: 8.3372, Validation Loss AVG: 8.3372, lr: 0.001
Epoch [13/80], Training Loss: 32.2144, Validation Loss Current: 8.0133, Validation Loss AVG: 8.0133, lr: 0.001
Epoch [14/80], Training Loss: 32.0937, Validation Loss Current: 8.3390, Validation Loss AVG: 8.3390, lr: 0.001
Epoch [15/80], Training Loss: 31.0276, Validation Loss Current: 8.3947, Validation Loss AVG: 8.3947, lr: 0.001
Epoch [16/80], Training Loss: 29.2891, Validation Loss Current: 7.6579, Validation Loss AVG: 7.6579, lr: 0.001
Epoch [17/80], Training Loss: 28.8972, Validation Loss Current: 7.6441, Validation Loss AVG: 7.6441, lr: 0.001
Epoch [18/80], Training Loss: 27.8449, Validation Loss Current: 7.6798, Validation Loss AVG: 7.6798, lr: 0.001
Epoch [19/80], Training Loss: 27.2953, Validation Loss Current: 7.3308, Validation Loss AVG: 7.3308, lr: 0.001
Epoch [20/80], Training Loss: 26.8842, Validation Loss Current: 7.6897, Validation Loss AVG: 7.6897, lr: 0.001
Epoch [21/80], Training Loss: 25.0006, Validation Loss Current: 7.0720, Validation Loss AVG: 7.0720, lr: 0.001
Epoch [22/80], Training Loss: 25.8051, Validation Loss Current: 7.6289, Validation Loss AVG: 7.6289, lr: 0.001
Epoch [23/80], Training Loss: 25.1742, Validation Loss Current: 7.9721, Validation Loss AVG: 7.9721, lr: 0.001
Epoch [24/80], Training Loss: 25.1055, Validation Loss Current: 7.1240, Validation Loss AVG: 7.1240, lr: 0.001
Epoch [25/80], Training Loss: 23.6090, Validation Loss Current: 6.8186, Validation Loss AVG: 6.8186, lr: 0.001
Epoch [26/80], Training Loss: 22.4912, Validation Loss Current: 7.0364, Validation Loss AVG: 7.0364, lr: 0.001
Epoch [27/80], Training Loss: 21.6431, Validation Loss Current: 6.9935, Validation Loss AVG: 6.9935, lr: 0.001
Epoch [28/80], Training Loss: 22.5262, Validation Loss Current: 11.3185, Validation Loss AVG: 11.3185, lr: 0.001
Epoch [29/80], Training Loss: 27.0740, Validation Loss Current: 8.1951, Validation Loss AVG: 8.1951, lr: 0.001
Epoch [30/80], Training Loss: 25.7517, Validation Loss Current: 9.3743, Validation Loss AVG: 9.3743, lr: 0.001
Epoch [31/80], Training Loss: 24.5126, Validation Loss Current: 6.9370, Validation Loss AVG: 6.9370, lr: 0.001
Epoch [32/80], Training Loss: 22.3455, Validation Loss Current: 7.1470, Validation Loss AVG: 7.1470, lr: 0.001
Epoch [33/80], Training Loss: 20.4987, Validation Loss Current: 6.8324, Validation Loss AVG: 6.8324, lr: 0.001
Epoch [34/80], Training Loss: 19.5135, Validation Loss Current: 6.4015, Validation Loss AVG: 6.4015, lr: 0.001
Epoch [35/80], Training Loss: 18.2065, Validation Loss Current: 6.5480, Validation Loss AVG: 6.5480, lr: 0.001
Epoch [36/80], Training Loss: 16.6813, Validation Loss Current: 6.4839, Validation Loss AVG: 6.4839, lr: 0.001
Epoch [37/80], Training Loss: 17.9317, Validation Loss Current: 6.6023, Validation Loss AVG: 6.6023, lr: 0.001
Epoch [38/80], Training Loss: 16.7863, Validation Loss Current: 6.7253, Validation Loss AVG: 6.7253, lr: 0.001
Epoch [39/80], Training Loss: 15.4731, Validation Loss Current: 6.3312, Validation Loss AVG: 6.3312, lr: 0.001
Epoch [40/80], Training Loss: 14.2041, Validation Loss Current: 7.2468, Validation Loss AVG: 7.2468, lr: 0.001
Epoch [41/80], Training Loss: 14.4953, Validation Loss Current: 6.3493, Validation Loss AVG: 6.3493, lr: 0.001
Epoch [42/80], Training Loss: 13.5562, Validation Loss Current: 7.6529, Validation Loss AVG: 7.6529, lr: 0.001
Epoch [43/80], Training Loss: 14.3877, Validation Loss Current: 7.0700, Validation Loss AVG: 7.0700, lr: 0.001
Epoch [44/80], Training Loss: 12.6320, Validation Loss Current: 6.5729, Validation Loss AVG: 6.5729, lr: 0.001
Epoch [45/80], Training Loss: 11.5815, Validation Loss Current: 7.2451, Validation Loss AVG: 7.2451, lr: 0.001
Epoch [46/80], Training Loss: 12.8561, Validation Loss Current: 7.1257, Validation Loss AVG: 7.1257, lr: 0.001
Epoch [47/80], Training Loss: 12.9700, Validation Loss Current: 8.5802, Validation Loss AVG: 8.5802, lr: 0.001
Epoch [48/80], Training Loss: 12.9485, Validation Loss Current: 7.5820, Validation Loss AVG: 7.5820, lr: 0.001
Epoch [49/80], Training Loss: 11.6885, Validation Loss Current: 7.9932, Validation Loss AVG: 7.9932, lr: 0.001
Epoch [50/80], Training Loss: 9.2219, Validation Loss Current: 7.0658, Validation Loss AVG: 7.0658, lr: 0.001
Epoch [51/80], Training Loss: 10.0478, Validation Loss Current: 7.1321, Validation Loss AVG: 7.1321, lr: 0.001
Epoch [52/80], Training Loss: 8.6416, Validation Loss Current: 6.4739, Validation Loss AVG: 6.4739, lr: 0.001
Epoch [53/80], Training Loss: 7.5687, Validation Loss Current: 7.4106, Validation Loss AVG: 7.4106, lr: 0.001
Epoch [54/80], Training Loss: 9.5679, Validation Loss Current: 7.0442, Validation Loss AVG: 7.0442, lr: 0.001
Epoch [55/80], Training Loss: 7.3544, Validation Loss Current: 7.0379, Validation Loss AVG: 7.0379, lr: 0.001
Epoch [56/80], Training Loss: 9.1208, Validation Loss Current: 6.6541, Validation Loss AVG: 6.6541, lr: 0.001
Epoch [57/80], Training Loss: 6.6790, Validation Loss Current: 7.0981, Validation Loss AVG: 7.0981, lr: 0.001
Epoch [58/80], Training Loss: 6.3900, Validation Loss Current: 7.8530, Validation Loss AVG: 7.8530, lr: 0.001
Epoch [59/80], Training Loss: 5.3718, Validation Loss Current: 8.1378, Validation Loss AVG: 8.1378, lr: 0.001
Epoch [60/80], Training Loss: 8.4433, Validation Loss Current: 18.1644, Validation Loss AVG: 18.1644, lr: 0.001
Epoch [61/80], Training Loss: 12.6132, Validation Loss Current: 9.7602, Validation Loss AVG: 9.7602, lr: 0.001
Epoch [62/80], Training Loss: 12.4146, Validation Loss Current: 9.0082, Validation Loss AVG: 9.0082, lr: 0.001
Epoch [63/80], Training Loss: 13.7657, Validation Loss Current: 10.0984, Validation Loss AVG: 10.0984, lr: 0.001
Epoch [64/80], Training Loss: 11.5364, Validation Loss Current: 9.6705, Validation Loss AVG: 9.6705, lr: 0.001
Epoch [65/80], Training Loss: 12.0034, Validation Loss Current: 7.9106, Validation Loss AVG: 7.9106, lr: 0.001
Epoch [66/80], Training Loss: 7.9219, Validation Loss Current: 8.0914, Validation Loss AVG: 8.0914, lr: 0.001
Epoch [67/80], Training Loss: 7.9372, Validation Loss Current: 9.4571, Validation Loss AVG: 9.4571, lr: 0.001
Epoch [68/80], Training Loss: 9.7010, Validation Loss Current: 7.8611, Validation Loss AVG: 7.8611, lr: 0.001
Epoch [69/80], Training Loss: 10.3226, Validation Loss Current: 9.0457, Validation Loss AVG: 9.0457, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random0 finished training. Best epoch: 39 Best val accuracy: [0.25032894736842104, 0.24802631578947368, 0.23157894736842105, 0.31776315789473686, 0.3292763157894737, 0.3592105263157895, 0.37730263157894733, 0.35328947368421054, 0.3904605263157894, 0.3940789473684211, 0.3911184210526316, 0.3960526315789473, 0.41776315789473684, 0.39769736842105263, 0.3917763157894737, 0.4677631578947368, 0.45230263157894735, 0.4509868421052631, 0.5019736842105262, 0.4634868421052631, 0.5111842105263158, 0.45065789473684215, 0.4309210526315789, 0.506578947368421, 0.5388157894736842, 0.5171052631578947, 0.5236842105263158, 0.30953947368421053, 0.43256578947368424, 0.40230263157894736, 0.5171052631578947, 0.4947368421052632, 0.5296052631578948, 0.5585526315789474, 0.5542763157894737, 0.5470394736842106, 0.5444078947368421, 0.5421052631578948, 0.5667763157894737, 0.530921052631579, 0.5618421052631579, 0.5019736842105262, 0.5302631578947369, 0.5552631578947368, 0.5325657894736843, 0.5338815789473684, 0.47269736842105264, 0.531578947368421, 0.49506578947368424, 0.5605263157894738, 0.5555921052631578, 0.5898026315789473, 0.5371710526315789, 0.5661184210526315, 0.5828947368421054, 0.5983552631578948, 0.569078947368421, 0.5588815789473683, 0.5562500000000001, 0.3490131578947368, 0.48848684210526316, 0.5263157894736843, 0.45592105263157895, 0.475, 0.5335526315789474, 0.5243421052631578, 0.5082236842105263, 0.5555921052631579, 0.4973684210526315] Best val loss: 6.331224906444549


Current group: llo_0.4_random1
Epoch [1/80], Training Loss: 30.8330, Validation Loss Current: 8.6459, Validation Loss AVG: 8.6459, lr: 0.001
Epoch [2/80], Training Loss: 23.3855, Validation Loss Current: 7.6431, Validation Loss AVG: 7.6431, lr: 0.001
Epoch [3/80], Training Loss: 18.0992, Validation Loss Current: 6.3000, Validation Loss AVG: 6.3000, lr: 0.001
Epoch [4/80], Training Loss: 15.1314, Validation Loss Current: 6.6501, Validation Loss AVG: 6.6501, lr: 0.001
Epoch [5/80], Training Loss: 15.2982, Validation Loss Current: 7.4607, Validation Loss AVG: 7.4607, lr: 0.001
Epoch [6/80], Training Loss: 12.4362, Validation Loss Current: 6.0442, Validation Loss AVG: 6.0442, lr: 0.001
Epoch [7/80], Training Loss: 11.9055, Validation Loss Current: 6.4907, Validation Loss AVG: 6.4907, lr: 0.001
Epoch [8/80], Training Loss: 12.8868, Validation Loss Current: 8.3648, Validation Loss AVG: 8.3648, lr: 0.001
Epoch [9/80], Training Loss: 11.3211, Validation Loss Current: 6.6241, Validation Loss AVG: 6.6241, lr: 0.001
Epoch [10/80], Training Loss: 8.1831, Validation Loss Current: 6.6724, Validation Loss AVG: 6.6724, lr: 0.001
Epoch [11/80], Training Loss: 6.8199, Validation Loss Current: 6.1769, Validation Loss AVG: 6.1769, lr: 0.001
Epoch [12/80], Training Loss: 7.6888, Validation Loss Current: 6.3436, Validation Loss AVG: 6.3436, lr: 0.001
Epoch [13/80], Training Loss: 8.0038, Validation Loss Current: 6.0072, Validation Loss AVG: 6.0072, lr: 0.001
Epoch [14/80], Training Loss: 6.3575, Validation Loss Current: 6.6169, Validation Loss AVG: 6.6169, lr: 0.001
Epoch [15/80], Training Loss: 5.8662, Validation Loss Current: 6.5438, Validation Loss AVG: 6.5438, lr: 0.001
Epoch [16/80], Training Loss: 4.3932, Validation Loss Current: 5.9991, Validation Loss AVG: 5.9991, lr: 0.001
Epoch [17/80], Training Loss: 6.9684, Validation Loss Current: 6.7716, Validation Loss AVG: 6.7716, lr: 0.001
Epoch [18/80], Training Loss: 7.7319, Validation Loss Current: 7.1571, Validation Loss AVG: 7.1571, lr: 0.001
Epoch [19/80], Training Loss: 4.6580, Validation Loss Current: 7.0275, Validation Loss AVG: 7.0275, lr: 0.001
Epoch [20/80], Training Loss: 4.8329, Validation Loss Current: 8.1469, Validation Loss AVG: 8.1469, lr: 0.001
Epoch [21/80], Training Loss: 11.5784, Validation Loss Current: 7.7445, Validation Loss AVG: 7.7445, lr: 0.001
Epoch [22/80], Training Loss: 5.2671, Validation Loss Current: 8.2477, Validation Loss AVG: 8.2477, lr: 0.001
Epoch [23/80], Training Loss: 6.0219, Validation Loss Current: 6.9641, Validation Loss AVG: 6.9641, lr: 0.001
Epoch [24/80], Training Loss: 6.0681, Validation Loss Current: 7.8575, Validation Loss AVG: 7.8575, lr: 0.001
Epoch [25/80], Training Loss: 10.2487, Validation Loss Current: 8.1106, Validation Loss AVG: 8.1106, lr: 0.001
Epoch [26/80], Training Loss: 6.4106, Validation Loss Current: 7.9735, Validation Loss AVG: 7.9735, lr: 0.001
Epoch [27/80], Training Loss: 5.9536, Validation Loss Current: 10.3271, Validation Loss AVG: 10.3271, lr: 0.001
Epoch [28/80], Training Loss: 4.7162, Validation Loss Current: 8.4253, Validation Loss AVG: 8.4253, lr: 0.001
Epoch [29/80], Training Loss: 5.3765, Validation Loss Current: 7.0304, Validation Loss AVG: 7.0304, lr: 0.001
Epoch [30/80], Training Loss: 7.1268, Validation Loss Current: 7.6244, Validation Loss AVG: 7.6244, lr: 0.001
Epoch [31/80], Training Loss: 6.7303, Validation Loss Current: 8.0162, Validation Loss AVG: 8.0162, lr: 0.001
Epoch [32/80], Training Loss: 3.3450, Validation Loss Current: 7.5726, Validation Loss AVG: 7.5726, lr: 0.001
Epoch [33/80], Training Loss: 2.7618, Validation Loss Current: 8.5312, Validation Loss AVG: 8.5312, lr: 0.001
Epoch [34/80], Training Loss: 2.7668, Validation Loss Current: 8.1962, Validation Loss AVG: 8.1962, lr: 0.001
Epoch [35/80], Training Loss: 4.5864, Validation Loss Current: 9.9987, Validation Loss AVG: 9.9987, lr: 0.001
Epoch [36/80], Training Loss: 4.8905, Validation Loss Current: 8.6622, Validation Loss AVG: 8.6622, lr: 0.001
Epoch [37/80], Training Loss: 9.2805, Validation Loss Current: 9.9666, Validation Loss AVG: 9.9666, lr: 0.001
Epoch [38/80], Training Loss: 3.5352, Validation Loss Current: 7.6021, Validation Loss AVG: 7.6021, lr: 0.001
Epoch [39/80], Training Loss: 3.3236, Validation Loss Current: 8.4912, Validation Loss AVG: 8.4912, lr: 0.001
Epoch [40/80], Training Loss: 5.8142, Validation Loss Current: 8.9438, Validation Loss AVG: 8.9438, lr: 0.001
Epoch [41/80], Training Loss: 6.7043, Validation Loss Current: 8.2690, Validation Loss AVG: 8.2690, lr: 0.001
Epoch [42/80], Training Loss: 5.7362, Validation Loss Current: 9.7336, Validation Loss AVG: 9.7336, lr: 0.001
Epoch [43/80], Training Loss: 5.4375, Validation Loss Current: 9.0706, Validation Loss AVG: 9.0706, lr: 0.001
Epoch [44/80], Training Loss: 8.4704, Validation Loss Current: 8.8901, Validation Loss AVG: 8.8901, lr: 0.001
Epoch [45/80], Training Loss: 4.9318, Validation Loss Current: 8.1174, Validation Loss AVG: 8.1174, lr: 0.001
Epoch [46/80], Training Loss: 2.5453, Validation Loss Current: 7.9024, Validation Loss AVG: 7.9024, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random1 finished training. Best epoch: 16 Best val accuracy: [0.5088815789473684, 0.5279605263157896, 0.5763157894736842, 0.5707236842105263, 0.53125, 0.6039473684210526, 0.5881578947368421, 0.5213815789473684, 0.5980263157894737, 0.594078947368421, 0.618421052631579, 0.6217105263157895, 0.6407894736842106, 0.6003289473684211, 0.6167763157894737, 0.6526315789473685, 0.5967105263157895, 0.593421052631579, 0.6052631578947368, 0.5736842105263158, 0.5641447368421052, 0.5684210526315789, 0.6167763157894737, 0.5664473684210526, 0.5960526315789474, 0.5851973684210526, 0.4796052631578947, 0.5578947368421052, 0.6072368421052631, 0.6032894736842105, 0.580921052631579, 0.5996710526315789, 0.5753289473684211, 0.5875, 0.55625, 0.5585526315789473, 0.5467105263157894, 0.6019736842105263, 0.5953947368421052, 0.5519736842105263, 0.5796052631578947, 0.5526315789473685, 0.5832236842105264, 0.5796052631578947, 0.5914473684210526, 0.6213815789473683] Best val loss: 5.999123239517212


Current group: llo_0.4_random2
Epoch [1/80], Training Loss: 33.5949, Validation Loss Current: 6.8687, Validation Loss AVG: 6.8687, lr: 0.001
Epoch [2/80], Training Loss: 19.2494, Validation Loss Current: 6.4906, Validation Loss AVG: 6.4906, lr: 0.001
Epoch [3/80], Training Loss: 13.8596, Validation Loss Current: 5.8296, Validation Loss AVG: 5.8296, lr: 0.001
Epoch [4/80], Training Loss: 13.9653, Validation Loss Current: 8.6854, Validation Loss AVG: 8.6854, lr: 0.001
Epoch [5/80], Training Loss: 10.5703, Validation Loss Current: 6.0559, Validation Loss AVG: 6.0559, lr: 0.001
Epoch [6/80], Training Loss: 10.2512, Validation Loss Current: 5.9340, Validation Loss AVG: 5.9340, lr: 0.001
Epoch [7/80], Training Loss: 11.7719, Validation Loss Current: 6.9888, Validation Loss AVG: 6.9888, lr: 0.001
Epoch [8/80], Training Loss: 10.3529, Validation Loss Current: 6.8244, Validation Loss AVG: 6.8244, lr: 0.001
Epoch [9/80], Training Loss: 11.1744, Validation Loss Current: 5.7709, Validation Loss AVG: 5.7709, lr: 0.001
Epoch [10/80], Training Loss: 5.3381, Validation Loss Current: 5.5977, Validation Loss AVG: 5.5977, lr: 0.001
Epoch [11/80], Training Loss: 5.6057, Validation Loss Current: 6.0400, Validation Loss AVG: 6.0400, lr: 0.001
Epoch [12/80], Training Loss: 6.2269, Validation Loss Current: 6.8238, Validation Loss AVG: 6.8238, lr: 0.001
Epoch [13/80], Training Loss: 5.1973, Validation Loss Current: 6.2584, Validation Loss AVG: 6.2584, lr: 0.001
Epoch [14/80], Training Loss: 5.5038, Validation Loss Current: 6.0614, Validation Loss AVG: 6.0614, lr: 0.001
Epoch [15/80], Training Loss: 4.8798, Validation Loss Current: 6.8848, Validation Loss AVG: 6.8848, lr: 0.001
Epoch [16/80], Training Loss: 7.9929, Validation Loss Current: 7.3287, Validation Loss AVG: 7.3287, lr: 0.001
Epoch [17/80], Training Loss: 9.1186, Validation Loss Current: 8.1975, Validation Loss AVG: 8.1975, lr: 0.001
Epoch [18/80], Training Loss: 4.5632, Validation Loss Current: 6.8235, Validation Loss AVG: 6.8235, lr: 0.001
Epoch [19/80], Training Loss: 3.0333, Validation Loss Current: 6.6878, Validation Loss AVG: 6.6878, lr: 0.001
Epoch [20/80], Training Loss: 4.2152, Validation Loss Current: 7.7775, Validation Loss AVG: 7.7775, lr: 0.001
Epoch [21/80], Training Loss: 5.2586, Validation Loss Current: 8.6429, Validation Loss AVG: 8.6429, lr: 0.001
Epoch [22/80], Training Loss: 4.7613, Validation Loss Current: 6.6493, Validation Loss AVG: 6.6493, lr: 0.001
Epoch [23/80], Training Loss: 7.1038, Validation Loss Current: 9.0351, Validation Loss AVG: 9.0351, lr: 0.001
Epoch [24/80], Training Loss: 7.9603, Validation Loss Current: 9.1399, Validation Loss AVG: 9.1399, lr: 0.001
Epoch [25/80], Training Loss: 7.0636, Validation Loss Current: 9.2766, Validation Loss AVG: 9.2766, lr: 0.001
Epoch [26/80], Training Loss: 5.3844, Validation Loss Current: 8.2825, Validation Loss AVG: 8.2825, lr: 0.001
Epoch [27/80], Training Loss: 6.1322, Validation Loss Current: 7.2361, Validation Loss AVG: 7.2361, lr: 0.001
Epoch [28/80], Training Loss: 4.4224, Validation Loss Current: 9.2594, Validation Loss AVG: 9.2594, lr: 0.001
Epoch [29/80], Training Loss: 8.6196, Validation Loss Current: 8.4428, Validation Loss AVG: 8.4428, lr: 0.001
Epoch [30/80], Training Loss: 6.3570, Validation Loss Current: 8.0235, Validation Loss AVG: 8.0235, lr: 0.001
Epoch [31/80], Training Loss: 4.3977, Validation Loss Current: 7.7256, Validation Loss AVG: 7.7256, lr: 0.001
Epoch [32/80], Training Loss: 5.6245, Validation Loss Current: 8.3788, Validation Loss AVG: 8.3788, lr: 0.001
Epoch [33/80], Training Loss: 7.7577, Validation Loss Current: 9.0922, Validation Loss AVG: 9.0922, lr: 0.001
Epoch [34/80], Training Loss: 3.3823, Validation Loss Current: 8.3961, Validation Loss AVG: 8.3961, lr: 0.001
Epoch [35/80], Training Loss: 3.4092, Validation Loss Current: 7.7713, Validation Loss AVG: 7.7713, lr: 0.001
Epoch [36/80], Training Loss: 2.0165, Validation Loss Current: 7.3840, Validation Loss AVG: 7.3840, lr: 0.001
Epoch [37/80], Training Loss: 0.8877, Validation Loss Current: 7.0867, Validation Loss AVG: 7.0867, lr: 0.001
Epoch [38/80], Training Loss: 3.5707, Validation Loss Current: 7.4777, Validation Loss AVG: 7.4777, lr: 0.001
Epoch [39/80], Training Loss: 6.0254, Validation Loss Current: 8.9488, Validation Loss AVG: 8.9488, lr: 0.001
Epoch [40/80], Training Loss: 1.9433, Validation Loss Current: 7.4239, Validation Loss AVG: 7.4239, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random2 finished training. Best epoch: 10 Best val accuracy: [0.6088815789473684, 0.6180921052631578, 0.6490131578947368, 0.5328947368421052, 0.6421052631578947, 0.6467105263157895, 0.6296052631578948, 0.6105263157894737, 0.6569078947368421, 0.6631578947368422, 0.6371710526315789, 0.6171052631578947, 0.6523026315789473, 0.6450657894736842, 0.6282894736842105, 0.6009868421052632, 0.5957236842105263, 0.6203947368421052, 0.6539473684210526, 0.5950657894736842, 0.6049342105263158, 0.6361842105263158, 0.5904605263157895, 0.5608552631578948, 0.5809210526315789, 0.5746710526315789, 0.6276315789473684, 0.5713815789473684, 0.5529605263157895, 0.6236842105263157, 0.6266447368421052, 0.6082236842105264, 0.5736842105263158, 0.60625, 0.6157894736842106, 0.6434210526315789, 0.6542763157894737, 0.6375, 0.5779605263157894, 0.6404605263157895] Best val loss: 5.597716224193573


Current group: llo_0.4_random3
Epoch [1/80], Training Loss: 33.0722, Validation Loss Current: 7.7596, Validation Loss AVG: 7.7596, lr: 0.001
Epoch [2/80], Training Loss: 21.2884, Validation Loss Current: 5.5341, Validation Loss AVG: 5.5341, lr: 0.001
Epoch [3/80], Training Loss: 16.3101, Validation Loss Current: 5.5452, Validation Loss AVG: 5.5452, lr: 0.001
Epoch [4/80], Training Loss: 12.2035, Validation Loss Current: 6.3624, Validation Loss AVG: 6.3624, lr: 0.001
Epoch [5/80], Training Loss: 12.0847, Validation Loss Current: 5.6121, Validation Loss AVG: 5.6121, lr: 0.001
Epoch [6/80], Training Loss: 7.0979, Validation Loss Current: 5.2670, Validation Loss AVG: 5.2670, lr: 0.001
Epoch [7/80], Training Loss: 8.4923, Validation Loss Current: 5.0358, Validation Loss AVG: 5.0358, lr: 0.001
Epoch [8/80], Training Loss: 8.2711, Validation Loss Current: 5.3405, Validation Loss AVG: 5.3405, lr: 0.001
Epoch [9/80], Training Loss: 7.8939, Validation Loss Current: 5.5629, Validation Loss AVG: 5.5629, lr: 0.001
Epoch [10/80], Training Loss: 9.8299, Validation Loss Current: 6.2235, Validation Loss AVG: 6.2235, lr: 0.001
Epoch [11/80], Training Loss: 7.2713, Validation Loss Current: 5.3263, Validation Loss AVG: 5.3263, lr: 0.001
Epoch [12/80], Training Loss: 5.3094, Validation Loss Current: 5.2753, Validation Loss AVG: 5.2753, lr: 0.001
Epoch [13/80], Training Loss: 3.4236, Validation Loss Current: 5.3305, Validation Loss AVG: 5.3305, lr: 0.001
Epoch [14/80], Training Loss: 1.8976, Validation Loss Current: 5.4106, Validation Loss AVG: 5.4106, lr: 0.001
Epoch [15/80], Training Loss: 2.1084, Validation Loss Current: 4.9535, Validation Loss AVG: 4.9535, lr: 0.001
Epoch [16/80], Training Loss: 3.3964, Validation Loss Current: 5.4861, Validation Loss AVG: 5.4861, lr: 0.001
Epoch [17/80], Training Loss: 2.3428, Validation Loss Current: 5.9886, Validation Loss AVG: 5.9886, lr: 0.001
Epoch [18/80], Training Loss: 3.3819, Validation Loss Current: 5.1333, Validation Loss AVG: 5.1333, lr: 0.001
Epoch [19/80], Training Loss: 4.2498, Validation Loss Current: 6.6127, Validation Loss AVG: 6.6127, lr: 0.001
Epoch [20/80], Training Loss: 4.1662, Validation Loss Current: 5.8210, Validation Loss AVG: 5.8210, lr: 0.001
Epoch [21/80], Training Loss: 2.7674, Validation Loss Current: 5.9881, Validation Loss AVG: 5.9881, lr: 0.001
Epoch [22/80], Training Loss: 5.6960, Validation Loss Current: 7.3917, Validation Loss AVG: 7.3917, lr: 0.001
Epoch [23/80], Training Loss: 5.7200, Validation Loss Current: 6.4977, Validation Loss AVG: 6.4977, lr: 0.001
Epoch [24/80], Training Loss: 6.0677, Validation Loss Current: 6.8291, Validation Loss AVG: 6.8291, lr: 0.001
Epoch [25/80], Training Loss: 10.6579, Validation Loss Current: 8.5715, Validation Loss AVG: 8.5715, lr: 0.001
Epoch [26/80], Training Loss: 13.7501, Validation Loss Current: 8.5792, Validation Loss AVG: 8.5792, lr: 0.001
Epoch [27/80], Training Loss: 12.4466, Validation Loss Current: 6.2825, Validation Loss AVG: 6.2825, lr: 0.001
Epoch [28/80], Training Loss: 5.5118, Validation Loss Current: 6.4507, Validation Loss AVG: 6.4507, lr: 0.001
Epoch [29/80], Training Loss: 5.1462, Validation Loss Current: 6.3200, Validation Loss AVG: 6.3200, lr: 0.001
Epoch [30/80], Training Loss: 5.8259, Validation Loss Current: 6.4212, Validation Loss AVG: 6.4212, lr: 0.001
Epoch [31/80], Training Loss: 9.4722, Validation Loss Current: 7.8049, Validation Loss AVG: 7.8049, lr: 0.001
Epoch [32/80], Training Loss: 7.0830, Validation Loss Current: 7.2801, Validation Loss AVG: 7.2801, lr: 0.001
Epoch [33/80], Training Loss: 4.8979, Validation Loss Current: 6.5887, Validation Loss AVG: 6.5887, lr: 0.001
Epoch [34/80], Training Loss: 3.7245, Validation Loss Current: 6.8564, Validation Loss AVG: 6.8564, lr: 0.001
Epoch [35/80], Training Loss: 1.7439, Validation Loss Current: 5.9480, Validation Loss AVG: 5.9480, lr: 0.001
Epoch [36/80], Training Loss: 2.4757, Validation Loss Current: 7.3396, Validation Loss AVG: 7.3396, lr: 0.001
Epoch [37/80], Training Loss: 3.6550, Validation Loss Current: 8.5286, Validation Loss AVG: 8.5286, lr: 0.001
Epoch [38/80], Training Loss: 4.9363, Validation Loss Current: 6.5371, Validation Loss AVG: 6.5371, lr: 0.001
Epoch [39/80], Training Loss: 7.6726, Validation Loss Current: 7.8070, Validation Loss AVG: 7.8070, lr: 0.001
Epoch [40/80], Training Loss: 3.6888, Validation Loss Current: 7.3079, Validation Loss AVG: 7.3079, lr: 0.001
Epoch [41/80], Training Loss: 6.8137, Validation Loss Current: 6.4502, Validation Loss AVG: 6.4502, lr: 0.001
Epoch [42/80], Training Loss: 4.1989, Validation Loss Current: 7.2596, Validation Loss AVG: 7.2596, lr: 0.001
Epoch [43/80], Training Loss: 1.5060, Validation Loss Current: 6.3474, Validation Loss AVG: 6.3474, lr: 0.001
Epoch [44/80], Training Loss: 2.0895, Validation Loss Current: 5.8632, Validation Loss AVG: 5.8632, lr: 0.001
Epoch [45/80], Training Loss: 2.7600, Validation Loss Current: 6.9023, Validation Loss AVG: 6.9023, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random3 finished training. Best epoch: 15 Best val accuracy: [0.5736842105263158, 0.6611842105263158, 0.6470394736842107, 0.6131578947368421, 0.669407894736842, 0.694078947368421, 0.6950657894736841, 0.6845394736842105, 0.6657894736842106, 0.6430921052631579, 0.6851973684210526, 0.6983552631578949, 0.7075657894736842, 0.6976973684210526, 0.7125, 0.6835526315789473, 0.6805921052631578, 0.7105263157894737, 0.6641447368421052, 0.6927631578947369, 0.6782894736842106, 0.6460526315789474, 0.6648026315789474, 0.6453947368421054, 0.6075657894736842, 0.5513157894736842, 0.6536184210526316, 0.649671052631579, 0.6720394736842106, 0.6480263157894737, 0.6085526315789473, 0.5898026315789474, 0.6585526315789474, 0.6526315789473685, 0.6842105263157895, 0.6453947368421054, 0.5763157894736842, 0.6657894736842105, 0.6180921052631578, 0.6529605263157895, 0.6654605263157894, 0.6282894736842105, 0.6671052631578948, 0.6858552631578948, 0.65] Best val loss: 4.953487759828567


Current group: 0.4
Epoch [1/80], Training Loss: 42.4262, Validation Loss Current: 7.7805, Validation Loss AVG: 7.7805, lr: 0.001
Epoch [2/80], Training Loss: 20.9709, Validation Loss Current: 7.7465, Validation Loss AVG: 7.7465, lr: 0.001
Epoch [3/80], Training Loss: 13.7411, Validation Loss Current: 6.2101, Validation Loss AVG: 6.2101, lr: 0.001
Epoch [4/80], Training Loss: 10.1915, Validation Loss Current: 6.7456, Validation Loss AVG: 6.7456, lr: 0.001
Epoch [5/80], Training Loss: 9.9051, Validation Loss Current: 7.5649, Validation Loss AVG: 7.5649, lr: 0.001
Epoch [6/80], Training Loss: 8.4809, Validation Loss Current: 7.2164, Validation Loss AVG: 7.2164, lr: 0.001
Epoch [7/80], Training Loss: 7.1995, Validation Loss Current: 6.6050, Validation Loss AVG: 6.6050, lr: 0.001
Epoch [8/80], Training Loss: 4.5381, Validation Loss Current: 6.8890, Validation Loss AVG: 6.8890, lr: 0.001
Epoch [9/80], Training Loss: 4.1569, Validation Loss Current: 6.9587, Validation Loss AVG: 6.9587, lr: 0.001
Epoch [10/80], Training Loss: 3.8594, Validation Loss Current: 8.4331, Validation Loss AVG: 8.4331, lr: 0.001
Epoch [11/80], Training Loss: 5.9840, Validation Loss Current: 7.8561, Validation Loss AVG: 7.8561, lr: 0.001
Epoch [12/80], Training Loss: 7.5514, Validation Loss Current: 8.6023, Validation Loss AVG: 8.6023, lr: 0.001
Epoch [13/80], Training Loss: 4.9568, Validation Loss Current: 7.9538, Validation Loss AVG: 7.9538, lr: 0.001
Epoch [14/80], Training Loss: 4.5620, Validation Loss Current: 8.3308, Validation Loss AVG: 8.3308, lr: 0.001
Epoch [15/80], Training Loss: 5.9951, Validation Loss Current: 7.6298, Validation Loss AVG: 7.6298, lr: 0.001
Epoch [16/80], Training Loss: 4.4531, Validation Loss Current: 8.4040, Validation Loss AVG: 8.4040, lr: 0.001
Epoch [17/80], Training Loss: 3.6443, Validation Loss Current: 8.3378, Validation Loss AVG: 8.3378, lr: 0.001
Epoch [18/80], Training Loss: 2.7986, Validation Loss Current: 8.0917, Validation Loss AVG: 8.0917, lr: 0.001
Epoch [19/80], Training Loss: 2.8493, Validation Loss Current: 9.8176, Validation Loss AVG: 9.8176, lr: 0.001
Epoch [20/80], Training Loss: 2.9530, Validation Loss Current: 9.1533, Validation Loss AVG: 9.1533, lr: 0.001
Epoch [21/80], Training Loss: 4.0597, Validation Loss Current: 8.3350, Validation Loss AVG: 8.3350, lr: 0.001
Epoch [22/80], Training Loss: 5.2343, Validation Loss Current: 9.2506, Validation Loss AVG: 9.2506, lr: 0.001
Epoch [23/80], Training Loss: 4.2486, Validation Loss Current: 9.0856, Validation Loss AVG: 9.0856, lr: 0.001
Epoch [24/80], Training Loss: 3.0687, Validation Loss Current: 9.3933, Validation Loss AVG: 9.3933, lr: 0.001
Epoch [25/80], Training Loss: 2.7110, Validation Loss Current: 10.0454, Validation Loss AVG: 10.0454, lr: 0.001
Epoch [26/80], Training Loss: 1.4772, Validation Loss Current: 8.7239, Validation Loss AVG: 8.7239, lr: 0.001
Epoch [27/80], Training Loss: 3.0851, Validation Loss Current: 9.5380, Validation Loss AVG: 9.5380, lr: 0.001
Epoch [28/80], Training Loss: 8.6539, Validation Loss Current: 10.8470, Validation Loss AVG: 10.8470, lr: 0.001
Epoch [29/80], Training Loss: 2.8992, Validation Loss Current: 9.0759, Validation Loss AVG: 9.0759, lr: 0.001
Epoch [30/80], Training Loss: 1.7279, Validation Loss Current: 8.8146, Validation Loss AVG: 8.8146, lr: 0.001
Epoch [31/80], Training Loss: 1.7623, Validation Loss Current: 9.8486, Validation Loss AVG: 9.8486, lr: 0.001
Epoch [32/80], Training Loss: 0.9493, Validation Loss Current: 9.1840, Validation Loss AVG: 9.1840, lr: 0.001
Epoch [33/80], Training Loss: 1.7839, Validation Loss Current: 9.1454, Validation Loss AVG: 9.1454, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 3 Best val accuracy: [0.6105263157894736, 0.5592105263157894, 0.6296052631578947, 0.6263157894736843, 0.5963815789473685, 0.6121710526315789, 0.6398026315789475, 0.618421052631579, 0.6276315789473684, 0.5878289473684211, 0.5871710526315789, 0.5618421052631579, 0.5815789473684211, 0.5878289473684211, 0.5973684210526315, 0.6036184210526315, 0.6009868421052632, 0.6023026315789474, 0.5657894736842105, 0.5740131578947368, 0.5957236842105263, 0.5743421052631579, 0.5756578947368421, 0.5973684210526317, 0.5707236842105263, 0.605592105263158, 0.587171052631579, 0.5470394736842106, 0.5763157894736842, 0.5957236842105262, 0.5796052631578947, 0.6039473684210527, 0.5980263157894736] Best val loss: 6.210134887695313


----- Training resnet18 with sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] -----
Current group: llo_0.6_random0
Epoch [1/80], Training Loss: 42.2628, Validation Loss Current: 10.0574, Validation Loss AVG: 10.0574, lr: 0.001
Epoch [2/80], Training Loss: 39.4635, Validation Loss Current: 9.7329, Validation Loss AVG: 9.7329, lr: 0.001
Epoch [3/80], Training Loss: 39.0280, Validation Loss Current: 9.6108, Validation Loss AVG: 9.6108, lr: 0.001
Epoch [4/80], Training Loss: 38.2336, Validation Loss Current: 9.4873, Validation Loss AVG: 9.4873, lr: 0.001
Epoch [5/80], Training Loss: 37.0114, Validation Loss Current: 9.5030, Validation Loss AVG: 9.5030, lr: 0.001
Epoch [6/80], Training Loss: 36.8676, Validation Loss Current: 9.2228, Validation Loss AVG: 9.2228, lr: 0.001
Epoch [7/80], Training Loss: 36.3730, Validation Loss Current: 9.0149, Validation Loss AVG: 9.0149, lr: 0.001
Epoch [8/80], Training Loss: 35.4612, Validation Loss Current: 8.8649, Validation Loss AVG: 8.8649, lr: 0.001
Epoch [9/80], Training Loss: 34.0614, Validation Loss Current: 8.7089, Validation Loss AVG: 8.7089, lr: 0.001
Epoch [10/80], Training Loss: 33.6161, Validation Loss Current: 8.4795, Validation Loss AVG: 8.4795, lr: 0.001
Epoch [11/80], Training Loss: 32.2778, Validation Loss Current: 8.4634, Validation Loss AVG: 8.4634, lr: 0.001
Epoch [12/80], Training Loss: 31.6569, Validation Loss Current: 8.4694, Validation Loss AVG: 8.4694, lr: 0.001
Epoch [13/80], Training Loss: 31.6771, Validation Loss Current: 8.6804, Validation Loss AVG: 8.6804, lr: 0.001
Epoch [14/80], Training Loss: 32.1169, Validation Loss Current: 8.3024, Validation Loss AVG: 8.3024, lr: 0.001
Epoch [15/80], Training Loss: 30.9059, Validation Loss Current: 8.2368, Validation Loss AVG: 8.2368, lr: 0.001
Epoch [16/80], Training Loss: 29.4713, Validation Loss Current: 8.8124, Validation Loss AVG: 8.8124, lr: 0.001
Epoch [17/80], Training Loss: 29.7723, Validation Loss Current: 8.5635, Validation Loss AVG: 8.5635, lr: 0.001
Epoch [18/80], Training Loss: 29.4719, Validation Loss Current: 7.9560, Validation Loss AVG: 7.9560, lr: 0.001
Epoch [19/80], Training Loss: 27.9370, Validation Loss Current: 7.5221, Validation Loss AVG: 7.5221, lr: 0.001
Epoch [20/80], Training Loss: 27.4737, Validation Loss Current: 7.4259, Validation Loss AVG: 7.4259, lr: 0.001
Epoch [21/80], Training Loss: 28.1743, Validation Loss Current: 7.7432, Validation Loss AVG: 7.7432, lr: 0.001
Epoch [22/80], Training Loss: 27.8088, Validation Loss Current: 7.3846, Validation Loss AVG: 7.3846, lr: 0.001
Epoch [23/80], Training Loss: 27.7995, Validation Loss Current: 8.5050, Validation Loss AVG: 8.5050, lr: 0.001
Epoch [24/80], Training Loss: 26.0935, Validation Loss Current: 7.4028, Validation Loss AVG: 7.4028, lr: 0.001
Epoch [25/80], Training Loss: 26.1273, Validation Loss Current: 7.3722, Validation Loss AVG: 7.3722, lr: 0.001
Epoch [26/80], Training Loss: 24.6657, Validation Loss Current: 6.9194, Validation Loss AVG: 6.9194, lr: 0.001
Epoch [27/80], Training Loss: 22.9971, Validation Loss Current: 6.8183, Validation Loss AVG: 6.8183, lr: 0.001
Epoch [28/80], Training Loss: 23.5031, Validation Loss Current: 7.3287, Validation Loss AVG: 7.3287, lr: 0.001
Epoch [29/80], Training Loss: 22.9470, Validation Loss Current: 7.5705, Validation Loss AVG: 7.5705, lr: 0.001
Epoch [30/80], Training Loss: 21.1609, Validation Loss Current: 7.3934, Validation Loss AVG: 7.3934, lr: 0.001
Epoch [31/80], Training Loss: 21.0489, Validation Loss Current: 6.9304, Validation Loss AVG: 6.9304, lr: 0.001
Epoch [32/80], Training Loss: 20.7630, Validation Loss Current: 7.2788, Validation Loss AVG: 7.2788, lr: 0.001
Epoch [33/80], Training Loss: 19.2448, Validation Loss Current: 7.0739, Validation Loss AVG: 7.0739, lr: 0.001
Epoch [34/80], Training Loss: 19.1244, Validation Loss Current: 6.8614, Validation Loss AVG: 6.8614, lr: 0.001
Epoch [35/80], Training Loss: 17.1477, Validation Loss Current: 7.4783, Validation Loss AVG: 7.4783, lr: 0.001
Epoch [36/80], Training Loss: 18.5392, Validation Loss Current: 6.8733, Validation Loss AVG: 6.8733, lr: 0.001
Epoch [37/80], Training Loss: 16.3661, Validation Loss Current: 6.6021, Validation Loss AVG: 6.6021, lr: 0.001
Epoch [38/80], Training Loss: 15.4162, Validation Loss Current: 6.6935, Validation Loss AVG: 6.6935, lr: 0.001
Epoch [39/80], Training Loss: 13.9285, Validation Loss Current: 7.6955, Validation Loss AVG: 7.6955, lr: 0.001
Epoch [40/80], Training Loss: 14.5562, Validation Loss Current: 6.5053, Validation Loss AVG: 6.5053, lr: 0.001
Epoch [41/80], Training Loss: 13.8002, Validation Loss Current: 8.2479, Validation Loss AVG: 8.2479, lr: 0.001
Epoch [42/80], Training Loss: 17.1540, Validation Loss Current: 8.6448, Validation Loss AVG: 8.6448, lr: 0.001
Epoch [43/80], Training Loss: 13.5241, Validation Loss Current: 6.7391, Validation Loss AVG: 6.7391, lr: 0.001
Epoch [44/80], Training Loss: 10.5465, Validation Loss Current: 7.2306, Validation Loss AVG: 7.2306, lr: 0.001
Epoch [45/80], Training Loss: 9.5654, Validation Loss Current: 6.4581, Validation Loss AVG: 6.4581, lr: 0.001
Epoch [46/80], Training Loss: 9.7167, Validation Loss Current: 8.9833, Validation Loss AVG: 8.9833, lr: 0.001
Epoch [47/80], Training Loss: 9.6587, Validation Loss Current: 7.1812, Validation Loss AVG: 7.1812, lr: 0.001
Epoch [48/80], Training Loss: 11.5854, Validation Loss Current: 7.3859, Validation Loss AVG: 7.3859, lr: 0.001
Epoch [49/80], Training Loss: 9.9799, Validation Loss Current: 7.3545, Validation Loss AVG: 7.3545, lr: 0.001
Epoch [50/80], Training Loss: 11.3428, Validation Loss Current: 7.1938, Validation Loss AVG: 7.1938, lr: 0.001
Epoch [51/80], Training Loss: 10.5840, Validation Loss Current: 11.9822, Validation Loss AVG: 11.9822, lr: 0.001
Epoch [52/80], Training Loss: 13.8882, Validation Loss Current: 7.6924, Validation Loss AVG: 7.6924, lr: 0.001
Epoch [53/80], Training Loss: 11.3294, Validation Loss Current: 7.2244, Validation Loss AVG: 7.2244, lr: 0.001
Epoch [54/80], Training Loss: 9.7754, Validation Loss Current: 7.6272, Validation Loss AVG: 7.6272, lr: 0.001
Epoch [55/80], Training Loss: 10.4816, Validation Loss Current: 10.5985, Validation Loss AVG: 10.5985, lr: 0.001
Epoch [56/80], Training Loss: 13.1937, Validation Loss Current: 8.7525, Validation Loss AVG: 8.7525, lr: 0.001
Epoch [57/80], Training Loss: 8.3638, Validation Loss Current: 7.2144, Validation Loss AVG: 7.2144, lr: 0.001
Epoch [58/80], Training Loss: 5.3374, Validation Loss Current: 6.9507, Validation Loss AVG: 6.9507, lr: 0.001
Epoch [59/80], Training Loss: 4.2048, Validation Loss Current: 7.5781, Validation Loss AVG: 7.5781, lr: 0.001
Epoch [60/80], Training Loss: 6.0789, Validation Loss Current: 10.0622, Validation Loss AVG: 10.0622, lr: 0.001
Epoch [61/80], Training Loss: 9.5849, Validation Loss Current: 9.7708, Validation Loss AVG: 9.7708, lr: 0.001
Epoch [62/80], Training Loss: 7.9855, Validation Loss Current: 8.2557, Validation Loss AVG: 8.2557, lr: 0.001
Epoch [63/80], Training Loss: 8.2456, Validation Loss Current: 8.2303, Validation Loss AVG: 8.2303, lr: 0.001
Epoch [64/80], Training Loss: 7.4588, Validation Loss Current: 9.4239, Validation Loss AVG: 9.4239, lr: 0.001
Epoch [65/80], Training Loss: 5.6936, Validation Loss Current: 8.5538, Validation Loss AVG: 8.5538, lr: 0.001
Epoch [66/80], Training Loss: 5.2705, Validation Loss Current: 8.0903, Validation Loss AVG: 8.0903, lr: 0.001
Epoch [67/80], Training Loss: 4.3571, Validation Loss Current: 8.0123, Validation Loss AVG: 8.0123, lr: 0.001
Epoch [68/80], Training Loss: 3.1709, Validation Loss Current: 7.8231, Validation Loss AVG: 7.8231, lr: 0.001
Epoch [69/80], Training Loss: 6.2648, Validation Loss Current: 8.2600, Validation Loss AVG: 8.2600, lr: 0.001
Epoch [70/80], Training Loss: 6.3974, Validation Loss Current: 9.0325, Validation Loss AVG: 9.0325, lr: 0.001
Epoch [71/80], Training Loss: 3.6206, Validation Loss Current: 7.8155, Validation Loss AVG: 7.8155, lr: 0.001
Epoch [72/80], Training Loss: 2.6245, Validation Loss Current: 8.7074, Validation Loss AVG: 8.7074, lr: 0.001
Epoch [73/80], Training Loss: 3.6409, Validation Loss Current: 8.9854, Validation Loss AVG: 8.9854, lr: 0.001
Epoch [74/80], Training Loss: 3.7882, Validation Loss Current: 10.2282, Validation Loss AVG: 10.2282, lr: 0.001
Epoch [75/80], Training Loss: 4.9076, Validation Loss Current: 10.8796, Validation Loss AVG: 10.8796, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random0 finished training. Best epoch: 45 Best val accuracy: [0.2457236842105263, 0.2792763157894737, 0.29539473684210527, 0.319078947368421, 0.2861842105263158, 0.32105263157894737, 0.3480263157894737, 0.3539473684210526, 0.3759868421052632, 0.3875, 0.39506578947368426, 0.3924342105263158, 0.3861842105263158, 0.40328947368421053, 0.40361842105263157, 0.3917763157894737, 0.3825657894736842, 0.44342105263157894, 0.4569078947368421, 0.4759868421052632, 0.4598684210526315, 0.4894736842105263, 0.42072368421052636, 0.4828947368421053, 0.47828947368421054, 0.5121710526315789, 0.5213815789473684, 0.4894736842105263, 0.4536184210526316, 0.49210526315789477, 0.5161184210526316, 0.49703947368421053, 0.5174342105263159, 0.5302631578947368, 0.4809210526315789, 0.5361842105263157, 0.555921052631579, 0.5421052631578948, 0.5088815789473684, 0.5529605263157895, 0.49967105263157896, 0.4319078947368421, 0.5605263157894737, 0.5398026315789475, 0.5888157894736843, 0.4634868421052632, 0.5575657894736843, 0.5473684210526316, 0.5453947368421053, 0.5421052631578946, 0.43519736842105256, 0.5526315789473685, 0.5325657894736843, 0.5414473684210528, 0.45559210526315785, 0.4822368421052632, 0.568092105263158, 0.575328947368421, 0.5710526315789475, 0.4789473684210527, 0.49078947368421055, 0.5335526315789474, 0.5151315789473684, 0.4947368421052632, 0.5434210526315789, 0.5776315789473684, 0.5595394736842106, 0.5717105263157893, 0.5361842105263158, 0.5388157894736841, 0.5565789473684211, 0.5773026315789473, 0.5618421052631579, 0.5236842105263158, 0.47828947368421054] Best val loss: 6.458064353466034


Current group: llo_0.6_random1
Epoch [1/80], Training Loss: 36.0550, Validation Loss Current: 9.8166, Validation Loss AVG: 9.8166, lr: 0.001
Epoch [2/80], Training Loss: 25.6231, Validation Loss Current: 8.7141, Validation Loss AVG: 8.7141, lr: 0.001
Epoch [3/80], Training Loss: 21.0467, Validation Loss Current: 6.7294, Validation Loss AVG: 6.7294, lr: 0.001
Epoch [4/80], Training Loss: 18.9609, Validation Loss Current: 7.5620, Validation Loss AVG: 7.5620, lr: 0.001
Epoch [5/80], Training Loss: 15.9709, Validation Loss Current: 7.6199, Validation Loss AVG: 7.6199, lr: 0.001
Epoch [6/80], Training Loss: 13.9529, Validation Loss Current: 5.9998, Validation Loss AVG: 5.9998, lr: 0.001
Epoch [7/80], Training Loss: 10.3382, Validation Loss Current: 6.3044, Validation Loss AVG: 6.3044, lr: 0.001
Epoch [8/80], Training Loss: 15.7320, Validation Loss Current: 9.1541, Validation Loss AVG: 9.1541, lr: 0.001
Epoch [9/80], Training Loss: 16.9586, Validation Loss Current: 11.1637, Validation Loss AVG: 11.1637, lr: 0.001
Epoch [10/80], Training Loss: 15.4221, Validation Loss Current: 7.9129, Validation Loss AVG: 7.9129, lr: 0.001
Epoch [11/80], Training Loss: 11.3385, Validation Loss Current: 6.8639, Validation Loss AVG: 6.8639, lr: 0.001
Epoch [12/80], Training Loss: 11.6252, Validation Loss Current: 7.2656, Validation Loss AVG: 7.2656, lr: 0.001
Epoch [13/80], Training Loss: 10.3714, Validation Loss Current: 7.5683, Validation Loss AVG: 7.5683, lr: 0.001
Epoch [14/80], Training Loss: 9.9209, Validation Loss Current: 6.6596, Validation Loss AVG: 6.6596, lr: 0.001
Epoch [15/80], Training Loss: 8.0034, Validation Loss Current: 6.4236, Validation Loss AVG: 6.4236, lr: 0.001
Epoch [16/80], Training Loss: 8.3078, Validation Loss Current: 9.9127, Validation Loss AVG: 9.9127, lr: 0.001
Epoch [17/80], Training Loss: 9.9003, Validation Loss Current: 7.8233, Validation Loss AVG: 7.8233, lr: 0.001
Epoch [18/80], Training Loss: 4.7904, Validation Loss Current: 7.2605, Validation Loss AVG: 7.2605, lr: 0.001
Epoch [19/80], Training Loss: 3.5101, Validation Loss Current: 6.4467, Validation Loss AVG: 6.4467, lr: 0.001
Epoch [20/80], Training Loss: 5.9038, Validation Loss Current: 7.1121, Validation Loss AVG: 7.1121, lr: 0.001
Epoch [21/80], Training Loss: 7.2353, Validation Loss Current: 7.4728, Validation Loss AVG: 7.4728, lr: 0.001
Epoch [22/80], Training Loss: 5.0564, Validation Loss Current: 6.8927, Validation Loss AVG: 6.8927, lr: 0.001
Epoch [23/80], Training Loss: 3.0919, Validation Loss Current: 7.0901, Validation Loss AVG: 7.0901, lr: 0.001
Epoch [24/80], Training Loss: 3.1698, Validation Loss Current: 7.0322, Validation Loss AVG: 7.0322, lr: 0.001
Epoch [25/80], Training Loss: 4.3633, Validation Loss Current: 7.7468, Validation Loss AVG: 7.7468, lr: 0.001
Epoch [26/80], Training Loss: 4.3106, Validation Loss Current: 8.4323, Validation Loss AVG: 8.4323, lr: 0.001
Epoch [27/80], Training Loss: 8.5537, Validation Loss Current: 8.7887, Validation Loss AVG: 8.7887, lr: 0.001
Epoch [28/80], Training Loss: 6.2374, Validation Loss Current: 10.2819, Validation Loss AVG: 10.2819, lr: 0.001
Epoch [29/80], Training Loss: 5.8876, Validation Loss Current: 8.4441, Validation Loss AVG: 8.4441, lr: 0.001
Epoch [30/80], Training Loss: 7.0785, Validation Loss Current: 12.3708, Validation Loss AVG: 12.3708, lr: 0.001
Epoch [31/80], Training Loss: 8.8462, Validation Loss Current: 8.3004, Validation Loss AVG: 8.3004, lr: 0.001
Epoch [32/80], Training Loss: 6.2488, Validation Loss Current: 8.2368, Validation Loss AVG: 8.2368, lr: 0.001
Epoch [33/80], Training Loss: 3.4762, Validation Loss Current: 8.2587, Validation Loss AVG: 8.2587, lr: 0.001
Epoch [34/80], Training Loss: 3.6544, Validation Loss Current: 8.0369, Validation Loss AVG: 8.0369, lr: 0.001
Epoch [35/80], Training Loss: 3.7165, Validation Loss Current: 7.5472, Validation Loss AVG: 7.5472, lr: 0.001
Epoch [36/80], Training Loss: 6.1655, Validation Loss Current: 9.3977, Validation Loss AVG: 9.3977, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random1 finished training. Best epoch: 6 Best val accuracy: [0.48157894736842105, 0.4930921052631579, 0.5842105263157895, 0.5546052631578948, 0.5421052631578948, 0.6299342105263157, 0.6226973684210526, 0.4848684210526316, 0.4809210526315789, 0.5305921052631579, 0.5809210526315789, 0.5700657894736842, 0.5661184210526315, 0.6203947368421053, 0.6233552631578947, 0.5095394736842105, 0.5552631578947368, 0.6023026315789474, 0.6378289473684211, 0.6194078947368421, 0.5881578947368421, 0.6319078947368422, 0.6289473684210527, 0.6375000000000001, 0.6075657894736842, 0.5592105263157896, 0.5671052631578947, 0.5463815789473684, 0.5970394736842106, 0.4878289473684211, 0.6125, 0.5720394736842105, 0.59375, 0.6154605263157894, 0.6174342105263158, 0.5434210526315789] Best val loss: 5.9998379111289974


Current group: llo_0.6_random2
Epoch [1/80], Training Loss: 37.2449, Validation Loss Current: 7.2198, Validation Loss AVG: 7.2198, lr: 0.001
Epoch [2/80], Training Loss: 23.3896, Validation Loss Current: 6.7978, Validation Loss AVG: 6.7978, lr: 0.001
Epoch [3/80], Training Loss: 18.1638, Validation Loss Current: 8.2120, Validation Loss AVG: 8.2120, lr: 0.001
Epoch [4/80], Training Loss: 16.4245, Validation Loss Current: 7.2010, Validation Loss AVG: 7.2010, lr: 0.001
Epoch [5/80], Training Loss: 11.4162, Validation Loss Current: 5.5522, Validation Loss AVG: 5.5522, lr: 0.001
Epoch [6/80], Training Loss: 9.7142, Validation Loss Current: 6.6356, Validation Loss AVG: 6.6356, lr: 0.001
Epoch [7/80], Training Loss: 10.8051, Validation Loss Current: 6.6380, Validation Loss AVG: 6.6380, lr: 0.001
Epoch [8/80], Training Loss: 6.8035, Validation Loss Current: 5.4557, Validation Loss AVG: 5.4557, lr: 0.001
Epoch [9/80], Training Loss: 6.5767, Validation Loss Current: 6.0539, Validation Loss AVG: 6.0539, lr: 0.001
Epoch [10/80], Training Loss: 7.0986, Validation Loss Current: 6.4049, Validation Loss AVG: 6.4049, lr: 0.001
Epoch [11/80], Training Loss: 8.4526, Validation Loss Current: 9.5123, Validation Loss AVG: 9.5123, lr: 0.001
Epoch [12/80], Training Loss: 6.8895, Validation Loss Current: 6.6089, Validation Loss AVG: 6.6089, lr: 0.001
Epoch [13/80], Training Loss: 3.1726, Validation Loss Current: 5.5484, Validation Loss AVG: 5.5484, lr: 0.001
Epoch [14/80], Training Loss: 4.2721, Validation Loss Current: 6.5076, Validation Loss AVG: 6.5076, lr: 0.001
Epoch [15/80], Training Loss: 6.5785, Validation Loss Current: 6.0371, Validation Loss AVG: 6.0371, lr: 0.001
Epoch [16/80], Training Loss: 8.8841, Validation Loss Current: 8.4676, Validation Loss AVG: 8.4676, lr: 0.001
Epoch [17/80], Training Loss: 12.8582, Validation Loss Current: 7.7854, Validation Loss AVG: 7.7854, lr: 0.001
Epoch [18/80], Training Loss: 4.9481, Validation Loss Current: 7.0830, Validation Loss AVG: 7.0830, lr: 0.001
Epoch [19/80], Training Loss: 2.5575, Validation Loss Current: 6.0717, Validation Loss AVG: 6.0717, lr: 0.001
Epoch [20/80], Training Loss: 2.9497, Validation Loss Current: 6.5193, Validation Loss AVG: 6.5193, lr: 0.001
Epoch [21/80], Training Loss: 3.4507, Validation Loss Current: 7.2344, Validation Loss AVG: 7.2344, lr: 0.001
Epoch [22/80], Training Loss: 4.2690, Validation Loss Current: 7.0330, Validation Loss AVG: 7.0330, lr: 0.001
Epoch [23/80], Training Loss: 6.6065, Validation Loss Current: 7.1630, Validation Loss AVG: 7.1630, lr: 0.001
Epoch [24/80], Training Loss: 4.9642, Validation Loss Current: 7.5859, Validation Loss AVG: 7.5859, lr: 0.001
Epoch [25/80], Training Loss: 4.0933, Validation Loss Current: 7.7329, Validation Loss AVG: 7.7329, lr: 0.001
Epoch [26/80], Training Loss: 4.3027, Validation Loss Current: 8.2107, Validation Loss AVG: 8.2107, lr: 0.001
Epoch [27/80], Training Loss: 6.0374, Validation Loss Current: 8.1142, Validation Loss AVG: 8.1142, lr: 0.001
Epoch [28/80], Training Loss: 9.8959, Validation Loss Current: 8.4590, Validation Loss AVG: 8.4590, lr: 0.001
Epoch [29/80], Training Loss: 8.0033, Validation Loss Current: 8.3103, Validation Loss AVG: 8.3103, lr: 0.001
Epoch [30/80], Training Loss: 5.4925, Validation Loss Current: 7.5937, Validation Loss AVG: 7.5937, lr: 0.001
Epoch [31/80], Training Loss: 3.7563, Validation Loss Current: 7.5770, Validation Loss AVG: 7.5770, lr: 0.001
Epoch [32/80], Training Loss: 2.9445, Validation Loss Current: 7.0065, Validation Loss AVG: 7.0065, lr: 0.001
Epoch [33/80], Training Loss: 3.2318, Validation Loss Current: 7.3799, Validation Loss AVG: 7.3799, lr: 0.001
Epoch [34/80], Training Loss: 5.1969, Validation Loss Current: 8.7951, Validation Loss AVG: 8.7951, lr: 0.001
Epoch [35/80], Training Loss: 2.9934, Validation Loss Current: 8.3968, Validation Loss AVG: 8.3968, lr: 0.001
Epoch [36/80], Training Loss: 3.5801, Validation Loss Current: 8.7489, Validation Loss AVG: 8.7489, lr: 0.001
Epoch [37/80], Training Loss: 2.4697, Validation Loss Current: 7.7252, Validation Loss AVG: 7.7252, lr: 0.001
Epoch [38/80], Training Loss: 4.2178, Validation Loss Current: 7.8695, Validation Loss AVG: 7.8695, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random2 finished training. Best epoch: 8 Best val accuracy: [0.5769736842105264, 0.5914473684210526, 0.5029605263157895, 0.5677631578947369, 0.6618421052631579, 0.6085526315789473, 0.6042763157894738, 0.6782894736842107, 0.6588815789473685, 0.6434210526315789, 0.5230263157894737, 0.6480263157894737, 0.6717105263157895, 0.655921052631579, 0.6667763157894736, 0.5513157894736842, 0.5565789473684211, 0.6279605263157895, 0.6585526315789474, 0.6552631578947368, 0.6180921052631578, 0.6384868421052632, 0.625328947368421, 0.618421052631579, 0.6075657894736841, 0.5858552631578948, 0.5950657894736843, 0.5763157894736841, 0.5858552631578947, 0.6177631578947368, 0.60625, 0.6476973684210526, 0.6335526315789474, 0.6115131578947368, 0.5881578947368421, 0.5898026315789474, 0.6279605263157895, 0.6332236842105263] Best val loss: 5.455689477920532


Current group: llo_0.6_random3
Epoch [1/80], Training Loss: 39.6849, Validation Loss Current: 8.1235, Validation Loss AVG: 8.1235, lr: 0.001
Epoch [2/80], Training Loss: 28.9059, Validation Loss Current: 8.1506, Validation Loss AVG: 8.1506, lr: 0.001
Epoch [3/80], Training Loss: 18.2349, Validation Loss Current: 6.5938, Validation Loss AVG: 6.5938, lr: 0.001
Epoch [4/80], Training Loss: 14.0267, Validation Loss Current: 6.7630, Validation Loss AVG: 6.7630, lr: 0.001
Epoch [5/80], Training Loss: 9.6256, Validation Loss Current: 5.4338, Validation Loss AVG: 5.4338, lr: 0.001
Epoch [6/80], Training Loss: 10.4180, Validation Loss Current: 6.2452, Validation Loss AVG: 6.2452, lr: 0.001
Epoch [7/80], Training Loss: 10.7582, Validation Loss Current: 6.2593, Validation Loss AVG: 6.2593, lr: 0.001
Epoch [8/80], Training Loss: 7.9198, Validation Loss Current: 5.6503, Validation Loss AVG: 5.6503, lr: 0.001
Epoch [9/80], Training Loss: 6.3720, Validation Loss Current: 6.2216, Validation Loss AVG: 6.2216, lr: 0.001
Epoch [10/80], Training Loss: 4.7847, Validation Loss Current: 5.4474, Validation Loss AVG: 5.4474, lr: 0.001
Epoch [11/80], Training Loss: 3.9697, Validation Loss Current: 5.1105, Validation Loss AVG: 5.1105, lr: 0.001
Epoch [12/80], Training Loss: 3.3195, Validation Loss Current: 5.3695, Validation Loss AVG: 5.3695, lr: 0.001
Epoch [13/80], Training Loss: 3.3087, Validation Loss Current: 5.9757, Validation Loss AVG: 5.9757, lr: 0.001
Epoch [14/80], Training Loss: 2.9826, Validation Loss Current: 6.1609, Validation Loss AVG: 6.1609, lr: 0.001
Epoch [15/80], Training Loss: 2.4392, Validation Loss Current: 6.0927, Validation Loss AVG: 6.0927, lr: 0.001
Epoch [16/80], Training Loss: 3.5574, Validation Loss Current: 6.4470, Validation Loss AVG: 6.4470, lr: 0.001
Epoch [17/80], Training Loss: 2.9023, Validation Loss Current: 6.3741, Validation Loss AVG: 6.3741, lr: 0.001
Epoch [18/80], Training Loss: 4.0317, Validation Loss Current: 5.9908, Validation Loss AVG: 5.9908, lr: 0.001
Epoch [19/80], Training Loss: 6.8953, Validation Loss Current: 6.2218, Validation Loss AVG: 6.2218, lr: 0.001
Epoch [20/80], Training Loss: 5.4715, Validation Loss Current: 7.0946, Validation Loss AVG: 7.0946, lr: 0.001
Epoch [21/80], Training Loss: 7.5838, Validation Loss Current: 6.9335, Validation Loss AVG: 6.9335, lr: 0.001
Epoch [22/80], Training Loss: 5.5440, Validation Loss Current: 6.9461, Validation Loss AVG: 6.9461, lr: 0.001
Epoch [23/80], Training Loss: 6.4877, Validation Loss Current: 8.8898, Validation Loss AVG: 8.8898, lr: 0.001
Epoch [24/80], Training Loss: 2.4785, Validation Loss Current: 6.3302, Validation Loss AVG: 6.3302, lr: 0.001
Epoch [25/80], Training Loss: 3.0716, Validation Loss Current: 6.9337, Validation Loss AVG: 6.9337, lr: 0.001
Epoch [26/80], Training Loss: 6.5454, Validation Loss Current: 8.8668, Validation Loss AVG: 8.8668, lr: 0.001
Epoch [27/80], Training Loss: 8.8590, Validation Loss Current: 7.8271, Validation Loss AVG: 7.8271, lr: 0.001
Epoch [28/80], Training Loss: 8.7135, Validation Loss Current: 8.5806, Validation Loss AVG: 8.5806, lr: 0.001
Epoch [29/80], Training Loss: 5.4625, Validation Loss Current: 7.3123, Validation Loss AVG: 7.3123, lr: 0.001
Epoch [30/80], Training Loss: 5.1217, Validation Loss Current: 8.5281, Validation Loss AVG: 8.5281, lr: 0.001
Epoch [31/80], Training Loss: 5.9372, Validation Loss Current: 7.1564, Validation Loss AVG: 7.1564, lr: 0.001
Epoch [32/80], Training Loss: 4.8258, Validation Loss Current: 7.9406, Validation Loss AVG: 7.9406, lr: 0.001
Epoch [33/80], Training Loss: 4.4648, Validation Loss Current: 7.6846, Validation Loss AVG: 7.6846, lr: 0.001
Epoch [34/80], Training Loss: 5.9594, Validation Loss Current: 7.9726, Validation Loss AVG: 7.9726, lr: 0.001
Epoch [35/80], Training Loss: 3.8847, Validation Loss Current: 7.1087, Validation Loss AVG: 7.1087, lr: 0.001
Epoch [36/80], Training Loss: 4.3701, Validation Loss Current: 7.7037, Validation Loss AVG: 7.7037, lr: 0.001
Epoch [37/80], Training Loss: 5.0883, Validation Loss Current: 7.8777, Validation Loss AVG: 7.8777, lr: 0.001
Epoch [38/80], Training Loss: 6.3920, Validation Loss Current: 7.3166, Validation Loss AVG: 7.3166, lr: 0.001
Epoch [39/80], Training Loss: 7.7032, Validation Loss Current: 8.7338, Validation Loss AVG: 8.7338, lr: 0.001
Epoch [40/80], Training Loss: 4.1638, Validation Loss Current: 7.4616, Validation Loss AVG: 7.4616, lr: 0.001
Epoch [41/80], Training Loss: 4.9857, Validation Loss Current: 9.3483, Validation Loss AVG: 9.3483, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random3 finished training. Best epoch: 11 Best val accuracy: [0.5861842105263158, 0.5542763157894737, 0.5986842105263157, 0.6154605263157895, 0.6792763157894737, 0.6394736842105263, 0.6384868421052632, 0.6753289473684211, 0.6361842105263158, 0.6921052631578947, 0.7055921052631579, 0.7174342105263157, 0.6641447368421053, 0.6828947368421053, 0.6832236842105263, 0.6720394736842106, 0.6782894736842107, 0.6819078947368421, 0.687171052631579, 0.6417763157894737, 0.6394736842105263, 0.6440789473684211, 0.5815789473684211, 0.675, 0.6723684210526316, 0.5947368421052632, 0.6256578947368421, 0.611842105263158, 0.6572368421052632, 0.6049342105263158, 0.649671052631579, 0.6325657894736842, 0.6536184210526316, 0.618421052631579, 0.6628289473684211, 0.6519736842105264, 0.6302631578947369, 0.6519736842105263, 0.6111842105263158, 0.6546052631578947, 0.6157894736842106] Best val loss: 5.110480558872223


Current group: 0.6
Epoch [1/80], Training Loss: 35.0931, Validation Loss Current: 6.4337, Validation Loss AVG: 6.4337, lr: 0.001
Epoch [2/80], Training Loss: 18.2326, Validation Loss Current: 6.6203, Validation Loss AVG: 6.6203, lr: 0.001
Epoch [3/80], Training Loss: 10.1409, Validation Loss Current: 6.7817, Validation Loss AVG: 6.7817, lr: 0.001
Epoch [4/80], Training Loss: 7.6018, Validation Loss Current: 6.7465, Validation Loss AVG: 6.7465, lr: 0.001
Epoch [5/80], Training Loss: 8.2458, Validation Loss Current: 8.3033, Validation Loss AVG: 8.3033, lr: 0.001
Epoch [6/80], Training Loss: 11.1823, Validation Loss Current: 7.1928, Validation Loss AVG: 7.1928, lr: 0.001
Epoch [7/80], Training Loss: 8.4467, Validation Loss Current: 8.8089, Validation Loss AVG: 8.8089, lr: 0.001
Epoch [8/80], Training Loss: 6.5320, Validation Loss Current: 7.4488, Validation Loss AVG: 7.4488, lr: 0.001
Epoch [9/80], Training Loss: 5.2042, Validation Loss Current: 7.0218, Validation Loss AVG: 7.0218, lr: 0.001
Epoch [10/80], Training Loss: 5.8143, Validation Loss Current: 7.1236, Validation Loss AVG: 7.1236, lr: 0.001
Epoch [11/80], Training Loss: 6.8339, Validation Loss Current: 8.4098, Validation Loss AVG: 8.4098, lr: 0.001
Epoch [12/80], Training Loss: 6.2116, Validation Loss Current: 7.8874, Validation Loss AVG: 7.8874, lr: 0.001
Epoch [13/80], Training Loss: 5.4593, Validation Loss Current: 8.0873, Validation Loss AVG: 8.0873, lr: 0.001
Epoch [14/80], Training Loss: 5.7873, Validation Loss Current: 7.0844, Validation Loss AVG: 7.0844, lr: 0.001
Epoch [15/80], Training Loss: 4.3617, Validation Loss Current: 8.5550, Validation Loss AVG: 8.5550, lr: 0.001
Epoch [16/80], Training Loss: 5.2685, Validation Loss Current: 8.8768, Validation Loss AVG: 8.8768, lr: 0.001
Epoch [17/80], Training Loss: 5.9802, Validation Loss Current: 7.8814, Validation Loss AVG: 7.8814, lr: 0.001
Epoch [18/80], Training Loss: 7.9698, Validation Loss Current: 9.2443, Validation Loss AVG: 9.2443, lr: 0.001
Epoch [19/80], Training Loss: 4.9380, Validation Loss Current: 8.5238, Validation Loss AVG: 8.5238, lr: 0.001
Epoch [20/80], Training Loss: 4.6430, Validation Loss Current: 8.1458, Validation Loss AVG: 8.1458, lr: 0.001
Epoch [21/80], Training Loss: 5.6371, Validation Loss Current: 8.1365, Validation Loss AVG: 8.1365, lr: 0.001
Epoch [22/80], Training Loss: 3.5312, Validation Loss Current: 7.8054, Validation Loss AVG: 7.8054, lr: 0.001
Epoch [23/80], Training Loss: 3.0703, Validation Loss Current: 8.7642, Validation Loss AVG: 8.7642, lr: 0.001
Epoch [24/80], Training Loss: 1.3211, Validation Loss Current: 7.9906, Validation Loss AVG: 7.9906, lr: 0.001
Epoch [25/80], Training Loss: 4.1530, Validation Loss Current: 7.9779, Validation Loss AVG: 7.9779, lr: 0.001
Epoch [26/80], Training Loss: 6.4522, Validation Loss Current: 9.7703, Validation Loss AVG: 9.7703, lr: 0.001
Epoch [27/80], Training Loss: 5.9981, Validation Loss Current: 9.4885, Validation Loss AVG: 9.4885, lr: 0.001
Epoch [28/80], Training Loss: 4.7680, Validation Loss Current: 10.7509, Validation Loss AVG: 10.7509, lr: 0.001
Epoch [29/80], Training Loss: 4.2135, Validation Loss Current: 9.2003, Validation Loss AVG: 9.2003, lr: 0.001
Epoch [30/80], Training Loss: 4.4976, Validation Loss Current: 11.3165, Validation Loss AVG: 11.3165, lr: 0.001
Epoch [31/80], Training Loss: 2.6944, Validation Loss Current: 9.4925, Validation Loss AVG: 9.4925, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 1 Best val accuracy: [0.6667763157894737, 0.6421052631578947, 0.6470394736842106, 0.6430921052631579, 0.5779605263157894, 0.6151315789473684, 0.5766447368421053, 0.6259868421052632, 0.6289473684210527, 0.6368421052631579, 0.5776315789473684, 0.6, 0.6, 0.6256578947368421, 0.5868421052631578, 0.5605263157894737, 0.5891447368421053, 0.5782894736842106, 0.5585526315789473, 0.6046052631578946, 0.5842105263157895, 0.606907894736842, 0.5710526315789475, 0.6078947368421053, 0.6009868421052632, 0.5575657894736842, 0.5440789473684211, 0.5292763157894737, 0.5371710526315789, 0.5421052631578946, 0.5720394736842106] Best val loss: 6.433711636066437


----- Training resnet18 with sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] -----
Current group: llo_1_random0
Epoch [1/80], Training Loss: 41.6273, Validation Loss Current: 10.0573, Validation Loss AVG: 10.0573, lr: 0.001
Epoch [2/80], Training Loss: 40.2394, Validation Loss Current: 9.8971, Validation Loss AVG: 9.8971, lr: 0.001
Epoch [3/80], Training Loss: 39.4336, Validation Loss Current: 9.8408, Validation Loss AVG: 9.8408, lr: 0.001
Epoch [4/80], Training Loss: 38.6929, Validation Loss Current: 9.5409, Validation Loss AVG: 9.5409, lr: 0.001
Epoch [5/80], Training Loss: 38.4258, Validation Loss Current: 9.4147, Validation Loss AVG: 9.4147, lr: 0.001
Epoch [6/80], Training Loss: 37.4958, Validation Loss Current: 9.2981, Validation Loss AVG: 9.2981, lr: 0.001
Epoch [7/80], Training Loss: 37.1359, Validation Loss Current: 9.0415, Validation Loss AVG: 9.0415, lr: 0.001
Epoch [8/80], Training Loss: 36.3485, Validation Loss Current: 8.8985, Validation Loss AVG: 8.8985, lr: 0.001
Epoch [9/80], Training Loss: 35.4672, Validation Loss Current: 8.8131, Validation Loss AVG: 8.8131, lr: 0.001
Epoch [10/80], Training Loss: 35.2925, Validation Loss Current: 8.8408, Validation Loss AVG: 8.8408, lr: 0.001
Epoch [11/80], Training Loss: 34.1893, Validation Loss Current: 8.5994, Validation Loss AVG: 8.5994, lr: 0.001
Epoch [12/80], Training Loss: 32.4910, Validation Loss Current: 8.3412, Validation Loss AVG: 8.3412, lr: 0.001
Epoch [13/80], Training Loss: 32.7780, Validation Loss Current: 8.3605, Validation Loss AVG: 8.3605, lr: 0.001
Epoch [14/80], Training Loss: 31.5753, Validation Loss Current: 7.9302, Validation Loss AVG: 7.9302, lr: 0.001
Epoch [15/80], Training Loss: 31.0376, Validation Loss Current: 7.7675, Validation Loss AVG: 7.7675, lr: 0.001
Epoch [16/80], Training Loss: 29.5353, Validation Loss Current: 7.6968, Validation Loss AVG: 7.6968, lr: 0.001
Epoch [17/80], Training Loss: 28.9485, Validation Loss Current: 7.8566, Validation Loss AVG: 7.8566, lr: 0.001
Epoch [18/80], Training Loss: 28.2591, Validation Loss Current: 7.4212, Validation Loss AVG: 7.4212, lr: 0.001
Epoch [19/80], Training Loss: 27.5560, Validation Loss Current: 7.8141, Validation Loss AVG: 7.8141, lr: 0.001
Epoch [20/80], Training Loss: 26.9157, Validation Loss Current: 7.5812, Validation Loss AVG: 7.5812, lr: 0.001
Epoch [21/80], Training Loss: 26.1382, Validation Loss Current: 7.4235, Validation Loss AVG: 7.4235, lr: 0.001
Epoch [22/80], Training Loss: 24.5921, Validation Loss Current: 7.3861, Validation Loss AVG: 7.3861, lr: 0.001
Epoch [23/80], Training Loss: 25.0091, Validation Loss Current: 8.0353, Validation Loss AVG: 8.0353, lr: 0.001
Epoch [24/80], Training Loss: 24.3619, Validation Loss Current: 8.2183, Validation Loss AVG: 8.2183, lr: 0.001
Epoch [25/80], Training Loss: 24.0736, Validation Loss Current: 7.5509, Validation Loss AVG: 7.5509, lr: 0.001
Epoch [26/80], Training Loss: 22.8190, Validation Loss Current: 7.4715, Validation Loss AVG: 7.4715, lr: 0.001
Epoch [27/80], Training Loss: 22.6007, Validation Loss Current: 6.9268, Validation Loss AVG: 6.9268, lr: 0.001
Epoch [28/80], Training Loss: 20.6869, Validation Loss Current: 7.1757, Validation Loss AVG: 7.1757, lr: 0.001
Epoch [29/80], Training Loss: 19.9302, Validation Loss Current: 7.1980, Validation Loss AVG: 7.1980, lr: 0.001
Epoch [30/80], Training Loss: 20.6643, Validation Loss Current: 7.9968, Validation Loss AVG: 7.9968, lr: 0.001
Epoch [31/80], Training Loss: 19.1667, Validation Loss Current: 6.8269, Validation Loss AVG: 6.8269, lr: 0.001
Epoch [32/80], Training Loss: 18.6354, Validation Loss Current: 8.0878, Validation Loss AVG: 8.0878, lr: 0.001
Epoch [33/80], Training Loss: 17.1029, Validation Loss Current: 7.3215, Validation Loss AVG: 7.3215, lr: 0.001
Epoch [34/80], Training Loss: 16.7784, Validation Loss Current: 6.9217, Validation Loss AVG: 6.9217, lr: 0.001
Epoch [35/80], Training Loss: 15.6530, Validation Loss Current: 6.9896, Validation Loss AVG: 6.9896, lr: 0.001
Epoch [36/80], Training Loss: 14.3947, Validation Loss Current: 6.8533, Validation Loss AVG: 6.8533, lr: 0.001
Epoch [37/80], Training Loss: 12.7207, Validation Loss Current: 7.8408, Validation Loss AVG: 7.8408, lr: 0.001
Epoch [38/80], Training Loss: 11.4347, Validation Loss Current: 7.0163, Validation Loss AVG: 7.0163, lr: 0.001
Epoch [39/80], Training Loss: 11.9540, Validation Loss Current: 7.5415, Validation Loss AVG: 7.5415, lr: 0.001
Epoch [40/80], Training Loss: 13.8523, Validation Loss Current: 7.7695, Validation Loss AVG: 7.7695, lr: 0.001
Epoch [41/80], Training Loss: 14.9178, Validation Loss Current: 8.0909, Validation Loss AVG: 8.0909, lr: 0.001
Epoch [42/80], Training Loss: 16.7757, Validation Loss Current: 9.1382, Validation Loss AVG: 9.1382, lr: 0.001
Epoch [43/80], Training Loss: 12.9619, Validation Loss Current: 9.1625, Validation Loss AVG: 9.1625, lr: 0.001
Epoch [44/80], Training Loss: 10.9409, Validation Loss Current: 7.7209, Validation Loss AVG: 7.7209, lr: 0.001
Epoch [45/80], Training Loss: 11.6638, Validation Loss Current: 13.7370, Validation Loss AVG: 13.7370, lr: 0.001
Epoch [46/80], Training Loss: 19.7097, Validation Loss Current: 12.6610, Validation Loss AVG: 12.6610, lr: 0.001
Epoch [47/80], Training Loss: 13.1515, Validation Loss Current: 8.1580, Validation Loss AVG: 8.1580, lr: 0.001
Epoch [48/80], Training Loss: 9.9762, Validation Loss Current: 8.1198, Validation Loss AVG: 8.1198, lr: 0.001
Epoch [49/80], Training Loss: 8.4534, Validation Loss Current: 7.0382, Validation Loss AVG: 7.0382, lr: 0.001
Epoch [50/80], Training Loss: 8.9960, Validation Loss Current: 8.6734, Validation Loss AVG: 8.6734, lr: 0.001
Epoch [51/80], Training Loss: 9.5806, Validation Loss Current: 11.3217, Validation Loss AVG: 11.3217, lr: 0.001
Epoch [52/80], Training Loss: 10.3517, Validation Loss Current: 9.5064, Validation Loss AVG: 9.5064, lr: 0.001
Epoch [53/80], Training Loss: 8.5867, Validation Loss Current: 8.0743, Validation Loss AVG: 8.0743, lr: 0.001
Epoch [54/80], Training Loss: 6.5690, Validation Loss Current: 7.5130, Validation Loss AVG: 7.5130, lr: 0.001
Epoch [55/80], Training Loss: 6.9230, Validation Loss Current: 9.0761, Validation Loss AVG: 9.0761, lr: 0.001
Epoch [56/80], Training Loss: 5.1543, Validation Loss Current: 8.8502, Validation Loss AVG: 8.8502, lr: 0.001
Epoch [57/80], Training Loss: 4.1767, Validation Loss Current: 9.7856, Validation Loss AVG: 9.7856, lr: 0.001
Epoch [58/80], Training Loss: 4.1498, Validation Loss Current: 8.3524, Validation Loss AVG: 8.3524, lr: 0.001
Epoch [59/80], Training Loss: 4.9315, Validation Loss Current: 8.0274, Validation Loss AVG: 8.0274, lr: 0.001
Epoch [60/80], Training Loss: 5.7314, Validation Loss Current: 16.4905, Validation Loss AVG: 16.4905, lr: 0.001
Epoch [61/80], Training Loss: 10.5421, Validation Loss Current: 11.8098, Validation Loss AVG: 11.8098, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random0 finished training. Best epoch: 31 Best val accuracy: [0.23980263157894735, 0.27236842105263154, 0.2555921052631579, 0.29078947368421054, 0.32894736842105265, 0.3401315789473684, 0.37203947368421053, 0.38026315789473686, 0.3661184210526316, 0.3648026315789473, 0.39671052631578946, 0.4046052631578948, 0.3967105263157895, 0.43684210526315786, 0.4598684210526316, 0.4707236842105263, 0.4375, 0.47828947368421054, 0.4598684210526316, 0.46940789473684214, 0.48125, 0.48026315789473684, 0.4529605263157895, 0.41480263157894737, 0.46644736842105267, 0.4838815789473684, 0.5174342105263158, 0.48355263157894735, 0.4990131578947368, 0.4697368421052632, 0.5305921052631579, 0.46809210526315786, 0.4894736842105263, 0.5266447368421053, 0.5177631578947369, 0.5480263157894737, 0.5263157894736843, 0.5486842105263159, 0.518092105263158, 0.5180921052631579, 0.4733552631578948, 0.44013157894736843, 0.4447368421052632, 0.5286184210526315, 0.4009868421052632, 0.3555921052631579, 0.49934210526315786, 0.5108552631578946, 0.5720394736842105, 0.4875, 0.46677631578947365, 0.46052631578947373, 0.5546052631578948, 0.5450657894736842, 0.5141447368421053, 0.5108552631578948, 0.49506578947368424, 0.562171052631579, 0.5582236842105264, 0.3424342105263158, 0.43684210526315786] Best val loss: 6.826932883262634


Current group: llo_1_random1
Epoch [1/80], Training Loss: 36.5145, Validation Loss Current: 13.8751, Validation Loss AVG: 13.8751, lr: 0.001
Epoch [2/80], Training Loss: 29.4720, Validation Loss Current: 10.6082, Validation Loss AVG: 10.6082, lr: 0.001
Epoch [3/80], Training Loss: 25.4970, Validation Loss Current: 8.2821, Validation Loss AVG: 8.2821, lr: 0.001
Epoch [4/80], Training Loss: 19.1792, Validation Loss Current: 8.1643, Validation Loss AVG: 8.1643, lr: 0.001
Epoch [5/80], Training Loss: 14.9166, Validation Loss Current: 6.6601, Validation Loss AVG: 6.6601, lr: 0.001
Epoch [6/80], Training Loss: 14.2458, Validation Loss Current: 7.3131, Validation Loss AVG: 7.3131, lr: 0.001
Epoch [7/80], Training Loss: 17.0292, Validation Loss Current: 7.7406, Validation Loss AVG: 7.7406, lr: 0.001
Epoch [8/80], Training Loss: 14.3069, Validation Loss Current: 6.9633, Validation Loss AVG: 6.9633, lr: 0.001
Epoch [9/80], Training Loss: 10.9322, Validation Loss Current: 6.4876, Validation Loss AVG: 6.4876, lr: 0.001
Epoch [10/80], Training Loss: 8.4947, Validation Loss Current: 7.1432, Validation Loss AVG: 7.1432, lr: 0.001
Epoch [11/80], Training Loss: 9.8905, Validation Loss Current: 7.1482, Validation Loss AVG: 7.1482, lr: 0.001
Epoch [12/80], Training Loss: 14.3517, Validation Loss Current: 14.2876, Validation Loss AVG: 14.2876, lr: 0.001
Epoch [13/80], Training Loss: 10.0732, Validation Loss Current: 7.6202, Validation Loss AVG: 7.6202, lr: 0.001
Epoch [14/80], Training Loss: 8.0126, Validation Loss Current: 6.7052, Validation Loss AVG: 6.7052, lr: 0.001
Epoch [15/80], Training Loss: 9.4489, Validation Loss Current: 10.8666, Validation Loss AVG: 10.8666, lr: 0.001
Epoch [16/80], Training Loss: 11.5116, Validation Loss Current: 7.0272, Validation Loss AVG: 7.0272, lr: 0.001
Epoch [17/80], Training Loss: 8.6006, Validation Loss Current: 7.1447, Validation Loss AVG: 7.1447, lr: 0.001
Epoch [18/80], Training Loss: 8.1750, Validation Loss Current: 7.7440, Validation Loss AVG: 7.7440, lr: 0.001
Epoch [19/80], Training Loss: 5.0316, Validation Loss Current: 7.3341, Validation Loss AVG: 7.3341, lr: 0.001
Epoch [20/80], Training Loss: 3.2714, Validation Loss Current: 6.6558, Validation Loss AVG: 6.6558, lr: 0.001
Epoch [21/80], Training Loss: 5.1889, Validation Loss Current: 6.8156, Validation Loss AVG: 6.8156, lr: 0.001
Epoch [22/80], Training Loss: 6.0435, Validation Loss Current: 9.2957, Validation Loss AVG: 9.2957, lr: 0.001
Epoch [23/80], Training Loss: 8.3324, Validation Loss Current: 8.1601, Validation Loss AVG: 8.1601, lr: 0.001
Epoch [24/80], Training Loss: 10.9508, Validation Loss Current: 8.5092, Validation Loss AVG: 8.5092, lr: 0.001
Epoch [25/80], Training Loss: 12.8792, Validation Loss Current: 10.9806, Validation Loss AVG: 10.9806, lr: 0.001
Epoch [26/80], Training Loss: 6.3019, Validation Loss Current: 7.7996, Validation Loss AVG: 7.7996, lr: 0.001
Epoch [27/80], Training Loss: 5.7772, Validation Loss Current: 7.4470, Validation Loss AVG: 7.4470, lr: 0.001
Epoch [28/80], Training Loss: 7.9140, Validation Loss Current: 8.9576, Validation Loss AVG: 8.9576, lr: 0.001
Epoch [29/80], Training Loss: 6.4145, Validation Loss Current: 9.7620, Validation Loss AVG: 9.7620, lr: 0.001
Epoch [30/80], Training Loss: 7.5062, Validation Loss Current: 10.3121, Validation Loss AVG: 10.3121, lr: 0.001
Epoch [31/80], Training Loss: 7.6625, Validation Loss Current: 7.5052, Validation Loss AVG: 7.5052, lr: 0.001
Epoch [32/80], Training Loss: 11.6663, Validation Loss Current: 9.2845, Validation Loss AVG: 9.2845, lr: 0.001
Epoch [33/80], Training Loss: 9.1909, Validation Loss Current: 10.4324, Validation Loss AVG: 10.4324, lr: 0.001
Epoch [34/80], Training Loss: 9.3899, Validation Loss Current: 8.9281, Validation Loss AVG: 8.9281, lr: 0.001
Epoch [35/80], Training Loss: 7.1979, Validation Loss Current: 13.0223, Validation Loss AVG: 13.0223, lr: 0.001
Epoch [36/80], Training Loss: 6.2532, Validation Loss Current: 8.1025, Validation Loss AVG: 8.1025, lr: 0.001
Epoch [37/80], Training Loss: 6.8787, Validation Loss Current: 8.2249, Validation Loss AVG: 8.2249, lr: 0.001
Epoch [38/80], Training Loss: 5.0380, Validation Loss Current: 8.5092, Validation Loss AVG: 8.5092, lr: 0.001
Epoch [39/80], Training Loss: 5.3830, Validation Loss Current: 8.5970, Validation Loss AVG: 8.5970, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random1 finished training. Best epoch: 9 Best val accuracy: [0.3838815789473684, 0.4240131578947368, 0.5032894736842105, 0.5006578947368421, 0.5720394736842105, 0.5578947368421052, 0.543092105263158, 0.5555921052631578, 0.5911184210526316, 0.5911184210526317, 0.5694078947368422, 0.40164473684210533, 0.5625000000000001, 0.6078947368421053, 0.4858552631578948, 0.5799342105263159, 0.5914473684210526, 0.5509868421052632, 0.6059210526315789, 0.6407894736842106, 0.6256578947368421, 0.5608552631578947, 0.5532894736842107, 0.5532894736842106, 0.47993421052631574, 0.6088815789473684, 0.6289473684210526, 0.5243421052631578, 0.5430921052631579, 0.512171052631579, 0.60625, 0.5335526315789474, 0.5391447368421053, 0.5263157894736843, 0.4825657894736842, 0.6006578947368422, 0.5967105263157894, 0.5664473684210527, 0.5973684210526315] Best val loss: 6.4876345753669735


Current group: llo_1_random2
Epoch [1/80], Training Loss: 35.4317, Validation Loss Current: 6.7300, Validation Loss AVG: 6.7300, lr: 0.001
Epoch [2/80], Training Loss: 23.0879, Validation Loss Current: 7.7097, Validation Loss AVG: 7.7097, lr: 0.001
Epoch [3/80], Training Loss: 17.0893, Validation Loss Current: 6.5046, Validation Loss AVG: 6.5046, lr: 0.001
Epoch [4/80], Training Loss: 13.1609, Validation Loss Current: 6.0515, Validation Loss AVG: 6.0515, lr: 0.001
Epoch [5/80], Training Loss: 11.5665, Validation Loss Current: 6.2440, Validation Loss AVG: 6.2440, lr: 0.001
Epoch [6/80], Training Loss: 12.3887, Validation Loss Current: 8.2007, Validation Loss AVG: 8.2007, lr: 0.001
Epoch [7/80], Training Loss: 11.5991, Validation Loss Current: 6.4267, Validation Loss AVG: 6.4267, lr: 0.001
Epoch [8/80], Training Loss: 9.1869, Validation Loss Current: 6.3108, Validation Loss AVG: 6.3108, lr: 0.001
Epoch [9/80], Training Loss: 6.8362, Validation Loss Current: 5.9199, Validation Loss AVG: 5.9199, lr: 0.001
Epoch [10/80], Training Loss: 6.1235, Validation Loss Current: 6.6325, Validation Loss AVG: 6.6325, lr: 0.001
Epoch [11/80], Training Loss: 4.3327, Validation Loss Current: 6.9411, Validation Loss AVG: 6.9411, lr: 0.001
Epoch [12/80], Training Loss: 5.7894, Validation Loss Current: 5.8756, Validation Loss AVG: 5.8756, lr: 0.001
Epoch [13/80], Training Loss: 7.9982, Validation Loss Current: 7.5670, Validation Loss AVG: 7.5670, lr: 0.001
Epoch [14/80], Training Loss: 5.5943, Validation Loss Current: 6.6093, Validation Loss AVG: 6.6093, lr: 0.001
Epoch [15/80], Training Loss: 3.6659, Validation Loss Current: 5.8300, Validation Loss AVG: 5.8300, lr: 0.001
Epoch [16/80], Training Loss: 7.0287, Validation Loss Current: 7.0614, Validation Loss AVG: 7.0614, lr: 0.001
Epoch [17/80], Training Loss: 4.4268, Validation Loss Current: 8.4430, Validation Loss AVG: 8.4430, lr: 0.001
Epoch [18/80], Training Loss: 5.8910, Validation Loss Current: 6.9073, Validation Loss AVG: 6.9073, lr: 0.001
Epoch [19/80], Training Loss: 3.7645, Validation Loss Current: 6.6881, Validation Loss AVG: 6.6881, lr: 0.001
Epoch [20/80], Training Loss: 4.9479, Validation Loss Current: 7.2122, Validation Loss AVG: 7.2122, lr: 0.001
Epoch [21/80], Training Loss: 4.3876, Validation Loss Current: 7.0435, Validation Loss AVG: 7.0435, lr: 0.001
Epoch [22/80], Training Loss: 5.1682, Validation Loss Current: 7.2867, Validation Loss AVG: 7.2867, lr: 0.001
Epoch [23/80], Training Loss: 3.4884, Validation Loss Current: 7.6520, Validation Loss AVG: 7.6520, lr: 0.001
Epoch [24/80], Training Loss: 4.4256, Validation Loss Current: 8.6066, Validation Loss AVG: 8.6066, lr: 0.001
Epoch [25/80], Training Loss: 2.3985, Validation Loss Current: 6.5509, Validation Loss AVG: 6.5509, lr: 0.001
Epoch [26/80], Training Loss: 2.7664, Validation Loss Current: 7.7765, Validation Loss AVG: 7.7765, lr: 0.001
Epoch [27/80], Training Loss: 5.1070, Validation Loss Current: 15.9403, Validation Loss AVG: 15.9403, lr: 0.001
Epoch [28/80], Training Loss: 4.6737, Validation Loss Current: 7.8856, Validation Loss AVG: 7.8856, lr: 0.001
Epoch [29/80], Training Loss: 3.0501, Validation Loss Current: 8.6980, Validation Loss AVG: 8.6980, lr: 0.001
Epoch [30/80], Training Loss: 3.9163, Validation Loss Current: 7.7017, Validation Loss AVG: 7.7017, lr: 0.001
Epoch [31/80], Training Loss: 7.5345, Validation Loss Current: 9.7022, Validation Loss AVG: 9.7022, lr: 0.001
Epoch [32/80], Training Loss: 6.6677, Validation Loss Current: 8.1207, Validation Loss AVG: 8.1207, lr: 0.001
Epoch [33/80], Training Loss: 4.3899, Validation Loss Current: 7.8304, Validation Loss AVG: 7.8304, lr: 0.001
Epoch [34/80], Training Loss: 4.0625, Validation Loss Current: 8.0013, Validation Loss AVG: 8.0013, lr: 0.001
Epoch [35/80], Training Loss: 5.8454, Validation Loss Current: 7.8284, Validation Loss AVG: 7.8284, lr: 0.001
Epoch [36/80], Training Loss: 3.3400, Validation Loss Current: 8.1162, Validation Loss AVG: 8.1162, lr: 0.001
Epoch [37/80], Training Loss: 4.8427, Validation Loss Current: 9.2219, Validation Loss AVG: 9.2219, lr: 0.001
Epoch [38/80], Training Loss: 7.0747, Validation Loss Current: 9.1200, Validation Loss AVG: 9.1200, lr: 0.001
Epoch [39/80], Training Loss: 10.4458, Validation Loss Current: 9.0427, Validation Loss AVG: 9.0427, lr: 0.001
Epoch [40/80], Training Loss: 6.8069, Validation Loss Current: 8.4893, Validation Loss AVG: 8.4893, lr: 0.001
Epoch [41/80], Training Loss: 4.4974, Validation Loss Current: 8.6489, Validation Loss AVG: 8.6489, lr: 0.001
Epoch [42/80], Training Loss: 5.0668, Validation Loss Current: 10.7540, Validation Loss AVG: 10.7540, lr: 0.001
Epoch [43/80], Training Loss: 5.0579, Validation Loss Current: 8.1774, Validation Loss AVG: 8.1774, lr: 0.001
Epoch [44/80], Training Loss: 5.7552, Validation Loss Current: 9.2072, Validation Loss AVG: 9.2072, lr: 0.001
Epoch [45/80], Training Loss: 4.5479, Validation Loss Current: 8.3905, Validation Loss AVG: 8.3905, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random2 finished training. Best epoch: 15 Best val accuracy: [0.6200657894736843, 0.5625, 0.6134868421052632, 0.6421052631578947, 0.6144736842105263, 0.6006578947368421, 0.6361842105263158, 0.6250000000000001, 0.6523026315789474, 0.6259868421052632, 0.649671052631579, 0.6582236842105263, 0.594078947368421, 0.6575657894736842, 0.6651315789473684, 0.6177631578947368, 0.6032894736842105, 0.6394736842105264, 0.6542763157894737, 0.6361842105263158, 0.6424342105263158, 0.6335526315789474, 0.6164473684210525, 0.5878289473684211, 0.6555921052631579, 0.6223684210526316, 0.50625, 0.6210526315789473, 0.613486842105263, 0.6075657894736842, 0.5967105263157896, 0.6032894736842105, 0.6111842105263158, 0.6240131578947368, 0.6263157894736843, 0.6069078947368421, 0.6144736842105264, 0.5618421052631579, 0.5641447368421052, 0.6036184210526316, 0.5835526315789473, 0.5361842105263158, 0.5986842105263157, 0.5947368421052632, 0.600328947368421] Best val loss: 5.829961657524109


Current group: llo_1_random3
Epoch [1/80], Training Loss: 41.4086, Validation Loss Current: 8.3654, Validation Loss AVG: 8.3654, lr: 0.001
Epoch [2/80], Training Loss: 24.8303, Validation Loss Current: 6.4776, Validation Loss AVG: 6.4776, lr: 0.001
Epoch [3/80], Training Loss: 16.5663, Validation Loss Current: 6.7556, Validation Loss AVG: 6.7556, lr: 0.001
Epoch [4/80], Training Loss: 15.1295, Validation Loss Current: 6.9556, Validation Loss AVG: 6.9556, lr: 0.001
Epoch [5/80], Training Loss: 15.5520, Validation Loss Current: 7.6180, Validation Loss AVG: 7.6180, lr: 0.001
Epoch [6/80], Training Loss: 10.5613, Validation Loss Current: 5.7222, Validation Loss AVG: 5.7222, lr: 0.001
Epoch [7/80], Training Loss: 8.9968, Validation Loss Current: 6.1023, Validation Loss AVG: 6.1023, lr: 0.001
Epoch [8/80], Training Loss: 13.7824, Validation Loss Current: 6.7381, Validation Loss AVG: 6.7381, lr: 0.001
Epoch [9/80], Training Loss: 12.6110, Validation Loss Current: 6.1468, Validation Loss AVG: 6.1468, lr: 0.001
Epoch [10/80], Training Loss: 8.4123, Validation Loss Current: 6.5184, Validation Loss AVG: 6.5184, lr: 0.001
Epoch [11/80], Training Loss: 9.0860, Validation Loss Current: 6.7210, Validation Loss AVG: 6.7210, lr: 0.001
Epoch [12/80], Training Loss: 6.3856, Validation Loss Current: 6.5852, Validation Loss AVG: 6.5852, lr: 0.001
Epoch [13/80], Training Loss: 4.2767, Validation Loss Current: 6.3314, Validation Loss AVG: 6.3314, lr: 0.001
Epoch [14/80], Training Loss: 3.1261, Validation Loss Current: 5.8258, Validation Loss AVG: 5.8258, lr: 0.001
Epoch [15/80], Training Loss: 3.5118, Validation Loss Current: 6.0027, Validation Loss AVG: 6.0027, lr: 0.001
Epoch [16/80], Training Loss: 7.7655, Validation Loss Current: 6.3932, Validation Loss AVG: 6.3932, lr: 0.001
Epoch [17/80], Training Loss: 3.5204, Validation Loss Current: 6.0460, Validation Loss AVG: 6.0460, lr: 0.001
Epoch [18/80], Training Loss: 4.5162, Validation Loss Current: 6.2832, Validation Loss AVG: 6.2832, lr: 0.001
Epoch [19/80], Training Loss: 3.5508, Validation Loss Current: 6.8405, Validation Loss AVG: 6.8405, lr: 0.001
Epoch [20/80], Training Loss: 2.1332, Validation Loss Current: 6.0486, Validation Loss AVG: 6.0486, lr: 0.001
Epoch [21/80], Training Loss: 1.7168, Validation Loss Current: 6.2821, Validation Loss AVG: 6.2821, lr: 0.001
Epoch [22/80], Training Loss: 7.2118, Validation Loss Current: 7.2950, Validation Loss AVG: 7.2950, lr: 0.001
Epoch [23/80], Training Loss: 3.8721, Validation Loss Current: 6.3209, Validation Loss AVG: 6.3209, lr: 0.001
Epoch [24/80], Training Loss: 2.7159, Validation Loss Current: 6.3855, Validation Loss AVG: 6.3855, lr: 0.001
Epoch [25/80], Training Loss: 1.3582, Validation Loss Current: 6.7950, Validation Loss AVG: 6.7950, lr: 0.001
Epoch [26/80], Training Loss: 2.6996, Validation Loss Current: 7.1339, Validation Loss AVG: 7.1339, lr: 0.001
Epoch [27/80], Training Loss: 8.8448, Validation Loss Current: 11.3300, Validation Loss AVG: 11.3300, lr: 0.001
Epoch [28/80], Training Loss: 4.6635, Validation Loss Current: 8.5346, Validation Loss AVG: 8.5346, lr: 0.001
Epoch [29/80], Training Loss: 2.8104, Validation Loss Current: 6.5162, Validation Loss AVG: 6.5162, lr: 0.001
Epoch [30/80], Training Loss: 4.4254, Validation Loss Current: 7.2741, Validation Loss AVG: 7.2741, lr: 0.001
Epoch [31/80], Training Loss: 5.7102, Validation Loss Current: 7.6740, Validation Loss AVG: 7.6740, lr: 0.001
Epoch [32/80], Training Loss: 7.0461, Validation Loss Current: 9.5057, Validation Loss AVG: 9.5057, lr: 0.001
Epoch [33/80], Training Loss: 4.8079, Validation Loss Current: 7.4023, Validation Loss AVG: 7.4023, lr: 0.001
Epoch [34/80], Training Loss: 4.8325, Validation Loss Current: 9.1231, Validation Loss AVG: 9.1231, lr: 0.001
Epoch [35/80], Training Loss: 9.6579, Validation Loss Current: 10.8874, Validation Loss AVG: 10.8874, lr: 0.001
Epoch [36/80], Training Loss: 6.4649, Validation Loss Current: 6.9109, Validation Loss AVG: 6.9109, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random3 finished training. Best epoch: 6 Best val accuracy: [0.5476973684210525, 0.6230263157894738, 0.5973684210526315, 0.6194078947368421, 0.5832236842105263, 0.6726973684210525, 0.655921052631579, 0.6138157894736842, 0.6503289473684211, 0.6335526315789474, 0.6703947368421053, 0.6404605263157894, 0.6703947368421053, 0.6822368421052631, 0.6608552631578947, 0.6776315789473685, 0.6828947368421051, 0.6753289473684211, 0.6552631578947368, 0.6921052631578949, 0.6986842105263158, 0.656578947368421, 0.6713815789473685, 0.680921052631579, 0.6618421052631579, 0.6575657894736843, 0.5194078947368421, 0.6286184210526315, 0.6657894736842105, 0.6546052631578947, 0.6197368421052631, 0.6023026315789474, 0.6460526315789473, 0.6243421052631579, 0.5509868421052632, 0.656578947368421] Best val loss: 5.722213363647461


Current group: 1
Epoch [1/80], Training Loss: 42.8238, Validation Loss Current: 10.1592, Validation Loss AVG: 10.9088, lr: 0.001
Epoch [2/80], Training Loss: 23.1817, Validation Loss Current: 8.0639, Validation Loss AVG: 8.7925, lr: 0.001
Epoch [3/80], Training Loss: 14.0942, Validation Loss Current: 8.4753, Validation Loss AVG: 9.7298, lr: 0.001
Epoch [4/80], Training Loss: 11.2558, Validation Loss Current: 7.8886, Validation Loss AVG: 10.0684, lr: 0.001
Epoch [5/80], Training Loss: 6.6778, Validation Loss Current: 6.4287, Validation Loss AVG: 8.2988, lr: 0.001
Epoch [6/80], Training Loss: 4.2093, Validation Loss Current: 6.5080, Validation Loss AVG: 8.9821, lr: 0.001
Epoch [7/80], Training Loss: 6.0297, Validation Loss Current: 6.3122, Validation Loss AVG: 8.1820, lr: 0.001
Epoch [8/80], Training Loss: 5.6282, Validation Loss Current: 7.1677, Validation Loss AVG: 11.1749, lr: 0.001
Epoch [9/80], Training Loss: 7.5727, Validation Loss Current: 7.5186, Validation Loss AVG: 10.0954, lr: 0.001
Epoch [10/80], Training Loss: 8.0526, Validation Loss Current: 7.8944, Validation Loss AVG: 10.7249, lr: 0.001
Epoch [11/80], Training Loss: 7.0739, Validation Loss Current: 8.4295, Validation Loss AVG: 12.2137, lr: 0.001
Epoch [12/80], Training Loss: 3.9216, Validation Loss Current: 7.6668, Validation Loss AVG: 8.8541, lr: 0.001
Epoch [13/80], Training Loss: 5.6788, Validation Loss Current: 7.4669, Validation Loss AVG: 10.7962, lr: 0.001
Epoch [14/80], Training Loss: 6.5341, Validation Loss Current: 7.6799, Validation Loss AVG: 11.1394, lr: 0.001
Epoch [15/80], Training Loss: 3.4971, Validation Loss Current: 7.3645, Validation Loss AVG: 9.0437, lr: 0.001
Epoch [16/80], Training Loss: 2.6138, Validation Loss Current: 7.1082, Validation Loss AVG: 10.5963, lr: 0.001
Epoch [17/80], Training Loss: 4.3548, Validation Loss Current: 7.2448, Validation Loss AVG: 9.0922, lr: 0.001
Epoch [18/80], Training Loss: 4.2176, Validation Loss Current: 7.7062, Validation Loss AVG: 12.0143, lr: 0.001
Epoch [19/80], Training Loss: 5.2808, Validation Loss Current: 8.1686, Validation Loss AVG: 14.2796, lr: 0.001
Epoch [20/80], Training Loss: 4.8337, Validation Loss Current: 7.9045, Validation Loss AVG: 13.6826, lr: 0.001
Epoch [21/80], Training Loss: 2.8477, Validation Loss Current: 7.2802, Validation Loss AVG: 10.5155, lr: 0.001
Epoch [22/80], Training Loss: 3.9186, Validation Loss Current: 7.3380, Validation Loss AVG: 11.0839, lr: 0.001
Epoch [23/80], Training Loss: 8.0301, Validation Loss Current: 9.5840, Validation Loss AVG: 12.0795, lr: 0.001
Epoch [24/80], Training Loss: 7.5699, Validation Loss Current: 10.3356, Validation Loss AVG: 13.1866, lr: 0.001
Epoch [25/80], Training Loss: 6.9848, Validation Loss Current: 11.4900, Validation Loss AVG: 14.8568, lr: 0.001
Epoch [26/80], Training Loss: 3.2923, Validation Loss Current: 8.7164, Validation Loss AVG: 10.4846, lr: 0.001
Epoch [27/80], Training Loss: 1.9691, Validation Loss Current: 7.3643, Validation Loss AVG: 12.2809, lr: 0.001
Epoch [28/80], Training Loss: 2.2411, Validation Loss Current: 7.0615, Validation Loss AVG: 11.6964, lr: 0.001
Epoch [29/80], Training Loss: 4.1051, Validation Loss Current: 8.3620, Validation Loss AVG: 12.9189, lr: 0.001
Epoch [30/80], Training Loss: 4.4219, Validation Loss Current: 10.1140, Validation Loss AVG: 14.4050, lr: 0.001
Epoch [31/80], Training Loss: 3.4539, Validation Loss Current: 8.5980, Validation Loss AVG: 11.3587, lr: 0.001
Epoch [32/80], Training Loss: 4.7549, Validation Loss Current: 7.4006, Validation Loss AVG: 11.3569, lr: 0.001
Epoch [33/80], Training Loss: 4.4121, Validation Loss Current: 8.1363, Validation Loss AVG: 9.8667, lr: 0.001
Epoch [34/80], Training Loss: 4.0330, Validation Loss Current: 7.8849, Validation Loss AVG: 11.2648, lr: 0.001
Epoch [35/80], Training Loss: 2.9356, Validation Loss Current: 9.0291, Validation Loss AVG: 10.8104, lr: 0.001
Epoch [36/80], Training Loss: 5.1694, Validation Loss Current: 7.9446, Validation Loss AVG: 11.7750, lr: 0.001
Epoch [37/80], Training Loss: 1.2831, Validation Loss Current: 7.7817, Validation Loss AVG: 11.3908, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 7 Best val accuracy: [0.4901315789473684, 0.5805921052631579, 0.5789473684210527, 0.5509868421052632, 0.6447368421052632, 0.6348684210526315, 0.6348684210526315, 0.6217105263157895, 0.5855263157894737, 0.600328947368421, 0.5953947368421053, 0.6118421052631579, 0.6134868421052632, 0.5970394736842105, 0.6101973684210527, 0.6365131578947368, 0.625, 0.59375, 0.6085526315789473, 0.600328947368421, 0.6365131578947368, 0.6167763157894737, 0.5674342105263158, 0.537828947368421, 0.5657894736842105, 0.5986842105263158, 0.6134868421052632, 0.6282894736842105, 0.618421052631579, 0.5707236842105263, 0.6101973684210527, 0.6217105263157895, 0.5986842105263158, 0.6052631578947368, 0.6167763157894737, 0.6233552631578947, 0.6332236842105263] Best val loss: 6.3122193813323975


Fold: 4
----- Training resnet18 with sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] -----
Current group: llo_0.2_random0
Epoch [1/80], Training Loss: 40.5772, Validation Loss Current: 9.9345, Validation Loss AVG: 9.9345, lr: 0.001
Epoch [2/80], Training Loss: 39.6851, Validation Loss Current: 9.7120, Validation Loss AVG: 9.7120, lr: 0.001
Epoch [3/80], Training Loss: 38.0543, Validation Loss Current: 9.5366, Validation Loss AVG: 9.5366, lr: 0.001
Epoch [4/80], Training Loss: 36.8987, Validation Loss Current: 9.3288, Validation Loss AVG: 9.3288, lr: 0.001
Epoch [5/80], Training Loss: 36.3441, Validation Loss Current: 9.2229, Validation Loss AVG: 9.2229, lr: 0.001
Epoch [6/80], Training Loss: 35.9015, Validation Loss Current: 9.0860, Validation Loss AVG: 9.0860, lr: 0.001
Epoch [7/80], Training Loss: 34.8920, Validation Loss Current: 8.9158, Validation Loss AVG: 8.9158, lr: 0.001
Epoch [8/80], Training Loss: 32.4945, Validation Loss Current: 8.6872, Validation Loss AVG: 8.6872, lr: 0.001
Epoch [9/80], Training Loss: 32.3242, Validation Loss Current: 8.5315, Validation Loss AVG: 8.5315, lr: 0.001
Epoch [10/80], Training Loss: 32.3168, Validation Loss Current: 8.3313, Validation Loss AVG: 8.3313, lr: 0.001
Epoch [11/80], Training Loss: 30.6101, Validation Loss Current: 8.3888, Validation Loss AVG: 8.3888, lr: 0.001
Epoch [12/80], Training Loss: 29.2617, Validation Loss Current: 8.1750, Validation Loss AVG: 8.1750, lr: 0.001
Epoch [13/80], Training Loss: 28.3104, Validation Loss Current: 8.0144, Validation Loss AVG: 8.0144, lr: 0.001
Epoch [14/80], Training Loss: 27.7113, Validation Loss Current: 7.8275, Validation Loss AVG: 7.8275, lr: 0.001
Epoch [15/80], Training Loss: 28.5050, Validation Loss Current: 7.7762, Validation Loss AVG: 7.7762, lr: 0.001
Epoch [16/80], Training Loss: 27.6628, Validation Loss Current: 8.1695, Validation Loss AVG: 8.1695, lr: 0.001
Epoch [17/80], Training Loss: 28.2365, Validation Loss Current: 8.7168, Validation Loss AVG: 8.7168, lr: 0.001
Epoch [18/80], Training Loss: 25.7951, Validation Loss Current: 7.8162, Validation Loss AVG: 7.8162, lr: 0.001
Epoch [19/80], Training Loss: 25.2977, Validation Loss Current: 7.3561, Validation Loss AVG: 7.3561, lr: 0.001
Epoch [20/80], Training Loss: 24.4069, Validation Loss Current: 7.5457, Validation Loss AVG: 7.5457, lr: 0.001
Epoch [21/80], Training Loss: 24.0157, Validation Loss Current: 7.5948, Validation Loss AVG: 7.5948, lr: 0.001
Epoch [22/80], Training Loss: 23.8686, Validation Loss Current: 7.6122, Validation Loss AVG: 7.6122, lr: 0.001
Epoch [23/80], Training Loss: 24.8505, Validation Loss Current: 8.0691, Validation Loss AVG: 8.0691, lr: 0.001
Epoch [24/80], Training Loss: 22.4649, Validation Loss Current: 7.3336, Validation Loss AVG: 7.3336, lr: 0.001
Epoch [25/80], Training Loss: 21.5554, Validation Loss Current: 7.1193, Validation Loss AVG: 7.1193, lr: 0.001
Epoch [26/80], Training Loss: 22.8692, Validation Loss Current: 7.3505, Validation Loss AVG: 7.3505, lr: 0.001
Epoch [27/80], Training Loss: 21.5326, Validation Loss Current: 6.9694, Validation Loss AVG: 6.9694, lr: 0.001
Epoch [28/80], Training Loss: 20.1062, Validation Loss Current: 7.3378, Validation Loss AVG: 7.3378, lr: 0.001
Epoch [29/80], Training Loss: 20.3036, Validation Loss Current: 6.9731, Validation Loss AVG: 6.9731, lr: 0.001
Epoch [30/80], Training Loss: 20.2723, Validation Loss Current: 6.7638, Validation Loss AVG: 6.7638, lr: 0.001
Epoch [31/80], Training Loss: 20.2178, Validation Loss Current: 7.5696, Validation Loss AVG: 7.5696, lr: 0.001
Epoch [32/80], Training Loss: 17.4215, Validation Loss Current: 6.9983, Validation Loss AVG: 6.9983, lr: 0.001
Epoch [33/80], Training Loss: 16.3457, Validation Loss Current: 6.3665, Validation Loss AVG: 6.3665, lr: 0.001
Epoch [34/80], Training Loss: 14.7438, Validation Loss Current: 7.0511, Validation Loss AVG: 7.0511, lr: 0.001
Epoch [35/80], Training Loss: 15.8006, Validation Loss Current: 6.3429, Validation Loss AVG: 6.3429, lr: 0.001
Epoch [36/80], Training Loss: 13.8914, Validation Loss Current: 6.3039, Validation Loss AVG: 6.3039, lr: 0.001
Epoch [37/80], Training Loss: 12.6277, Validation Loss Current: 6.1554, Validation Loss AVG: 6.1554, lr: 0.001
Epoch [38/80], Training Loss: 11.1855, Validation Loss Current: 6.6037, Validation Loss AVG: 6.6037, lr: 0.001
Epoch [39/80], Training Loss: 11.4177, Validation Loss Current: 7.5317, Validation Loss AVG: 7.5317, lr: 0.001
Epoch [40/80], Training Loss: 10.5879, Validation Loss Current: 7.3143, Validation Loss AVG: 7.3143, lr: 0.001
Epoch [41/80], Training Loss: 10.6410, Validation Loss Current: 6.5747, Validation Loss AVG: 6.5747, lr: 0.001
Epoch [42/80], Training Loss: 10.4266, Validation Loss Current: 7.3565, Validation Loss AVG: 7.3565, lr: 0.001
Epoch [43/80], Training Loss: 11.6938, Validation Loss Current: 7.8135, Validation Loss AVG: 7.8135, lr: 0.001
Epoch [44/80], Training Loss: 13.0747, Validation Loss Current: 7.4343, Validation Loss AVG: 7.4343, lr: 0.001
Epoch [45/80], Training Loss: 9.8182, Validation Loss Current: 9.1479, Validation Loss AVG: 9.1479, lr: 0.001
Epoch [46/80], Training Loss: 8.8435, Validation Loss Current: 7.6345, Validation Loss AVG: 7.6345, lr: 0.001
Epoch [47/80], Training Loss: 9.2930, Validation Loss Current: 8.3094, Validation Loss AVG: 8.3094, lr: 0.001
Epoch [48/80], Training Loss: 10.1741, Validation Loss Current: 7.4102, Validation Loss AVG: 7.4102, lr: 0.001
Epoch [49/80], Training Loss: 11.4571, Validation Loss Current: 8.0161, Validation Loss AVG: 8.0161, lr: 0.001
Epoch [50/80], Training Loss: 8.4910, Validation Loss Current: 8.4794, Validation Loss AVG: 8.4794, lr: 0.001
Epoch [51/80], Training Loss: 11.2040, Validation Loss Current: 8.3734, Validation Loss AVG: 8.3734, lr: 0.001
Epoch [52/80], Training Loss: 8.5647, Validation Loss Current: 7.4170, Validation Loss AVG: 7.4170, lr: 0.001
Epoch [53/80], Training Loss: 7.4830, Validation Loss Current: 7.3067, Validation Loss AVG: 7.3067, lr: 0.001
Epoch [54/80], Training Loss: 8.8507, Validation Loss Current: 9.1600, Validation Loss AVG: 9.1600, lr: 0.001
Epoch [55/80], Training Loss: 10.9269, Validation Loss Current: 8.1844, Validation Loss AVG: 8.1844, lr: 0.001
Epoch [56/80], Training Loss: 6.1734, Validation Loss Current: 7.4018, Validation Loss AVG: 7.4018, lr: 0.001
Epoch [57/80], Training Loss: 5.3361, Validation Loss Current: 7.2614, Validation Loss AVG: 7.2614, lr: 0.001
Epoch [58/80], Training Loss: 4.1798, Validation Loss Current: 8.0927, Validation Loss AVG: 8.0927, lr: 0.001
Epoch [59/80], Training Loss: 5.7013, Validation Loss Current: 8.1689, Validation Loss AVG: 8.1689, lr: 0.001
Epoch [60/80], Training Loss: 8.0211, Validation Loss Current: 8.3136, Validation Loss AVG: 8.3136, lr: 0.001
Epoch [61/80], Training Loss: 4.3050, Validation Loss Current: 8.3520, Validation Loss AVG: 8.3520, lr: 0.001
Epoch [62/80], Training Loss: 3.9134, Validation Loss Current: 8.1022, Validation Loss AVG: 8.1022, lr: 0.001
Epoch [63/80], Training Loss: 5.5019, Validation Loss Current: 8.0629, Validation Loss AVG: 8.0629, lr: 0.001
Epoch [64/80], Training Loss: 4.2460, Validation Loss Current: 8.7166, Validation Loss AVG: 8.7166, lr: 0.001
Epoch [65/80], Training Loss: 4.2973, Validation Loss Current: 8.0578, Validation Loss AVG: 8.0578, lr: 0.001
Epoch [66/80], Training Loss: 5.7442, Validation Loss Current: 8.4524, Validation Loss AVG: 8.4524, lr: 0.001
Epoch [67/80], Training Loss: 7.6645, Validation Loss Current: 8.4661, Validation Loss AVG: 8.4661, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random0 finished training. Best epoch: 37 Best val accuracy: [0.26776315789473687, 0.2983552631578947, 0.31513157894736843, 0.3259868421052632, 0.32730263157894735, 0.35756578947368417, 0.35230263157894737, 0.38684210526315793, 0.38421052631578945, 0.41940789473684204, 0.41776315789473684, 0.4098684210526316, 0.44046052631578947, 0.45065789473684215, 0.4414473684210526, 0.41578947368421054, 0.38552631578947366, 0.4529605263157895, 0.4654605263157895, 0.47171052631578947, 0.45625, 0.45394736842105265, 0.44605263157894737, 0.4786184210526316, 0.48717105263157895, 0.480921052631579, 0.4934210526315789, 0.4756578947368421, 0.49736842105263157, 0.5128289473684211, 0.4516447368421053, 0.5121710526315789, 0.5575657894736843, 0.5259868421052631, 0.5657894736842104, 0.562828947368421, 0.5825657894736842, 0.5444078947368421, 0.5141447368421053, 0.49967105263157896, 0.55625, 0.5322368421052632, 0.4947368421052632, 0.5059210526315789, 0.5174342105263159, 0.5355263157894737, 0.5161184210526316, 0.5381578947368422, 0.5098684210526316, 0.49572368421052637, 0.50625, 0.5509868421052632, 0.5641447368421052, 0.4447368421052632, 0.48125, 0.5598684210526316, 0.562171052631579, 0.5536184210526315, 0.5424342105263158, 0.5273026315789473, 0.5345394736842105, 0.5453947368421053, 0.5503289473684211, 0.5217105263157895, 0.5486842105263158, 0.5394736842105262, 0.5398026315789474] Best val loss: 6.155434155464173


Current group: llo_0.2_random1
Epoch [1/80], Training Loss: 29.3725, Validation Loss Current: 6.9857, Validation Loss AVG: 6.9857, lr: 0.001
Epoch [2/80], Training Loss: 23.0380, Validation Loss Current: 10.4094, Validation Loss AVG: 10.4094, lr: 0.001
Epoch [3/80], Training Loss: 20.2495, Validation Loss Current: 6.9679, Validation Loss AVG: 6.9679, lr: 0.001
Epoch [4/80], Training Loss: 17.4075, Validation Loss Current: 8.2835, Validation Loss AVG: 8.2835, lr: 0.001
Epoch [5/80], Training Loss: 14.4992, Validation Loss Current: 6.1590, Validation Loss AVG: 6.1590, lr: 0.001
Epoch [6/80], Training Loss: 12.2899, Validation Loss Current: 7.6579, Validation Loss AVG: 7.6579, lr: 0.001
Epoch [7/80], Training Loss: 10.7670, Validation Loss Current: 5.8530, Validation Loss AVG: 5.8530, lr: 0.001
Epoch [8/80], Training Loss: 8.5025, Validation Loss Current: 5.9614, Validation Loss AVG: 5.9614, lr: 0.001
Epoch [9/80], Training Loss: 9.1959, Validation Loss Current: 6.7427, Validation Loss AVG: 6.7427, lr: 0.001
Epoch [10/80], Training Loss: 8.0160, Validation Loss Current: 6.3216, Validation Loss AVG: 6.3216, lr: 0.001
Epoch [11/80], Training Loss: 7.7416, Validation Loss Current: 8.0229, Validation Loss AVG: 8.0229, lr: 0.001
Epoch [12/80], Training Loss: 11.5220, Validation Loss Current: 7.4394, Validation Loss AVG: 7.4394, lr: 0.001
Epoch [13/80], Training Loss: 9.6452, Validation Loss Current: 6.2476, Validation Loss AVG: 6.2476, lr: 0.001
Epoch [14/80], Training Loss: 8.3517, Validation Loss Current: 7.9770, Validation Loss AVG: 7.9770, lr: 0.001
Epoch [15/80], Training Loss: 6.7235, Validation Loss Current: 6.2870, Validation Loss AVG: 6.2870, lr: 0.001
Epoch [16/80], Training Loss: 4.9488, Validation Loss Current: 7.2200, Validation Loss AVG: 7.2200, lr: 0.001
Epoch [17/80], Training Loss: 4.3242, Validation Loss Current: 7.3528, Validation Loss AVG: 7.3528, lr: 0.001
Epoch [18/80], Training Loss: 8.3314, Validation Loss Current: 7.0210, Validation Loss AVG: 7.0210, lr: 0.001
Epoch [19/80], Training Loss: 8.8763, Validation Loss Current: 7.2640, Validation Loss AVG: 7.2640, lr: 0.001
Epoch [20/80], Training Loss: 5.6643, Validation Loss Current: 7.8797, Validation Loss AVG: 7.8797, lr: 0.001
Epoch [21/80], Training Loss: 5.0486, Validation Loss Current: 7.3768, Validation Loss AVG: 7.3768, lr: 0.001
Epoch [22/80], Training Loss: 5.5226, Validation Loss Current: 6.7647, Validation Loss AVG: 6.7647, lr: 0.001
Epoch [23/80], Training Loss: 4.2249, Validation Loss Current: 7.3361, Validation Loss AVG: 7.3361, lr: 0.001
Epoch [24/80], Training Loss: 3.9185, Validation Loss Current: 8.7637, Validation Loss AVG: 8.7637, lr: 0.001
Epoch [25/80], Training Loss: 14.5794, Validation Loss Current: 11.0856, Validation Loss AVG: 11.0856, lr: 0.001
Epoch [26/80], Training Loss: 13.3726, Validation Loss Current: 9.9414, Validation Loss AVG: 9.9414, lr: 0.001
Epoch [27/80], Training Loss: 8.7363, Validation Loss Current: 9.2243, Validation Loss AVG: 9.2243, lr: 0.001
Epoch [28/80], Training Loss: 12.4048, Validation Loss Current: 9.2039, Validation Loss AVG: 9.2039, lr: 0.001
Epoch [29/80], Training Loss: 8.6938, Validation Loss Current: 8.0691, Validation Loss AVG: 8.0691, lr: 0.001
Epoch [30/80], Training Loss: 7.7329, Validation Loss Current: 8.1365, Validation Loss AVG: 8.1365, lr: 0.001
Epoch [31/80], Training Loss: 6.0032, Validation Loss Current: 7.0166, Validation Loss AVG: 7.0166, lr: 0.001
Epoch [32/80], Training Loss: 6.6067, Validation Loss Current: 8.1087, Validation Loss AVG: 8.1087, lr: 0.001
Epoch [33/80], Training Loss: 3.8986, Validation Loss Current: 7.4504, Validation Loss AVG: 7.4504, lr: 0.001
Epoch [34/80], Training Loss: 3.7471, Validation Loss Current: 6.9755, Validation Loss AVG: 6.9755, lr: 0.001
Epoch [35/80], Training Loss: 3.8630, Validation Loss Current: 7.3399, Validation Loss AVG: 7.3399, lr: 0.001
Epoch [36/80], Training Loss: 2.4085, Validation Loss Current: 7.2283, Validation Loss AVG: 7.2283, lr: 0.001
Epoch [37/80], Training Loss: 2.2140, Validation Loss Current: 7.5662, Validation Loss AVG: 7.5662, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random1 finished training. Best epoch: 7 Best val accuracy: [0.5615131578947368, 0.45394736842105254, 0.5644736842105263, 0.5039473684210527, 0.5881578947368421, 0.5371710526315789, 0.6184210526315789, 0.6138157894736842, 0.5842105263157895, 0.6078947368421053, 0.5674342105263157, 0.5713815789473684, 0.6141447368421054, 0.5888157894736843, 0.6269736842105262, 0.5970394736842104, 0.6085526315789475, 0.58125, 0.5638157894736843, 0.542763157894737, 0.5868421052631579, 0.5986842105263157, 0.5980263157894736, 0.5657894736842105, 0.4677631578947368, 0.5151315789473685, 0.5075657894736842, 0.5233552631578948, 0.5644736842105263, 0.5713815789473684, 0.6141447368421054, 0.5667763157894736, 0.6125, 0.6111842105263158, 0.6026315789473684, 0.5990131578947369, 0.5937499999999999] Best val loss: 5.852955138683319


Current group: llo_0.2_random2
Epoch [1/80], Training Loss: 26.5637, Validation Loss Current: 6.6107, Validation Loss AVG: 6.6107, lr: 0.001
Epoch [2/80], Training Loss: 15.0663, Validation Loss Current: 5.1294, Validation Loss AVG: 5.1294, lr: 0.001
Epoch [3/80], Training Loss: 11.3942, Validation Loss Current: 5.0025, Validation Loss AVG: 5.0025, lr: 0.001
Epoch [4/80], Training Loss: 11.9577, Validation Loss Current: 5.5657, Validation Loss AVG: 5.5657, lr: 0.001
Epoch [5/80], Training Loss: 7.3529, Validation Loss Current: 5.6641, Validation Loss AVG: 5.6641, lr: 0.001
Epoch [6/80], Training Loss: 6.8872, Validation Loss Current: 5.2357, Validation Loss AVG: 5.2357, lr: 0.001
Epoch [7/80], Training Loss: 4.6106, Validation Loss Current: 7.0145, Validation Loss AVG: 7.0145, lr: 0.001
Epoch [8/80], Training Loss: 3.6948, Validation Loss Current: 5.7501, Validation Loss AVG: 5.7501, lr: 0.001
Epoch [9/80], Training Loss: 3.3350, Validation Loss Current: 5.8717, Validation Loss AVG: 5.8717, lr: 0.001
Epoch [10/80], Training Loss: 9.5919, Validation Loss Current: 5.9107, Validation Loss AVG: 5.9107, lr: 0.001
Epoch [11/80], Training Loss: 5.6214, Validation Loss Current: 7.0501, Validation Loss AVG: 7.0501, lr: 0.001
Epoch [12/80], Training Loss: 4.7912, Validation Loss Current: 6.4803, Validation Loss AVG: 6.4803, lr: 0.001
Epoch [13/80], Training Loss: 6.5942, Validation Loss Current: 5.5250, Validation Loss AVG: 5.5250, lr: 0.001
Epoch [14/80], Training Loss: 5.4800, Validation Loss Current: 7.9743, Validation Loss AVG: 7.9743, lr: 0.001
Epoch [15/80], Training Loss: 9.5702, Validation Loss Current: 7.5783, Validation Loss AVG: 7.5783, lr: 0.001
Epoch [16/80], Training Loss: 10.9041, Validation Loss Current: 7.8038, Validation Loss AVG: 7.8038, lr: 0.001
Epoch [17/80], Training Loss: 5.4244, Validation Loss Current: 6.6452, Validation Loss AVG: 6.6452, lr: 0.001
Epoch [18/80], Training Loss: 4.4826, Validation Loss Current: 6.4338, Validation Loss AVG: 6.4338, lr: 0.001
Epoch [19/80], Training Loss: 7.2146, Validation Loss Current: 7.4628, Validation Loss AVG: 7.4628, lr: 0.001
Epoch [20/80], Training Loss: 6.0768, Validation Loss Current: 5.8456, Validation Loss AVG: 5.8456, lr: 0.001
Epoch [21/80], Training Loss: 6.1800, Validation Loss Current: 7.6018, Validation Loss AVG: 7.6018, lr: 0.001
Epoch [22/80], Training Loss: 5.7776, Validation Loss Current: 6.3052, Validation Loss AVG: 6.3052, lr: 0.001
Epoch [23/80], Training Loss: 5.7482, Validation Loss Current: 7.4790, Validation Loss AVG: 7.4790, lr: 0.001
Epoch [24/80], Training Loss: 5.6839, Validation Loss Current: 7.3277, Validation Loss AVG: 7.3277, lr: 0.001
Epoch [25/80], Training Loss: 4.5747, Validation Loss Current: 7.4051, Validation Loss AVG: 7.4051, lr: 0.001
Epoch [26/80], Training Loss: 3.3350, Validation Loss Current: 7.9150, Validation Loss AVG: 7.9150, lr: 0.001
Epoch [27/80], Training Loss: 1.7835, Validation Loss Current: 5.9459, Validation Loss AVG: 5.9459, lr: 0.001
Epoch [28/80], Training Loss: 3.1214, Validation Loss Current: 6.5144, Validation Loss AVG: 6.5144, lr: 0.001
Epoch [29/80], Training Loss: 3.1493, Validation Loss Current: 6.0867, Validation Loss AVG: 6.0867, lr: 0.001
Epoch [30/80], Training Loss: 8.9539, Validation Loss Current: 6.8122, Validation Loss AVG: 6.8122, lr: 0.001
Epoch [31/80], Training Loss: 5.8815, Validation Loss Current: 8.4057, Validation Loss AVG: 8.4057, lr: 0.001
Epoch [32/80], Training Loss: 6.3877, Validation Loss Current: 6.9532, Validation Loss AVG: 6.9532, lr: 0.001
Epoch [33/80], Training Loss: 6.5467, Validation Loss Current: 6.6759, Validation Loss AVG: 6.6759, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random2 finished training. Best epoch: 3 Best val accuracy: [0.6124999999999999, 0.6654605263157894, 0.6723684210526316, 0.6608552631578948, 0.656578947368421, 0.6588815789473684, 0.6072368421052632, 0.6493421052631578, 0.6648026315789474, 0.6480263157894737, 0.6210526315789473, 0.6463815789473685, 0.6680921052631579, 0.5799342105263159, 0.5661184210526315, 0.5924342105263158, 0.6167763157894737, 0.63125, 0.60625, 0.6463815789473684, 0.5825657894736842, 0.6460526315789472, 0.5953947368421053, 0.6029605263157894, 0.6055921052631579, 0.5736842105263158, 0.65, 0.6457236842105264, 0.6453947368421054, 0.6194078947368421, 0.5651315789473684, 0.6292763157894736, 0.6335526315789475] Best val loss: 5.002466320991516


Current group: llo_0.2_random3
Epoch [1/80], Training Loss: 31.4345, Validation Loss Current: 6.5499, Validation Loss AVG: 6.5499, lr: 0.001
Epoch [2/80], Training Loss: 15.3967, Validation Loss Current: 5.3148, Validation Loss AVG: 5.3148, lr: 0.001
Epoch [3/80], Training Loss: 8.8328, Validation Loss Current: 5.0983, Validation Loss AVG: 5.0983, lr: 0.001
Epoch [4/80], Training Loss: 9.5740, Validation Loss Current: 5.1788, Validation Loss AVG: 5.1788, lr: 0.001
Epoch [5/80], Training Loss: 8.3645, Validation Loss Current: 5.3656, Validation Loss AVG: 5.3656, lr: 0.001
Epoch [6/80], Training Loss: 6.9636, Validation Loss Current: 6.3988, Validation Loss AVG: 6.3988, lr: 0.001
Epoch [7/80], Training Loss: 8.1051, Validation Loss Current: 5.6547, Validation Loss AVG: 5.6547, lr: 0.001
Epoch [8/80], Training Loss: 5.9670, Validation Loss Current: 5.8474, Validation Loss AVG: 5.8474, lr: 0.001
Epoch [9/80], Training Loss: 4.8176, Validation Loss Current: 5.7884, Validation Loss AVG: 5.7884, lr: 0.001
Epoch [10/80], Training Loss: 2.8132, Validation Loss Current: 5.4897, Validation Loss AVG: 5.4897, lr: 0.001
Epoch [11/80], Training Loss: 2.7446, Validation Loss Current: 5.6944, Validation Loss AVG: 5.6944, lr: 0.001
Epoch [12/80], Training Loss: 5.0659, Validation Loss Current: 6.8519, Validation Loss AVG: 6.8519, lr: 0.001
Epoch [13/80], Training Loss: 12.4586, Validation Loss Current: 9.6930, Validation Loss AVG: 9.6930, lr: 0.001
Epoch [14/80], Training Loss: 13.8219, Validation Loss Current: 10.4613, Validation Loss AVG: 10.4613, lr: 0.001
Epoch [15/80], Training Loss: 7.2293, Validation Loss Current: 6.5191, Validation Loss AVG: 6.5191, lr: 0.001
Epoch [16/80], Training Loss: 4.1284, Validation Loss Current: 5.9321, Validation Loss AVG: 5.9321, lr: 0.001
Epoch [17/80], Training Loss: 5.9856, Validation Loss Current: 5.2790, Validation Loss AVG: 5.2790, lr: 0.001
Epoch [18/80], Training Loss: 5.1540, Validation Loss Current: 6.0653, Validation Loss AVG: 6.0653, lr: 0.001
Epoch [19/80], Training Loss: 4.2594, Validation Loss Current: 5.7208, Validation Loss AVG: 5.7208, lr: 0.001
Epoch [20/80], Training Loss: 3.5318, Validation Loss Current: 5.9327, Validation Loss AVG: 5.9327, lr: 0.001
Epoch [21/80], Training Loss: 3.2689, Validation Loss Current: 7.1979, Validation Loss AVG: 7.1979, lr: 0.001
Epoch [22/80], Training Loss: 1.5349, Validation Loss Current: 5.4511, Validation Loss AVG: 5.4511, lr: 0.001
Epoch [23/80], Training Loss: 0.9810, Validation Loss Current: 5.6899, Validation Loss AVG: 5.6899, lr: 0.001
Epoch [24/80], Training Loss: 1.3461, Validation Loss Current: 5.5434, Validation Loss AVG: 5.5434, lr: 0.001
Epoch [25/80], Training Loss: 4.4261, Validation Loss Current: 5.5780, Validation Loss AVG: 5.5780, lr: 0.001
Epoch [26/80], Training Loss: 8.5848, Validation Loss Current: 8.6725, Validation Loss AVG: 8.6725, lr: 0.001
Epoch [27/80], Training Loss: 4.5816, Validation Loss Current: 6.6787, Validation Loss AVG: 6.6787, lr: 0.001
Epoch [28/80], Training Loss: 7.5224, Validation Loss Current: 6.7493, Validation Loss AVG: 6.7493, lr: 0.001
Epoch [29/80], Training Loss: 7.9735, Validation Loss Current: 6.6768, Validation Loss AVG: 6.6768, lr: 0.001
Epoch [30/80], Training Loss: 3.8274, Validation Loss Current: 6.3988, Validation Loss AVG: 6.3988, lr: 0.001
Epoch [31/80], Training Loss: 5.7715, Validation Loss Current: 8.4408, Validation Loss AVG: 8.4408, lr: 0.001
Epoch [32/80], Training Loss: 4.8610, Validation Loss Current: 6.4767, Validation Loss AVG: 6.4767, lr: 0.001
Epoch [33/80], Training Loss: 4.7194, Validation Loss Current: 7.5231, Validation Loss AVG: 7.5231, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.2_random3 finished training. Best epoch: 3 Best val accuracy: [0.6144736842105264, 0.6786184210526315, 0.6973684210526315, 0.6881578947368421, 0.7016447368421053, 0.6578947368421052, 0.6957236842105263, 0.6644736842105263, 0.6855263157894737, 0.6993421052631579, 0.7065789473684211, 0.68125, 0.5549342105263159, 0.4927631578947368, 0.65, 0.6549342105263158, 0.7026315789473684, 0.675, 0.6930921052631579, 0.6921052631578948, 0.6569078947368421, 0.7082236842105263, 0.7088815789473684, 0.7246710526315789, 0.7118421052631578, 0.5963815789473684, 0.6437499999999999, 0.6677631578947368, 0.6351973684210527, 0.6697368421052631, 0.6240131578947368, 0.674342105263158, 0.6230263157894738] Best val loss: 5.098327803611755


Current group: 0.2
Epoch [1/80], Training Loss: 46.4890, Validation Loss Current: 30.6706, Validation Loss AVG: 30.6706, lr: 0.001
Epoch [2/80], Training Loss: 28.4552, Validation Loss Current: 11.7006, Validation Loss AVG: 11.7006, lr: 0.001
Epoch [3/80], Training Loss: 21.7899, Validation Loss Current: 12.8620, Validation Loss AVG: 12.8620, lr: 0.001
Epoch [4/80], Training Loss: 18.7300, Validation Loss Current: 19.9356, Validation Loss AVG: 19.9356, lr: 0.001
Epoch [5/80], Training Loss: 17.4439, Validation Loss Current: 11.8134, Validation Loss AVG: 11.8134, lr: 0.001
Epoch [6/80], Training Loss: 12.8718, Validation Loss Current: 12.1886, Validation Loss AVG: 12.1886, lr: 0.001
Epoch [7/80], Training Loss: 10.4518, Validation Loss Current: 13.3278, Validation Loss AVG: 13.3278, lr: 0.001
Epoch [8/80], Training Loss: 8.8593, Validation Loss Current: 12.7318, Validation Loss AVG: 12.7318, lr: 0.001
Epoch [9/80], Training Loss: 8.9436, Validation Loss Current: 17.4431, Validation Loss AVG: 17.4431, lr: 0.001
Epoch [10/80], Training Loss: 14.3104, Validation Loss Current: 17.4851, Validation Loss AVG: 17.4851, lr: 0.001
Epoch [11/80], Training Loss: 8.2106, Validation Loss Current: 16.0235, Validation Loss AVG: 16.0235, lr: 0.001
Epoch [12/80], Training Loss: 4.9779, Validation Loss Current: 19.6242, Validation Loss AVG: 19.6242, lr: 0.001
Epoch [13/80], Training Loss: 3.8564, Validation Loss Current: 16.1289, Validation Loss AVG: 16.1289, lr: 0.001
Epoch [14/80], Training Loss: 4.6937, Validation Loss Current: 16.7109, Validation Loss AVG: 16.7109, lr: 0.001
Epoch [15/80], Training Loss: 4.3892, Validation Loss Current: 17.1084, Validation Loss AVG: 17.1084, lr: 0.001
Epoch [16/80], Training Loss: 5.3365, Validation Loss Current: 13.6595, Validation Loss AVG: 13.6595, lr: 0.001
Epoch [17/80], Training Loss: 2.8462, Validation Loss Current: 16.5922, Validation Loss AVG: 16.5922, lr: 0.001
Epoch [18/80], Training Loss: 5.7442, Validation Loss Current: 25.6783, Validation Loss AVG: 25.6783, lr: 0.001
Epoch [19/80], Training Loss: 17.5354, Validation Loss Current: 20.2527, Validation Loss AVG: 20.2527, lr: 0.001
Epoch [20/80], Training Loss: 10.3322, Validation Loss Current: 21.3436, Validation Loss AVG: 21.3436, lr: 0.001
Epoch [21/80], Training Loss: 7.5895, Validation Loss Current: 19.4017, Validation Loss AVG: 19.4017, lr: 0.001
Epoch [22/80], Training Loss: 9.6853, Validation Loss Current: 20.3854, Validation Loss AVG: 20.3854, lr: 0.001
Epoch [23/80], Training Loss: 6.8398, Validation Loss Current: 19.5753, Validation Loss AVG: 19.5753, lr: 0.001
Epoch [24/80], Training Loss: 6.5641, Validation Loss Current: 25.2817, Validation Loss AVG: 25.2817, lr: 0.001
Epoch [25/80], Training Loss: 8.9978, Validation Loss Current: 31.5466, Validation Loss AVG: 31.5466, lr: 0.001
Epoch [26/80], Training Loss: 12.8251, Validation Loss Current: 16.0650, Validation Loss AVG: 16.0650, lr: 0.001
Epoch [27/80], Training Loss: 7.3839, Validation Loss Current: 16.0739, Validation Loss AVG: 16.0739, lr: 0.001
Epoch [28/80], Training Loss: 5.1918, Validation Loss Current: 14.6067, Validation Loss AVG: 14.6067, lr: 0.001
Epoch [29/80], Training Loss: 3.5969, Validation Loss Current: 17.0166, Validation Loss AVG: 17.0166, lr: 0.001
Epoch [30/80], Training Loss: 5.8375, Validation Loss Current: 19.1133, Validation Loss AVG: 19.1133, lr: 0.001
Epoch [31/80], Training Loss: 4.7865, Validation Loss Current: 16.9538, Validation Loss AVG: 16.9538, lr: 0.001
Epoch [32/80], Training Loss: 3.2239, Validation Loss Current: 14.9504, Validation Loss AVG: 14.9504, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.2 finished training. Best epoch: 2 Best val accuracy: [0.23782894736842106, 0.4480263157894737, 0.3582236842105263, 0.26085526315789476, 0.4118421052631579, 0.39671052631578946, 0.4026315789473684, 0.4302631578947368, 0.34013157894736845, 0.35625000000000007, 0.38026315789473686, 0.3282894736842105, 0.37105263157894736, 0.40855263157894733, 0.38848684210526313, 0.43322368421052626, 0.3835526315789474, 0.2990131578947368, 0.33749999999999997, 0.28651315789473686, 0.2911184210526316, 0.3697368421052632, 0.33519736842105263, 0.2388157894736842, 0.23980263157894735, 0.44342105263157894, 0.34375, 0.3973684210526316, 0.3615131578947368, 0.3667763157894737, 0.4266447368421053, 0.40493421052631584] Best val loss: 11.700646924972535


----- Training resnet18 with sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] -----
Current group: llo_0.8_random0
Epoch [1/80], Training Loss: 40.9637, Validation Loss Current: 9.9681, Validation Loss AVG: 9.9681, lr: 0.001
Epoch [2/80], Training Loss: 39.6371, Validation Loss Current: 9.8506, Validation Loss AVG: 9.8506, lr: 0.001
Epoch [3/80], Training Loss: 39.8805, Validation Loss Current: 9.7348, Validation Loss AVG: 9.7348, lr: 0.001
Epoch [4/80], Training Loss: 38.8769, Validation Loss Current: 9.6010, Validation Loss AVG: 9.6010, lr: 0.001
Epoch [5/80], Training Loss: 38.5335, Validation Loss Current: 9.2991, Validation Loss AVG: 9.2991, lr: 0.001
Epoch [6/80], Training Loss: 37.0323, Validation Loss Current: 9.1018, Validation Loss AVG: 9.1018, lr: 0.001
Epoch [7/80], Training Loss: 36.6042, Validation Loss Current: 8.9342, Validation Loss AVG: 8.9342, lr: 0.001
Epoch [8/80], Training Loss: 35.6295, Validation Loss Current: 8.8331, Validation Loss AVG: 8.8331, lr: 0.001
Epoch [9/80], Training Loss: 35.5285, Validation Loss Current: 8.6493, Validation Loss AVG: 8.6493, lr: 0.001
Epoch [10/80], Training Loss: 34.6354, Validation Loss Current: 8.6213, Validation Loss AVG: 8.6213, lr: 0.001
Epoch [11/80], Training Loss: 33.3181, Validation Loss Current: 8.4167, Validation Loss AVG: 8.4167, lr: 0.001
Epoch [12/80], Training Loss: 34.2508, Validation Loss Current: 8.8233, Validation Loss AVG: 8.8233, lr: 0.001
Epoch [13/80], Training Loss: 32.9556, Validation Loss Current: 8.3299, Validation Loss AVG: 8.3299, lr: 0.001
Epoch [14/80], Training Loss: 32.7098, Validation Loss Current: 8.0111, Validation Loss AVG: 8.0111, lr: 0.001
Epoch [15/80], Training Loss: 31.8021, Validation Loss Current: 8.0097, Validation Loss AVG: 8.0097, lr: 0.001
Epoch [16/80], Training Loss: 31.3670, Validation Loss Current: 7.8123, Validation Loss AVG: 7.8123, lr: 0.001
Epoch [17/80], Training Loss: 29.4084, Validation Loss Current: 7.9061, Validation Loss AVG: 7.9061, lr: 0.001
Epoch [18/80], Training Loss: 30.2918, Validation Loss Current: 8.0182, Validation Loss AVG: 8.0182, lr: 0.001
Epoch [19/80], Training Loss: 29.5835, Validation Loss Current: 7.6746, Validation Loss AVG: 7.6746, lr: 0.001
Epoch [20/80], Training Loss: 28.5934, Validation Loss Current: 8.4471, Validation Loss AVG: 8.4471, lr: 0.001
Epoch [21/80], Training Loss: 27.1364, Validation Loss Current: 7.7317, Validation Loss AVG: 7.7317, lr: 0.001
Epoch [22/80], Training Loss: 27.4270, Validation Loss Current: 7.2377, Validation Loss AVG: 7.2377, lr: 0.001
Epoch [23/80], Training Loss: 26.1663, Validation Loss Current: 7.3243, Validation Loss AVG: 7.3243, lr: 0.001
Epoch [24/80], Training Loss: 26.1403, Validation Loss Current: 7.6837, Validation Loss AVG: 7.6837, lr: 0.001
Epoch [25/80], Training Loss: 24.6680, Validation Loss Current: 8.3681, Validation Loss AVG: 8.3681, lr: 0.001
Epoch [26/80], Training Loss: 24.5830, Validation Loss Current: 7.4069, Validation Loss AVG: 7.4069, lr: 0.001
Epoch [27/80], Training Loss: 25.1239, Validation Loss Current: 7.5187, Validation Loss AVG: 7.5187, lr: 0.001
Epoch [28/80], Training Loss: 23.6981, Validation Loss Current: 7.7076, Validation Loss AVG: 7.7076, lr: 0.001
Epoch [29/80], Training Loss: 22.6974, Validation Loss Current: 7.5549, Validation Loss AVG: 7.5549, lr: 0.001
Epoch [30/80], Training Loss: 21.4060, Validation Loss Current: 6.7741, Validation Loss AVG: 6.7741, lr: 0.001
Epoch [31/80], Training Loss: 20.9737, Validation Loss Current: 7.2998, Validation Loss AVG: 7.2998, lr: 0.001
Epoch [32/80], Training Loss: 19.7499, Validation Loss Current: 7.2848, Validation Loss AVG: 7.2848, lr: 0.001
Epoch [33/80], Training Loss: 20.5772, Validation Loss Current: 7.8369, Validation Loss AVG: 7.8369, lr: 0.001
Epoch [34/80], Training Loss: 21.5555, Validation Loss Current: 8.0865, Validation Loss AVG: 8.0865, lr: 0.001
Epoch [35/80], Training Loss: 19.8838, Validation Loss Current: 7.2581, Validation Loss AVG: 7.2581, lr: 0.001
Epoch [36/80], Training Loss: 19.0032, Validation Loss Current: 6.9614, Validation Loss AVG: 6.9614, lr: 0.001
Epoch [37/80], Training Loss: 17.4597, Validation Loss Current: 7.0065, Validation Loss AVG: 7.0065, lr: 0.001
Epoch [38/80], Training Loss: 16.7080, Validation Loss Current: 7.1329, Validation Loss AVG: 7.1329, lr: 0.001
Epoch [39/80], Training Loss: 15.1436, Validation Loss Current: 6.4924, Validation Loss AVG: 6.4924, lr: 0.001
Epoch [40/80], Training Loss: 14.6487, Validation Loss Current: 6.6351, Validation Loss AVG: 6.6351, lr: 0.001
Epoch [41/80], Training Loss: 15.0503, Validation Loss Current: 6.7948, Validation Loss AVG: 6.7948, lr: 0.001
Epoch [42/80], Training Loss: 15.5779, Validation Loss Current: 7.2769, Validation Loss AVG: 7.2769, lr: 0.001
Epoch [43/80], Training Loss: 12.4760, Validation Loss Current: 6.3475, Validation Loss AVG: 6.3475, lr: 0.001
Epoch [44/80], Training Loss: 12.0227, Validation Loss Current: 7.1408, Validation Loss AVG: 7.1408, lr: 0.001
Epoch [45/80], Training Loss: 16.2969, Validation Loss Current: 7.0794, Validation Loss AVG: 7.0794, lr: 0.001
Epoch [46/80], Training Loss: 12.7299, Validation Loss Current: 6.9066, Validation Loss AVG: 6.9066, lr: 0.001
Epoch [47/80], Training Loss: 10.6068, Validation Loss Current: 7.5216, Validation Loss AVG: 7.5216, lr: 0.001
Epoch [48/80], Training Loss: 14.5078, Validation Loss Current: 12.5255, Validation Loss AVG: 12.5255, lr: 0.001
Epoch [49/80], Training Loss: 17.3424, Validation Loss Current: 7.8521, Validation Loss AVG: 7.8521, lr: 0.001
Epoch [50/80], Training Loss: 13.4687, Validation Loss Current: 6.5305, Validation Loss AVG: 6.5305, lr: 0.001
Epoch [51/80], Training Loss: 9.5088, Validation Loss Current: 6.7038, Validation Loss AVG: 6.7038, lr: 0.001
Epoch [52/80], Training Loss: 8.5156, Validation Loss Current: 6.8286, Validation Loss AVG: 6.8286, lr: 0.001
Epoch [53/80], Training Loss: 7.9948, Validation Loss Current: 7.4751, Validation Loss AVG: 7.4751, lr: 0.001
Epoch [54/80], Training Loss: 7.3210, Validation Loss Current: 6.7454, Validation Loss AVG: 6.7454, lr: 0.001
Epoch [55/80], Training Loss: 7.2588, Validation Loss Current: 7.9476, Validation Loss AVG: 7.9476, lr: 0.001
Epoch [56/80], Training Loss: 11.6896, Validation Loss Current: 8.0248, Validation Loss AVG: 8.0248, lr: 0.001
Epoch [57/80], Training Loss: 9.8617, Validation Loss Current: 7.3285, Validation Loss AVG: 7.3285, lr: 0.001
Epoch [58/80], Training Loss: 7.3550, Validation Loss Current: 7.6962, Validation Loss AVG: 7.6962, lr: 0.001
Epoch [59/80], Training Loss: 7.5553, Validation Loss Current: 7.4948, Validation Loss AVG: 7.4948, lr: 0.001
Epoch [60/80], Training Loss: 7.0096, Validation Loss Current: 7.3465, Validation Loss AVG: 7.3465, lr: 0.001
Epoch [61/80], Training Loss: 5.1787, Validation Loss Current: 8.3174, Validation Loss AVG: 8.3174, lr: 0.001
Epoch [62/80], Training Loss: 6.0730, Validation Loss Current: 7.3073, Validation Loss AVG: 7.3073, lr: 0.001
Epoch [63/80], Training Loss: 4.9097, Validation Loss Current: 7.2707, Validation Loss AVG: 7.2707, lr: 0.001
Epoch [64/80], Training Loss: 4.7672, Validation Loss Current: 8.1325, Validation Loss AVG: 8.1325, lr: 0.001
Epoch [65/80], Training Loss: 4.4798, Validation Loss Current: 7.1374, Validation Loss AVG: 7.1374, lr: 0.001
Epoch [66/80], Training Loss: 4.1013, Validation Loss Current: 7.7361, Validation Loss AVG: 7.7361, lr: 0.001
Epoch [67/80], Training Loss: 8.6892, Validation Loss Current: 10.5014, Validation Loss AVG: 10.5014, lr: 0.001
Epoch [68/80], Training Loss: 7.5830, Validation Loss Current: 8.6356, Validation Loss AVG: 8.6356, lr: 0.001
Epoch [69/80], Training Loss: 8.2923, Validation Loss Current: 13.9919, Validation Loss AVG: 13.9919, lr: 0.001
Epoch [70/80], Training Loss: 14.2115, Validation Loss Current: 13.3974, Validation Loss AVG: 13.3974, lr: 0.001
Epoch [71/80], Training Loss: 9.3848, Validation Loss Current: 9.2309, Validation Loss AVG: 9.2309, lr: 0.001
Epoch [72/80], Training Loss: 6.1020, Validation Loss Current: 8.0867, Validation Loss AVG: 8.0867, lr: 0.001
Epoch [73/80], Training Loss: 5.7834, Validation Loss Current: 7.7203, Validation Loss AVG: 7.7203, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random0 finished training. Best epoch: 43 Best val accuracy: [0.2625, 0.2648026315789474, 0.2911184210526315, 0.3003289473684211, 0.32894736842105265, 0.33421052631578946, 0.3424342105263158, 0.3473684210526316, 0.36447368421052634, 0.36743421052631575, 0.3805921052631579, 0.36282894736842103, 0.3917763157894737, 0.41743421052631585, 0.4128289473684211, 0.42631578947368415, 0.4345394736842104, 0.41085526315789467, 0.4496710526315789, 0.41776315789473684, 0.4421052631578948, 0.48026315789473684, 0.47105263157894744, 0.4638157894736842, 0.4213815789473684, 0.47828947368421054, 0.46743421052631573, 0.4618421052631579, 0.47993421052631585, 0.5213815789473685, 0.47434210526315795, 0.4901315789473684, 0.4526315789473685, 0.4720394736842105, 0.4858552631578948, 0.511513157894737, 0.5101973684210527, 0.5128289473684211, 0.5394736842105263, 0.5394736842105263, 0.5332236842105262, 0.5052631578947369, 0.5700657894736841, 0.5292763157894737, 0.5322368421052632, 0.5273026315789473, 0.5108552631578946, 0.3, 0.5141447368421053, 0.5694078947368421, 0.5592105263157895, 0.5569078947368422, 0.5598684210526316, 0.5661184210526315, 0.5220394736842107, 0.4990131578947368, 0.5483552631578947, 0.5368421052631579, 0.5509868421052632, 0.5588815789473685, 0.5269736842105264, 0.5796052631578947, 0.5766447368421053, 0.5615131578947369, 0.5957236842105263, 0.5483552631578947, 0.5006578947368421, 0.5220394736842107, 0.3842105263157895, 0.37006578947368424, 0.5118421052631579, 0.5605263157894738, 0.5733552631578948] Best val loss: 6.347521877288818


Current group: llo_0.8_random1
Epoch [1/80], Training Loss: 34.5060, Validation Loss Current: 7.6538, Validation Loss AVG: 7.6538, lr: 0.001
Epoch [2/80], Training Loss: 23.3062, Validation Loss Current: 8.7020, Validation Loss AVG: 8.7020, lr: 0.001
Epoch [3/80], Training Loss: 19.7806, Validation Loss Current: 7.1389, Validation Loss AVG: 7.1389, lr: 0.001
Epoch [4/80], Training Loss: 17.4320, Validation Loss Current: 6.9305, Validation Loss AVG: 6.9305, lr: 0.001
Epoch [5/80], Training Loss: 18.3723, Validation Loss Current: 6.2236, Validation Loss AVG: 6.2236, lr: 0.001
Epoch [6/80], Training Loss: 12.6641, Validation Loss Current: 6.3725, Validation Loss AVG: 6.3725, lr: 0.001
Epoch [7/80], Training Loss: 11.2063, Validation Loss Current: 6.6147, Validation Loss AVG: 6.6147, lr: 0.001
Epoch [8/80], Training Loss: 13.8316, Validation Loss Current: 6.9193, Validation Loss AVG: 6.9193, lr: 0.001
Epoch [9/80], Training Loss: 12.8878, Validation Loss Current: 7.2839, Validation Loss AVG: 7.2839, lr: 0.001
Epoch [10/80], Training Loss: 9.3220, Validation Loss Current: 6.1461, Validation Loss AVG: 6.1461, lr: 0.001
Epoch [11/80], Training Loss: 9.3893, Validation Loss Current: 8.0536, Validation Loss AVG: 8.0536, lr: 0.001
Epoch [12/80], Training Loss: 8.8433, Validation Loss Current: 8.0459, Validation Loss AVG: 8.0459, lr: 0.001
Epoch [13/80], Training Loss: 8.3844, Validation Loss Current: 10.8446, Validation Loss AVG: 10.8446, lr: 0.001
Epoch [14/80], Training Loss: 9.8686, Validation Loss Current: 6.6368, Validation Loss AVG: 6.6368, lr: 0.001
Epoch [15/80], Training Loss: 7.8916, Validation Loss Current: 6.6900, Validation Loss AVG: 6.6900, lr: 0.001
Epoch [16/80], Training Loss: 8.7133, Validation Loss Current: 6.6235, Validation Loss AVG: 6.6235, lr: 0.001
Epoch [17/80], Training Loss: 7.8899, Validation Loss Current: 6.8523, Validation Loss AVG: 6.8523, lr: 0.001
Epoch [18/80], Training Loss: 6.2667, Validation Loss Current: 7.2703, Validation Loss AVG: 7.2703, lr: 0.001
Epoch [19/80], Training Loss: 5.5018, Validation Loss Current: 6.4241, Validation Loss AVG: 6.4241, lr: 0.001
Epoch [20/80], Training Loss: 6.0171, Validation Loss Current: 6.7052, Validation Loss AVG: 6.7052, lr: 0.001
Epoch [21/80], Training Loss: 9.1660, Validation Loss Current: 7.8540, Validation Loss AVG: 7.8540, lr: 0.001
Epoch [22/80], Training Loss: 12.7966, Validation Loss Current: 9.8771, Validation Loss AVG: 9.8771, lr: 0.001
Epoch [23/80], Training Loss: 13.5231, Validation Loss Current: 8.4382, Validation Loss AVG: 8.4382, lr: 0.001
Epoch [24/80], Training Loss: 10.1314, Validation Loss Current: 7.7647, Validation Loss AVG: 7.7647, lr: 0.001
Epoch [25/80], Training Loss: 7.2890, Validation Loss Current: 7.3776, Validation Loss AVG: 7.3776, lr: 0.001
Epoch [26/80], Training Loss: 9.7178, Validation Loss Current: 10.3893, Validation Loss AVG: 10.3893, lr: 0.001
Epoch [27/80], Training Loss: 5.3380, Validation Loss Current: 8.1499, Validation Loss AVG: 8.1499, lr: 0.001
Epoch [28/80], Training Loss: 5.7968, Validation Loss Current: 6.8709, Validation Loss AVG: 6.8709, lr: 0.001
Epoch [29/80], Training Loss: 6.8321, Validation Loss Current: 7.1789, Validation Loss AVG: 7.1789, lr: 0.001
Epoch [30/80], Training Loss: 4.8953, Validation Loss Current: 7.8320, Validation Loss AVG: 7.8320, lr: 0.001
Epoch [31/80], Training Loss: 3.4002, Validation Loss Current: 6.9959, Validation Loss AVG: 6.9959, lr: 0.001
Epoch [32/80], Training Loss: 2.7949, Validation Loss Current: 8.2326, Validation Loss AVG: 8.2326, lr: 0.001
Epoch [33/80], Training Loss: 4.1665, Validation Loss Current: 8.2278, Validation Loss AVG: 8.2278, lr: 0.001
Epoch [34/80], Training Loss: 4.7255, Validation Loss Current: 10.7993, Validation Loss AVG: 10.7993, lr: 0.001
Epoch [35/80], Training Loss: 4.3974, Validation Loss Current: 8.6393, Validation Loss AVG: 8.6393, lr: 0.001
Epoch [36/80], Training Loss: 4.6894, Validation Loss Current: 7.8139, Validation Loss AVG: 7.8139, lr: 0.001
Epoch [37/80], Training Loss: 5.2003, Validation Loss Current: 7.9457, Validation Loss AVG: 7.9457, lr: 0.001
Epoch [38/80], Training Loss: 5.8737, Validation Loss Current: 9.7976, Validation Loss AVG: 9.7976, lr: 0.001
Epoch [39/80], Training Loss: 6.6322, Validation Loss Current: 7.8976, Validation Loss AVG: 7.8976, lr: 0.001
Epoch [40/80], Training Loss: 4.7927, Validation Loss Current: 8.2588, Validation Loss AVG: 8.2588, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random1 finished training. Best epoch: 10 Best val accuracy: [0.531578947368421, 0.48519736842105265, 0.5450657894736841, 0.5519736842105264, 0.6006578947368422, 0.6098684210526316, 0.5901315789473685, 0.5733552631578948, 0.544407894736842, 0.61875, 0.5569078947368421, 0.5532894736842107, 0.46546052631578955, 0.6069078947368421, 0.6236842105263157, 0.618421052631579, 0.6144736842105264, 0.5845394736842106, 0.6381578947368421, 0.6253289473684209, 0.5661184210526315, 0.5009868421052632, 0.5463815789473684, 0.5733552631578946, 0.5861842105263159, 0.5342105263157895, 0.5710526315789474, 0.6302631578947369, 0.6289473684210526, 0.5802631578947368, 0.625, 0.5815789473684211, 0.6055921052631579, 0.4947368421052632, 0.5743421052631579, 0.6141447368421052, 0.593421052631579, 0.5651315789473684, 0.5993421052631579, 0.5901315789473685] Best val loss: 6.146114659309387


Current group: llo_0.8_random2
Epoch [1/80], Training Loss: 36.8429, Validation Loss Current: 7.8527, Validation Loss AVG: 7.8527, lr: 0.001
Epoch [2/80], Training Loss: 23.5089, Validation Loss Current: 7.7728, Validation Loss AVG: 7.7728, lr: 0.001
Epoch [3/80], Training Loss: 20.7432, Validation Loss Current: 5.5412, Validation Loss AVG: 5.5412, lr: 0.001
Epoch [4/80], Training Loss: 16.2641, Validation Loss Current: 6.5228, Validation Loss AVG: 6.5228, lr: 0.001
Epoch [5/80], Training Loss: 20.5552, Validation Loss Current: 11.3222, Validation Loss AVG: 11.3222, lr: 0.001
Epoch [6/80], Training Loss: 18.9081, Validation Loss Current: 5.7313, Validation Loss AVG: 5.7313, lr: 0.001
Epoch [7/80], Training Loss: 11.3764, Validation Loss Current: 5.6332, Validation Loss AVG: 5.6332, lr: 0.001
Epoch [8/80], Training Loss: 10.8802, Validation Loss Current: 5.0220, Validation Loss AVG: 5.0220, lr: 0.001
Epoch [9/80], Training Loss: 6.4013, Validation Loss Current: 4.9266, Validation Loss AVG: 4.9266, lr: 0.001
Epoch [10/80], Training Loss: 7.5701, Validation Loss Current: 7.3758, Validation Loss AVG: 7.3758, lr: 0.001
Epoch [11/80], Training Loss: 12.7029, Validation Loss Current: 7.0190, Validation Loss AVG: 7.0190, lr: 0.001
Epoch [12/80], Training Loss: 9.9589, Validation Loss Current: 6.8014, Validation Loss AVG: 6.8014, lr: 0.001
Epoch [13/80], Training Loss: 15.1920, Validation Loss Current: 7.4383, Validation Loss AVG: 7.4383, lr: 0.001
Epoch [14/80], Training Loss: 9.3487, Validation Loss Current: 5.7368, Validation Loss AVG: 5.7368, lr: 0.001
Epoch [15/80], Training Loss: 6.0662, Validation Loss Current: 5.6889, Validation Loss AVG: 5.6889, lr: 0.001
Epoch [16/80], Training Loss: 4.7022, Validation Loss Current: 5.9941, Validation Loss AVG: 5.9941, lr: 0.001
Epoch [17/80], Training Loss: 3.2218, Validation Loss Current: 5.4841, Validation Loss AVG: 5.4841, lr: 0.001
Epoch [18/80], Training Loss: 3.3986, Validation Loss Current: 5.4360, Validation Loss AVG: 5.4360, lr: 0.001
Epoch [19/80], Training Loss: 3.3202, Validation Loss Current: 5.6069, Validation Loss AVG: 5.6069, lr: 0.001
Epoch [20/80], Training Loss: 2.6339, Validation Loss Current: 5.6378, Validation Loss AVG: 5.6378, lr: 0.001
Epoch [21/80], Training Loss: 4.4104, Validation Loss Current: 5.9694, Validation Loss AVG: 5.9694, lr: 0.001
Epoch [22/80], Training Loss: 3.9036, Validation Loss Current: 8.3058, Validation Loss AVG: 8.3058, lr: 0.001
Epoch [23/80], Training Loss: 3.9777, Validation Loss Current: 6.3137, Validation Loss AVG: 6.3137, lr: 0.001
Epoch [24/80], Training Loss: 6.6678, Validation Loss Current: 6.8826, Validation Loss AVG: 6.8826, lr: 0.001
Epoch [25/80], Training Loss: 5.0978, Validation Loss Current: 6.5296, Validation Loss AVG: 6.5296, lr: 0.001
Epoch [26/80], Training Loss: 5.9300, Validation Loss Current: 7.2234, Validation Loss AVG: 7.2234, lr: 0.001
Epoch [27/80], Training Loss: 8.9174, Validation Loss Current: 7.8572, Validation Loss AVG: 7.8572, lr: 0.001
Epoch [28/80], Training Loss: 4.4504, Validation Loss Current: 6.9566, Validation Loss AVG: 6.9566, lr: 0.001
Epoch [29/80], Training Loss: 6.4130, Validation Loss Current: 7.1278, Validation Loss AVG: 7.1278, lr: 0.001
Epoch [30/80], Training Loss: 5.5668, Validation Loss Current: 7.1148, Validation Loss AVG: 7.1148, lr: 0.001
Epoch [31/80], Training Loss: 5.2735, Validation Loss Current: 6.9101, Validation Loss AVG: 6.9101, lr: 0.001
Epoch [32/80], Training Loss: 4.3368, Validation Loss Current: 6.9842, Validation Loss AVG: 6.9842, lr: 0.001
Epoch [33/80], Training Loss: 4.3159, Validation Loss Current: 6.7245, Validation Loss AVG: 6.7245, lr: 0.001
Epoch [34/80], Training Loss: 6.1676, Validation Loss Current: 7.9592, Validation Loss AVG: 7.9592, lr: 0.001
Epoch [35/80], Training Loss: 5.6477, Validation Loss Current: 6.9079, Validation Loss AVG: 6.9079, lr: 0.001
Epoch [36/80], Training Loss: 3.5426, Validation Loss Current: 7.2102, Validation Loss AVG: 7.2102, lr: 0.001
Epoch [37/80], Training Loss: 3.6009, Validation Loss Current: 8.4744, Validation Loss AVG: 8.4744, lr: 0.001
Epoch [38/80], Training Loss: 8.7967, Validation Loss Current: 8.7231, Validation Loss AVG: 8.7231, lr: 0.001
Epoch [39/80], Training Loss: 4.4570, Validation Loss Current: 7.8539, Validation Loss AVG: 7.8539, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random2 finished training. Best epoch: 9 Best val accuracy: [0.5608552631578947, 0.54375, 0.6233552631578948, 0.5904605263157895, 0.43157894736842106, 0.6384868421052631, 0.6506578947368421, 0.6842105263157895, 0.69375, 0.6, 0.5996710526315789, 0.5907894736842105, 0.5838815789473684, 0.6549342105263158, 0.6592105263157894, 0.6529605263157895, 0.6825657894736842, 0.6832236842105264, 0.6601973684210526, 0.6759868421052632, 0.6611842105263158, 0.5723684210526316, 0.65, 0.6378289473684211, 0.6473684210526315, 0.6319078947368422, 0.6138157894736842, 0.5927631578947369, 0.6276315789473685, 0.625, 0.6480263157894737, 0.6207236842105263, 0.6503289473684211, 0.6013157894736842, 0.6430921052631579, 0.6174342105263158, 0.5730263157894737, 0.5641447368421053, 0.6289473684210526] Best val loss: 4.926602423191071


Current group: llo_0.8_random3
Epoch [1/80], Training Loss: 42.6502, Validation Loss Current: 7.1619, Validation Loss AVG: 7.1619, lr: 0.001
Epoch [2/80], Training Loss: 28.2567, Validation Loss Current: 7.1577, Validation Loss AVG: 7.1577, lr: 0.001
Epoch [3/80], Training Loss: 20.1645, Validation Loss Current: 5.4677, Validation Loss AVG: 5.4677, lr: 0.001
Epoch [4/80], Training Loss: 17.6831, Validation Loss Current: 6.2804, Validation Loss AVG: 6.2804, lr: 0.001
Epoch [5/80], Training Loss: 13.5263, Validation Loss Current: 6.4136, Validation Loss AVG: 6.4136, lr: 0.001
Epoch [6/80], Training Loss: 10.0612, Validation Loss Current: 4.5413, Validation Loss AVG: 4.5413, lr: 0.001
Epoch [7/80], Training Loss: 8.1143, Validation Loss Current: 4.7005, Validation Loss AVG: 4.7005, lr: 0.001
Epoch [8/80], Training Loss: 11.8454, Validation Loss Current: 4.9860, Validation Loss AVG: 4.9860, lr: 0.001
Epoch [9/80], Training Loss: 8.2690, Validation Loss Current: 5.5193, Validation Loss AVG: 5.5193, lr: 0.001
Epoch [10/80], Training Loss: 8.3193, Validation Loss Current: 4.5907, Validation Loss AVG: 4.5907, lr: 0.001
Epoch [11/80], Training Loss: 5.3179, Validation Loss Current: 4.7230, Validation Loss AVG: 4.7230, lr: 0.001
Epoch [12/80], Training Loss: 4.6932, Validation Loss Current: 4.5884, Validation Loss AVG: 4.5884, lr: 0.001
Epoch [13/80], Training Loss: 5.8698, Validation Loss Current: 6.3175, Validation Loss AVG: 6.3175, lr: 0.001
Epoch [14/80], Training Loss: 5.0514, Validation Loss Current: 5.3604, Validation Loss AVG: 5.3604, lr: 0.001
Epoch [15/80], Training Loss: 3.7738, Validation Loss Current: 4.9380, Validation Loss AVG: 4.9380, lr: 0.001
Epoch [16/80], Training Loss: 2.2433, Validation Loss Current: 4.6482, Validation Loss AVG: 4.6482, lr: 0.001
Epoch [17/80], Training Loss: 4.3795, Validation Loss Current: 4.8522, Validation Loss AVG: 4.8522, lr: 0.001
Epoch [18/80], Training Loss: 5.6316, Validation Loss Current: 7.1560, Validation Loss AVG: 7.1560, lr: 0.001
Epoch [19/80], Training Loss: 7.4857, Validation Loss Current: 6.7509, Validation Loss AVG: 6.7509, lr: 0.001
Epoch [20/80], Training Loss: 8.3273, Validation Loss Current: 6.1155, Validation Loss AVG: 6.1155, lr: 0.001
Epoch [21/80], Training Loss: 5.4468, Validation Loss Current: 5.7255, Validation Loss AVG: 5.7255, lr: 0.001
Epoch [22/80], Training Loss: 5.3002, Validation Loss Current: 6.1025, Validation Loss AVG: 6.1025, lr: 0.001
Epoch [23/80], Training Loss: 4.7226, Validation Loss Current: 5.0769, Validation Loss AVG: 5.0769, lr: 0.001
Epoch [24/80], Training Loss: 2.5672, Validation Loss Current: 5.4460, Validation Loss AVG: 5.4460, lr: 0.001
Epoch [25/80], Training Loss: 2.1158, Validation Loss Current: 5.8390, Validation Loss AVG: 5.8390, lr: 0.001
Epoch [26/80], Training Loss: 5.9597, Validation Loss Current: 5.8959, Validation Loss AVG: 5.8959, lr: 0.001
Epoch [27/80], Training Loss: 4.1331, Validation Loss Current: 6.0727, Validation Loss AVG: 6.0727, lr: 0.001
Epoch [28/80], Training Loss: 3.7774, Validation Loss Current: 5.5364, Validation Loss AVG: 5.5364, lr: 0.001
Epoch [29/80], Training Loss: 7.2705, Validation Loss Current: 6.0453, Validation Loss AVG: 6.0453, lr: 0.001
Epoch [30/80], Training Loss: 6.7573, Validation Loss Current: 5.7222, Validation Loss AVG: 5.7222, lr: 0.001
Epoch [31/80], Training Loss: 6.0027, Validation Loss Current: 5.9496, Validation Loss AVG: 5.9496, lr: 0.001
Epoch [32/80], Training Loss: 3.9898, Validation Loss Current: 6.8934, Validation Loss AVG: 6.8934, lr: 0.001
Epoch [33/80], Training Loss: 7.2806, Validation Loss Current: 7.2500, Validation Loss AVG: 7.2500, lr: 0.001
Epoch [34/80], Training Loss: 14.2334, Validation Loss Current: 8.7430, Validation Loss AVG: 8.7430, lr: 0.001
Epoch [35/80], Training Loss: 5.9017, Validation Loss Current: 6.2935, Validation Loss AVG: 6.2935, lr: 0.001
Epoch [36/80], Training Loss: 3.0733, Validation Loss Current: 6.3531, Validation Loss AVG: 6.3531, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.8_random3 finished training. Best epoch: 6 Best val accuracy: [0.6, 0.60625, 0.6611842105263157, 0.6203947368421053, 0.5707236842105263, 0.7141447368421052, 0.7144736842105264, 0.6825657894736843, 0.675, 0.7230263157894737, 0.7161184210526316, 0.7167763157894738, 0.656907894736842, 0.6953947368421052, 0.7111842105263158, 0.7197368421052632, 0.7200657894736842, 0.6473684210526316, 0.6351973684210527, 0.6526315789473685, 0.6865131578947368, 0.6776315789473684, 0.7157894736842105, 0.7042763157894736, 0.6973684210526315, 0.6911184210526315, 0.6733552631578947, 0.6884868421052631, 0.6776315789473684, 0.6947368421052632, 0.6749999999999999, 0.6444078947368421, 0.631578947368421, 0.5266447368421052, 0.6763157894736842, 0.6674342105263158] Best val loss: 4.5413069248199465


Current group: 0.8
Epoch [1/80], Training Loss: 38.6914, Validation Loss Current: 11.6887, Validation Loss AVG: 11.6887, lr: 0.001
Epoch [2/80], Training Loss: 24.9242, Validation Loss Current: 10.9940, Validation Loss AVG: 10.9940, lr: 0.001
Epoch [3/80], Training Loss: 15.0452, Validation Loss Current: 7.9506, Validation Loss AVG: 7.9506, lr: 0.001
Epoch [4/80], Training Loss: 10.0747, Validation Loss Current: 7.8773, Validation Loss AVG: 7.8773, lr: 0.001
Epoch [5/80], Training Loss: 8.5692, Validation Loss Current: 6.4693, Validation Loss AVG: 6.4693, lr: 0.001
Epoch [6/80], Training Loss: 5.4698, Validation Loss Current: 7.8386, Validation Loss AVG: 7.8386, lr: 0.001
Epoch [7/80], Training Loss: 5.8366, Validation Loss Current: 7.3648, Validation Loss AVG: 7.3648, lr: 0.001
Epoch [8/80], Training Loss: 6.2517, Validation Loss Current: 8.4743, Validation Loss AVG: 8.4743, lr: 0.001
Epoch [9/80], Training Loss: 5.1987, Validation Loss Current: 7.4866, Validation Loss AVG: 7.4866, lr: 0.001
Epoch [10/80], Training Loss: 3.8725, Validation Loss Current: 7.8627, Validation Loss AVG: 7.8627, lr: 0.001
Epoch [11/80], Training Loss: 2.2867, Validation Loss Current: 8.1013, Validation Loss AVG: 8.1013, lr: 0.001
Epoch [12/80], Training Loss: 6.2929, Validation Loss Current: 8.1692, Validation Loss AVG: 8.1692, lr: 0.001
Epoch [13/80], Training Loss: 4.6054, Validation Loss Current: 9.5517, Validation Loss AVG: 9.5517, lr: 0.001
Epoch [14/80], Training Loss: 2.1445, Validation Loss Current: 7.7323, Validation Loss AVG: 7.7323, lr: 0.001
Epoch [15/80], Training Loss: 3.7439, Validation Loss Current: 7.6007, Validation Loss AVG: 7.6007, lr: 0.001
Epoch [16/80], Training Loss: 4.7706, Validation Loss Current: 10.5620, Validation Loss AVG: 10.5620, lr: 0.001
Epoch [17/80], Training Loss: 12.4850, Validation Loss Current: 15.2723, Validation Loss AVG: 15.2723, lr: 0.001
Epoch [18/80], Training Loss: 7.5698, Validation Loss Current: 9.8018, Validation Loss AVG: 9.8018, lr: 0.001
Epoch [19/80], Training Loss: 8.6423, Validation Loss Current: 8.9830, Validation Loss AVG: 8.9830, lr: 0.001
Epoch [20/80], Training Loss: 5.2453, Validation Loss Current: 9.6154, Validation Loss AVG: 9.6154, lr: 0.001
Epoch [21/80], Training Loss: 3.7023, Validation Loss Current: 8.7917, Validation Loss AVG: 8.7917, lr: 0.001
Epoch [22/80], Training Loss: 3.0247, Validation Loss Current: 8.6582, Validation Loss AVG: 8.6582, lr: 0.001
Epoch [23/80], Training Loss: 4.0745, Validation Loss Current: 8.6307, Validation Loss AVG: 8.6307, lr: 0.001
Epoch [24/80], Training Loss: 6.7594, Validation Loss Current: 10.2631, Validation Loss AVG: 10.2631, lr: 0.001
Epoch [25/80], Training Loss: 5.7181, Validation Loss Current: 10.4298, Validation Loss AVG: 10.4298, lr: 0.001
Epoch [26/80], Training Loss: 4.2666, Validation Loss Current: 11.4264, Validation Loss AVG: 11.4264, lr: 0.001
Epoch [27/80], Training Loss: 8.1340, Validation Loss Current: 9.7543, Validation Loss AVG: 9.7543, lr: 0.001
Epoch [28/80], Training Loss: 2.3344, Validation Loss Current: 10.6781, Validation Loss AVG: 10.6781, lr: 0.001
Epoch [29/80], Training Loss: 4.1684, Validation Loss Current: 10.1331, Validation Loss AVG: 10.1331, lr: 0.001
Epoch [30/80], Training Loss: 5.9046, Validation Loss Current: 9.8993, Validation Loss AVG: 9.8993, lr: 0.001
Epoch [31/80], Training Loss: 3.5739, Validation Loss Current: 11.0256, Validation Loss AVG: 11.0256, lr: 0.001
Epoch [32/80], Training Loss: 2.3454, Validation Loss Current: 9.1685, Validation Loss AVG: 9.1685, lr: 0.001
Epoch [33/80], Training Loss: 2.1810, Validation Loss Current: 10.1585, Validation Loss AVG: 10.1585, lr: 0.001
Epoch [34/80], Training Loss: 2.0411, Validation Loss Current: 11.4935, Validation Loss AVG: 11.4935, lr: 0.001
Epoch [35/80], Training Loss: 6.0288, Validation Loss Current: 10.4364, Validation Loss AVG: 10.4364, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.8 finished training. Best epoch: 5 Best val accuracy: [0.45032894736842105, 0.4848684210526316, 0.5605263157894737, 0.54375, 0.6055921052631579, 0.5595394736842105, 0.5595394736842106, 0.5726973684210527, 0.5904605263157894, 0.5723684210526316, 0.5697368421052632, 0.5717105263157894, 0.5269736842105264, 0.5970394736842105, 0.5710526315789474, 0.5516447368421054, 0.41578947368421054, 0.5184210526315789, 0.5259868421052631, 0.5078947368421053, 0.544407894736842, 0.5519736842105264, 0.5289473684210526, 0.5036184210526315, 0.5328947368421052, 0.47828947368421054, 0.5023026315789474, 0.5194078947368421, 0.5296052631578947, 0.5276315789473685, 0.5273026315789473, 0.5575657894736842, 0.5095394736842105, 0.5414473684210526, 0.5302631578947368] Best val loss: 6.469343614578247


----- Training resnet18 with sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] -----
Current group: llo_0.4_random0
Epoch [1/80], Training Loss: 41.7910, Validation Loss Current: 10.0199, Validation Loss AVG: 10.0199, lr: 0.001
Epoch [2/80], Training Loss: 39.5316, Validation Loss Current: 10.0045, Validation Loss AVG: 10.0045, lr: 0.001
Epoch [3/80], Training Loss: 39.0301, Validation Loss Current: 9.9154, Validation Loss AVG: 9.9154, lr: 0.001
Epoch [4/80], Training Loss: 39.0577, Validation Loss Current: 9.6329, Validation Loss AVG: 9.6329, lr: 0.001
Epoch [5/80], Training Loss: 37.5139, Validation Loss Current: 9.3256, Validation Loss AVG: 9.3256, lr: 0.001
Epoch [6/80], Training Loss: 36.3661, Validation Loss Current: 9.0866, Validation Loss AVG: 9.0866, lr: 0.001
Epoch [7/80], Training Loss: 34.7587, Validation Loss Current: 8.7792, Validation Loss AVG: 8.7792, lr: 0.001
Epoch [8/80], Training Loss: 34.2074, Validation Loss Current: 8.5837, Validation Loss AVG: 8.5837, lr: 0.001
Epoch [9/80], Training Loss: 33.2409, Validation Loss Current: 8.6382, Validation Loss AVG: 8.6382, lr: 0.001
Epoch [10/80], Training Loss: 32.9355, Validation Loss Current: 8.7142, Validation Loss AVG: 8.7142, lr: 0.001
Epoch [11/80], Training Loss: 32.5882, Validation Loss Current: 8.4391, Validation Loss AVG: 8.4391, lr: 0.001
Epoch [12/80], Training Loss: 31.9097, Validation Loss Current: 8.1101, Validation Loss AVG: 8.1101, lr: 0.001
Epoch [13/80], Training Loss: 30.5319, Validation Loss Current: 7.9177, Validation Loss AVG: 7.9177, lr: 0.001
Epoch [14/80], Training Loss: 29.5334, Validation Loss Current: 7.7589, Validation Loss AVG: 7.7589, lr: 0.001
Epoch [15/80], Training Loss: 29.8472, Validation Loss Current: 7.8565, Validation Loss AVG: 7.8565, lr: 0.001
Epoch [16/80], Training Loss: 28.4933, Validation Loss Current: 7.7606, Validation Loss AVG: 7.7606, lr: 0.001
Epoch [17/80], Training Loss: 27.1699, Validation Loss Current: 7.4125, Validation Loss AVG: 7.4125, lr: 0.001
Epoch [18/80], Training Loss: 26.0110, Validation Loss Current: 7.6811, Validation Loss AVG: 7.6811, lr: 0.001
Epoch [19/80], Training Loss: 26.5770, Validation Loss Current: 7.3022, Validation Loss AVG: 7.3022, lr: 0.001
Epoch [20/80], Training Loss: 25.0826, Validation Loss Current: 7.1549, Validation Loss AVG: 7.1549, lr: 0.001
Epoch [21/80], Training Loss: 23.8817, Validation Loss Current: 7.1887, Validation Loss AVG: 7.1887, lr: 0.001
Epoch [22/80], Training Loss: 22.7482, Validation Loss Current: 6.7944, Validation Loss AVG: 6.7944, lr: 0.001
Epoch [23/80], Training Loss: 22.8515, Validation Loss Current: 7.2435, Validation Loss AVG: 7.2435, lr: 0.001
Epoch [24/80], Training Loss: 22.6090, Validation Loss Current: 8.4662, Validation Loss AVG: 8.4662, lr: 0.001
Epoch [25/80], Training Loss: 21.5420, Validation Loss Current: 6.7632, Validation Loss AVG: 6.7632, lr: 0.001
Epoch [26/80], Training Loss: 21.6044, Validation Loss Current: 6.8971, Validation Loss AVG: 6.8971, lr: 0.001
Epoch [27/80], Training Loss: 22.0601, Validation Loss Current: 7.7332, Validation Loss AVG: 7.7332, lr: 0.001
Epoch [28/80], Training Loss: 20.0942, Validation Loss Current: 6.7405, Validation Loss AVG: 6.7405, lr: 0.001
Epoch [29/80], Training Loss: 19.2961, Validation Loss Current: 6.4973, Validation Loss AVG: 6.4973, lr: 0.001
Epoch [30/80], Training Loss: 18.6372, Validation Loss Current: 6.6600, Validation Loss AVG: 6.6600, lr: 0.001
Epoch [31/80], Training Loss: 16.8707, Validation Loss Current: 6.5302, Validation Loss AVG: 6.5302, lr: 0.001
Epoch [32/80], Training Loss: 15.6573, Validation Loss Current: 6.3537, Validation Loss AVG: 6.3537, lr: 0.001
Epoch [33/80], Training Loss: 15.0147, Validation Loss Current: 6.5257, Validation Loss AVG: 6.5257, lr: 0.001
Epoch [34/80], Training Loss: 15.2703, Validation Loss Current: 6.6014, Validation Loss AVG: 6.6014, lr: 0.001
Epoch [35/80], Training Loss: 13.6018, Validation Loss Current: 6.7525, Validation Loss AVG: 6.7525, lr: 0.001
Epoch [36/80], Training Loss: 15.6877, Validation Loss Current: 6.7413, Validation Loss AVG: 6.7413, lr: 0.001
Epoch [37/80], Training Loss: 13.0971, Validation Loss Current: 6.7230, Validation Loss AVG: 6.7230, lr: 0.001
Epoch [38/80], Training Loss: 12.5798, Validation Loss Current: 7.5912, Validation Loss AVG: 7.5912, lr: 0.001
Epoch [39/80], Training Loss: 14.6914, Validation Loss Current: 9.5485, Validation Loss AVG: 9.5485, lr: 0.001
Epoch [40/80], Training Loss: 14.1466, Validation Loss Current: 7.2568, Validation Loss AVG: 7.2568, lr: 0.001
Epoch [41/80], Training Loss: 12.7975, Validation Loss Current: 6.5500, Validation Loss AVG: 6.5500, lr: 0.001
Epoch [42/80], Training Loss: 11.3381, Validation Loss Current: 6.5003, Validation Loss AVG: 6.5003, lr: 0.001
Epoch [43/80], Training Loss: 10.7772, Validation Loss Current: 7.1220, Validation Loss AVG: 7.1220, lr: 0.001
Epoch [44/80], Training Loss: 10.9592, Validation Loss Current: 6.9967, Validation Loss AVG: 6.9967, lr: 0.001
Epoch [45/80], Training Loss: 14.1751, Validation Loss Current: 7.2239, Validation Loss AVG: 7.2239, lr: 0.001
Epoch [46/80], Training Loss: 9.0484, Validation Loss Current: 6.7804, Validation Loss AVG: 6.7804, lr: 0.001
Epoch [47/80], Training Loss: 7.8727, Validation Loss Current: 7.6671, Validation Loss AVG: 7.6671, lr: 0.001
Epoch [48/80], Training Loss: 9.6946, Validation Loss Current: 7.8028, Validation Loss AVG: 7.8028, lr: 0.001
Epoch [49/80], Training Loss: 9.9916, Validation Loss Current: 8.7245, Validation Loss AVG: 8.7245, lr: 0.001
Epoch [50/80], Training Loss: 10.8028, Validation Loss Current: 7.3467, Validation Loss AVG: 7.3467, lr: 0.001
Epoch [51/80], Training Loss: 6.9136, Validation Loss Current: 6.9095, Validation Loss AVG: 6.9095, lr: 0.001
Epoch [52/80], Training Loss: 5.7769, Validation Loss Current: 7.4157, Validation Loss AVG: 7.4157, lr: 0.001
Epoch [53/80], Training Loss: 9.9138, Validation Loss Current: 19.1741, Validation Loss AVG: 19.1741, lr: 0.001
Epoch [54/80], Training Loss: 26.1456, Validation Loss Current: 9.5836, Validation Loss AVG: 9.5836, lr: 0.001
Epoch [55/80], Training Loss: 14.9523, Validation Loss Current: 8.8147, Validation Loss AVG: 8.8147, lr: 0.001
Epoch [56/80], Training Loss: 13.0843, Validation Loss Current: 9.0249, Validation Loss AVG: 9.0249, lr: 0.001
Epoch [57/80], Training Loss: 9.8539, Validation Loss Current: 6.9715, Validation Loss AVG: 6.9715, lr: 0.001
Epoch [58/80], Training Loss: 7.6821, Validation Loss Current: 6.7973, Validation Loss AVG: 6.7973, lr: 0.001
Epoch [59/80], Training Loss: 8.2173, Validation Loss Current: 7.1403, Validation Loss AVG: 7.1403, lr: 0.001
Epoch [60/80], Training Loss: 6.3984, Validation Loss Current: 7.9986, Validation Loss AVG: 7.9986, lr: 0.001
Epoch [61/80], Training Loss: 5.3271, Validation Loss Current: 7.7944, Validation Loss AVG: 7.7944, lr: 0.001
Epoch [62/80], Training Loss: 6.3762, Validation Loss Current: 8.6722, Validation Loss AVG: 8.6722, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random0 finished training. Best epoch: 32 Best val accuracy: [0.2351973684210526, 0.21480263157894736, 0.23355263157894735, 0.31282894736842104, 0.3207236842105263, 0.3394736842105263, 0.34901315789473686, 0.37664473684210525, 0.3796052631578947, 0.34901315789473686, 0.40625, 0.4276315789473684, 0.4493421052631579, 0.43618421052631584, 0.4407894736842105, 0.44572368421052627, 0.48355263157894746, 0.45131578947368417, 0.4707236842105263, 0.48881578947368426, 0.4796052631578947, 0.5217105263157895, 0.4983552631578948, 0.40361842105263157, 0.5250000000000001, 0.5088815789473684, 0.4565789473684211, 0.5253289473684211, 0.5421052631578946, 0.5289473684210526, 0.5417763157894736, 0.5549342105263159, 0.5516447368421054, 0.5526315789473684, 0.537828947368421, 0.5476973684210527, 0.5539473684210525, 0.48125, 0.4447368421052632, 0.524671052631579, 0.5677631578947369, 0.5713815789473684, 0.5444078947368421, 0.5424342105263158, 0.5203947368421054, 0.5381578947368422, 0.5351973684210527, 0.5414473684210527, 0.4983552631578948, 0.5338815789473685, 0.5710526315789475, 0.5328947368421052, 0.3703947368421053, 0.3967105263157895, 0.4542763157894737, 0.4407894736842105, 0.5677631578947369, 0.5776315789473684, 0.5598684210526315, 0.5328947368421053, 0.5526315789473685, 0.5164473684210527] Best val loss: 6.353658449649811


Current group: llo_0.4_random1
Epoch [1/80], Training Loss: 31.5971, Validation Loss Current: 7.8548, Validation Loss AVG: 7.8548, lr: 0.001
Epoch [2/80], Training Loss: 25.4969, Validation Loss Current: 7.9798, Validation Loss AVG: 7.9798, lr: 0.001
Epoch [3/80], Training Loss: 23.6739, Validation Loss Current: 9.8555, Validation Loss AVG: 9.8555, lr: 0.001
Epoch [4/80], Training Loss: 21.6468, Validation Loss Current: 8.1869, Validation Loss AVG: 8.1869, lr: 0.001
Epoch [5/80], Training Loss: 17.9762, Validation Loss Current: 6.6662, Validation Loss AVG: 6.6662, lr: 0.001
Epoch [6/80], Training Loss: 15.5336, Validation Loss Current: 6.3684, Validation Loss AVG: 6.3684, lr: 0.001
Epoch [7/80], Training Loss: 15.6096, Validation Loss Current: 7.2719, Validation Loss AVG: 7.2719, lr: 0.001
Epoch [8/80], Training Loss: 12.3583, Validation Loss Current: 6.8260, Validation Loss AVG: 6.8260, lr: 0.001
Epoch [9/80], Training Loss: 11.1804, Validation Loss Current: 5.8302, Validation Loss AVG: 5.8302, lr: 0.001
Epoch [10/80], Training Loss: 11.3383, Validation Loss Current: 6.6068, Validation Loss AVG: 6.6068, lr: 0.001
Epoch [11/80], Training Loss: 10.1843, Validation Loss Current: 6.7750, Validation Loss AVG: 6.7750, lr: 0.001
Epoch [12/80], Training Loss: 14.5709, Validation Loss Current: 8.2298, Validation Loss AVG: 8.2298, lr: 0.001
Epoch [13/80], Training Loss: 9.7085, Validation Loss Current: 6.5080, Validation Loss AVG: 6.5080, lr: 0.001
Epoch [14/80], Training Loss: 9.7612, Validation Loss Current: 7.0968, Validation Loss AVG: 7.0968, lr: 0.001
Epoch [15/80], Training Loss: 9.2120, Validation Loss Current: 7.3282, Validation Loss AVG: 7.3282, lr: 0.001
Epoch [16/80], Training Loss: 6.8721, Validation Loss Current: 7.2741, Validation Loss AVG: 7.2741, lr: 0.001
Epoch [17/80], Training Loss: 7.7915, Validation Loss Current: 8.5336, Validation Loss AVG: 8.5336, lr: 0.001
Epoch [18/80], Training Loss: 7.3671, Validation Loss Current: 7.4453, Validation Loss AVG: 7.4453, lr: 0.001
Epoch [19/80], Training Loss: 5.4570, Validation Loss Current: 7.3963, Validation Loss AVG: 7.3963, lr: 0.001
Epoch [20/80], Training Loss: 9.9711, Validation Loss Current: 7.3966, Validation Loss AVG: 7.3966, lr: 0.001
Epoch [21/80], Training Loss: 8.1865, Validation Loss Current: 7.4694, Validation Loss AVG: 7.4694, lr: 0.001
Epoch [22/80], Training Loss: 7.1353, Validation Loss Current: 7.9828, Validation Loss AVG: 7.9828, lr: 0.001
Epoch [23/80], Training Loss: 4.8140, Validation Loss Current: 6.9204, Validation Loss AVG: 6.9204, lr: 0.001
Epoch [24/80], Training Loss: 5.4127, Validation Loss Current: 6.7965, Validation Loss AVG: 6.7965, lr: 0.001
Epoch [25/80], Training Loss: 5.7926, Validation Loss Current: 9.2980, Validation Loss AVG: 9.2980, lr: 0.001
Epoch [26/80], Training Loss: 6.5255, Validation Loss Current: 7.4580, Validation Loss AVG: 7.4580, lr: 0.001
Epoch [27/80], Training Loss: 9.1573, Validation Loss Current: 9.6945, Validation Loss AVG: 9.6945, lr: 0.001
Epoch [28/80], Training Loss: 7.6461, Validation Loss Current: 7.7031, Validation Loss AVG: 7.7031, lr: 0.001
Epoch [29/80], Training Loss: 6.0790, Validation Loss Current: 8.4098, Validation Loss AVG: 8.4098, lr: 0.001
Epoch [30/80], Training Loss: 6.8545, Validation Loss Current: 8.4400, Validation Loss AVG: 8.4400, lr: 0.001
Epoch [31/80], Training Loss: 5.3950, Validation Loss Current: 8.4958, Validation Loss AVG: 8.4958, lr: 0.001
Epoch [32/80], Training Loss: 3.5712, Validation Loss Current: 7.2683, Validation Loss AVG: 7.2683, lr: 0.001
Epoch [33/80], Training Loss: 3.2588, Validation Loss Current: 8.0533, Validation Loss AVG: 8.0533, lr: 0.001
Epoch [34/80], Training Loss: 7.0108, Validation Loss Current: 8.0058, Validation Loss AVG: 8.0058, lr: 0.001
Epoch [35/80], Training Loss: 4.5791, Validation Loss Current: 7.6397, Validation Loss AVG: 7.6397, lr: 0.001
Epoch [36/80], Training Loss: 6.0629, Validation Loss Current: 8.0203, Validation Loss AVG: 8.0203, lr: 0.001
Epoch [37/80], Training Loss: 2.7943, Validation Loss Current: 8.3117, Validation Loss AVG: 8.3117, lr: 0.001
Epoch [38/80], Training Loss: 1.5965, Validation Loss Current: 7.7754, Validation Loss AVG: 7.7754, lr: 0.001
Epoch [39/80], Training Loss: 5.1152, Validation Loss Current: 8.9574, Validation Loss AVG: 8.9574, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random1 finished training. Best epoch: 9 Best val accuracy: [0.49934210526315786, 0.5134868421052632, 0.4006578947368421, 0.49572368421052637, 0.5421052631578946, 0.58125, 0.5391447368421052, 0.5388157894736842, 0.605921052631579, 0.575, 0.5651315789473684, 0.5174342105263158, 0.6016447368421052, 0.5539473684210525, 0.5585526315789473, 0.5713815789473685, 0.5434210526315789, 0.5661184210526315, 0.5799342105263158, 0.5680921052631579, 0.5496710526315789, 0.5532894736842106, 0.5914473684210526, 0.6059210526315789, 0.5243421052631578, 0.5828947368421052, 0.5184210526315789, 0.5779605263157894, 0.5467105263157894, 0.5463815789473684, 0.5361842105263157, 0.5805921052631579, 0.5773026315789475, 0.5898026315789473, 0.5851973684210526, 0.5792763157894737, 0.5575657894736843, 0.5878289473684211, 0.5555921052631578] Best val loss: 5.83015205860138


Current group: llo_0.4_random2
Epoch [1/80], Training Loss: 37.0687, Validation Loss Current: 7.2941, Validation Loss AVG: 7.2941, lr: 0.001
Epoch [2/80], Training Loss: 24.6650, Validation Loss Current: 7.2869, Validation Loss AVG: 7.2869, lr: 0.001
Epoch [3/80], Training Loss: 17.2755, Validation Loss Current: 5.7604, Validation Loss AVG: 5.7604, lr: 0.001
Epoch [4/80], Training Loss: 13.0445, Validation Loss Current: 6.6808, Validation Loss AVG: 6.6808, lr: 0.001
Epoch [5/80], Training Loss: 11.6607, Validation Loss Current: 5.8714, Validation Loss AVG: 5.8714, lr: 0.001
Epoch [6/80], Training Loss: 9.5749, Validation Loss Current: 6.2329, Validation Loss AVG: 6.2329, lr: 0.001
Epoch [7/80], Training Loss: 15.3255, Validation Loss Current: 6.7079, Validation Loss AVG: 6.7079, lr: 0.001
Epoch [8/80], Training Loss: 12.2567, Validation Loss Current: 5.8483, Validation Loss AVG: 5.8483, lr: 0.001
Epoch [9/80], Training Loss: 10.7555, Validation Loss Current: 6.5981, Validation Loss AVG: 6.5981, lr: 0.001
Epoch [10/80], Training Loss: 7.4411, Validation Loss Current: 6.1665, Validation Loss AVG: 6.1665, lr: 0.001
Epoch [11/80], Training Loss: 4.8940, Validation Loss Current: 5.3496, Validation Loss AVG: 5.3496, lr: 0.001
Epoch [12/80], Training Loss: 6.3686, Validation Loss Current: 7.0118, Validation Loss AVG: 7.0118, lr: 0.001
Epoch [13/80], Training Loss: 5.4526, Validation Loss Current: 5.3206, Validation Loss AVG: 5.3206, lr: 0.001
Epoch [14/80], Training Loss: 6.9541, Validation Loss Current: 6.8258, Validation Loss AVG: 6.8258, lr: 0.001
Epoch [15/80], Training Loss: 5.4504, Validation Loss Current: 6.0888, Validation Loss AVG: 6.0888, lr: 0.001
Epoch [16/80], Training Loss: 3.4807, Validation Loss Current: 5.6089, Validation Loss AVG: 5.6089, lr: 0.001
Epoch [17/80], Training Loss: 4.3826, Validation Loss Current: 8.0724, Validation Loss AVG: 8.0724, lr: 0.001
Epoch [18/80], Training Loss: 10.4625, Validation Loss Current: 7.3369, Validation Loss AVG: 7.3369, lr: 0.001
Epoch [19/80], Training Loss: 4.6077, Validation Loss Current: 6.1625, Validation Loss AVG: 6.1625, lr: 0.001
Epoch [20/80], Training Loss: 2.7641, Validation Loss Current: 6.6781, Validation Loss AVG: 6.6781, lr: 0.001
Epoch [21/80], Training Loss: 4.0757, Validation Loss Current: 6.9195, Validation Loss AVG: 6.9195, lr: 0.001
Epoch [22/80], Training Loss: 3.5422, Validation Loss Current: 6.6002, Validation Loss AVG: 6.6002, lr: 0.001
Epoch [23/80], Training Loss: 3.3696, Validation Loss Current: 7.2001, Validation Loss AVG: 7.2001, lr: 0.001
Epoch [24/80], Training Loss: 7.9158, Validation Loss Current: 7.7073, Validation Loss AVG: 7.7073, lr: 0.001
Epoch [25/80], Training Loss: 4.6528, Validation Loss Current: 7.1506, Validation Loss AVG: 7.1506, lr: 0.001
Epoch [26/80], Training Loss: 4.9686, Validation Loss Current: 7.6870, Validation Loss AVG: 7.6870, lr: 0.001
Epoch [27/80], Training Loss: 6.6459, Validation Loss Current: 7.1637, Validation Loss AVG: 7.1637, lr: 0.001
Epoch [28/80], Training Loss: 6.4538, Validation Loss Current: 9.9726, Validation Loss AVG: 9.9726, lr: 0.001
Epoch [29/80], Training Loss: 5.6467, Validation Loss Current: 9.6198, Validation Loss AVG: 9.6198, lr: 0.001
Epoch [30/80], Training Loss: 4.4185, Validation Loss Current: 7.4441, Validation Loss AVG: 7.4441, lr: 0.001
Epoch [31/80], Training Loss: 7.7749, Validation Loss Current: 7.0870, Validation Loss AVG: 7.0870, lr: 0.001
Epoch [32/80], Training Loss: 4.8198, Validation Loss Current: 6.9081, Validation Loss AVG: 6.9081, lr: 0.001
Epoch [33/80], Training Loss: 4.8702, Validation Loss Current: 6.9910, Validation Loss AVG: 6.9910, lr: 0.001
Epoch [34/80], Training Loss: 3.9950, Validation Loss Current: 7.4509, Validation Loss AVG: 7.4509, lr: 0.001
Epoch [35/80], Training Loss: 7.1156, Validation Loss Current: 8.9951, Validation Loss AVG: 8.9951, lr: 0.001
Epoch [36/80], Training Loss: 7.8360, Validation Loss Current: 7.5486, Validation Loss AVG: 7.5486, lr: 0.001
Epoch [37/80], Training Loss: 4.6948, Validation Loss Current: 7.9934, Validation Loss AVG: 7.9934, lr: 0.001
Epoch [38/80], Training Loss: 4.0674, Validation Loss Current: 6.9580, Validation Loss AVG: 6.9580, lr: 0.001
Epoch [39/80], Training Loss: 2.8537, Validation Loss Current: 6.7922, Validation Loss AVG: 6.7922, lr: 0.001
Epoch [40/80], Training Loss: 4.0780, Validation Loss Current: 8.2158, Validation Loss AVG: 8.2158, lr: 0.001
Epoch [41/80], Training Loss: 2.7888, Validation Loss Current: 7.4210, Validation Loss AVG: 7.4210, lr: 0.001
Epoch [42/80], Training Loss: 2.0836, Validation Loss Current: 7.2145, Validation Loss AVG: 7.2145, lr: 0.001
Epoch [43/80], Training Loss: 1.9737, Validation Loss Current: 6.7015, Validation Loss AVG: 6.7015, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random2 finished training. Best epoch: 13 Best val accuracy: [0.5641447368421052, 0.5664473684210526, 0.6213815789473685, 0.6072368421052632, 0.6180921052631578, 0.6217105263157896, 0.5868421052631579, 0.619407894736842, 0.6049342105263158, 0.6269736842105263, 0.6598684210526315, 0.5875, 0.6802631578947368, 0.6210526315789474, 0.6417763157894737, 0.6661184210526316, 0.5644736842105263, 0.5861842105263158, 0.6411184210526316, 0.65625, 0.6230263157894737, 0.6332236842105263, 0.6088815789473683, 0.6026315789473684, 0.6309210526315789, 0.605592105263158, 0.6039473684210527, 0.5618421052631579, 0.5286184210526316, 0.6019736842105263, 0.6299342105263158, 0.6269736842105262, 0.6289473684210527, 0.6092105263157894, 0.59375, 0.6046052631578948, 0.6210526315789474, 0.625328947368421, 0.6398026315789475, 0.6, 0.6190789473684211, 0.624671052631579, 0.6526315789473685] Best val loss: 5.320629286766052


Current group: llo_0.4_random3
Epoch [1/80], Training Loss: 40.1601, Validation Loss Current: 7.5301, Validation Loss AVG: 7.5301, lr: 0.001
Epoch [2/80], Training Loss: 21.8718, Validation Loss Current: 7.1103, Validation Loss AVG: 7.1103, lr: 0.001
Epoch [3/80], Training Loss: 15.7899, Validation Loss Current: 5.5281, Validation Loss AVG: 5.5281, lr: 0.001
Epoch [4/80], Training Loss: 13.1111, Validation Loss Current: 5.2226, Validation Loss AVG: 5.2226, lr: 0.001
Epoch [5/80], Training Loss: 10.5975, Validation Loss Current: 4.9966, Validation Loss AVG: 4.9966, lr: 0.001
Epoch [6/80], Training Loss: 6.5093, Validation Loss Current: 4.7010, Validation Loss AVG: 4.7010, lr: 0.001
Epoch [7/80], Training Loss: 5.3221, Validation Loss Current: 4.5692, Validation Loss AVG: 4.5692, lr: 0.001
Epoch [8/80], Training Loss: 5.5582, Validation Loss Current: 5.1253, Validation Loss AVG: 5.1253, lr: 0.001
Epoch [9/80], Training Loss: 8.1870, Validation Loss Current: 5.4614, Validation Loss AVG: 5.4614, lr: 0.001
Epoch [10/80], Training Loss: 6.5261, Validation Loss Current: 7.3162, Validation Loss AVG: 7.3162, lr: 0.001
Epoch [11/80], Training Loss: 7.8600, Validation Loss Current: 6.4385, Validation Loss AVG: 6.4385, lr: 0.001
Epoch [12/80], Training Loss: 6.9810, Validation Loss Current: 6.1541, Validation Loss AVG: 6.1541, lr: 0.001
Epoch [13/80], Training Loss: 6.5016, Validation Loss Current: 5.3912, Validation Loss AVG: 5.3912, lr: 0.001
Epoch [14/80], Training Loss: 6.3500, Validation Loss Current: 6.0809, Validation Loss AVG: 6.0809, lr: 0.001
Epoch [15/80], Training Loss: 5.3511, Validation Loss Current: 6.8647, Validation Loss AVG: 6.8647, lr: 0.001
Epoch [16/80], Training Loss: 6.4716, Validation Loss Current: 5.9248, Validation Loss AVG: 5.9248, lr: 0.001
Epoch [17/80], Training Loss: 7.7137, Validation Loss Current: 8.3829, Validation Loss AVG: 8.3829, lr: 0.001
Epoch [18/80], Training Loss: 7.7733, Validation Loss Current: 6.1341, Validation Loss AVG: 6.1341, lr: 0.001
Epoch [19/80], Training Loss: 6.2145, Validation Loss Current: 5.9753, Validation Loss AVG: 5.9753, lr: 0.001
Epoch [20/80], Training Loss: 3.6878, Validation Loss Current: 6.0628, Validation Loss AVG: 6.0628, lr: 0.001
Epoch [21/80], Training Loss: 4.3538, Validation Loss Current: 6.4959, Validation Loss AVG: 6.4959, lr: 0.001
Epoch [22/80], Training Loss: 14.7504, Validation Loss Current: 8.9689, Validation Loss AVG: 8.9689, lr: 0.001
Epoch [23/80], Training Loss: 6.2700, Validation Loss Current: 6.7829, Validation Loss AVG: 6.7829, lr: 0.001
Epoch [24/80], Training Loss: 10.1866, Validation Loss Current: 8.0366, Validation Loss AVG: 8.0366, lr: 0.001
Epoch [25/80], Training Loss: 6.9381, Validation Loss Current: 6.5937, Validation Loss AVG: 6.5937, lr: 0.001
Epoch [26/80], Training Loss: 7.8611, Validation Loss Current: 7.1834, Validation Loss AVG: 7.1834, lr: 0.001
Epoch [27/80], Training Loss: 3.4689, Validation Loss Current: 6.4840, Validation Loss AVG: 6.4840, lr: 0.001
Epoch [28/80], Training Loss: 2.8826, Validation Loss Current: 5.6142, Validation Loss AVG: 5.6142, lr: 0.001
Epoch [29/80], Training Loss: 3.5653, Validation Loss Current: 8.1527, Validation Loss AVG: 8.1527, lr: 0.001
Epoch [30/80], Training Loss: 6.6119, Validation Loss Current: 8.9408, Validation Loss AVG: 8.9408, lr: 0.001
Epoch [31/80], Training Loss: 5.9187, Validation Loss Current: 6.7010, Validation Loss AVG: 6.7010, lr: 0.001
Epoch [32/80], Training Loss: 4.6095, Validation Loss Current: 6.9625, Validation Loss AVG: 6.9625, lr: 0.001
Epoch [33/80], Training Loss: 3.0930, Validation Loss Current: 6.6564, Validation Loss AVG: 6.6564, lr: 0.001
Epoch [34/80], Training Loss: 4.1852, Validation Loss Current: 7.1328, Validation Loss AVG: 7.1328, lr: 0.001
Epoch [35/80], Training Loss: 5.9244, Validation Loss Current: 7.1763, Validation Loss AVG: 7.1763, lr: 0.001
Epoch [36/80], Training Loss: 5.2868, Validation Loss Current: 7.8407, Validation Loss AVG: 7.8407, lr: 0.001
Epoch [37/80], Training Loss: 1.8395, Validation Loss Current: 6.3134, Validation Loss AVG: 6.3134, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.4_random3 finished training. Best epoch: 7 Best val accuracy: [0.5875, 0.605592105263158, 0.6608552631578948, 0.6874999999999999, 0.6930921052631579, 0.7141447368421053, 0.7213815789473684, 0.7032894736842106, 0.6848684210526316, 0.6203947368421052, 0.6486842105263159, 0.6434210526315789, 0.6799342105263159, 0.6615131578947369, 0.61875, 0.6763157894736842, 0.5937500000000001, 0.6539473684210526, 0.6582236842105262, 0.6611842105263157, 0.6463815789473684, 0.5509868421052632, 0.6421052631578947, 0.5819078947368421, 0.6444078947368421, 0.6101973684210527, 0.64375, 0.6901315789473684, 0.6069078947368421, 0.5552631578947368, 0.6404605263157894, 0.6325657894736842, 0.6578947368421053, 0.6585526315789474, 0.6453947368421054, 0.6200657894736843, 0.6733552631578947] Best val loss: 4.569151532649994


Current group: 0.4
Epoch [1/80], Training Loss: 39.4790, Validation Loss Current: 8.1649, Validation Loss AVG: 8.1649, lr: 0.001
Epoch [2/80], Training Loss: 22.5098, Validation Loss Current: 8.3818, Validation Loss AVG: 8.3818, lr: 0.001
Epoch [3/80], Training Loss: 16.1192, Validation Loss Current: 7.1990, Validation Loss AVG: 7.1990, lr: 0.001
Epoch [4/80], Training Loss: 11.4975, Validation Loss Current: 6.4300, Validation Loss AVG: 6.4300, lr: 0.001
Epoch [5/80], Training Loss: 8.6441, Validation Loss Current: 6.7767, Validation Loss AVG: 6.7767, lr: 0.001
Epoch [6/80], Training Loss: 5.5352, Validation Loss Current: 6.5022, Validation Loss AVG: 6.5022, lr: 0.001
Epoch [7/80], Training Loss: 4.4102, Validation Loss Current: 7.3580, Validation Loss AVG: 7.3580, lr: 0.001
Epoch [8/80], Training Loss: 5.0441, Validation Loss Current: 9.0677, Validation Loss AVG: 9.0677, lr: 0.001
Epoch [9/80], Training Loss: 6.0931, Validation Loss Current: 8.2239, Validation Loss AVG: 8.2239, lr: 0.001
Epoch [10/80], Training Loss: 4.7564, Validation Loss Current: 10.1867, Validation Loss AVG: 10.1867, lr: 0.001
Epoch [11/80], Training Loss: 8.6096, Validation Loss Current: 9.7709, Validation Loss AVG: 9.7709, lr: 0.001
Epoch [12/80], Training Loss: 9.0918, Validation Loss Current: 10.1913, Validation Loss AVG: 10.1913, lr: 0.001
Epoch [13/80], Training Loss: 11.4325, Validation Loss Current: 11.2909, Validation Loss AVG: 11.2909, lr: 0.001
Epoch [14/80], Training Loss: 7.4672, Validation Loss Current: 8.6394, Validation Loss AVG: 8.6394, lr: 0.001
Epoch [15/80], Training Loss: 6.6674, Validation Loss Current: 9.4456, Validation Loss AVG: 9.4456, lr: 0.001
Epoch [16/80], Training Loss: 5.9831, Validation Loss Current: 9.7732, Validation Loss AVG: 9.7732, lr: 0.001
Epoch [17/80], Training Loss: 4.7420, Validation Loss Current: 8.9556, Validation Loss AVG: 8.9556, lr: 0.001
Epoch [18/80], Training Loss: 2.4467, Validation Loss Current: 8.5680, Validation Loss AVG: 8.5680, lr: 0.001
Epoch [19/80], Training Loss: 3.1688, Validation Loss Current: 8.7789, Validation Loss AVG: 8.7789, lr: 0.001
Epoch [20/80], Training Loss: 3.2637, Validation Loss Current: 9.5125, Validation Loss AVG: 9.5125, lr: 0.001
Epoch [21/80], Training Loss: 3.6448, Validation Loss Current: 10.1199, Validation Loss AVG: 10.1199, lr: 0.001
Epoch [22/80], Training Loss: 3.3889, Validation Loss Current: 10.1093, Validation Loss AVG: 10.1093, lr: 0.001
Epoch [23/80], Training Loss: 2.5391, Validation Loss Current: 9.7433, Validation Loss AVG: 9.7433, lr: 0.001
Epoch [24/80], Training Loss: 4.0046, Validation Loss Current: 11.4287, Validation Loss AVG: 11.4287, lr: 0.001
Epoch [25/80], Training Loss: 5.7622, Validation Loss Current: 9.2161, Validation Loss AVG: 9.2161, lr: 0.001
Epoch [26/80], Training Loss: 4.3163, Validation Loss Current: 9.8157, Validation Loss AVG: 9.8157, lr: 0.001
Epoch [27/80], Training Loss: 5.3034, Validation Loss Current: 10.8534, Validation Loss AVG: 10.8534, lr: 0.001
Epoch [28/80], Training Loss: 4.4156, Validation Loss Current: 10.6113, Validation Loss AVG: 10.6113, lr: 0.001
Epoch [29/80], Training Loss: 6.8416, Validation Loss Current: 10.9960, Validation Loss AVG: 10.9960, lr: 0.001
Epoch [30/80], Training Loss: 5.9727, Validation Loss Current: 11.8462, Validation Loss AVG: 11.8462, lr: 0.001
Epoch [31/80], Training Loss: 3.0505, Validation Loss Current: 9.6964, Validation Loss AVG: 9.6964, lr: 0.001
Epoch [32/80], Training Loss: 3.9126, Validation Loss Current: 8.9090, Validation Loss AVG: 8.9090, lr: 0.001
Epoch [33/80], Training Loss: 7.9417, Validation Loss Current: 11.3135, Validation Loss AVG: 11.3135, lr: 0.001
Epoch [34/80], Training Loss: 5.3125, Validation Loss Current: 10.8863, Validation Loss AVG: 10.8863, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.4 finished training. Best epoch: 4 Best val accuracy: [0.5914473684210526, 0.5516447368421052, 0.5944078947368421, 0.6233552631578947, 0.6138157894736842, 0.6345394736842106, 0.6026315789473685, 0.5888157894736843, 0.5730263157894736, 0.5496710526315789, 0.5473684210526315, 0.4825657894736842, 0.49967105263157896, 0.5634868421052632, 0.5447368421052631, 0.5286184210526315, 0.5608552631578948, 0.5782894736842106, 0.575, 0.5684210526315789, 0.5444078947368421, 0.5302631578947369, 0.549671052631579, 0.5601973684210526, 0.5802631578947369, 0.5661184210526315, 0.5351973684210527, 0.518421052631579, 0.4875, 0.5309210526315791, 0.5710526315789474, 0.5855263157894737, 0.49868421052631573, 0.5401315789473685] Best val loss: 6.430004560947419


----- Training resnet18 with sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] -----
Current group: llo_0.6_random0
Epoch [1/80], Training Loss: 40.0335, Validation Loss Current: 9.9123, Validation Loss AVG: 9.9123, lr: 0.001
Epoch [2/80], Training Loss: 39.1748, Validation Loss Current: 9.8644, Validation Loss AVG: 9.8644, lr: 0.001
Epoch [3/80], Training Loss: 39.1899, Validation Loss Current: 9.8392, Validation Loss AVG: 9.8392, lr: 0.001
Epoch [4/80], Training Loss: 38.5010, Validation Loss Current: 9.6472, Validation Loss AVG: 9.6472, lr: 0.001
Epoch [5/80], Training Loss: 37.8063, Validation Loss Current: 9.4864, Validation Loss AVG: 9.4864, lr: 0.001
Epoch [6/80], Training Loss: 37.9991, Validation Loss Current: 9.3438, Validation Loss AVG: 9.3438, lr: 0.001
Epoch [7/80], Training Loss: 36.5533, Validation Loss Current: 9.0651, Validation Loss AVG: 9.0651, lr: 0.001
Epoch [8/80], Training Loss: 36.0226, Validation Loss Current: 8.9488, Validation Loss AVG: 8.9488, lr: 0.001
Epoch [9/80], Training Loss: 34.6342, Validation Loss Current: 8.7290, Validation Loss AVG: 8.7290, lr: 0.001
Epoch [10/80], Training Loss: 33.9865, Validation Loss Current: 8.6352, Validation Loss AVG: 8.6352, lr: 0.001
Epoch [11/80], Training Loss: 33.4501, Validation Loss Current: 8.3574, Validation Loss AVG: 8.3574, lr: 0.001
Epoch [12/80], Training Loss: 32.9409, Validation Loss Current: 8.3173, Validation Loss AVG: 8.3173, lr: 0.001
Epoch [13/80], Training Loss: 31.2485, Validation Loss Current: 8.0548, Validation Loss AVG: 8.0548, lr: 0.001
Epoch [14/80], Training Loss: 30.6935, Validation Loss Current: 7.8573, Validation Loss AVG: 7.8573, lr: 0.001
Epoch [15/80], Training Loss: 30.3964, Validation Loss Current: 8.2792, Validation Loss AVG: 8.2792, lr: 0.001
Epoch [16/80], Training Loss: 30.7439, Validation Loss Current: 8.2023, Validation Loss AVG: 8.2023, lr: 0.001
Epoch [17/80], Training Loss: 29.0845, Validation Loss Current: 7.6618, Validation Loss AVG: 7.6618, lr: 0.001
Epoch [18/80], Training Loss: 28.7777, Validation Loss Current: 7.8727, Validation Loss AVG: 7.8727, lr: 0.001
Epoch [19/80], Training Loss: 27.9543, Validation Loss Current: 7.5562, Validation Loss AVG: 7.5562, lr: 0.001
Epoch [20/80], Training Loss: 27.7225, Validation Loss Current: 7.5710, Validation Loss AVG: 7.5710, lr: 0.001
Epoch [21/80], Training Loss: 26.0983, Validation Loss Current: 7.4079, Validation Loss AVG: 7.4079, lr: 0.001
Epoch [22/80], Training Loss: 26.2376, Validation Loss Current: 7.6049, Validation Loss AVG: 7.6049, lr: 0.001
Epoch [23/80], Training Loss: 25.6019, Validation Loss Current: 7.2954, Validation Loss AVG: 7.2954, lr: 0.001
Epoch [24/80], Training Loss: 23.4345, Validation Loss Current: 7.8404, Validation Loss AVG: 7.8404, lr: 0.001
Epoch [25/80], Training Loss: 24.0103, Validation Loss Current: 7.3117, Validation Loss AVG: 7.3117, lr: 0.001
Epoch [26/80], Training Loss: 22.1418, Validation Loss Current: 6.9250, Validation Loss AVG: 6.9250, lr: 0.001
Epoch [27/80], Training Loss: 21.6362, Validation Loss Current: 6.7270, Validation Loss AVG: 6.7270, lr: 0.001
Epoch [28/80], Training Loss: 19.0183, Validation Loss Current: 6.9111, Validation Loss AVG: 6.9111, lr: 0.001
Epoch [29/80], Training Loss: 19.0445, Validation Loss Current: 7.1537, Validation Loss AVG: 7.1537, lr: 0.001
Epoch [30/80], Training Loss: 19.8248, Validation Loss Current: 7.4360, Validation Loss AVG: 7.4360, lr: 0.001
Epoch [31/80], Training Loss: 19.2622, Validation Loss Current: 7.4188, Validation Loss AVG: 7.4188, lr: 0.001
Epoch [32/80], Training Loss: 17.5404, Validation Loss Current: 6.6790, Validation Loss AVG: 6.6790, lr: 0.001
Epoch [33/80], Training Loss: 16.8822, Validation Loss Current: 9.3410, Validation Loss AVG: 9.3410, lr: 0.001
Epoch [34/80], Training Loss: 20.8118, Validation Loss Current: 6.9190, Validation Loss AVG: 6.9190, lr: 0.001
Epoch [35/80], Training Loss: 16.9825, Validation Loss Current: 6.7963, Validation Loss AVG: 6.7963, lr: 0.001
Epoch [36/80], Training Loss: 15.1283, Validation Loss Current: 7.0389, Validation Loss AVG: 7.0389, lr: 0.001
Epoch [37/80], Training Loss: 14.3326, Validation Loss Current: 6.9074, Validation Loss AVG: 6.9074, lr: 0.001
Epoch [38/80], Training Loss: 14.5903, Validation Loss Current: 10.9031, Validation Loss AVG: 10.9031, lr: 0.001
Epoch [39/80], Training Loss: 17.8867, Validation Loss Current: 7.3793, Validation Loss AVG: 7.3793, lr: 0.001
Epoch [40/80], Training Loss: 15.1309, Validation Loss Current: 7.6654, Validation Loss AVG: 7.6654, lr: 0.001
Epoch [41/80], Training Loss: 20.7424, Validation Loss Current: 9.8399, Validation Loss AVG: 9.8399, lr: 0.001
Epoch [42/80], Training Loss: 16.8858, Validation Loss Current: 7.2864, Validation Loss AVG: 7.2864, lr: 0.001
Epoch [43/80], Training Loss: 14.0123, Validation Loss Current: 6.8037, Validation Loss AVG: 6.8037, lr: 0.001
Epoch [44/80], Training Loss: 12.9923, Validation Loss Current: 7.5766, Validation Loss AVG: 7.5766, lr: 0.001
Epoch [45/80], Training Loss: 11.9523, Validation Loss Current: 7.2422, Validation Loss AVG: 7.2422, lr: 0.001
Epoch [46/80], Training Loss: 10.3377, Validation Loss Current: 7.2030, Validation Loss AVG: 7.2030, lr: 0.001
Epoch [47/80], Training Loss: 13.8210, Validation Loss Current: 7.2823, Validation Loss AVG: 7.2823, lr: 0.001
Epoch [48/80], Training Loss: 11.8984, Validation Loss Current: 7.0796, Validation Loss AVG: 7.0796, lr: 0.001
Epoch [49/80], Training Loss: 8.9204, Validation Loss Current: 6.3155, Validation Loss AVG: 6.3155, lr: 0.001
Epoch [50/80], Training Loss: 8.0879, Validation Loss Current: 6.9359, Validation Loss AVG: 6.9359, lr: 0.001
Epoch [51/80], Training Loss: 7.5983, Validation Loss Current: 7.5023, Validation Loss AVG: 7.5023, lr: 0.001
Epoch [52/80], Training Loss: 8.3523, Validation Loss Current: 7.7627, Validation Loss AVG: 7.7627, lr: 0.001
Epoch [53/80], Training Loss: 10.4412, Validation Loss Current: 9.2845, Validation Loss AVG: 9.2845, lr: 0.001
Epoch [54/80], Training Loss: 14.0425, Validation Loss Current: 10.4860, Validation Loss AVG: 10.4860, lr: 0.001
Epoch [55/80], Training Loss: 9.6782, Validation Loss Current: 7.3614, Validation Loss AVG: 7.3614, lr: 0.001
Epoch [56/80], Training Loss: 9.9999, Validation Loss Current: 8.0269, Validation Loss AVG: 8.0269, lr: 0.001
Epoch [57/80], Training Loss: 10.9489, Validation Loss Current: 8.0719, Validation Loss AVG: 8.0719, lr: 0.001
Epoch [58/80], Training Loss: 11.3480, Validation Loss Current: 7.8162, Validation Loss AVG: 7.8162, lr: 0.001
Epoch [59/80], Training Loss: 10.0748, Validation Loss Current: 7.0550, Validation Loss AVG: 7.0550, lr: 0.001
Epoch [60/80], Training Loss: 6.3315, Validation Loss Current: 7.7577, Validation Loss AVG: 7.7577, lr: 0.001
Epoch [61/80], Training Loss: 5.3189, Validation Loss Current: 7.5535, Validation Loss AVG: 7.5535, lr: 0.001
Epoch [62/80], Training Loss: 7.3313, Validation Loss Current: 9.6738, Validation Loss AVG: 9.6738, lr: 0.001
Epoch [63/80], Training Loss: 10.2615, Validation Loss Current: 8.9917, Validation Loss AVG: 8.9917, lr: 0.001
Epoch [64/80], Training Loss: 6.0716, Validation Loss Current: 8.7303, Validation Loss AVG: 8.7303, lr: 0.001
Epoch [65/80], Training Loss: 7.6004, Validation Loss Current: 7.5038, Validation Loss AVG: 7.5038, lr: 0.001
Epoch [66/80], Training Loss: 6.9652, Validation Loss Current: 8.8437, Validation Loss AVG: 8.8437, lr: 0.001
Epoch [67/80], Training Loss: 7.4253, Validation Loss Current: 10.0359, Validation Loss AVG: 10.0359, lr: 0.001
Epoch [68/80], Training Loss: 11.7497, Validation Loss Current: 10.6401, Validation Loss AVG: 10.6401, lr: 0.001
Epoch [69/80], Training Loss: 6.8227, Validation Loss Current: 7.8828, Validation Loss AVG: 7.8828, lr: 0.001
Epoch [70/80], Training Loss: 7.8859, Validation Loss Current: 7.3986, Validation Loss AVG: 7.3986, lr: 0.001
Epoch [71/80], Training Loss: 6.5144, Validation Loss Current: 7.6702, Validation Loss AVG: 7.6702, lr: 0.001
Epoch [72/80], Training Loss: 3.0618, Validation Loss Current: 7.8670, Validation Loss AVG: 7.8670, lr: 0.001
Epoch [73/80], Training Loss: 2.3487, Validation Loss Current: 7.3387, Validation Loss AVG: 7.3387, lr: 0.001
Epoch [74/80], Training Loss: 4.3534, Validation Loss Current: 9.4108, Validation Loss AVG: 9.4108, lr: 0.001
Epoch [75/80], Training Loss: 4.3363, Validation Loss Current: 8.1312, Validation Loss AVG: 8.1312, lr: 0.001
Epoch [76/80], Training Loss: 5.3585, Validation Loss Current: 8.7725, Validation Loss AVG: 8.7725, lr: 0.001
Epoch [77/80], Training Loss: 3.2588, Validation Loss Current: 9.0898, Validation Loss AVG: 9.0898, lr: 0.001
Epoch [78/80], Training Loss: 3.8621, Validation Loss Current: 8.8584, Validation Loss AVG: 8.8584, lr: 0.001
Epoch [79/80], Training Loss: 12.3890, Validation Loss Current: 22.4415, Validation Loss AVG: 22.4415, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random0 finished training. Best epoch: 49 Best val accuracy: [0.2611842105263158, 0.26184210526315793, 0.25361842105263155, 0.28717105263157894, 0.3003289473684211, 0.31184210526315786, 0.33059210526315785, 0.36414473684210524, 0.38092105263157894, 0.3713815789473684, 0.3944078947368421, 0.4200657894736842, 0.42993421052631586, 0.44210526315789467, 0.4134868421052632, 0.4036184210526315, 0.44243421052631576, 0.4200657894736842, 0.4703947368421053, 0.44506578947368425, 0.46842105263157896, 0.47565789473684206, 0.46875, 0.46578947368421053, 0.4726973684210526, 0.5105263157894737, 0.5180921052631579, 0.5236842105263159, 0.49539473684210533, 0.47171052631578947, 0.4930921052631579, 0.5365131578947369, 0.39342105263157895, 0.5197368421052632, 0.5203947368421052, 0.5092105263157894, 0.5319078947368421, 0.3960526315789474, 0.5128289473684211, 0.5108552631578948, 0.3891447368421053, 0.4733552631578948, 0.5282894736842105, 0.5220394736842106, 0.5223684210526315, 0.5358552631578947, 0.5184210526315789, 0.5328947368421052, 0.5832236842105264, 0.5585526315789474, 0.5256578947368421, 0.531578947368421, 0.48322368421052636, 0.3888157894736842, 0.5542763157894737, 0.5019736842105262, 0.530921052631579, 0.5177631578947368, 0.5476973684210527, 0.5430921052631579, 0.5450657894736841, 0.4950657894736842, 0.5266447368421053, 0.5256578947368421, 0.5546052631578948, 0.5115131578947368, 0.49802631578947365, 0.4532894736842105, 0.5424342105263158, 0.5536184210526317, 0.569078947368421, 0.5529605263157895, 0.5776315789473685, 0.5305921052631579, 0.5513157894736842, 0.5546052631578947, 0.5289473684210527, 0.5470394736842106, 0.33651315789473685] Best val loss: 6.315519523620606


Current group: llo_0.6_random1
Epoch [1/80], Training Loss: 38.1726, Validation Loss Current: 8.6976, Validation Loss AVG: 8.6976, lr: 0.001
Epoch [2/80], Training Loss: 28.3900, Validation Loss Current: 8.6315, Validation Loss AVG: 8.6315, lr: 0.001
Epoch [3/80], Training Loss: 21.1554, Validation Loss Current: 7.3029, Validation Loss AVG: 7.3029, lr: 0.001
Epoch [4/80], Training Loss: 18.6541, Validation Loss Current: 6.8935, Validation Loss AVG: 6.8935, lr: 0.001
Epoch [5/80], Training Loss: 15.2219, Validation Loss Current: 6.6394, Validation Loss AVG: 6.6394, lr: 0.001
Epoch [6/80], Training Loss: 17.0155, Validation Loss Current: 7.8001, Validation Loss AVG: 7.8001, lr: 0.001
Epoch [7/80], Training Loss: 17.0951, Validation Loss Current: 7.2285, Validation Loss AVG: 7.2285, lr: 0.001
Epoch [8/80], Training Loss: 12.1971, Validation Loss Current: 6.6744, Validation Loss AVG: 6.6744, lr: 0.001
Epoch [9/80], Training Loss: 11.2407, Validation Loss Current: 6.1284, Validation Loss AVG: 6.1284, lr: 0.001
Epoch [10/80], Training Loss: 8.8612, Validation Loss Current: 6.8686, Validation Loss AVG: 6.8686, lr: 0.001
Epoch [11/80], Training Loss: 8.1163, Validation Loss Current: 6.4258, Validation Loss AVG: 6.4258, lr: 0.001
Epoch [12/80], Training Loss: 11.3155, Validation Loss Current: 7.7031, Validation Loss AVG: 7.7031, lr: 0.001
Epoch [13/80], Training Loss: 9.3155, Validation Loss Current: 9.0130, Validation Loss AVG: 9.0130, lr: 0.001
Epoch [14/80], Training Loss: 6.1416, Validation Loss Current: 6.8306, Validation Loss AVG: 6.8306, lr: 0.001
Epoch [15/80], Training Loss: 5.1036, Validation Loss Current: 7.3264, Validation Loss AVG: 7.3264, lr: 0.001
Epoch [16/80], Training Loss: 6.1542, Validation Loss Current: 9.5992, Validation Loss AVG: 9.5992, lr: 0.001
Epoch [17/80], Training Loss: 5.8763, Validation Loss Current: 7.2378, Validation Loss AVG: 7.2378, lr: 0.001
Epoch [18/80], Training Loss: 4.0501, Validation Loss Current: 7.4839, Validation Loss AVG: 7.4839, lr: 0.001
Epoch [19/80], Training Loss: 3.3297, Validation Loss Current: 6.4420, Validation Loss AVG: 6.4420, lr: 0.001
Epoch [20/80], Training Loss: 2.6134, Validation Loss Current: 7.3348, Validation Loss AVG: 7.3348, lr: 0.001
Epoch [21/80], Training Loss: 4.0239, Validation Loss Current: 10.1033, Validation Loss AVG: 10.1033, lr: 0.001
Epoch [22/80], Training Loss: 9.0266, Validation Loss Current: 12.0130, Validation Loss AVG: 12.0130, lr: 0.001
Epoch [23/80], Training Loss: 13.6266, Validation Loss Current: 10.4956, Validation Loss AVG: 10.4956, lr: 0.001
Epoch [24/80], Training Loss: 17.2459, Validation Loss Current: 10.1693, Validation Loss AVG: 10.1693, lr: 0.001
Epoch [25/80], Training Loss: 11.4310, Validation Loss Current: 9.2546, Validation Loss AVG: 9.2546, lr: 0.001
Epoch [26/80], Training Loss: 7.1833, Validation Loss Current: 8.0284, Validation Loss AVG: 8.0284, lr: 0.001
Epoch [27/80], Training Loss: 3.3755, Validation Loss Current: 7.4828, Validation Loss AVG: 7.4828, lr: 0.001
Epoch [28/80], Training Loss: 5.3317, Validation Loss Current: 7.0470, Validation Loss AVG: 7.0470, lr: 0.001
Epoch [29/80], Training Loss: 2.9300, Validation Loss Current: 7.5785, Validation Loss AVG: 7.5785, lr: 0.001
Epoch [30/80], Training Loss: 4.5257, Validation Loss Current: 7.2155, Validation Loss AVG: 7.2155, lr: 0.001
Epoch [31/80], Training Loss: 4.7499, Validation Loss Current: 7.3375, Validation Loss AVG: 7.3375, lr: 0.001
Epoch [32/80], Training Loss: 6.5214, Validation Loss Current: 7.9715, Validation Loss AVG: 7.9715, lr: 0.001
Epoch [33/80], Training Loss: 9.6926, Validation Loss Current: 10.4359, Validation Loss AVG: 10.4359, lr: 0.001
Epoch [34/80], Training Loss: 6.7692, Validation Loss Current: 8.7529, Validation Loss AVG: 8.7529, lr: 0.001
Epoch [35/80], Training Loss: 5.1046, Validation Loss Current: 10.6347, Validation Loss AVG: 10.6347, lr: 0.001
Epoch [36/80], Training Loss: 5.8306, Validation Loss Current: 11.4156, Validation Loss AVG: 11.4156, lr: 0.001
Epoch [37/80], Training Loss: 4.7907, Validation Loss Current: 8.3192, Validation Loss AVG: 8.3192, lr: 0.001
Epoch [38/80], Training Loss: 3.4140, Validation Loss Current: 8.9645, Validation Loss AVG: 8.9645, lr: 0.001
Epoch [39/80], Training Loss: 5.0252, Validation Loss Current: 8.6623, Validation Loss AVG: 8.6623, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random1 finished training. Best epoch: 9 Best val accuracy: [0.5342105263157895, 0.48684210526315785, 0.5460526315789473, 0.5664473684210527, 0.5736842105263158, 0.5263157894736843, 0.5480263157894737, 0.5858552631578948, 0.6006578947368422, 0.5766447368421053, 0.5884868421052631, 0.5713815789473685, 0.5032894736842105, 0.5865131578947368, 0.5759868421052632, 0.5220394736842106, 0.5904605263157894, 0.5838815789473685, 0.6266447368421053, 0.6072368421052631, 0.48519736842105254, 0.4615131578947368, 0.5345394736842105, 0.5101973684210526, 0.499342105263158, 0.5401315789473684, 0.5891447368421053, 0.5881578947368421, 0.5894736842105263, 0.5963815789473685, 0.6013157894736842, 0.5842105263157895, 0.4881578947368421, 0.5572368421052631, 0.5203947368421054, 0.5019736842105262, 0.5657894736842105, 0.555921052631579, 0.5740131578947368] Best val loss: 6.128408992290497


Current group: llo_0.6_random2
Epoch [1/80], Training Loss: 39.3254, Validation Loss Current: 7.8944, Validation Loss AVG: 7.8944, lr: 0.001
Epoch [2/80], Training Loss: 25.8472, Validation Loss Current: 6.2911, Validation Loss AVG: 6.2911, lr: 0.001
Epoch [3/80], Training Loss: 18.9544, Validation Loss Current: 6.2510, Validation Loss AVG: 6.2510, lr: 0.001
Epoch [4/80], Training Loss: 13.1254, Validation Loss Current: 5.4252, Validation Loss AVG: 5.4252, lr: 0.001
Epoch [5/80], Training Loss: 10.2083, Validation Loss Current: 5.6089, Validation Loss AVG: 5.6089, lr: 0.001
Epoch [6/80], Training Loss: 8.7320, Validation Loss Current: 5.8281, Validation Loss AVG: 5.8281, lr: 0.001
Epoch [7/80], Training Loss: 7.8303, Validation Loss Current: 6.7110, Validation Loss AVG: 6.7110, lr: 0.001
Epoch [8/80], Training Loss: 9.0423, Validation Loss Current: 10.4607, Validation Loss AVG: 10.4607, lr: 0.001
Epoch [9/80], Training Loss: 10.0405, Validation Loss Current: 12.2537, Validation Loss AVG: 12.2537, lr: 0.001
Epoch [10/80], Training Loss: 16.8954, Validation Loss Current: 8.7987, Validation Loss AVG: 8.7987, lr: 0.001
Epoch [11/80], Training Loss: 9.7562, Validation Loss Current: 6.2761, Validation Loss AVG: 6.2761, lr: 0.001
Epoch [12/80], Training Loss: 5.4207, Validation Loss Current: 6.4837, Validation Loss AVG: 6.4837, lr: 0.001
Epoch [13/80], Training Loss: 4.8460, Validation Loss Current: 5.8677, Validation Loss AVG: 5.8677, lr: 0.001
Epoch [14/80], Training Loss: 7.4679, Validation Loss Current: 6.1328, Validation Loss AVG: 6.1328, lr: 0.001
Epoch [15/80], Training Loss: 5.1079, Validation Loss Current: 6.5452, Validation Loss AVG: 6.5452, lr: 0.001
Epoch [16/80], Training Loss: 6.6013, Validation Loss Current: 6.7111, Validation Loss AVG: 6.7111, lr: 0.001
Epoch [17/80], Training Loss: 3.9904, Validation Loss Current: 6.3375, Validation Loss AVG: 6.3375, lr: 0.001
Epoch [18/80], Training Loss: 3.1912, Validation Loss Current: 6.2301, Validation Loss AVG: 6.2301, lr: 0.001
Epoch [19/80], Training Loss: 5.2283, Validation Loss Current: 6.8993, Validation Loss AVG: 6.8993, lr: 0.001
Epoch [20/80], Training Loss: 5.4684, Validation Loss Current: 7.4950, Validation Loss AVG: 7.4950, lr: 0.001
Epoch [21/80], Training Loss: 4.7077, Validation Loss Current: 7.0657, Validation Loss AVG: 7.0657, lr: 0.001
Epoch [22/80], Training Loss: 5.5948, Validation Loss Current: 6.9192, Validation Loss AVG: 6.9192, lr: 0.001
Epoch [23/80], Training Loss: 5.9342, Validation Loss Current: 9.1149, Validation Loss AVG: 9.1149, lr: 0.001
Epoch [24/80], Training Loss: 4.1211, Validation Loss Current: 6.8564, Validation Loss AVG: 6.8564, lr: 0.001
Epoch [25/80], Training Loss: 4.8921, Validation Loss Current: 7.6064, Validation Loss AVG: 7.6064, lr: 0.001
Epoch [26/80], Training Loss: 5.6197, Validation Loss Current: 6.8291, Validation Loss AVG: 6.8291, lr: 0.001
Epoch [27/80], Training Loss: 10.2640, Validation Loss Current: 8.2038, Validation Loss AVG: 8.2038, lr: 0.001
Epoch [28/80], Training Loss: 4.0927, Validation Loss Current: 7.2313, Validation Loss AVG: 7.2313, lr: 0.001
Epoch [29/80], Training Loss: 3.1581, Validation Loss Current: 6.7408, Validation Loss AVG: 6.7408, lr: 0.001
Epoch [30/80], Training Loss: 6.5639, Validation Loss Current: 7.4959, Validation Loss AVG: 7.4959, lr: 0.001
Epoch [31/80], Training Loss: 6.3243, Validation Loss Current: 8.8359, Validation Loss AVG: 8.8359, lr: 0.001
Epoch [32/80], Training Loss: 4.7565, Validation Loss Current: 7.6574, Validation Loss AVG: 7.6574, lr: 0.001
Epoch [33/80], Training Loss: 9.7397, Validation Loss Current: 7.7609, Validation Loss AVG: 7.7609, lr: 0.001
Epoch [34/80], Training Loss: 8.6428, Validation Loss Current: 8.0340, Validation Loss AVG: 8.0340, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random2 finished training. Best epoch: 4 Best val accuracy: [0.55625, 0.5891447368421053, 0.5917763157894737, 0.6562500000000001, 0.6519736842105264, 0.6335526315789474, 0.6082236842105262, 0.48519736842105265, 0.4529605263157895, 0.5519736842105264, 0.6052631578947368, 0.6148026315789474, 0.6595394736842105, 0.6463815789473684, 0.6355263157894737, 0.6286184210526317, 0.6542763157894738, 0.6480263157894737, 0.6148026315789473, 0.6197368421052631, 0.6180921052631578, 0.6338815789473685, 0.5529605263157895, 0.6417763157894737, 0.6171052631578948, 0.6493421052631578, 0.5970394736842105, 0.6286184210526317, 0.6358552631578946, 0.6223684210526316, 0.5756578947368421, 0.6131578947368421, 0.6098684210526317, 0.6] Best val loss: 5.425200772285462


Current group: llo_0.6_random3
Epoch [1/80], Training Loss: 39.5288, Validation Loss Current: 8.9161, Validation Loss AVG: 8.9161, lr: 0.001
Epoch [2/80], Training Loss: 22.7994, Validation Loss Current: 6.2741, Validation Loss AVG: 6.2741, lr: 0.001
Epoch [3/80], Training Loss: 23.5324, Validation Loss Current: 8.0998, Validation Loss AVG: 8.0998, lr: 0.001
Epoch [4/80], Training Loss: 16.6994, Validation Loss Current: 5.6666, Validation Loss AVG: 5.6666, lr: 0.001
Epoch [5/80], Training Loss: 11.1521, Validation Loss Current: 4.5857, Validation Loss AVG: 4.5857, lr: 0.001
Epoch [6/80], Training Loss: 8.7904, Validation Loss Current: 5.0260, Validation Loss AVG: 5.0260, lr: 0.001
Epoch [7/80], Training Loss: 9.1816, Validation Loss Current: 5.3486, Validation Loss AVG: 5.3486, lr: 0.001
Epoch [8/80], Training Loss: 9.7703, Validation Loss Current: 6.1525, Validation Loss AVG: 6.1525, lr: 0.001
Epoch [9/80], Training Loss: 9.3427, Validation Loss Current: 5.2186, Validation Loss AVG: 5.2186, lr: 0.001
Epoch [10/80], Training Loss: 6.9672, Validation Loss Current: 5.5941, Validation Loss AVG: 5.5941, lr: 0.001
Epoch [11/80], Training Loss: 5.8397, Validation Loss Current: 5.1226, Validation Loss AVG: 5.1226, lr: 0.001
Epoch [12/80], Training Loss: 6.4024, Validation Loss Current: 5.6966, Validation Loss AVG: 5.6966, lr: 0.001
Epoch [13/80], Training Loss: 8.6512, Validation Loss Current: 7.0955, Validation Loss AVG: 7.0955, lr: 0.001
Epoch [14/80], Training Loss: 6.5964, Validation Loss Current: 9.0973, Validation Loss AVG: 9.0973, lr: 0.001
Epoch [15/80], Training Loss: 10.2733, Validation Loss Current: 6.4877, Validation Loss AVG: 6.4877, lr: 0.001
Epoch [16/80], Training Loss: 6.8682, Validation Loss Current: 5.8272, Validation Loss AVG: 5.8272, lr: 0.001
Epoch [17/80], Training Loss: 6.6048, Validation Loss Current: 6.9986, Validation Loss AVG: 6.9986, lr: 0.001
Epoch [18/80], Training Loss: 9.4268, Validation Loss Current: 6.5685, Validation Loss AVG: 6.5685, lr: 0.001
Epoch [19/80], Training Loss: 5.8656, Validation Loss Current: 6.0693, Validation Loss AVG: 6.0693, lr: 0.001
Epoch [20/80], Training Loss: 4.1320, Validation Loss Current: 5.8042, Validation Loss AVG: 5.8042, lr: 0.001
Epoch [21/80], Training Loss: 1.8775, Validation Loss Current: 5.5260, Validation Loss AVG: 5.5260, lr: 0.001
Epoch [22/80], Training Loss: 3.1693, Validation Loss Current: 5.4590, Validation Loss AVG: 5.4590, lr: 0.001
Epoch [23/80], Training Loss: 4.6344, Validation Loss Current: 6.5005, Validation Loss AVG: 6.5005, lr: 0.001
Epoch [24/80], Training Loss: 5.3447, Validation Loss Current: 5.9177, Validation Loss AVG: 5.9177, lr: 0.001
Epoch [25/80], Training Loss: 8.5371, Validation Loss Current: 6.6184, Validation Loss AVG: 6.6184, lr: 0.001
Epoch [26/80], Training Loss: 6.7423, Validation Loss Current: 6.9278, Validation Loss AVG: 6.9278, lr: 0.001
Epoch [27/80], Training Loss: 5.3180, Validation Loss Current: 6.6004, Validation Loss AVG: 6.6004, lr: 0.001
Epoch [28/80], Training Loss: 2.5382, Validation Loss Current: 5.8221, Validation Loss AVG: 5.8221, lr: 0.001
Epoch [29/80], Training Loss: 4.8017, Validation Loss Current: 6.6267, Validation Loss AVG: 6.6267, lr: 0.001
Epoch [30/80], Training Loss: 6.3098, Validation Loss Current: 7.4129, Validation Loss AVG: 7.4129, lr: 0.001
Epoch [31/80], Training Loss: 3.9176, Validation Loss Current: 6.6389, Validation Loss AVG: 6.6389, lr: 0.001
Epoch [32/80], Training Loss: 6.8445, Validation Loss Current: 6.7670, Validation Loss AVG: 6.7670, lr: 0.001
Epoch [33/80], Training Loss: 4.7615, Validation Loss Current: 7.3102, Validation Loss AVG: 7.3102, lr: 0.001
Epoch [34/80], Training Loss: 10.1689, Validation Loss Current: 7.2491, Validation Loss AVG: 7.2491, lr: 0.001
Epoch [35/80], Training Loss: 8.1962, Validation Loss Current: 8.4075, Validation Loss AVG: 8.4075, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_0.6_random3 finished training. Best epoch: 5 Best val accuracy: [0.5230263157894737, 0.6118421052631579, 0.544407894736842, 0.6384868421052631, 0.6953947368421052, 0.675, 0.6671052631578946, 0.65, 0.6792763157894737, 0.6700657894736842, 0.6888157894736842, 0.6644736842105263, 0.624671052631579, 0.5924342105263158, 0.6286184210526315, 0.6555921052631579, 0.6217105263157894, 0.6358552631578946, 0.6598684210526315, 0.6782894736842104, 0.6845394736842105, 0.6907894736842105, 0.6473684210526316, 0.6674342105263158, 0.662828947368421, 0.6391447368421053, 0.6523026315789473, 0.6865131578947368, 0.6539473684210526, 0.6230263157894738, 0.6532894736842105, 0.6401315789473683, 0.6417763157894737, 0.6322368421052632, 0.5631578947368421] Best val loss: 4.585705280303955


Current group: 0.6
Epoch [1/80], Training Loss: 37.2657, Validation Loss Current: 7.1535, Validation Loss AVG: 7.1535, lr: 0.001
Epoch [2/80], Training Loss: 26.6089, Validation Loss Current: 8.6859, Validation Loss AVG: 8.6859, lr: 0.001
Epoch [3/80], Training Loss: 24.9163, Validation Loss Current: 7.7991, Validation Loss AVG: 7.7991, lr: 0.001
Epoch [4/80], Training Loss: 16.1491, Validation Loss Current: 7.1049, Validation Loss AVG: 7.1049, lr: 0.001
Epoch [5/80], Training Loss: 13.4630, Validation Loss Current: 7.2061, Validation Loss AVG: 7.2061, lr: 0.001
Epoch [6/80], Training Loss: 8.0254, Validation Loss Current: 6.4120, Validation Loss AVG: 6.4120, lr: 0.001
Epoch [7/80], Training Loss: 7.7700, Validation Loss Current: 7.4023, Validation Loss AVG: 7.4023, lr: 0.001
Epoch [8/80], Training Loss: 7.5008, Validation Loss Current: 7.2608, Validation Loss AVG: 7.2608, lr: 0.001
Epoch [9/80], Training Loss: 5.1361, Validation Loss Current: 6.5710, Validation Loss AVG: 6.5710, lr: 0.001
Epoch [10/80], Training Loss: 6.1947, Validation Loss Current: 6.1037, Validation Loss AVG: 6.1037, lr: 0.001
Epoch [11/80], Training Loss: 3.0713, Validation Loss Current: 6.2805, Validation Loss AVG: 6.2805, lr: 0.001
Epoch [12/80], Training Loss: 2.7880, Validation Loss Current: 7.5390, Validation Loss AVG: 7.5390, lr: 0.001
Epoch [13/80], Training Loss: 2.9225, Validation Loss Current: 6.8825, Validation Loss AVG: 6.8825, lr: 0.001
Epoch [14/80], Training Loss: 3.0113, Validation Loss Current: 7.5296, Validation Loss AVG: 7.5296, lr: 0.001
Epoch [15/80], Training Loss: 3.5951, Validation Loss Current: 7.2371, Validation Loss AVG: 7.2371, lr: 0.001
Epoch [16/80], Training Loss: 8.0418, Validation Loss Current: 8.0903, Validation Loss AVG: 8.0903, lr: 0.001
Epoch [17/80], Training Loss: 3.4699, Validation Loss Current: 7.2737, Validation Loss AVG: 7.2737, lr: 0.001
Epoch [18/80], Training Loss: 2.2351, Validation Loss Current: 8.7651, Validation Loss AVG: 8.7651, lr: 0.001
Epoch [19/80], Training Loss: 2.2509, Validation Loss Current: 7.4881, Validation Loss AVG: 7.4881, lr: 0.001
Epoch [20/80], Training Loss: 1.8434, Validation Loss Current: 7.7644, Validation Loss AVG: 7.7644, lr: 0.001
Epoch [21/80], Training Loss: 0.9212, Validation Loss Current: 7.4678, Validation Loss AVG: 7.4678, lr: 0.001
Epoch [22/80], Training Loss: 3.5383, Validation Loss Current: 7.6383, Validation Loss AVG: 7.6383, lr: 0.001
Epoch [23/80], Training Loss: 3.1324, Validation Loss Current: 8.0157, Validation Loss AVG: 8.0157, lr: 0.001
Epoch [24/80], Training Loss: 3.6943, Validation Loss Current: 8.9068, Validation Loss AVG: 8.9068, lr: 0.001
Epoch [25/80], Training Loss: 3.6903, Validation Loss Current: 8.4640, Validation Loss AVG: 8.4640, lr: 0.001
Epoch [26/80], Training Loss: 4.5173, Validation Loss Current: 8.3154, Validation Loss AVG: 8.3154, lr: 0.001
Epoch [27/80], Training Loss: 3.0360, Validation Loss Current: 9.0663, Validation Loss AVG: 9.0663, lr: 0.001
Epoch [28/80], Training Loss: 1.9754, Validation Loss Current: 8.3130, Validation Loss AVG: 8.3130, lr: 0.001
Epoch [29/80], Training Loss: 1.8008, Validation Loss Current: 8.3595, Validation Loss AVG: 8.3595, lr: 0.001
Epoch [30/80], Training Loss: 2.7094, Validation Loss Current: 8.7683, Validation Loss AVG: 8.7683, lr: 0.001
Epoch [31/80], Training Loss: 7.7181, Validation Loss Current: 10.0544, Validation Loss AVG: 10.0544, lr: 0.001
Epoch [32/80], Training Loss: 8.3452, Validation Loss Current: 9.8172, Validation Loss AVG: 9.8172, lr: 0.001
Epoch [33/80], Training Loss: 4.1301, Validation Loss Current: 9.3804, Validation Loss AVG: 9.3804, lr: 0.001
Epoch [34/80], Training Loss: 6.5573, Validation Loss Current: 8.8726, Validation Loss AVG: 8.8726, lr: 0.001
Epoch [35/80], Training Loss: 3.1682, Validation Loss Current: 8.1388, Validation Loss AVG: 8.1388, lr: 0.001
Epoch [36/80], Training Loss: 2.7233, Validation Loss Current: 9.3696, Validation Loss AVG: 9.3696, lr: 0.001
Epoch [37/80], Training Loss: 1.8682, Validation Loss Current: 9.0853, Validation Loss AVG: 9.0853, lr: 0.001
Epoch [38/80], Training Loss: 2.0308, Validation Loss Current: 9.1823, Validation Loss AVG: 9.1823, lr: 0.001
Epoch [39/80], Training Loss: 1.5240, Validation Loss Current: 9.3737, Validation Loss AVG: 9.3737, lr: 0.001
Epoch [40/80], Training Loss: 1.9913, Validation Loss Current: 9.2111, Validation Loss AVG: 9.2111, lr: 0.001
 --- Early Stopped ---
Patch distance: 0.6 finished training. Best epoch: 10 Best val accuracy: [0.6157894736842104, 0.5273026315789474, 0.5529605263157894, 0.5618421052631579, 0.5651315789473684, 0.6019736842105263, 0.5773026315789475, 0.5809210526315789, 0.600328947368421, 0.6226973684210526, 0.6226973684210526, 0.5888157894736843, 0.60625, 0.5796052631578947, 0.5957236842105262, 0.5717105263157894, 0.5953947368421053, 0.5483552631578947, 0.5865131578947369, 0.5861842105263158, 0.5904605263157895, 0.5944078947368421, 0.5750000000000001, 0.55625, 0.5717105263157894, 0.5901315789473685, 0.5641447368421053, 0.5746710526315789, 0.5769736842105263, 0.5684210526315789, 0.5486842105263159, 0.5240131578947368, 0.5322368421052632, 0.5555921052631578, 0.5756578947368421, 0.5460526315789475, 0.5697368421052632, 0.5588815789473685, 0.5618421052631579, 0.5694078947368422] Best val loss: 6.103659892082215


----- Training resnet18 with sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] -----
Current group: llo_1_random0
Epoch [1/80], Training Loss: 41.5531, Validation Loss Current: 10.0366, Validation Loss AVG: 10.0366, lr: 0.001
Epoch [2/80], Training Loss: 40.0233, Validation Loss Current: 9.8309, Validation Loss AVG: 9.8309, lr: 0.001
Epoch [3/80], Training Loss: 39.1430, Validation Loss Current: 9.7315, Validation Loss AVG: 9.7315, lr: 0.001
Epoch [4/80], Training Loss: 38.7656, Validation Loss Current: 9.4274, Validation Loss AVG: 9.4274, lr: 0.001
Epoch [5/80], Training Loss: 39.1096, Validation Loss Current: 9.3440, Validation Loss AVG: 9.3440, lr: 0.001
Epoch [6/80], Training Loss: 37.4900, Validation Loss Current: 9.2983, Validation Loss AVG: 9.2983, lr: 0.001
Epoch [7/80], Training Loss: 37.1679, Validation Loss Current: 9.1683, Validation Loss AVG: 9.1683, lr: 0.001
Epoch [8/80], Training Loss: 35.8313, Validation Loss Current: 8.9060, Validation Loss AVG: 8.9060, lr: 0.001
Epoch [9/80], Training Loss: 35.3199, Validation Loss Current: 8.7904, Validation Loss AVG: 8.7904, lr: 0.001
Epoch [10/80], Training Loss: 34.2951, Validation Loss Current: 8.4912, Validation Loss AVG: 8.4912, lr: 0.001
Epoch [11/80], Training Loss: 34.2686, Validation Loss Current: 8.4838, Validation Loss AVG: 8.4838, lr: 0.001
Epoch [12/80], Training Loss: 33.1296, Validation Loss Current: 8.2889, Validation Loss AVG: 8.2889, lr: 0.001
Epoch [13/80], Training Loss: 32.0049, Validation Loss Current: 8.3303, Validation Loss AVG: 8.3303, lr: 0.001
Epoch [14/80], Training Loss: 30.8750, Validation Loss Current: 8.5884, Validation Loss AVG: 8.5884, lr: 0.001
Epoch [15/80], Training Loss: 30.4606, Validation Loss Current: 8.2334, Validation Loss AVG: 8.2334, lr: 0.001
Epoch [16/80], Training Loss: 28.9925, Validation Loss Current: 7.8028, Validation Loss AVG: 7.8028, lr: 0.001
Epoch [17/80], Training Loss: 29.6423, Validation Loss Current: 8.0413, Validation Loss AVG: 8.0413, lr: 0.001
Epoch [18/80], Training Loss: 28.5071, Validation Loss Current: 7.8548, Validation Loss AVG: 7.8548, lr: 0.001
Epoch [19/80], Training Loss: 28.0989, Validation Loss Current: 7.5723, Validation Loss AVG: 7.5723, lr: 0.001
Epoch [20/80], Training Loss: 26.5988, Validation Loss Current: 7.4878, Validation Loss AVG: 7.4878, lr: 0.001
Epoch [21/80], Training Loss: 25.2760, Validation Loss Current: 7.3143, Validation Loss AVG: 7.3143, lr: 0.001
Epoch [22/80], Training Loss: 25.0176, Validation Loss Current: 10.1783, Validation Loss AVG: 10.1783, lr: 0.001
Epoch [23/80], Training Loss: 25.3828, Validation Loss Current: 7.7610, Validation Loss AVG: 7.7610, lr: 0.001
Epoch [24/80], Training Loss: 25.5005, Validation Loss Current: 7.4714, Validation Loss AVG: 7.4714, lr: 0.001
Epoch [25/80], Training Loss: 23.7785, Validation Loss Current: 7.1044, Validation Loss AVG: 7.1044, lr: 0.001
Epoch [26/80], Training Loss: 21.6552, Validation Loss Current: 7.7945, Validation Loss AVG: 7.7945, lr: 0.001
Epoch [27/80], Training Loss: 21.7568, Validation Loss Current: 7.2097, Validation Loss AVG: 7.2097, lr: 0.001
Epoch [28/80], Training Loss: 21.8829, Validation Loss Current: 7.0563, Validation Loss AVG: 7.0563, lr: 0.001
Epoch [29/80], Training Loss: 20.5632, Validation Loss Current: 6.9044, Validation Loss AVG: 6.9044, lr: 0.001
Epoch [30/80], Training Loss: 20.3360, Validation Loss Current: 6.9687, Validation Loss AVG: 6.9687, lr: 0.001
Epoch [31/80], Training Loss: 18.9873, Validation Loss Current: 6.9173, Validation Loss AVG: 6.9173, lr: 0.001
Epoch [32/80], Training Loss: 19.7202, Validation Loss Current: 9.3823, Validation Loss AVG: 9.3823, lr: 0.001
Epoch [33/80], Training Loss: 24.1925, Validation Loss Current: 9.0425, Validation Loss AVG: 9.0425, lr: 0.001
Epoch [34/80], Training Loss: 21.6531, Validation Loss Current: 9.1888, Validation Loss AVG: 9.1888, lr: 0.001
Epoch [35/80], Training Loss: 19.0559, Validation Loss Current: 7.6718, Validation Loss AVG: 7.6718, lr: 0.001
Epoch [36/80], Training Loss: 19.4064, Validation Loss Current: 9.0293, Validation Loss AVG: 9.0293, lr: 0.001
Epoch [37/80], Training Loss: 18.4545, Validation Loss Current: 7.0828, Validation Loss AVG: 7.0828, lr: 0.001
Epoch [38/80], Training Loss: 16.7107, Validation Loss Current: 7.1202, Validation Loss AVG: 7.1202, lr: 0.001
Epoch [39/80], Training Loss: 15.8148, Validation Loss Current: 8.7482, Validation Loss AVG: 8.7482, lr: 0.001
Epoch [40/80], Training Loss: 14.1284, Validation Loss Current: 6.8784, Validation Loss AVG: 6.8784, lr: 0.001
Epoch [41/80], Training Loss: 13.2348, Validation Loss Current: 7.1202, Validation Loss AVG: 7.1202, lr: 0.001
Epoch [42/80], Training Loss: 11.5021, Validation Loss Current: 7.3170, Validation Loss AVG: 7.3170, lr: 0.001
Epoch [43/80], Training Loss: 10.4619, Validation Loss Current: 7.2185, Validation Loss AVG: 7.2185, lr: 0.001
Epoch [44/80], Training Loss: 11.5401, Validation Loss Current: 10.3920, Validation Loss AVG: 10.3920, lr: 0.001
Epoch [45/80], Training Loss: 12.3787, Validation Loss Current: 8.2882, Validation Loss AVG: 8.2882, lr: 0.001
Epoch [46/80], Training Loss: 11.9898, Validation Loss Current: 7.3344, Validation Loss AVG: 7.3344, lr: 0.001
Epoch [47/80], Training Loss: 12.6071, Validation Loss Current: 12.6384, Validation Loss AVG: 12.6384, lr: 0.001
Epoch [48/80], Training Loss: 14.3928, Validation Loss Current: 12.4796, Validation Loss AVG: 12.4796, lr: 0.001
Epoch [49/80], Training Loss: 15.6454, Validation Loss Current: 8.5336, Validation Loss AVG: 8.5336, lr: 0.001
Epoch [50/80], Training Loss: 12.6838, Validation Loss Current: 9.2342, Validation Loss AVG: 9.2342, lr: 0.001
Epoch [51/80], Training Loss: 13.1979, Validation Loss Current: 8.1233, Validation Loss AVG: 8.1233, lr: 0.001
Epoch [52/80], Training Loss: 13.4125, Validation Loss Current: 9.9355, Validation Loss AVG: 9.9355, lr: 0.001
Epoch [53/80], Training Loss: 11.4779, Validation Loss Current: 7.3226, Validation Loss AVG: 7.3226, lr: 0.001
Epoch [54/80], Training Loss: 8.1129, Validation Loss Current: 7.2322, Validation Loss AVG: 7.2322, lr: 0.001
Epoch [55/80], Training Loss: 6.4500, Validation Loss Current: 6.7116, Validation Loss AVG: 6.7116, lr: 0.001
Epoch [56/80], Training Loss: 6.3368, Validation Loss Current: 8.0136, Validation Loss AVG: 8.0136, lr: 0.001
Epoch [57/80], Training Loss: 9.5404, Validation Loss Current: 9.0111, Validation Loss AVG: 9.0111, lr: 0.001
Epoch [58/80], Training Loss: 11.9263, Validation Loss Current: 7.9502, Validation Loss AVG: 7.9502, lr: 0.001
Epoch [59/80], Training Loss: 9.2916, Validation Loss Current: 8.8720, Validation Loss AVG: 8.8720, lr: 0.001
Epoch [60/80], Training Loss: 8.2495, Validation Loss Current: 11.7191, Validation Loss AVG: 11.7191, lr: 0.001
Epoch [61/80], Training Loss: 13.9602, Validation Loss Current: 9.1595, Validation Loss AVG: 9.1595, lr: 0.001
Epoch [62/80], Training Loss: 9.1882, Validation Loss Current: 8.3036, Validation Loss AVG: 8.3036, lr: 0.001
Epoch [63/80], Training Loss: 6.3034, Validation Loss Current: 7.8055, Validation Loss AVG: 7.8055, lr: 0.001
Epoch [64/80], Training Loss: 6.7578, Validation Loss Current: 7.5558, Validation Loss AVG: 7.5558, lr: 0.001
Epoch [65/80], Training Loss: 7.7961, Validation Loss Current: 8.8198, Validation Loss AVG: 8.8198, lr: 0.001
Epoch [66/80], Training Loss: 6.7507, Validation Loss Current: 7.2156, Validation Loss AVG: 7.2156, lr: 0.001
Epoch [67/80], Training Loss: 6.4776, Validation Loss Current: 7.5813, Validation Loss AVG: 7.5813, lr: 0.001
Epoch [68/80], Training Loss: 7.0959, Validation Loss Current: 9.0696, Validation Loss AVG: 9.0696, lr: 0.001
Epoch [69/80], Training Loss: 4.3061, Validation Loss Current: 7.7374, Validation Loss AVG: 7.7374, lr: 0.001
Epoch [70/80], Training Loss: 3.1109, Validation Loss Current: 7.6123, Validation Loss AVG: 7.6123, lr: 0.001
Epoch [71/80], Training Loss: 2.6064, Validation Loss Current: 7.6436, Validation Loss AVG: 7.6436, lr: 0.001
Epoch [72/80], Training Loss: 4.3577, Validation Loss Current: 9.0312, Validation Loss AVG: 9.0312, lr: 0.001
Epoch [73/80], Training Loss: 7.5301, Validation Loss Current: 11.3310, Validation Loss AVG: 11.3310, lr: 0.001
Epoch [74/80], Training Loss: 6.5941, Validation Loss Current: 10.0370, Validation Loss AVG: 10.0370, lr: 0.001
Epoch [75/80], Training Loss: 6.7911, Validation Loss Current: 9.1729, Validation Loss AVG: 9.1729, lr: 0.001
Epoch [76/80], Training Loss: 5.8078, Validation Loss Current: 9.3712, Validation Loss AVG: 9.3712, lr: 0.001
Epoch [77/80], Training Loss: 6.3050, Validation Loss Current: 8.6242, Validation Loss AVG: 8.6242, lr: 0.001
Epoch [78/80], Training Loss: 5.3872, Validation Loss Current: 9.9897, Validation Loss AVG: 9.9897, lr: 0.001
Epoch [79/80], Training Loss: 4.9673, Validation Loss Current: 10.5515, Validation Loss AVG: 10.5515, lr: 0.001
Epoch [80/80], Training Loss: 7.0440, Validation Loss Current: 9.1892, Validation Loss AVG: 9.1892, lr: 0.001
Patch distance: llo_1_random0 finished training. Best epoch: 55 Best val accuracy: [0.2513157894736842, 0.2746710526315789, 0.2694078947368421, 0.3292763157894737, 0.33026315789473687, 0.29934210526315785, 0.32072368421052627, 0.3391447368421052, 0.37434210526315786, 0.3898026315789474, 0.39375, 0.39868421052631586, 0.38651315789473684, 0.380921052631579, 0.39473684210526316, 0.4358552631578947, 0.4180921052631579, 0.43782894736842104, 0.449342105263158, 0.4615131578947368, 0.4828947368421052, 0.3805921052631579, 0.4532894736842105, 0.4651315789473684, 0.4930921052631579, 0.46644736842105267, 0.49407894736842106, 0.4858552631578947, 0.5210526315789473, 0.5049342105263157, 0.5174342105263159, 0.40032894736842106, 0.4305921052631579, 0.3549342105263158, 0.4733552631578948, 0.4496710526315789, 0.5082236842105263, 0.49769736842105267, 0.4427631578947368, 0.5430921052631579, 0.5302631578947368, 0.5092105263157894, 0.5453947368421053, 0.4526315789473684, 0.5, 0.5401315789473684, 0.3697368421052632, 0.36907894736842106, 0.4641447368421052, 0.47368421052631576, 0.4759868421052632, 0.47006578947368427, 0.5371710526315789, 0.5398026315789474, 0.5611842105263157, 0.5430921052631579, 0.500328947368421, 0.5134868421052632, 0.49506578947368424, 0.3983552631578947, 0.4759868421052631, 0.5052631578947369, 0.5296052631578948, 0.5552631578947368, 0.5453947368421053, 0.5634868421052631, 0.5575657894736842, 0.5358552631578947, 0.5575657894736842, 0.5680921052631579, 0.5717105263157894, 0.5154605263157894, 0.5226973684210527, 0.46940789473684214, 0.5105263157894737, 0.5167763157894737, 0.5457236842105264, 0.4875, 0.47664473684210523, 0.562171052631579] Best val loss: 6.711619663238525


Current group: llo_1_random1
Epoch [1/80], Training Loss: 38.7993, Validation Loss Current: 8.7144, Validation Loss AVG: 8.7144, lr: 0.001
Epoch [2/80], Training Loss: 30.2165, Validation Loss Current: 11.1928, Validation Loss AVG: 11.1928, lr: 0.001
Epoch [3/80], Training Loss: 22.0126, Validation Loss Current: 7.2349, Validation Loss AVG: 7.2349, lr: 0.001
Epoch [4/80], Training Loss: 16.8518, Validation Loss Current: 6.6059, Validation Loss AVG: 6.6059, lr: 0.001
Epoch [5/80], Training Loss: 14.2728, Validation Loss Current: 6.4586, Validation Loss AVG: 6.4586, lr: 0.001
Epoch [6/80], Training Loss: 9.6047, Validation Loss Current: 6.1874, Validation Loss AVG: 6.1874, lr: 0.001
Epoch [7/80], Training Loss: 7.8939, Validation Loss Current: 6.0537, Validation Loss AVG: 6.0537, lr: 0.001
Epoch [8/80], Training Loss: 9.3898, Validation Loss Current: 6.3612, Validation Loss AVG: 6.3612, lr: 0.001
Epoch [9/80], Training Loss: 9.0611, Validation Loss Current: 7.1086, Validation Loss AVG: 7.1086, lr: 0.001
Epoch [10/80], Training Loss: 6.3755, Validation Loss Current: 6.2722, Validation Loss AVG: 6.2722, lr: 0.001
Epoch [11/80], Training Loss: 9.5399, Validation Loss Current: 8.3532, Validation Loss AVG: 8.3532, lr: 0.001
Epoch [12/80], Training Loss: 6.9788, Validation Loss Current: 6.6940, Validation Loss AVG: 6.6940, lr: 0.001
Epoch [13/80], Training Loss: 4.4082, Validation Loss Current: 6.6615, Validation Loss AVG: 6.6615, lr: 0.001
Epoch [14/80], Training Loss: 5.7057, Validation Loss Current: 7.0527, Validation Loss AVG: 7.0527, lr: 0.001
Epoch [15/80], Training Loss: 5.5181, Validation Loss Current: 6.9846, Validation Loss AVG: 6.9846, lr: 0.001
Epoch [16/80], Training Loss: 3.6032, Validation Loss Current: 7.0014, Validation Loss AVG: 7.0014, lr: 0.001
Epoch [17/80], Training Loss: 4.0024, Validation Loss Current: 7.6150, Validation Loss AVG: 7.6150, lr: 0.001
Epoch [18/80], Training Loss: 4.2961, Validation Loss Current: 7.3397, Validation Loss AVG: 7.3397, lr: 0.001
Epoch [19/80], Training Loss: 6.8809, Validation Loss Current: 9.0080, Validation Loss AVG: 9.0080, lr: 0.001
Epoch [20/80], Training Loss: 9.6097, Validation Loss Current: 9.1187, Validation Loss AVG: 9.1187, lr: 0.001
Epoch [21/80], Training Loss: 8.4743, Validation Loss Current: 7.6100, Validation Loss AVG: 7.6100, lr: 0.001
Epoch [22/80], Training Loss: 5.8002, Validation Loss Current: 7.6235, Validation Loss AVG: 7.6235, lr: 0.001
Epoch [23/80], Training Loss: 5.6677, Validation Loss Current: 7.7017, Validation Loss AVG: 7.7017, lr: 0.001
Epoch [24/80], Training Loss: 5.0999, Validation Loss Current: 9.8484, Validation Loss AVG: 9.8484, lr: 0.001
Epoch [25/80], Training Loss: 5.9103, Validation Loss Current: 7.9331, Validation Loss AVG: 7.9331, lr: 0.001
Epoch [26/80], Training Loss: 6.1947, Validation Loss Current: 8.5440, Validation Loss AVG: 8.5440, lr: 0.001
Epoch [27/80], Training Loss: 5.2342, Validation Loss Current: 11.2747, Validation Loss AVG: 11.2747, lr: 0.001
Epoch [28/80], Training Loss: 7.7820, Validation Loss Current: 9.7932, Validation Loss AVG: 9.7932, lr: 0.001
Epoch [29/80], Training Loss: 10.7420, Validation Loss Current: 12.7595, Validation Loss AVG: 12.7595, lr: 0.001
Epoch [30/80], Training Loss: 5.6076, Validation Loss Current: 9.3586, Validation Loss AVG: 9.3586, lr: 0.001
Epoch [31/80], Training Loss: 9.3875, Validation Loss Current: 8.7038, Validation Loss AVG: 8.7038, lr: 0.001
Epoch [32/80], Training Loss: 4.7658, Validation Loss Current: 7.6983, Validation Loss AVG: 7.6983, lr: 0.001
Epoch [33/80], Training Loss: 4.3247, Validation Loss Current: 7.8029, Validation Loss AVG: 7.8029, lr: 0.001
Epoch [34/80], Training Loss: 5.4158, Validation Loss Current: 11.3556, Validation Loss AVG: 11.3556, lr: 0.001
Epoch [35/80], Training Loss: 9.8071, Validation Loss Current: 10.6779, Validation Loss AVG: 10.6779, lr: 0.001
Epoch [36/80], Training Loss: 12.4048, Validation Loss Current: 8.3029, Validation Loss AVG: 8.3029, lr: 0.001
Epoch [37/80], Training Loss: 7.4844, Validation Loss Current: 9.2965, Validation Loss AVG: 9.2965, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random1 finished training. Best epoch: 7 Best val accuracy: [0.5259868421052631, 0.39111842105263156, 0.5493421052631579, 0.5631578947368421, 0.5700657894736842, 0.6026315789473684, 0.6338815789473685, 0.6098684210526317, 0.5927631578947368, 0.625, 0.5851973684210525, 0.6098684210526316, 0.6138157894736842, 0.5865131578947368, 0.6029605263157894, 0.6059210526315788, 0.6085526315789475, 0.5884868421052631, 0.5319078947368421, 0.5421052631578946, 0.5861842105263158, 0.5973684210526315, 0.5848684210526316, 0.5138157894736842, 0.5713815789473684, 0.5743421052631579, 0.5151315789473684, 0.5289473684210526, 0.506578947368421, 0.5526315789473685, 0.5572368421052631, 0.5891447368421053, 0.6042763157894737, 0.5078947368421053, 0.5121710526315789, 0.5585526315789474, 0.5121710526315789] Best val loss: 6.053650772571563


Current group: llo_1_random2
Epoch [1/80], Training Loss: 37.4273, Validation Loss Current: 7.6842, Validation Loss AVG: 7.6842, lr: 0.001
Epoch [2/80], Training Loss: 22.6291, Validation Loss Current: 6.1056, Validation Loss AVG: 6.1056, lr: 0.001
Epoch [3/80], Training Loss: 17.3721, Validation Loss Current: 6.1862, Validation Loss AVG: 6.1862, lr: 0.001
Epoch [4/80], Training Loss: 13.5641, Validation Loss Current: 5.4914, Validation Loss AVG: 5.4914, lr: 0.001
Epoch [5/80], Training Loss: 11.7629, Validation Loss Current: 5.5711, Validation Loss AVG: 5.5711, lr: 0.001
Epoch [6/80], Training Loss: 9.3761, Validation Loss Current: 5.6332, Validation Loss AVG: 5.6332, lr: 0.001
Epoch [7/80], Training Loss: 7.9013, Validation Loss Current: 6.1766, Validation Loss AVG: 6.1766, lr: 0.001
Epoch [8/80], Training Loss: 6.7616, Validation Loss Current: 5.5456, Validation Loss AVG: 5.5456, lr: 0.001
Epoch [9/80], Training Loss: 4.8621, Validation Loss Current: 5.0923, Validation Loss AVG: 5.0923, lr: 0.001
Epoch [10/80], Training Loss: 7.9650, Validation Loss Current: 5.6398, Validation Loss AVG: 5.6398, lr: 0.001
Epoch [11/80], Training Loss: 12.6220, Validation Loss Current: 9.5153, Validation Loss AVG: 9.5153, lr: 0.001
Epoch [12/80], Training Loss: 9.8176, Validation Loss Current: 6.4888, Validation Loss AVG: 6.4888, lr: 0.001
Epoch [13/80], Training Loss: 9.8050, Validation Loss Current: 6.6121, Validation Loss AVG: 6.6121, lr: 0.001
Epoch [14/80], Training Loss: 11.6417, Validation Loss Current: 14.8105, Validation Loss AVG: 14.8105, lr: 0.001
Epoch [15/80], Training Loss: 9.9878, Validation Loss Current: 8.4772, Validation Loss AVG: 8.4772, lr: 0.001
Epoch [16/80], Training Loss: 5.0580, Validation Loss Current: 7.0296, Validation Loss AVG: 7.0296, lr: 0.001
Epoch [17/80], Training Loss: 4.9799, Validation Loss Current: 6.0795, Validation Loss AVG: 6.0795, lr: 0.001
Epoch [18/80], Training Loss: 7.6471, Validation Loss Current: 8.2313, Validation Loss AVG: 8.2313, lr: 0.001
Epoch [19/80], Training Loss: 6.1986, Validation Loss Current: 6.2839, Validation Loss AVG: 6.2839, lr: 0.001
Epoch [20/80], Training Loss: 5.3809, Validation Loss Current: 6.7219, Validation Loss AVG: 6.7219, lr: 0.001
Epoch [21/80], Training Loss: 7.9974, Validation Loss Current: 7.0133, Validation Loss AVG: 7.0133, lr: 0.001
Epoch [22/80], Training Loss: 4.5961, Validation Loss Current: 6.4739, Validation Loss AVG: 6.4739, lr: 0.001
Epoch [23/80], Training Loss: 5.8816, Validation Loss Current: 6.8474, Validation Loss AVG: 6.8474, lr: 0.001
Epoch [24/80], Training Loss: 6.7983, Validation Loss Current: 8.0660, Validation Loss AVG: 8.0660, lr: 0.001
Epoch [25/80], Training Loss: 7.2669, Validation Loss Current: 8.8068, Validation Loss AVG: 8.8068, lr: 0.001
Epoch [26/80], Training Loss: 7.1481, Validation Loss Current: 8.3419, Validation Loss AVG: 8.3419, lr: 0.001
Epoch [27/80], Training Loss: 8.4020, Validation Loss Current: 8.8130, Validation Loss AVG: 8.8130, lr: 0.001
Epoch [28/80], Training Loss: 10.1667, Validation Loss Current: 9.5459, Validation Loss AVG: 9.5459, lr: 0.001
Epoch [29/80], Training Loss: 8.4739, Validation Loss Current: 6.7299, Validation Loss AVG: 6.7299, lr: 0.001
Epoch [30/80], Training Loss: 4.4093, Validation Loss Current: 7.1720, Validation Loss AVG: 7.1720, lr: 0.001
Epoch [31/80], Training Loss: 5.0676, Validation Loss Current: 6.7579, Validation Loss AVG: 6.7579, lr: 0.001
Epoch [32/80], Training Loss: 2.9067, Validation Loss Current: 6.6277, Validation Loss AVG: 6.6277, lr: 0.001
Epoch [33/80], Training Loss: 3.4405, Validation Loss Current: 6.2829, Validation Loss AVG: 6.2829, lr: 0.001
Epoch [34/80], Training Loss: 7.7144, Validation Loss Current: 7.4308, Validation Loss AVG: 7.4308, lr: 0.001
Epoch [35/80], Training Loss: 5.4490, Validation Loss Current: 6.6539, Validation Loss AVG: 6.6539, lr: 0.001
Epoch [36/80], Training Loss: 3.8060, Validation Loss Current: 7.4896, Validation Loss AVG: 7.4896, lr: 0.001
Epoch [37/80], Training Loss: 3.4674, Validation Loss Current: 7.8080, Validation Loss AVG: 7.8080, lr: 0.001
Epoch [38/80], Training Loss: 4.8764, Validation Loss Current: 8.5633, Validation Loss AVG: 8.5633, lr: 0.001
Epoch [39/80], Training Loss: 2.4891, Validation Loss Current: 7.0903, Validation Loss AVG: 7.0903, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random2 finished training. Best epoch: 9 Best val accuracy: [0.5401315789473683, 0.6289473684210527, 0.6009868421052632, 0.6398026315789473, 0.6542763157894738, 0.644407894736842, 0.6398026315789473, 0.6585526315789474, 0.6805921052631578, 0.6572368421052631, 0.5351973684210526, 0.6190789473684211, 0.5838815789473684, 0.4733552631578948, 0.5457236842105263, 0.6164473684210525, 0.6411184210526316, 0.562828947368421, 0.6351973684210526, 0.6138157894736842, 0.5999999999999999, 0.6407894736842105, 0.625328947368421, 0.6013157894736841, 0.550986842105263, 0.5608552631578947, 0.5694078947368422, 0.5506578947368421, 0.6368421052631579, 0.6177631578947369, 0.6430921052631579, 0.63125, 0.6381578947368421, 0.6108552631578947, 0.6286184210526317, 0.5868421052631579, 0.6105263157894736, 0.6138157894736842, 0.6365131578947368] Best val loss: 5.092333340644837


Current group: llo_1_random3
Epoch [1/80], Training Loss: 39.8249, Validation Loss Current: 6.5914, Validation Loss AVG: 6.5914, lr: 0.001
Epoch [2/80], Training Loss: 23.8414, Validation Loss Current: 5.2802, Validation Loss AVG: 5.2802, lr: 0.001
Epoch [3/80], Training Loss: 18.3037, Validation Loss Current: 5.0496, Validation Loss AVG: 5.0496, lr: 0.001
Epoch [4/80], Training Loss: 13.0422, Validation Loss Current: 4.9463, Validation Loss AVG: 4.9463, lr: 0.001
Epoch [5/80], Training Loss: 11.3809, Validation Loss Current: 5.2273, Validation Loss AVG: 5.2273, lr: 0.001
Epoch [6/80], Training Loss: 8.8846, Validation Loss Current: 4.6206, Validation Loss AVG: 4.6206, lr: 0.001
Epoch [7/80], Training Loss: 9.6008, Validation Loss Current: 6.1564, Validation Loss AVG: 6.1564, lr: 0.001
Epoch [8/80], Training Loss: 7.7912, Validation Loss Current: 6.9205, Validation Loss AVG: 6.9205, lr: 0.001
Epoch [9/80], Training Loss: 4.9248, Validation Loss Current: 4.8168, Validation Loss AVG: 4.8168, lr: 0.001
Epoch [10/80], Training Loss: 7.3587, Validation Loss Current: 5.7040, Validation Loss AVG: 5.7040, lr: 0.001
Epoch [11/80], Training Loss: 3.7608, Validation Loss Current: 4.9315, Validation Loss AVG: 4.9315, lr: 0.001
Epoch [12/80], Training Loss: 3.6971, Validation Loss Current: 5.2659, Validation Loss AVG: 5.2659, lr: 0.001
Epoch [13/80], Training Loss: 7.9917, Validation Loss Current: 7.7743, Validation Loss AVG: 7.7743, lr: 0.001
Epoch [14/80], Training Loss: 12.7706, Validation Loss Current: 7.8795, Validation Loss AVG: 7.8795, lr: 0.001
Epoch [15/80], Training Loss: 6.4622, Validation Loss Current: 7.1372, Validation Loss AVG: 7.1372, lr: 0.001
Epoch [16/80], Training Loss: 4.1478, Validation Loss Current: 5.5245, Validation Loss AVG: 5.5245, lr: 0.001
Epoch [17/80], Training Loss: 3.7509, Validation Loss Current: 6.8134, Validation Loss AVG: 6.8134, lr: 0.001
Epoch [18/80], Training Loss: 8.7410, Validation Loss Current: 6.4182, Validation Loss AVG: 6.4182, lr: 0.001
Epoch [19/80], Training Loss: 3.5832, Validation Loss Current: 5.5995, Validation Loss AVG: 5.5995, lr: 0.001
Epoch [20/80], Training Loss: 4.1302, Validation Loss Current: 6.7089, Validation Loss AVG: 6.7089, lr: 0.001
Epoch [21/80], Training Loss: 5.0348, Validation Loss Current: 6.5527, Validation Loss AVG: 6.5527, lr: 0.001
Epoch [22/80], Training Loss: 3.1795, Validation Loss Current: 5.9240, Validation Loss AVG: 5.9240, lr: 0.001
Epoch [23/80], Training Loss: 4.3300, Validation Loss Current: 6.7280, Validation Loss AVG: 6.7280, lr: 0.001
Epoch [24/80], Training Loss: 6.5367, Validation Loss Current: 6.9559, Validation Loss AVG: 6.9559, lr: 0.001
Epoch [25/80], Training Loss: 5.5098, Validation Loss Current: 5.7280, Validation Loss AVG: 5.7280, lr: 0.001
Epoch [26/80], Training Loss: 3.7331, Validation Loss Current: 6.4625, Validation Loss AVG: 6.4625, lr: 0.001
Epoch [27/80], Training Loss: 3.3251, Validation Loss Current: 6.6728, Validation Loss AVG: 6.6728, lr: 0.001
Epoch [28/80], Training Loss: 5.5560, Validation Loss Current: 7.0180, Validation Loss AVG: 7.0180, lr: 0.001
Epoch [29/80], Training Loss: 5.0321, Validation Loss Current: 7.5877, Validation Loss AVG: 7.5877, lr: 0.001
Epoch [30/80], Training Loss: 3.8046, Validation Loss Current: 6.5631, Validation Loss AVG: 6.5631, lr: 0.001
Epoch [31/80], Training Loss: 5.9127, Validation Loss Current: 7.5139, Validation Loss AVG: 7.5139, lr: 0.001
Epoch [32/80], Training Loss: 5.9415, Validation Loss Current: 8.1391, Validation Loss AVG: 8.1391, lr: 0.001
Epoch [33/80], Training Loss: 4.7154, Validation Loss Current: 6.6268, Validation Loss AVG: 6.6268, lr: 0.001
Epoch [34/80], Training Loss: 4.2744, Validation Loss Current: 6.8759, Validation Loss AVG: 6.8759, lr: 0.001
Epoch [35/80], Training Loss: 4.5758, Validation Loss Current: 6.9657, Validation Loss AVG: 6.9657, lr: 0.001
Epoch [36/80], Training Loss: 4.2615, Validation Loss Current: 6.2685, Validation Loss AVG: 6.2685, lr: 0.001
 --- Early Stopped ---
Patch distance: llo_1_random3 finished training. Best epoch: 6 Best val accuracy: [0.6095394736842105, 0.6546052631578947, 0.6851973684210526, 0.6914473684210526, 0.6914473684210527, 0.7069078947368421, 0.6569078947368421, 0.6009868421052631, 0.7088815789473684, 0.6894736842105262, 0.7177631578947369, 0.6980263157894736, 0.6292763157894736, 0.5799342105263158, 0.6240131578947369, 0.6845394736842106, 0.6532894736842105, 0.6575657894736843, 0.6927631578947367, 0.6631578947368422, 0.6707236842105264, 0.6858552631578948, 0.6700657894736842, 0.6266447368421052, 0.6907894736842105, 0.66875, 0.6523026315789473, 0.6407894736842106, 0.6256578947368421, 0.6384868421052632, 0.6460526315789473, 0.6049342105263158, 0.6615131578947369, 0.6601973684210527, 0.630592105263158, 0.6664473684210527] Best val loss: 4.620629501342774


Current group: 1
Epoch [1/80], Training Loss: 38.4005, Validation Loss Current: 9.6574, Validation Loss AVG: 8.6607, lr: 0.001
Epoch [2/80], Training Loss: 17.1452, Validation Loss Current: 7.8546, Validation Loss AVG: 8.0467, lr: 0.001
Epoch [3/80], Training Loss: 10.2634, Validation Loss Current: 7.5584, Validation Loss AVG: 8.3173, lr: 0.001
Epoch [4/80], Training Loss: 12.5275, Validation Loss Current: 10.2312, Validation Loss AVG: 10.9470, lr: 0.001
Epoch [5/80], Training Loss: 12.0894, Validation Loss Current: 8.4782, Validation Loss AVG: 11.5905, lr: 0.001
Epoch [6/80], Training Loss: 6.9924, Validation Loss Current: 8.1368, Validation Loss AVG: 10.4888, lr: 0.001
Epoch [7/80], Training Loss: 6.8322, Validation Loss Current: 7.4503, Validation Loss AVG: 11.0444, lr: 0.001
Epoch [8/80], Training Loss: 6.6359, Validation Loss Current: 7.3324, Validation Loss AVG: 8.9842, lr: 0.001
Epoch [9/80], Training Loss: 3.6605, Validation Loss Current: 6.8959, Validation Loss AVG: 9.8249, lr: 0.001
Epoch [10/80], Training Loss: 5.0162, Validation Loss Current: 7.4290, Validation Loss AVG: 9.5133, lr: 0.001
Epoch [11/80], Training Loss: 7.5024, Validation Loss Current: 10.0274, Validation Loss AVG: 13.5780, lr: 0.001
Epoch [12/80], Training Loss: 8.7246, Validation Loss Current: 8.7078, Validation Loss AVG: 12.0319, lr: 0.001
Epoch [13/80], Training Loss: 4.6458, Validation Loss Current: 7.9597, Validation Loss AVG: 10.7300, lr: 0.001
Epoch [14/80], Training Loss: 9.5635, Validation Loss Current: 8.3611, Validation Loss AVG: 11.1937, lr: 0.001
Epoch [15/80], Training Loss: 4.1642, Validation Loss Current: 8.8152, Validation Loss AVG: 11.4748, lr: 0.001
Epoch [16/80], Training Loss: 4.3581, Validation Loss Current: 7.5789, Validation Loss AVG: 9.8243, lr: 0.001
Epoch [17/80], Training Loss: 3.0863, Validation Loss Current: 7.9364, Validation Loss AVG: 10.3566, lr: 0.001
Epoch [18/80], Training Loss: 1.1651, Validation Loss Current: 7.4328, Validation Loss AVG: 9.5168, lr: 0.001
Epoch [19/80], Training Loss: 0.7640, Validation Loss Current: 7.5104, Validation Loss AVG: 11.0524, lr: 0.001
Epoch [20/80], Training Loss: 2.4504, Validation Loss Current: 7.6911, Validation Loss AVG: 10.4594, lr: 0.001
Epoch [21/80], Training Loss: 1.9154, Validation Loss Current: 7.7359, Validation Loss AVG: 10.8203, lr: 0.001
Epoch [22/80], Training Loss: 1.8455, Validation Loss Current: 7.8601, Validation Loss AVG: 11.6882, lr: 0.001
Epoch [23/80], Training Loss: 2.1316, Validation Loss Current: 9.6818, Validation Loss AVG: 11.3399, lr: 0.001
Epoch [24/80], Training Loss: 2.0686, Validation Loss Current: 8.5835, Validation Loss AVG: 11.3155, lr: 0.001
Epoch [25/80], Training Loss: 2.5009, Validation Loss Current: 8.2027, Validation Loss AVG: 12.1054, lr: 0.001
Epoch [26/80], Training Loss: 5.7540, Validation Loss Current: 9.0051, Validation Loss AVG: 12.2887, lr: 0.001
Epoch [27/80], Training Loss: 2.8454, Validation Loss Current: 8.7790, Validation Loss AVG: 14.0489, lr: 0.001
Epoch [28/80], Training Loss: 4.6790, Validation Loss Current: 9.1429, Validation Loss AVG: 13.7201, lr: 0.001
Epoch [29/80], Training Loss: 3.4514, Validation Loss Current: 8.9089, Validation Loss AVG: 12.4515, lr: 0.001
Epoch [30/80], Training Loss: 2.0807, Validation Loss Current: 7.9140, Validation Loss AVG: 11.0883, lr: 0.001
Epoch [31/80], Training Loss: 2.6566, Validation Loss Current: 8.2934, Validation Loss AVG: 12.6170, lr: 0.001
Epoch [32/80], Training Loss: 2.6172, Validation Loss Current: 9.4560, Validation Loss AVG: 14.0205, lr: 0.001
Epoch [33/80], Training Loss: 4.8573, Validation Loss Current: 9.2823, Validation Loss AVG: 14.8677, lr: 0.001
Epoch [34/80], Training Loss: 3.3710, Validation Loss Current: 9.0998, Validation Loss AVG: 12.3763, lr: 0.001
Epoch [35/80], Training Loss: 2.5057, Validation Loss Current: 8.9162, Validation Loss AVG: 11.9436, lr: 0.001
Epoch [36/80], Training Loss: 3.1879, Validation Loss Current: 9.4047, Validation Loss AVG: 12.7677, lr: 0.001
Epoch [37/80], Training Loss: 3.1903, Validation Loss Current: 8.3785, Validation Loss AVG: 11.6316, lr: 0.001
Epoch [38/80], Training Loss: 2.2031, Validation Loss Current: 10.1684, Validation Loss AVG: 15.1162, lr: 0.001
Epoch [39/80], Training Loss: 1.5829, Validation Loss Current: 8.4112, Validation Loss AVG: 11.6874, lr: 0.001
 --- Early Stopped ---
Patch distance: 1 finished training. Best epoch: 9 Best val accuracy: [0.5131578947368421, 0.5625, 0.555921052631579, 0.5707236842105263, 0.5493421052631579, 0.5526315789473685, 0.5888157894736842, 0.618421052631579, 0.6266447368421053, 0.6052631578947368, 0.5394736842105263, 0.5904605263157895, 0.6101973684210527, 0.5740131578947368, 0.5509868421052632, 0.5970394736842105, 0.5805921052631579, 0.6101973684210527, 0.6134868421052632, 0.6118421052631579, 0.600328947368421, 0.6217105263157895, 0.5641447368421053, 0.6019736842105263, 0.600328947368421, 0.5855263157894737, 0.5773026315789473, 0.5805921052631579, 0.6101973684210527, 0.5986842105263158, 0.6069078947368421, 0.5986842105263158, 0.6036184210526315, 0.5805921052631579, 0.5822368421052632, 0.5756578947368421, 0.6101973684210527, 0.555921052631579, 0.6167763157894737] Best val loss: 6.895949721336365


-------------------- All training done --------------------


 --- Evaluating ---
Fold: 0
---- Testing model trained on sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.41940412528647825
Test set distance: 0.8 Top 1 Accuracy: 0.3315508021390374
Test set distance: 0.4 Top 1 Accuracy: 0.3155080213903743
Test set distance: 0.6 Top 1 Accuracy: 0.3269671504965623
Test set distance: 1 Top 1 Accuracy: 0.3254392666157372
---- Testing model trained on sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.34988540870893814
Test set distance: 0.8 Top 1 Accuracy: 0.5721925133689839
Test set distance: 0.4 Top 1 Accuracy: 0.4423223834988541
Test set distance: 0.6 Top 1 Accuracy: 0.5355233002291826
Test set distance: 1 Top 1 Accuracy: 0.5813598166539343
---- Testing model trained on sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3941940412528648
Test set distance: 0.8 Top 1 Accuracy: 0.5347593582887701
Test set distance: 0.4 Top 1 Accuracy: 0.5821237585943468
Test set distance: 0.6 Top 1 Accuracy: 0.5225362872421696
Test set distance: 1 Top 1 Accuracy: 0.5126050420168067
---- Testing model trained on sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3919022154316272
Test set distance: 0.8 Top 1 Accuracy: 0.5362872421695951
Test set distance: 0.4 Top 1 Accuracy: 0.48739495798319327
Test set distance: 0.6 Top 1 Accuracy: 0.5553857906799083
Test set distance: 1 Top 1 Accuracy: 0.5126050420168067
---- Testing model trained on sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.25668449197860965
Test set distance: 0.8 Top 1 Accuracy: 0.5317035905271199
Test set distance: 0.4 Top 1 Accuracy: 0.3147440794499618
Test set distance: 0.6 Top 1 Accuracy: 0.43391902215431627
Test set distance: 1 Top 1 Accuracy: 0.5951107715813598
Fold: 1
---- Testing model trained on sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4025974025974026
Test set distance: 0.8 Top 1 Accuracy: 0.36287242169595113
Test set distance: 0.4 Top 1 Accuracy: 0.35294117647058826
Test set distance: 0.6 Top 1 Accuracy: 0.37433155080213903
Test set distance: 1 Top 1 Accuracy: 0.3559969442322384
---- Testing model trained on sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3177998472116119
Test set distance: 0.8 Top 1 Accuracy: 0.6004583651642476
Test set distance: 0.4 Top 1 Accuracy: 0.4820473644003056
Test set distance: 0.6 Top 1 Accuracy: 0.5767761650114591
Test set distance: 1 Top 1 Accuracy: 0.5851795263559969
---- Testing model trained on sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3460656990068755
Test set distance: 0.8 Top 1 Accuracy: 0.4614209320091673
Test set distance: 0.4 Top 1 Accuracy: 0.5019098548510313
Test set distance: 0.6 Top 1 Accuracy: 0.4637127578304049
Test set distance: 1 Top 1 Accuracy: 0.43086325439266615
---- Testing model trained on sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.28647822765469827
Test set distance: 0.8 Top 1 Accuracy: 0.5721925133689839
Test set distance: 0.4 Top 1 Accuracy: 0.49961802902979374
Test set distance: 0.6 Top 1 Accuracy: 0.5974025974025974
Test set distance: 1 Top 1 Accuracy: 0.5492742551566081
---- Testing model trained on sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.24064171122994651
Test set distance: 0.8 Top 1 Accuracy: 0.5126050420168067
Test set distance: 0.4 Top 1 Accuracy: 0.29564553093964857
Test set distance: 0.6 Top 1 Accuracy: 0.4400305576776165
Test set distance: 1 Top 1 Accuracy: 0.5538579067990833
Fold: 2
---- Testing model trained on sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.49961802902979374
Test set distance: 0.8 Top 1 Accuracy: 0.32620320855614976
Test set distance: 0.4 Top 1 Accuracy: 0.34988540870893814
Test set distance: 0.6 Top 1 Accuracy: 0.3552330022918258
Test set distance: 1 Top 1 Accuracy: 0.34912146676852557
---- Testing model trained on sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.33537051184110006
Test set distance: 0.8 Top 1 Accuracy: 0.6073338426279603
Test set distance: 0.4 Top 1 Accuracy: 0.439266615737204
Test set distance: 0.6 Top 1 Accuracy: 0.5324675324675324
Test set distance: 1 Top 1 Accuracy: 0.5790679908326967
---- Testing model trained on sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3804430863254393
Test set distance: 0.8 Top 1 Accuracy: 0.5133689839572193
Test set distance: 0.4 Top 1 Accuracy: 0.5775401069518716
Test set distance: 0.6 Top 1 Accuracy: 0.5286478227654698
Test set distance: 1 Top 1 Accuracy: 0.45454545454545453
---- Testing model trained on sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.28953399541634833
Test set distance: 0.8 Top 1 Accuracy: 0.5294117647058824
Test set distance: 0.4 Top 1 Accuracy: 0.48586707410236823
Test set distance: 0.6 Top 1 Accuracy: 0.5844155844155844
Test set distance: 1 Top 1 Accuracy: 0.4965622612681436
---- Testing model trained on sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.19098548510313215
Test set distance: 0.8 Top 1 Accuracy: 0.5324675324675324
Test set distance: 0.4 Top 1 Accuracy: 0.35064935064935066
Test set distance: 0.6 Top 1 Accuracy: 0.44385026737967914
Test set distance: 1 Top 1 Accuracy: 0.5637891520244461
Fold: 3
---- Testing model trained on sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.49809014514896865
Test set distance: 0.8 Top 1 Accuracy: 0.32314744079449964
Test set distance: 0.4 Top 1 Accuracy: 0.3422459893048128
Test set distance: 0.6 Top 1 Accuracy: 0.33766233766233766
Test set distance: 1 Top 1 Accuracy: 0.34835752482811305
---- Testing model trained on sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.28647822765469827
Test set distance: 0.8 Top 1 Accuracy: 0.6073338426279603
Test set distance: 0.4 Top 1 Accuracy: 0.42780748663101603
Test set distance: 0.6 Top 1 Accuracy: 0.5187165775401069
Test set distance: 1 Top 1 Accuracy: 0.5721925133689839
---- Testing model trained on sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.40336134453781514
Test set distance: 0.8 Top 1 Accuracy: 0.5423987776928954
Test set distance: 0.4 Top 1 Accuracy: 0.5660809778456837
Test set distance: 0.6 Top 1 Accuracy: 0.5141329258976318
Test set distance: 1 Top 1 Accuracy: 0.5034377387318564
---- Testing model trained on sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3116883116883117
Test set distance: 0.8 Top 1 Accuracy: 0.5798319327731093
Test set distance: 0.4 Top 1 Accuracy: 0.4820473644003056
Test set distance: 0.6 Top 1 Accuracy: 0.5912910618792971
Test set distance: 1 Top 1 Accuracy: 0.5614973262032086
---- Testing model trained on sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.2475171886936593
Test set distance: 0.8 Top 1 Accuracy: 0.5515660809778457
Test set distance: 0.4 Top 1 Accuracy: 0.36210847975553856
Test set distance: 0.6 Top 1 Accuracy: 0.44385026737967914
Test set distance: 1 Top 1 Accuracy: 0.6019862490450726
Fold: 4
---- Testing model trained on sequence: ['llo_0.2_random0', 'llo_0.2_random1', 'llo_0.2_random2', 'llo_0.2_random3', '0.2'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.4935064935064935
Test set distance: 0.8 Top 1 Accuracy: 0.35064935064935066
Test set distance: 0.4 Top 1 Accuracy: 0.3177998472116119
Test set distance: 0.6 Top 1 Accuracy: 0.33613445378151263
Test set distance: 1 Top 1 Accuracy: 0.3307868601986249
---- Testing model trained on sequence: ['llo_0.8_random0', 'llo_0.8_random1', 'llo_0.8_random2', 'llo_0.8_random3', '0.8'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.29411764705882354
Test set distance: 0.8 Top 1 Accuracy: 0.6241405653170359
Test set distance: 0.4 Top 1 Accuracy: 0.43086325439266615
Test set distance: 0.6 Top 1 Accuracy: 0.5592055003819709
Test set distance: 1 Top 1 Accuracy: 0.6027501909854851
---- Testing model trained on sequence: ['llo_0.4_random0', 'llo_0.4_random1', 'llo_0.4_random2', 'llo_0.4_random3', '0.4'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.3544690603514133
Test set distance: 0.8 Top 1 Accuracy: 0.5057295645530939
Test set distance: 0.4 Top 1 Accuracy: 0.5347593582887701
Test set distance: 0.6 Top 1 Accuracy: 0.5248281130634072
Test set distance: 1 Top 1 Accuracy: 0.4766997708174179
---- Testing model trained on sequence: ['llo_0.6_random0', 'llo_0.6_random1', 'llo_0.6_random2', 'llo_0.6_random3', '0.6'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.29640947288006114
Test set distance: 0.8 Top 1 Accuracy: 0.5538579067990833
Test set distance: 0.4 Top 1 Accuracy: 0.4957983193277311
Test set distance: 0.6 Top 1 Accuracy: 0.6088617265087853
Test set distance: 1 Top 1 Accuracy: 0.5248281130634072
---- Testing model trained on sequence: ['llo_1_random0', 'llo_1_random1', 'llo_1_random2', 'llo_1_random3', '1'] ----
Test set distance: 0.2 Top 1 Accuracy: 0.28647822765469827
Test set distance: 0.8 Top 1 Accuracy: 0.5485103132161956
Test set distance: 0.4 Top 1 Accuracy: 0.3949579831932773
Test set distance: 0.6 Top 1 Accuracy: 0.48128342245989303
Test set distance: 1 Top 1 Accuracy: 0.5844155844155844
------------------------------ End ------------------------------








